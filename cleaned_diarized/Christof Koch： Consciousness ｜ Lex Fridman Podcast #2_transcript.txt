Speaker A: As part of MIT course six s zero nine nine on artificial general intelligence, I got a chance to sit down with Christoph Koch, who is one of the seminal figures in neurobiology, neuroscience, and generally in the study of consciousness. He is the president, the chief scientific officer of the Allen Institute for Brain Science in Seattle. From 1986 to 2013, he was the professor at Caltech. Before that, he was at MIT. He is extremely well cited, over 100,000 citations. His research, his writing, his ideas have had big impact on the scientific community and the general public in the way we think about consciousness, in the way we see ourselves as human beings. He's the author of several books, the Quest for Consciousness, a neurobiological approach, and a more recent book, Confessions of a romantic Reductionist. If you enjoy this conversation this course, subscribe. Click the little bell icon to make sure you never miss a video, and in the comments, leave suggestions for any people you'd like to see, be part of the course or any ideas that you would like us to explore. Thanks very much, and I hope you enjoy. Okay, before we delve into the beautiful mysteries of consciousness, let's zoom out a little bit. And let me ask do you think there's intelligent life out there in the universe?
Speaker B: Yes, I do believe so. We have no evidence of it, but I think the probabilities are overwhelming in favor of it. Given a universe where we have ten to the eleven galaxies, and each galaxy has between ten to the ten to the twelve stars, and we know most stars have one or more planets.
Speaker A: So how does that make you feel?
Speaker B: It still makes me feel special because I have experiences. I feel the world. I experience the world. And independent of whether there are other creatures out there, I still feel the world. And I have access to this world in this very strange, compelling way. And that's the core of human existence.
Speaker A: Now, you said human. Do you think if those intelligent creatures are out there, do you think they experience their world? That's true.
Speaker B: If they are evolved, if they are a product of natural evolution, as they would have to be, they will also experience their own world. So consciousness isn't just human. You're right. It's much wider. It's probably, it may be spread across all of biology we have. The only thing that we have special is we can talk about it. Of course, not all people can talk about it. Babies and little children can talk about it. Patients who have a stroke in the, let's see, the left inferior frontal gyrus can't talk about it, but most normal adult people can talk about it. And so we think that makes us special compared to letting monkeys, a dog, a cats, a mice, or all the other creatures that we share the planet with. But all the evidence seems to suggest that they, too, experience the world. And so it's overwhelmingly likely that other alien, that aliens would also experience their world, of course, differently, because they have a different sensorium, they have different sensors, but very different environment. But the fact that I would strongly suppose that they also have experiences, they feel pain and pleasure and see in some sort of spectrum and hear and have all the other senses.
Speaker A: Of course, their language, if they have one, would be different. So we might not be able to understand their poetry about the experiences that they have.
Speaker B: That's correct.
Speaker A: Right. So, in a talk, in a video, I've heard you mention Sopuzzle dachshund that you came up with, that you grew up with, was part of your family when you were young. First of all, you're technically a midwestern boy.
Speaker B: You just technically.
Speaker A: But after that, you traveled around a bit, hence a little bit of the accent. You talked about Sapozo, the dachshund, having these elements of humanness, of consciousness that you discovered. So I just wanted to ask, can you look back in your childhood and remember when was the first time you realized you yourself, sort of from a third person perspective, are a conscious being? This idea of stepping outside yourself and seeing there's something special going on here in my brain.
Speaker B: I can't really. Actually, it's a good question. I'm not sure I recall a discrete moment. I mean, you take it for granted, because that's the only world you know. The only world I know you know, is the world of seeing and hearing voices and touching and all the other things. So it's only much later at early in my undergraduate days, when I became. When I enrolled in physics and in philosophy, that I really thought about it and thought, well, this is really fundamentally very, very mysterious. And there's nothing really in physics right now that explains this transition from the physics of the brain to feelings. Where do the feelings come in? So you can look at the foundational equation of quantum mechanics, general relativity. You can look at the period table of the elements. You can look at the endless ATGC chat analogy. In no ways consciousness. Yet I wake up every morning to a world where I have experiences. And so that's the heart of the ancient mind body problem. How do experiences get into the world?
Speaker A: So what is consciousness?
Speaker B: Experience. Consciousness is any experience. Some people call it subjective feeling. Some people call it phenomenology. Some people call it qualia, if they're philosopher, but they all denote the same thing. It feels like something in the famous word of the philosopher Thomas Nagel. It feels like something to be a bat or to be an american or to be angry or to be sad or to be in love or to have pain. And that is what experience is. Any possible experience could be as mundane as just sitting here in a chair. Could be as exalted as having a mystical moment in deep meditation. Those are just different forms of experiences, experience.
Speaker A: So if you were to sit down with maybe the next, skip a couple generations of IBM, Watson, something that won jeopardy, what is the gap? I guess the question is between Watson that might be much smarter than you, than us, than all, any human alive, but may not have experience, what is the gap?
Speaker B: Well, so that's a big, big question that's occupied people for the last. Certainly last 50 years, since we, you know, since the advent, the birth of computers. That's a question Alan Turing tried to answer. And of course, he did it in this indirect way by proposing a test, an operational test. So. But that's not really. That's, you know, he tried to get it. What does it mean for a person to think? And then he had this test, right? You log him away, and then you have a communication with them, and then you try to guess after a while whether that is a person or whether it's a computer system. There's no question that now or very soon, you know, Alexa or Siri or, you know, Google now will pass this test, right? And you can game it, but, you know, ultimately, certainly in your generation, there will be machines that will speak with complete poise, that will remember everything you ever said. They'll remember every email you ever had. Like. Like Samantha. Remember in the movie her?
Speaker A: Yeah.
Speaker B: There's no question it's going to happen. But of course, the key question is, does it feel like anything to be Samantha in the movie her, or does it feel like anything to be Watson? And there, one has to very, very strongly. There are two different concepts here that we commingle. There is a concept of intelligence, natural or artificial, and there is a concept of consciousness of experience, natural or artificial. Those are very, very different things. Now, historically, we associate consciousness with intelligence. Why? Because we live in a world, leaving aside computers of natural selection, where we are surrounded by creatures, either our own kin, that are less or more intelligent, or we go across species. Some are more adapted to a particular environment. Others are less adapted, whether it's a whale or dog or you go talk about a parametrium, or a little worm. We see the complexity of the nervous system goes from one cell to specialized cells, to a worm that has three net, that has 30% of its cells are nerve cells, to creature like aso, like a blue whale that has 100 billion even more nerve cells. And so, based on behavioral evidence and based on the underlying neuroscience, we believe that as these creatures become more complex, they are better adapted to their particular ecological niche. And they become more conscious partly because their brain grows. And we believe consciousness, unlike the ancient, ancient people, thought, most, almost every culture thought that consciousness with intelligence has to do with your heart. And you still see that today. You see, honey, I love you with all my heart, but what you should actually say is you say, no, honey, I love you with all my lateral hypothalamus. And for Valentine's Day, you should give your sweetheart a hypothalamic piece of chocolate, not a heart shaped chocolate. So we still have this language, but now we believe it's a brain. And so we see brains of different complexity, and we think, well, they have different levels of consciousness, they're capable of different experiences. But now we confront a world where we know where we're beginning to engineer intelligence. And it's radical unclear whether the intelligence we're engineering has anything to do with consciousness and whether it can experience anything, because fundamentally, what's the difference? Intelligence is about function. Intelligence, no matter exactly how you define it, sort of adaptation to new environments, being able to learn and quickly understand, you know, the setup of this and what's going on and who are the actors and what's going to happen next. That's all about function. Consciousness is not about function. Consciousness is about being. It's in some sense much fundamental. You can see this in several cases. You can see it, for instance, in the case of the clinic, when you're dealing with patients who are, let's say, had a stroke or were in traffic accident, etcetera, they're pretty much immobile. TeRRy Schiavo, you may have heard historically, she was a person here in the nineties in Florida. Her heart stood still, she was reanimated, and for the next 14 years, she was what's called in a vegetative state. There's thousands of people in a vegetative state. So they're, you know, they're, you know, they're like this. Occasionally they open their eyes for 23456 8 hours and then close their eyes. They have sleep wake cycle, occasionally they have behaviors they do like, you know, they. But there's no way that you can establish a lawful relationship between what you say or the doctor says or the mom says and what the patient does.
Speaker A: Right.
Speaker B: So. So there isn't any behavior. Yet in some of these people, there is still experience. You can design and build brain machine interfaces where you can see they still experience something. And of course, there are these cases of locked in state. There's this famous book called the Diving Bell and the Butterfly, where you had an editor, a french editor, he had a stroke in the brainstem, unable to move except his vertical eyes, eye movement. He could just move his eyes up and down. And he dictated an entire book. And some people even lose this at the end. All the evidence seems to suggest that they're still in there. In this case, you have no behavior. You have consciousness. Second case is tonight, like all of us, you're going to go to sleep. Close your eyes, you go to sleep, you will wake up inside your sleeping body, and you will have conscious experiences. They are different from everyday experience. You might fly. You might not be surprised that you're flying. You might meet a long dead pet, childhood dog, and you're not surprised that you're meeting them, you know, but you have conscious experience of love, of hate. You know, they can be very emotional. Your body during this state, typically it's a rem state, sends an active signal to your motor neurons to paralyze you. It's called etonia. Right? Because if you don't have that, like some patients, what do you do? You act out your dreams. You get, for example, rem behavioral disorder, which is the bad, which is bad juju to get. Okay. Third case is pure experience. So I recently had this, what some people call a mystical experience. I went to Singapore and went into flotation tank. So this is a big tub filled with water. That's body temperature. And absent salt, you strip completely naked. You lie inside of it, you close the lid. Darkness, complete darkness, soundproof. So very quickly, you become body less because you're floating and you're naked. You have no rings, no watch, no nothing. You don't feel your body anymore. No sound. Soundless. There's no photon. Sightless, timeless. Because after a while, early on, you actually hear your heart. But then that you. You sort of adapt to that, and then sort of the passage of time ceases. And if you train yourself, like in a meditation, not to think early on, you think a lot. It's a little bit spooky. You feel somewhat uncomfortable, or you think, well, I'm going to get bored. But if you try to, not to think actively. You become a mindless. There you are, body less, timeless, you know, soundless, sightless, mindless. But you're in a conscious experience. You're not asleep. You're not asleep. You are being of pure. You're pure being. There isn't any function. You aren't doing any computation. You're not remembering, you're not projecting, you're not planning yet you are fully conscious.
Speaker A: You're fully conscious. There's something going on there. It could be just a side effect. So what is the.
Speaker B: You mean IP phenomena?
Speaker A: So what's the select meaning? Why? What is the function of you being able to lay in this sensory free deprivation tank and still have a conscious experience?
Speaker B: Evolutionary.
Speaker A: Evolutionary.
Speaker B: Obviously, we didn't evolve with flotation tanks in our environment. I mean, so biology is notoriously bad at asking why? Question. Telenomical question. Why do we have two eyes? Why don't we have four eyes, like some features or three eyes or something? Well, no, there's probably. There is a function to that, but we're not very good at answering those questions. We can speculate endlessly where biology is very. Or science is very good about mechanistic question, why is there charge in the universe? Right? We find a certain universe where there are positive and negative charges. Why? Why does quantum mechanics hold? You know, why doesn't some other theory hold? Quantum mechanics hold in our universe? It's very unclear why. So telenomical question, why? Questions are difficult to answer. Clearly, there's some relationship between complexity, brain processing power, and consciousness. But however, in these cases, in the three examples I gave, one is an everyday experience at night. The other one is trauma. And third one is, in principle, everybody can have these sort of mystical experiences. You have a dissociation of function, of intelligence from consciousness.
Speaker A: From consciousness. You caught me asking a why question. Let me ask a question that's not a why question. You're giving a talk later today on the Turing test for intelligence and consciousness, drawing lines between the two. So is there a scientific way to say there's consciousness present in this entity or not? And to anticipate your answer, because there's a neurobiological answer. So we can test the human brain. But if you take a machine brain that you don't know tests for yet, how would you even begin to approach a test if there's consciousness present in this thing?
Speaker B: Okay, that's a really good question. So let me take in two steps. So, as you point out, for humans, let's just stick with humans. There's now a test called zap and zip. It's a procedure where you ping the brain using transcranial magnetic stimulation. You look at the electrical reverberations, essentially using Egypt, and then you can measure the complexity of this brain response. And you can do this in awake people, in their sleep, normal people. You can do it in awake people and then anesthetize them. You can do it in patients, and it has 100% accuracy that in all those cases, when you're clear, the patient or the person is either conscious or unconscious, the complexity is either high or low. And then you can adopt these techniques to similar creatures, like monkeys and dogs and mice that have very similar brainstor. Now, of course, you point out that may not help you because we don't have a cortex. If I send a magnetic pulse into my iPhone or my computer, it's probably going to break something. So we don't have that. So what we need, ultimately, we need a theory of consciousness. We can't just rely on our intuition. Our intuition is, well, yeah, if somebody talks, they're conscious. However, then there are all these children. Babies don't talk. Right? But we believe that the babies also have conscious experiences. Right. Then there are all these patients I mentioned, and they don't talk. When you dream, you can't talk because you're paralyzed. So what we ultimately need, we can't just rely on our intuition. We need a theory of consciousness that tells us, what is it about a piece of matter. What is it about a piece of highly excitable matter like the brain or like a computer that gives rise to conscious experience? We all believe. None of us believes anymore. In the old story, it's a soul, right? That used to be the most common explanation that most people accept that. And still a lot of people today believe, well, there's God endowed only us with a special thing that animals don't have. Rene Descartes famously said, a dog, if you hit it with your carriage, may yelp, may cry, but it doesn't have this special thing. It doesn't have the magic sauce. It doesn't have Rath Kogitan, the soul. Now, we believe that isn't the case anymore. So what is the difference between brains and these guys? Silicon, and in particular, once their behavior matches? So if you have Siri or Alexa in 20 years from now, that she can talk just as good as any possible human, what grounds do you have to say she's not conscious? In particular, if she says, I said, of course she will. Well, of course I'm conscious. You ask her how are you doing? And she'll say, well, you know, they'll generate some way to. Of course, she'll behave like a yemenite, like a person. Now, there are several differences. One is, so this relates to the problem, the very hard. Why is consciousness a hard problem? It's because it's subjective, right? Only I have it for only I know I have direct experience of my own consciousness. I don't have experience, your consciousness. Now, I assume as a sort of a bayesian person who believes in probability theory and all of that, you know, I can do, I can do an abduction to the, to the best available facts. I deduce your brain is very similar to mine. If I put you in a scanner, your brain is roughly going to behave the same way as I do. If I give you this muesli and ask you, how does it taste, you tell me things that I would also say more or less. So I infer, based on all of that, that you're conscious now with Siri, I can't do that. So there I really need a theory that tells me what is it about any system, this or this that makes it conscious. We have such a theory.
Speaker A: Yes. So the integrated information theory. But let me first, maybe his introduction for people are not familiar. Descartes, can you, you talk a lot about panpsychism. Can you describe what physicalism versus dualism. This, you mentioned the soul. What, what is the history of that idea? What it.
Speaker B: The idea of panpsychism?
Speaker A: Well, no. The debate really out of which panpsychism can emerge of dualism versus physicalism, or do you not see panpsychism as fitting into that?
Speaker B: No, you can argue there's some. Okay, so let's step back. So panpsychism is a very ancient belief that's been around. I mean, Plato and Aristotle talks about it. Modern philosophers talk about it. Of course, in Buddhism, the idea is very prevalent that, I mean, there are different versions of it. One version says everything is in salt. Everything rocks and stones and dogs and people and forests and iPhones, all have a soul, right? All matter is in soul. That's sort of one version. Another version is that all biology, all creatures small or large, from a single cell to a giant sequoia tree, feel like something. That's one I think is somewhat more realistic. So there are different versions.
Speaker A: What do you mean by feel like something? Have feeling, have some kind of.
Speaker B: It feels like some. It may well be possible that it feels like something to be a paramecium. I think it's pretty likely it feels like something to be a bee or a mouse or a dog.
Speaker A: Sure. Okay.
Speaker B: So you can say that's also. Panpsychem is very broad and you can. So some people, for example, Bertrand Russell, try to advocate this idea. It's called Rasselan monism, that panpsychism is really physics viewed from the inside. So the idea is that physics is very good at describing relationship among objects like charges or like gravity. Right. You know, describe the relationship between curvature and mass distribution. Okay. That's the relationship among things. Physics doesn't really describe the ultimate reality itself. It's just relationship among, you know, quarks or all these other.
Speaker A: Like a third person observer.
Speaker B: Yes, yes. And consciousness is what physics feels from the inside. So my conscious experience, it's the way the physics of my brain, particularly my cortex, feels from the inside. And so if you are parametrium, you got to remember, you say parametrium. Well, that's a pretty dumb creature. It is. But it has already a billion different molecules, probably, you know, 5000 different proteins assembled in a highly, highly complex system that no single person, no computer system so far on this planet has ever managed to accurately simulate. Its complexity vastly escapes us. Yes. And it may well be that that little thing feels like a tiny bit. Now. It doesn't have a voice in the head like me. It doesn't have expectations. You know, it doesn't have all that complex things, but it may well feel like something.
Speaker A: Yep. So this is really interesting. Can we draw some lines and maybe try to understand the difference between life, intelligence and consciousness? How do you see all of those? If you have to define what is a living thing, what is a conscious thing and what is an intelligent thing? Do those intermix for you or are they totally separate?
Speaker B: Okay, so a. That's a question that we don't have a full answer.
Speaker A: Right. A lot of the stuff we're talking about today is full of mysteries and fascinating ones. Right.
Speaker B: Well, for example, you can go to Aristotle, who's probably the most important scientist and philosopher who's ever lived in, certainly in western culture. He had this idea. It's called hylomorphism. It's quite popular these days that there are different forms of soul. The soul is really the form of something. He says all biological creatures have a vegetative soul. That's life principle. Today, we think we understand something more that it's biochemistry and nonlinear thermodynamics. Then he said they have a sensitive soul. Only animals and humans have also a sensitive soul or an appetitive soul. They can see, they can smell, and they have drives, they want to reproduce, they want to eat, etcetera. And then only humans have what he called a rational soul. Okay? And that idea then made it into Christendom. And then the rational soul is the one that lives forever. He was very unclear. He wasn't really. I mean, different readings of Aristotle give different. Whether did he believe that rational soul was immortal or not? I probably think he didn't. But then, of course, that made it into Plato, into Christianity, and then this soul became immortal and then became the connection to God. Now, so you asked me, essentially, what is our modern conception of these three? Aristotle would have called them different forms. Life. We think we know something about it, at least life on this planet, right? Although we don't understand how it originated, but it's been difficult to rigorously pin down. You see this in modern definitions of death. In fact, right now, there's a conference, ongoing, again, that tries to define legally and medically what is death. It used to be very simple. Death is you stop breathing, your heart stops beating, you're dead. Totally uncontroversial. If it's. If you're unsure, you wait another ten minutes. If the patient doesn't breathe, you know, he's dead. Well, now we have ventilators, we have heart pacemaker. So it's much more difficult to define what death is. Typically, death is defined as the end of life, and life is defined before death.
Speaker A: Before death.
Speaker B: Okay, so we don't have really very good definitions. Intelligence, we don't have a rigorous definition. We know something how to measure. It's called IQ or gfacte, and we're beginning to build it in a narrow sense, like go Alphago and Watson and Google cars and Uber cars and all of that. That's still narrow AI. And some people are thinking about artificial general intelligence. But roughly, as we said before, it's something to do with the ability to learn and to adapt to new environments. But that is, as I said, also, it's radical difference from experience, and it's very unclear. If you build a machine that has AGI, it's not at all a priori, it's not at all clear that this machine will have consciousness. It may or may not.
Speaker A: So let's ask it the other way. Do you think, if you were to try to build an artificial general intelligence system, do you think figuring out how to build artificial consciousness would help you get to an AGI? Or put another way, do you think intelligent requires consciousness?
Speaker B: In human, it goes hand in hand in human, or, I think in biology, consciousness, intelligence goes hand in hand. Qui is illusion. Because the brain evolved to be highly complex. Complexity via the theory, integrated information theory is sort of ultimately, is what is closely tied to consciousness. Ultimately, it's causal power upon itself. And so in evolved systems, they go together. In artificial system, particularly in digital machines, they do not go together. And if you ask me point blank, is Alexa 20.0 in the year 2040, when she can easily pass every turing test. Is she conscious? No. Even if she claims she's conscious. In fact, you could even do a more radical version of this thought experiment. We can build a computer simulation of the human brain. You know what Henry Markham in the blue brain project or the human brain project in Switzerland is trying to do? Let's grant them all the success. So in ten years, we have this perfect simulation, the human brain. Every neuron is simulated, and it has a larnics and it has motor neurons, it has a pocket area. And of course, they'll talk and they'll say, hi, I just woken up. I feel great. Okay. Even that computer simulation that can, in principle, map onto your brain will not be conscious. Why? Because it simulates. It's a difference between the simulated and the real. So it simulates the behavior associated with consciousness. It might be. It will, if it's done properly, will have all the intelligence at that particular person they're simulating has. But simulating intelligence is not the same as having conscious experiences. And I give you a really nice metaphor that engineers and physicists typically get. I can write down Einstein's field equation, nine or ten equations that describe the link in general relativity between curvature and mass. I can do that. I can run this on my laptop to predict that the central. The black hole at the center of our galaxy will be so massive that it will twist spacetime around it so no light can escape. It's a black hole. Right? But funny. Have you ever wondered, why doesn't this computer simulation suck me in? Right? It simulates gravity, but it doesn't have the causal power of gravity. That's a huge difference. So it's a difference between the real and the simulator. Just like it doesn't get wet inside a computer when the computer runs code that simulates a weather storm. And so in order but to have artificial consciousness, you have to give it the same causal power as a human brain. You have to build so called a neuromorphic machine that has hardware that is very similar to the human brain, not a digital clock phenomenon computer.
Speaker A: So that's just to clarify, though, you think that consciousness is not required to create human level intelligence. It seems to accompany in the human brain, but for machine not.
Speaker B: That's correct.
Speaker A: So maybe just because this is AGI, let's dig in a little bit about what we mean by intelligence. So one thing is the g factor, these kind of IQ tests of intelligence. But I think if you maybe another way to say so, in 2040, 2050, people will have Siri. That is just really impressive. Do you think people will say Siri is intelligent?
Speaker B: Yes.
Speaker A: Intelligence is this amorphous thing. So to be intelligent, it seems like you have to have some kind of connections with other human beings, in a sense that you have to impress them with your intelligence. And there feels you have to somehow operate in this world full of humans. And for that there feels like there has to be something like consciousness. So you think you can have just the world's best natural NLP system, natural language, understanding generation, and that will get us happy and say, you know what? We've created an AGI?
Speaker B: I don't know happy. Yes, I do believe we can get what we call high level functional intelligence, particular sort of the g, this fluid like intelligence that we cherish, particularly at a place like mitzvah in machines. I see a priori, no reasons, and I see a lot of reason to believe it's going to happen over the next 50 years or 30 years.
Speaker A: So for beneficial AI, for creating an AI system that's so. You mentioned ethics, that is exceptionally intelligent, but also does not do, does aligns its values with our values as humanity. Do you think then it needs consciousness?
Speaker B: Yes, I think that is a very good argument that if we are concerned about AI and the threat of AI a la Nick Bostrom, I think having an intelligence that has empathy. Right. Why do we find abusing a dog, why do most of us find that abhorrent, abusing any animal, why do we find that abhorrent? Because we have this thing called empathy, which if you look at the greek, really means feeling. With, I feel pathos, empathy. I have feeling with you. I see somebody else suffer that isn't even my conspic. It's not a person, it's not a love, it's not my wife or my kids, it's a dog. But I feel naturally, most of us, not all of us, most of us will feel emphatic. And so it may well be in the long term interest of survival of homo sapiens sapiens, that if we do build AGI and it really becomes very powerful, that it has an emphatic response and doesn't just exterminate humanity.
Speaker A: So as part of the full conscious experience to create a consciousness, artificial or in our human consciousness, do you think fear, maybe we're going to get into your earlier days with Nietzsche and so on, but do you think fear and suffering are essential to have consciousness? Do you have to have the full range of experience to have a system that has experience? Or can you have a system that only has a very particular kinds of very positive experiences?
Speaker B: Look, you can have, in principle, people have done this in the rat, where you implant an electrode in the hypothalamus, the pleasure center of the rat. And the rat stimulates itself above and beyond anything else. It doesn't care about food or natural sex or drink anymore. It just stimulates itself because it's such a pleasurable feeling. I guess it's like an orgasm, just you have all day long. And so a priori, I see no reason why you need different, why you need a great variety. Now, clearly to survive, that wouldn't work. But if I engineered artificially, I don't think you need a great variety of conscious experience. You could have just pleasure or just fear. It might be a terrible existence. But I think that's possible, at least on conceptual, logical ground, because any real creature, whether artificially engineered, you want to give it fear, the fear of extinction that we all have. And you also want to give it positive, repetitive states, states that it wants to, that you want the machine encouraged to do because they give the machine positive feedback.
Speaker A: So you mentioned panpsychism. To jump back a little bit. You know, everything having some kind of mental property, how do you go from there to something like human consciousness? So everything having some elements of consciousness, is there something special about human consciousness?
Speaker B: So just, it's not everything like a spoon. There's no. The form of Pentagon I think about doesn't ascribe consciousness to anything like this, the spoon or my liver. However it is the theory, the integrated information theory does say that system, even ones that look from the outside, relatively simple, at least if they have this internal causal power or they are, it does feel like something. The theory apriori doesn't say anything. What's special about human biologically? We know what the one thing that's special about human is. We speak and we have an overblown sense of our own importance. We believe we're exceptional and we're just God's gift and to the universe. But behaviorally, the main thing that we have, we can plan over the long term and we have language, and that gives us enormous amount of power, and that's why we are the dominant species on the planet.
Speaker A: So you mentioned God. You grew up a devout Roman Catholic, Roman catholic family. So with consciousness, you're sort of exploring some really deeply fundamental human things that religion also touches on. So where does religion fit into your thinking about consciousness? You've grown throughout your life and changed your views on religion, as far as I understand.
Speaker B: Yeah, I mean, I'm now much closer to. So I'm not a Roman Catholic anymore. I don't believe there's sort of this God, the God I was educated to believe in, you know, sit somewhere in the fullness of time, I'll be united in some sort of everlasting bliss. I just don't see any evidence for that. Look, the world, the night, is large and full of wonders, right? I. There are many things that I don't understand. I think many things that we, as a cult, look, we don't even understand more than 4% of all the universe, right? Dark matter, dark energy, we have no idea what it is. Maybe it's lost sox. What do I know? So. So all I can tell you is it's a sort of. My current religious or spiritual sentiment is much closer to some form of Buddhism. Can you describe it without the reincarnation? Unfortunately, there's no evidence for a reincarnation.
Speaker A: So can you describe the way Buddhism sees the world a little bit?
Speaker B: Well, so they talk about. So when I spent several meetings with the Dalai Lama, and what always impressed me about him, he really unlike, for example, let's say the pope or some cardinal, he always emphasized minimizing the suffering of all creatures. So they have this from the early beginning, they look at suffering in all creatures, not just in people, but in everybody. This universal, and of course, by degrees, right in the animal general, is less capable of suffering than a well developed, normally developed human. And they think consciousness pervades in this universe. And they have these techniques. You can think of them like mindfulness, etcetera, and meditation, that tries to access what they claim of this more fundamental aspect of reality. I'm not sure it's more fundamentalist. I think about it. There's a physical, and then there's inside view consciousness. And those are the two aspects. That's the only thing I have access to in my life. And you've got to remember my conscious experience. And your conscious experience comes prior to anything you know about physics, comes prior to knowledge about the universe, and atoms and super strings and molecules and all of that. The only thing you directly are acquainted with is this world that's populated with things and images and sounds in your head and touches and all of that.
Speaker A: I actually have a question. So it sounds like you kind of have a rich life. You talk about rock climbing, and it seems like you really love literature, and consciousness is all about experiencing things. So do you think that has helped your research on this topic?
Speaker B: Yes, particularly if you think about it, the various states. So, for example, when you do rock climbing, or now I do rowing, crew rowing and a bike every day you can get into this thing called the zone. And I've always wondered about it, particularly with respect to consciousness, because it's a strangely addictive state. You want to. You want to appear, I mean, once people have it, once they want to keep on going back to it, and you wonder, what is it so addicting about it? And I think it's the experience of almost close to pure experience, because in this zone, you're not conscious of inner voice anymore. There's always this inner voice nagging you. You have to do this, you have to do that, you have to pay your taxes, you had this fight with your ex, and all of those things, they're always there. But when you're in the zone, all of that is gone, and you're just in this wonderful state where you're fully out in the world, right? You're climbing or you're rowing or biking or doing soccer or whatever you're doing. And sort of consciousness sort of is this. You're all action, or in this case, of pure experience, you're not action at all. But in both cases, you experience some aspect of. You touch some basic part of conscious existence that is so basic and so deeply satisfying, I think you touch the root of being. That's really what you're touching there. You're getting close to the root of being, and that's very different from intelligence.
Speaker A: So what do you think about the simulation hypothesis? Simulation theory, the idea that we all live in a computer simulation.
Speaker B: Have you got raptors for nerds?
Speaker A: Raptures for nerds?
Speaker B: I think it's as likely as the hypothesis that engaged hundreds of scholars for many centuries. Are we all just existing in the mind of God? And this is just a modern version of it? It's equally plausible. People love talking about these sorts of things. I know their book written about the simulation hypothesis. If that's what people want to do, that's fine. It seems rather esoteric.
Speaker A: It's never testable, but it's not useful for you to think of in those terms. So maybe connecting to the questions of free will, which you've talked about, I think I vaguely remember you saying that the idea that there's no free will, it makes you very uncomfortable. So what do you think about free will from a physics perspective? From a consciousness perspective, what does it all fit?
Speaker B: Okay, so from the physics perspective, leaving aside quantum mechanics, we believe we live in a fully deterministic world, right? But then comes, of course, quantum mechanics. So now we know that certain things are, in principle, not predictable, which, as you said, I prefer, because the idea that the initial condition of the universe and then everything else, we're just acting out the initial condition of the universe, that doesn't. That doesn't.
Speaker A: It's not a romantic notion.
Speaker B: Certainly not right now. When it comes to consciousness, I think we do have certain freedom. We are much more constrained by physics, of course, and by our path and by our own conscious desires and what our parents told us us and what our environment tells us. We all know that, right? There's hundreds of experiments that show how we can be influenced. But finally, in the final analysis, when you make a life, and I'm talking really about critical decision, where you really think, should I marry? Should I go to this school or that school? Should I take this job or that job? Should I cheat on my taxes or not? Right? Sort of. These are things where you really deliberate. And I think under those conditions, you are as free as you can be. When you bring your entire being, your entire conscious being, to that question and try to analyze it on all the various conditions, and then you make a decision, you are as free as you can ever be. That is, I think what free will is. It's not a will that's totally free to do anything it wants. That's not possible.
Speaker A: Right. So, as Jack mentioned, you actually write a blog about books. You've read amazing books from. I'm russian, from Bogakov to. Yeah. Neil Gaiman, Carl Sagan, Murakami. So what is a book that, early in your life transformed the way you saw the world? Something that changed your life?
Speaker B: Nietzsche, I guess, did. Thus broke the trust because he talks about some of these problems. You know, he was one of the first discoverer of the unconscious. This is, you know, a little bit before Freud when he was in the air. He makes all these claims that people sort of under the guise or under the mass of charity, actually are very non charitable. So he is sort of really the first discoverer of the great land of the unconscious. And that really struck me.
Speaker A: And what do you think about the unconscious. What do you think about Freud? What do you think about these ideas? What's just like dark matter in the universe? What's over there in that unconscious?
Speaker B: A lot. I mean, much more than we think. This is what a lot of last hundred years of research has shown. So I think he was a genius. Misguided towards the end, but he was all, he started out as a neuroscientist, right? He contributed. He did studies on the, on the lamprey. He contributed himself to the neuron hypothesis, the idea that they're discrete units that we call nerve cells. And then he wrote about the unconscious. And I think it's true. There's lots of stuff happening. You feel this particular when you're in a relationship and it breaks asunder. And then you have this terrible, you can have love and hate and lust and anger. And all of it is mixed in. And when you try to analyze yourself, why am I so upset? It's very, very difficult to penetrate to those basements, those cabins in your mind, because the prying eyes of conscience doesn't have access to those. But they're there in the amygdala or lots of other places. They make you upset or angry or sad or depressed. And it's very difficult to try to actually uncover the reason. You can go to a shrink, you can talk with your friend endlessly. You construct, finally a story why this happened, why you love her or don't love her or whatever, but you don't really know whether that's actually, whether that actually happened, because you simply don't have access to those parts of the brain, and they're very powerful.
Speaker A: Do you think that's a feature or a bug of our brain? The fact that we have this deep, difficult to dive into subconscious, I think.
Speaker B: It'S a feature because otherwise, look, we are like any other brain or nervous system or computer. We are severely band limited if we, if everything I do, every emotion I feel, every eye movements I make, if all of that had to be under the control of consciousness, I could, I wouldn't be here. So what you do early on, your brain, you have to be conscious when you learn things like typing or riding on a bike. But then what you do, you train up routes, I think, that involve basal ganglia and striatum. You train up different parts of your brain. And then once you do it automatically, like typing, you can show, you do it much faster without even thinking about it because you've got these highly specialized, what Franz Crick and I call zombie agents that are sort of. They're taking care of that. While your consciousness can sort of worry about the abstract sense of the text you want to write. And I think that's true for many, many things.
Speaker A: But for the things like all the fights you had with an ex girlfriend, things that you would think are not useful to still linger somewhere in the subconscious. So that seems like a bug, that it would stay there.
Speaker B: You think it would be better if you can analyze and then get it.
Speaker A: Out of the system or just forget it ever happened? You know, that. That seems a very buggy kind of.
Speaker B: Well, yeah, in general, we don't have. And that's probably functional. We don't have an ability unless it's extreme. There are cases, clinical dissociations, right. When people are heavily abused, when they completely repress the memory. But that doesn't happen in, you know, in normal people. We don't have an ability to remove traumatic memory, and of course, we suffer from that. On the other hand, probably if you had the ability to constantly wipe your memory, you probably do it to an extent that isn't useful to you.
Speaker A: So, yeah, it's a good question. It's a balance. So, on the books, as Jack mentioned, correct me if I'm wrong, but broadly speaking, academia and the different scientific disciplines, certainly in engineering, reading literature seems to be a rare pursuit. Perhaps I'm wrong in this, but that's in my experience, most people read much more technical texts and do not sort of escape or seek truth. In literature, it seems like you do. So what do you think is the value? What do you think literature adds to the pursuit of scientific truth? Do you think it's good?
Speaker B: It's useful for access to a much wider array of human experiences.
Speaker A: How valuable do you think it is?
Speaker B: Well, if you want to understand human nature and nature in general, then I think you have to better understand a wide variety of experiences, not just sitting in a lab, staring at a screen and having a face flashed onto you for 100 milliseconds and pushing a button. That's what I used to do. That's what most psychologists do. There's nothing wrong with that. But you need to consider lots of other strange states.
Speaker A: And literature is a shortcut for this?
Speaker B: Well, yeah, because literature, that's what literature is all about. All sorts of interesting experiences. People have the contingency of it. The fact that women experience the world different, black people experience the world different. And one way to experience that is reading all these different literature and try to find out. You see, everything is so relative. You read a book 300 years ago, they thought about certain problems very, very differently than us. Today. We today, like any culture, think we know it all. That's common to every culture. Every culture believes that it's heyday. They know all. And then you realize, well, there's other ways of viewing the universe, and some of them may have lots of things in their favor.
Speaker A: So this is a question I wanted to ask about time scale or scale in general, when you with IIT or in general, try to think about consciousness, try to think about these ideas. We kind of naturally think in human time scales. Do you, or. And also entities that are sized close to humans, do you think of things that are much larger, much smaller, as containing consciousness? And do you think of things that take, you know, ages, eons to operate in their conscious. Cause effect. Cause effect.
Speaker B: That's a very good question. So, yeah, I think a lot about small creatures, because experimentally, a lot of people work on flies and bees. Most people just think they're automata. They're just bugs, for heaven's sake. But if you look at their behavior like bees, they can recognize individual humans. They have this very complicated way to communicate. If you've ever been involved or, you know, your parents, when they bought a house, what sort of agonizing decision that is. And bees have to do that once a year, right, when they swarm in the spring. And then they have this very elaborate way. They have three nut scouts. They go to the individual sites, they come back, they have this power, this dance, literally, where they dance for several days. They try to recruit other deeds. It's very complicated decision way. When they finally, once they make a decision, the entire swarm, the scouts warm up the entire swarm and then go to one location. They don't go to 50 location. They go to one location that the scouts have agreed upon by themselves. That's awesome. If you look at the circuit complexity, it's ten times more denser than anything we have in our brain. Now. They only have a million neurons, but the neurons are amazingly complex. Complex behavior, very complicated circuitry. So there's no question they experienced something. Their life is very different. They're tiny. They only live, you know, for workers live maybe for two months. So I think an IaT tells you this. In principle, the substrate of consciousness is the substrate that maximizes the cause effect power over all possible spatial temple grains. So when I think about, for example, do you know the science fiction story the Black Cloud? Okay. It's a classic by Fred Hoyle, the astronomer. He has this cloud intervening between the earth and the sun and leading to some sort of. To global cooling. This is written in the fifties. It turns out you can, using the radio dish, they communicate with actually an entity. It's actually an intelligent entity, and they convince it to move away. So here you have a radical different entity, and in principle, it says, well, you can measure the integrated information in principle at least. And yes, if the maximum of that occurs at a time scale of months rather than in us, it's sort of a fraction of a second. Yes. And they would experience life where each moment is a month rather than. Or microsecond. Right. Rather than a fraction of a second in the human case. And so there may be forms of consciousness that we simply don't recognize for what they are because they are so radical different from anything you and I are used to. Again, that's why it's good to read or to watch science fiction movie. Well, to think about this like this is. Do you know Stanislav Lehm, this polish science fiction writer? He wrote Solaris that was turned into a Hollywood movie. Yes, his best novel. So it was in the sixties, very engineering, engineering background. His most interesting novel is called the victorious, where human civilization, they have this mission to this planet and everything is destroyed, and they discover machines. Humans got killed, and then these machines took over. And there was this machine evolution, a darwinian evolution. He talks about this very vividly. And finally, the dominant machine intelligence organism that survived are gigantic clouds of little hexagonal universal cellar automata. This was written in the sixties, so typically they're all lying on the ground individually by themselves, but in times of crisis, they can communicate the assembly into gigantic nets into clouds or trillions of these particles, and then they become hyper intelligent and they can beat anything that humans can throw at it. It's a very beautiful and compelling where you have an intelligence, where finally the humans leave the planet, they simply unable to understand and comprehend this creature. And they can say, well, either we can nuke the entire planet and destroy it, or we just have to leave, because fundamentally, it's an alien. It's so alien from us and our ideas that we cannot communicate with them.
Speaker A: Yeah, actually, in the conversation Stephen Wolfram brought up is that there could be his ideas that, you know, you already have these artificial general intelligence, like super smart, or maybe conscious beings in these cellular automata. We just don't know how to talk to them. So it's the language of communication. You don't know what to do with it. So that's one sort of view, is consciousness is only something you can measure. So it's not conscious if you can't measure it.
Speaker B: So you're making an ontological and an epistemic statement. One is there. It's just like seeing their multiverses. That might be true, but I can't communicate with them. I don't. I can't have any knowledge of them. That's an epistemic argument. Right? So those are two different things. So it may well be possible. Look, another case that's happening right now, people are building these mini organoids. Do you know about this? So, you know, you can take stem cells from under your arm, put it in a dish, add four transcription factors, and then you. You can induce them to grow into large. Well, large, they're a few millimeter. They're like a half a million neurons that look like nerve cells in a dish called mini organoids. At Harvard, at Stanford, everywhere they're building them, it may well be possible that they're beginning to feel like something, but we can't really communicate with them right now. So people are beginning to think about the ethics of this. So, yes, he may be perfectly right, but they may. It's one question. Are they conscious or not? It's a totally separate question. How would I know? Those are two different things.
Speaker A: Right. If you could give advice to a young researcher sort of dreaming of understanding or creating human level intelligence or consciousness, what would you say?
Speaker B: Just follow your dreams, read widely.
Speaker A: No, I mean, I suppose, what discipline? What is the pursuit that they should take on? Is it neuroscience? Is it competition? Cognitive science? Is it philosophy? Is it computer science? Robotics?
Speaker B: No, in a sense that. Okay, so the only known system that have high level of intelligence is homo sapiens. So if you wanted to build it, it's probably good to continue to study closely what humans do. So cognitive neuroscience, you know, somewhere between cognitive neuroscience on the one hand, then some philosophy of mind, and then AI, computer science, you can look at all the original ideas. Neural networks. They all came from neuroscience, right? Reinforcement. Whether it's snarky Minsky building his snarky, or whether it's the early Schubel and Wiesel experiments at Harvard that then gave rise to networks and then multilayer networks. So it may well be possible. In fact, some people argue that to make the next big step in AI, once we realize the limits of deep convolutional networks, they can do certain things, but they can't really understand. I can't really show them one image. I can show you a single image of somebody, a pickpocket who steals a wallet from a purse, you immediately know that's a pickpocket. Now, computer system would just say, well, it's a man, it's a woman, it's a purse. Right. Unless you train this machine on showing it a hundred thousand pickpockets. Right. So it doesn't. It doesn't have this easy understanding that you have. Right. So some people make the argument in order to go to the next step, or you really want to build machines that understand, in a way, you and I, we have to go to psychology. We need to understand how we do it and how our brains enable us to do it. And so, therefore, being on the cusp, it's also so exciting to try to understand better our nature and then to build, to take some of those insight and build them. So I think the most exciting thing is somewhere in the interface between cognitive science, neuroscience, AI, computer science, and philosophy of mind.
Speaker A: Beautiful. Yeah, I'd say if there is, from the machine learning from the computer science, computer vision perspective, many of the researchers kind of ignore the way the human brain works, ignore even psychology or literature or studying the brain. I would hope. Josh Tenenbaum talks about bringing that in more and more, and that's. Yeah. So you've worked on some amazing stuff throughout your life. What's the thing that you're really excited about? What's the mystery that you would love to uncover in the near term beyond all the mysteries that you're already surrounded by?
Speaker B: Well, so there's a structure called the claustron. Okay? This is structure. It's underneath our cortex. It's yay big. You have one on the left, on the right, underneath this part, underneath the insula. It's very thin. It's like 1 mm. It's embedded in wiring in white matter. So it's very difficult to image, and it has connection to every cortical region. And Francis Crick, the last paper he ever wrote, he dictated corrections the day he died in hospital. On this paper. Now, we hypothesize, well, because it has this unique anatomy, it gets input from every cortical area and projects back to every cortical area that the function of this structure is similar. It's just a metaphor to the role of a conductor in a symphony orchestra. You have all the different cortical players. You have some that do motion, some that do theory of mind that infer social interaction and color and hearing and all the different modules and cortex. But, of course, what consciousness is, consciousness puts it all together into one package. Right. The binding problem, all of that, and this is really the function because it has relatively few neurons compared to cortex, but it talks it, so it receives input from all of them and it projects back to all of them. And so we are testing that right now. We've got this beautiful neuronal reconstruction in the mouse called crown of Thorne count of thorn neurons that are in the claustron that have the most widespread connection of any neuron I've ever seen. You have individual neurons that sit in the clouds from tiny, but then they have this single neurons have this huge axonal tree that cover both ipsy and contralateral cortex, and trying to turn, using fancy tools like optogenetics, trying to turn those neurons on or off and study what happens in the mouth.
Speaker A: So this thing is perhaps where the parts become the whole.
Speaker B: Perhaps it's one of the structures. It's a very good way of putting it, where the individual parts turn into the whole of the conscious experience.
Speaker A: Well, with that, thank you very much for being here today.
Speaker B: Thank you very much. Thank you much.
