Speaker A: By the time you get to 2045, we'll be able to multiply our intelligence many millions fold, and it's just very hard to imagine what that will be like.
Speaker B: The following is a conversation with Ray Kurzweil, author, inventor, and futurist, who has an optimistic view of our future as a human civilization. Predicting that exponentially improving technologies will take us to a point of a singularity, beyond which super intelligent artificial intelligence will transform our world in nearly unimaginable ways. 18 years ago in the book singularity is near, he predicted that the onset of the singularity will happen in the year 2045. He still holds to this prediction and estimate. In fact, he's working on a new book on this topic that will hopefully be out next year. This is the Lex Friedman podcast. To support it. Please check out our sponsors in the description. And now, dear friends, here's Ray Kurzweil. In your 2005 book titled the Singularities near, you predicted that the singularity will happen in 2045. So now, 18 years later, do you still estimate that the singularity will happen on 2045? And maybe first, what is the singularity, the technological singularity, and when will it happen?
Speaker A: Singularity is where computers really change our view of what's important and change who we are. But we're getting close to some salient things that will change who we are. A key thing is 2029, when computers will pass the Turing test. And there's also some controversy whether the Turing test is valid. I believe it is. Most people do believe that, but there's some controversy about that. But Stanford got very alarmed at my prediction about 2029. I made this in 1999 in my.
Speaker B: Book the Age of Spiritual Machines. And then you repeated the prediction in 2005.
Speaker A: 2005, yeah. So they held international conference, you might have been aware of it, of AI experts in 1999 to assess this view. So people gave different predictions, and they took a poll. It was really the first time that AI experts worldwide were polled on this prediction, and the average poll was 100 years. 20% believed it would never happen, and that was the view. In 1999, 80% believed it would happen, but not within their lifetimes. There's been so many advances in AI that the poll of AI experts has come down over the years. So a year ago, something called meticulous, which you may be aware of, assesses different types of experts on the future. They again assessed what AI experts then felt, and they were saying 2042 for the Turing test. For the Turing test. So it's coming down, and I was still saying 2029. A few weeks ago, they again did another poll, and it was 2030. So AA experts now basically agree with me. I haven't changed at all. I've stayed with 2029, and a experts now agree with me, but they didn't agree at first.
Speaker B: So Alan Turing formulated the Turing test.
Speaker A: Right now, what he said was very little about it. I mean, the 1950 paper where he had articulated the Turing test, there's, like a few lines that talk about the Turing test, and it really wasn't very clear how to administer it. And he said if they did it in, like, 15 minutes, that would be sufficient, which I don't really think is the case. These large language models. Now, some people are convinced by it already. I mean, you can talk to it and have a conversation with it, and you can actually talk to it for hours, so it requires a little more depth. There's some problems with large language models, which we can talk about, but some people are convinced by the Turing test. Now, if somebody passes the Turing test, what are the implications of that? Does that mean that they're sentient, that they're conscious or not? It's not necessarily clear what the implications are. Anyway. I believe 2029, that's six, seven years from now, we'll have something that passes the Turing test and a valid Turing test, meaning it goes for hours, not just a few minutes.
Speaker B: Can you speak to that a little bit? What is your formulation of the Turing test? You've proposed a very difficult version of the Turing test. So what does that look like?
Speaker A: Basically, it's just to assess it over several hours and also have a human judge that's a fairly sophisticated on what computers can do and can't do. If you take somebody who's not that sophisticated or even an average engineer, they may not really assess various aspects of it.
Speaker B: So you really want the human to challenge the system?
Speaker A: Exactly. Exactly.
Speaker B: On its ability to do things like common sense reasoning.
Speaker A: Perhaps that's actually a key problem with large language models. They don't do these kinds of tests that would involve assessing chains of reasoning, but you can lose track of that if you talk to them. They actually can talk to you pretty well, and you can be convinced by it, but it's somebody that would really convince you that it's a human, whatever that takes. Maybe it would take days or weeks, but it would really convince you that it's human. Large language models can appear that way. You can read conversations and they appear pretty good. There are some problems with it. It doesn't do math very well. You can ask, how many legs did ten elephants have. And they'll tell you, well, okay, each elephant has four legs and it's ten elephants. So it's 40 legs. And you go, okay, that's pretty good. How many legs do eleven elephants have? And they don't seem to understand the question.
Speaker B: Do all humans understand that question?
Speaker A: No, that's a key thing. I mean, how advanced the human do you want it to be? But we do expect a human to be able to do multi chain reasoning, to be able to take a few facts and put them together, not perfectly. And we see that in a lot of polls that people don't do that perfectly at all. So it's not very well defined, but it's something where it really would convince you that it's a human.
Speaker B: Is your intuition that large language models will not be solely the kind of system that passes the Turing test in 2029? Do we need something else?
Speaker A: No, I think it will be a large language model, but they have to go beyond what they're doing now. I think we're getting there. And another key issue is if somebody actually passes the Turing test, validly, I would believe they're conscious. Not everybody would say that, okay, we can pass a Turing test, but we don't really believe that it's conscious. That's a whole other issue. But if it really passes the Turing test, I would believe that it's conscious. But I don't believe that of large language models today.
Speaker B: If it appears to be conscious, that's as good as being conscious, at least for you in some sense.
Speaker A: I mean, consciousness is not something that's scientific. I mean, I believe you're conscious, but it's really just a belief. And we believe that about other humans that at least appear to be conscious. When you go outside of shared human assumption, like, are animals conscious? Some people believe they're not conscious. Some people believe they are conscious. And would a machine that acts just like a human be conscious? I mean, I believe it would be, but that's really a philosophical belief. You can't prove it. I can't take an entity and prove that it's conscious. There's nothing that you can do that would indicate that.
Speaker B: It's like saying a piece of art is beautiful. You can say it. Multiple people can experience a piece of art as beautiful, but you can't prove it.
Speaker A: But it's also an extremely important issue. I mean, imagine if you had something where nobody's conscious. The world may as well not exist. And so some people, like, say, Marvin Minsky said, well, consciousness is nothing logical. It's not scientific, and therefore we should dismiss it. And any talk about consciousness is just not to be believed. But when he actually engaged with somebody who was conscious, he actually acted as if they were conscious. He didn't ignore that.
Speaker B: He acted as if consciousness does matter.
Speaker A: Exactly. Whereas he said it didn't matter.
Speaker B: Well, that's Marvin Minsky. He's full of contradictions, but that's true.
Speaker A: Of a lot of people as well.
Speaker B: But to you, consciousness matters.
Speaker A: But to me, it's very important. But I would say it's not a scientific issue. It's a philosophical issue, and people have different views, and some people believe that anything that makes a decision is conscious. So your light switch is conscious. Its level of consciousness is low. Not very interesting, but that's a consciousness. So a computer that makes a more interesting decision, still not at human levels, but it's also conscious and at a higher level than your light switch. So that's one view. There's many different views of what consciousness is.
Speaker B: So if a system passes the Turing test, it's not scientific. But in issues of philosophy, things like ethics start to enter the picture. Do you think there would be, we would start contending as a human species about the ethics of turning off such a machine?
Speaker A: Yeah, I mean, that's definitely come up, hasn't come up in reality yet. But I'm talking about 2029. It's not that many years from now. And so what are our obligations to it? It has a different. I mean, a computer that's conscious has a little bit different connotations than a human. We have a continuous consciousness. We're in an entity that does not last forever. Now, actually, a significant portion of humans still exist and are therefore still conscious. But anybody who is over a certain age doesn't exist anymore. That wouldn't be true of a computer program. You could completely turn it off, and a copy of it could be stored, and you could recreate it. And so it has a different type of validity. You could actually take it back in time. You could eliminate its memory and have it go over again. I mean, it has a different kind of connotation than humans do.
Speaker B: Well, perhaps you can do the same thing with humans. It's just that we don't know how to do that yet. It's possible that we figure out all of these things on the machine first. But that doesn't mean the machine isn't conscious.
Speaker A: I mean, if you look at the way people react, say three CPO or other machines that are conscious in movies, they don't actually present how it's conscious, but we see that they are a machine, and people will believe that they are conscious, and they'll actually worry about it if they get into trouble, and so on.
Speaker B: So 2029 is going to be the first year when a major thing happens, and that will shake our civilization to start to consider the role of AI.
Speaker A: Well, yes and no. I mean, this one guy at Google claimed that the machine was conscious, but.
Speaker B: That'S just one person, right? So it starts to happen to scale.
Speaker A: Well, that's exactly right, because most people have not taken that position. I don't take that position. I mean, I've used different things like this, and they don't appear to me to be conscious. As we eliminate various problems of these large language models, more and more people will accept that they're conscious. So when we get to 2029, I think a large fraction of people will believe that they're conscious. So it's not going to happen all at once. I believe that it would actually happen gradually, and it's already started to happen.
Speaker B: And so that takes us one step closer to the singularity.
Speaker A: Another step, then, is in the 2030s, when we can actually connect our neocortex, which is where we do our thinking, to computers. And, I mean, just as this actually gains a lot to being connected to computers, that will amplify its abilities. I mean, if this did not have any connection, it would be pretty stupid. It could not answer any of your.
Speaker B: Questions if you're just listening to this. By the way, Ray's holding up the all powerful smartphone, so we're going to.
Speaker A: Do that directly from our brains. I mean, these are pretty good. These already have amplified our intelligence. I'm already much smarter than I would otherwise be if I didn't have this, because I remember my first book, the Age of Intelligent Machines. There was no way to get information from computers. I actually would go to a library, find a book, find the page that had an information I wanted, and I go to the copier. And my most significant information tool was a roll of quarters where I could feed the copier. So we're already greatly advanced that we have these things. There's a few problems with it. First of all, I constantly put it down, and I don't remember where I put it. I've actually never lost it. But you have to find it and then you have to turn it on. So there's a certain amount of steps. It would actually be quite useful if someone would just listen to your conversation and say, oh, that's so and so. Actress and tell you what you're talking about.
Speaker B: So going from active to passive, where it just permeates your whole life.
Speaker A: Yeah, exactly.
Speaker B: The way your brain does when you're awake. Your brain is always there.
Speaker A: Right now, that's something that could actually just about be done today, where you would listen to your conversation, understand what you're saying, understand what you're not missing, and give you that information. But another step is to actually go inside your brain. And there are some prototypes where you can connect your brain. They actually don't have the amount of bandwidth that we need. They can work, but they work fairly slowly. So if it actually would connect to your neocortex and the neocortex which I described and how to create a mind. The neocortex is actually. It has different levels, and as you go up the levels, it's kind of like a pyramid. The top level is fairly small, and that's the level where you want to connect these brain extenders. So I believe that will happen in the 2030s. So just the way this is greatly amplified by being connected to the cloud, we can connect our own brain to the cloud and just do what we can do by using this machine.
Speaker B: Do you think it would look like the brain computer interface of neuralink? So would it be?
Speaker A: Well, neuralink is an attempt to do that. It doesn't have the bandwidth that we need yet. Right, right. I. I mean, they're going to get permission for this because there are a lot of people who absolutely need it because they can't communicate. I know a couple of people like that who have ideas and they cannot move their muscles and so on. They can't communicate. So for them, this would be very valuable, but we could all use it. Basically, it'd be turn us into something that would be like, we have a phone, but it would be, in our minds, it would be kind of instantaneous.
Speaker B: And maybe communication between two people would not require this low bandwidth mechanism of language, of spoken words.
Speaker A: Exactly. We don't know what that would be, although we do know that computers can share information like language instantly. They can share many, many books in a second. So we could do that as well. If you look at what our brain does, it actually can manipulate different parameters. So we talk about these large language models. I mean, I had written that it requires a certain amount of information in order to be effective, and that we would not see AI really being effective until it got to that level. We had large language models that were like, 10 billion bytes didn't work very well. They finally got to 100 billion bytes, and now they work fairly well. And now we're going to a trillion bytes. If you say lambda has 100 billion bytes, what does that mean? Well, what if you had something that had one byte, one parameter? Maybe you want to tell whether or not something's an elephant or not. And so you put in something that would detect its trunk. If it has a trunk, it's an elephant. If it doesn't have a trunk, it's not an elephant. That would work fairly well. There's a few problems with it, and really wouldn't be able to tell what the trunk is, but anyway.
Speaker B: And maybe other things other than elephants have trunks, you might get really confused.
Speaker A: Yeah, exactly.
Speaker B: I'm not sure which animals have trunks, but, you know, that's. How do you define a trunk? But, yeah, that's one parameter you can do.
Speaker A: Okay, so these things have 100 billion parameters, so they're able to deal with very complex issues, all kinds of trunks. Human beings actually have a little bit more than that, but they're getting to the point where they can emulate humans. If we were able to connect this to our neocortex, we would basically add more of these abilities to make distinctions, and it could ultimately be much smarter and also be attached to information that we feel is reliable. So that's where we're headed.
Speaker B: So you think that there will be a merger in the thirties, an increasing amount of merging between the human brain and the AI brain.
Speaker A: Exactly. And the AI brain is really an emulation of human beings. I mean, that's why we're creating them, because human beings act the same way. And this is basically to amplify them. I mean, this amplifies our brain. It's a little bit clumsy to interact with, but it definitely way beyond what we had 15 years ago.
Speaker B: But the implementation becomes different, just like a bird versus the airplane. Even though the AI brain is in emulation, it starts adding features we might not otherwise have, like ability to consume a huge amount of information quickly. Like look up thousands of Wikipedia articles in one take.
Speaker A: Exactly. And we can get, for example, issues like simulated biology, where it can simulate many different things at once. We already had one example of simulated biology, which is the Moderna vaccine, and that's going to be now the way in which we create medications. But they were able to simulate what each example of an mRNA would do to a human being, and they were able to simulate that quite reliably. We actually simulated billions of different mRNA sequences, and they found the ones that were the best, and they created the vaccine. And they did, and talk about doing that quickly. They did that in two days. Now how long would a human being take to simulate billions of different mRNA sequences? I don't know that we could do it at all, but it would take many years. They did it in two days. And one of the reasons that people didn't like vaccines is because it was done too quickly, it was done too fast, and they actually included the time it took to test it out, which was ten months. So they figured, okay, it took ten months to create this. Actually, it took us two days. And we also will be able to ultimately do the tests in a few.
Speaker B: Days as well, because we can simulate how the body will respond to it more and more.
Speaker A: That's a little bit more complicated because the body has a lot of different elements and we have to simulate all of that. But that's coming as well. So ultimately we could create it in a few days, and then test it in a few days and it would be done. And we can do that with every type of medical insufficiency that we have.
Speaker B: So curing all diseases, improving certain functions of the body, supplements drugs for recreation, for health, for performance, for productivity, all that good stuff.
Speaker A: Well, that's where we're headed, because I mean, right now we have a very inefficient way of creating these new medications. But we've already shown it, and the Moderna vaccine is actually the best of the vaccines we've had. And it literally took two days to create. And we'll get to the point where we can test it out also quickly.
Speaker B: Are you impressed by alphafold and the solution to the protein folding, which essentially is simulating, modeling this primitive building block of life, which is a protein, and.
Speaker A: It'S 3d shape, it's pretty remarkable that they can actually predict what the 3d shape of these things are. But they did it with the same type of neural net that won, for example, the go test.
Speaker B: So it's all the same.
Speaker A: It's all the same. They took that same thing and just changed the rules to chess. And within a couple of days it now played a master level of chess, greater than any human being. And the same thing then worked for alpha phone, which no human had done. I mean, human beings could do the best. Humans could maybe do 15 20% of figuring out what the shape would be, and after a few takes, it ultimately did just about 100%.
Speaker B: Do you still think the singularity will happen in 2045? And what does that look like?
Speaker A: Once we can amplify our brain with computers, directly, which will happen in the 2030s. That's going to keep growing. It's another whole theme, which is the exponential growth of computing power.
Speaker B: Yeah. So looking at price performance of computation from 1939 to 2021.
Speaker A: Right. So that starts with the very first computer actually created by German during World War two. You might have thought that that might be significant, but actually, the Germans didn't think computers were significant, and they completely rejected it. The second one was also the Zusa two.
Speaker B: And by the way, we're looking at a plot with the x Axis being the year from 1935 to 2025. And on the y axis and log scale is competition per second, perennial constant dollar. So dollar normalized inflation, and it's growing linearly on the log scale, which means it's growing exponentially.
Speaker A: The third one was the british computer, which the Allies did take very seriously, and it cracked the german code and enabled the British to win the battle of Britain, which otherwise absolutely would not have happened if they hadn't cracked the code using that computer. But that's an exponential graph. So a straight line on that graph is exponential growth. And you see 80 years of exponential growth, and I would say about every five years. And this happened shortly before the pandemic. People saying, well, they call it Moore's law, which is not the correct, because that's not all intel. In fact, it started decades before intel was even created. It wasn't with transistors formed into a grid.
Speaker B: It was not just transistor count or transistor size.
Speaker A: Right. It started with relays, then went to vacuum tubes, then went to individual transistors, and then to integrated circuits. And integrated circuits actually starts, like, in the middle of this graph, and has nothing to do with intel. Intel actually was a key part of this, but a few years ago, they stopped making the fastest chips. But if you take the fastest chip of any technology in that year, you get this kind of graph, and it's definitely continuing for 80 years.
Speaker B: So you don't think Moore's law, broadly defined as dead. It's been declared dead multiple times throughout this process.
Speaker A: I don't like the term Moore's law because it has nothing to do with Moore or with intel. But, yes, the exponential growth of computing is continuing and has never stopped.
Speaker B: And from various sources.
Speaker A: I mean, it went through World War two, it went through global recessions. It's just continuing. And if you continue that out, along with software gains, which is all nother issue, and they really multiply. Whatever you get from software gains, you multiply by the computer gains, you get faster and faster speed. This is actually the fastest computer models that have been created, and that actually expands roughly twice a year. Like every six months, it expands by two.
Speaker B: So we're looking at a plot from 2010 to 2022. On the x axis is the publication date of the model, and the perhaps sometimes the actual paper associated with it. And on the y axis is training compute and flops. And so, basically, this is looking at the increase in not transistors, but the computational power of neural networks.
Speaker A: Yes, the computational power that created these models. And that's doubled every six months, which.
Speaker B: Is even faster than transistor division.
Speaker A: Yeah. Now, actually, since it goes faster than the amount of cost, this has actually become a greater investment to create these. But at any rate, by the time we get to 2045, we'll be able to multiply our intelligence many millions fold. And it's just very hard to imagine what that will be like.
Speaker B: And that's the singularity where we can't even imagine.
Speaker A: Right. That's why we call it the singularity, because the singularity in physics, something gets sucked into its singularity, and you can't tell what's going on in there because no information can get out of it. There's various problems with that, but that's the idea. It's too much beyond what we can imagine.
Speaker B: Do you think it's possible we don't notice that what the singularity actually feels like is we just live through it with exponentially increasing cognitive capabilities? And we almost, because everything is moving so quickly, aren't really able to introspect that our life has changed.
Speaker A: Yeah, but, I mean, we will have that much greater capacity to understand things, so we should be able to look.
Speaker B: Back, looking at history, understand history.
Speaker A: But we will need people basically like you and me, to actually think about these things.
Speaker B: But we might be distracted by all the other sources of entertainment and fun, because the exponential power of intellect is growing.
Speaker A: But also, that'll be a lot of fun.
Speaker B: The amount of ways you can have, you know, I mean, we already.
Speaker A: Have a lot of fun with computer games and so on that are really quite remarkable.
Speaker B: What do you think about the digital world, the metaverse, virtual reality? Will that have a component in this, or will most of our advancement be in physical reality?
Speaker A: Well, that's a little bit like second life. Although the second life actually didn't work very well because it couldn't actually handle too many people. And I don't think the metaverse has come to being. I think there will be something like that. It won't necessarily be from that one company. I mean, there's going to be competitors, but yes, we're going to live increasingly online, and particularly if our brains are online. I mean, how could we not be online?
Speaker B: Do you think it's possible that given this merger with AI, most of our meaningful interactions will be in this virtual world most of our life? We fall in love, we make friends, we come up with ideas, we do collaborations, we have fun.
Speaker A: I actually know somebody who's marrying somebody that they never met. I think they just met her briefly before the wedding, but she actually fell in love with this other person, never having met them. And I think it's. I think the love is real.
Speaker B: That's a beautiful story. But do you think that story is one that might be experienced as opposed to by hundreds of thousands of people, but instead by hundreds of millions of people?
Speaker A: I mean, it really gives you appreciation for these virtual ways of communicating, and if anybody can do it, then it's really not such a freak story. So I think more and more people.
Speaker B: Will do that, but that's turning our back on our entire history of evolution. The old days, we used to fall in love by holding hands and sitting by the fire, that kind of stuff.
Speaker A: Here, actually, I have five patents on where you can hold hands even if you're separated.
Speaker B: Great. So the touch, the sense, it's all just senses, it's all just.
Speaker A: It's not just that you're touching someone or not. There's a whole way of doing it, and it's very subtle, but ultimately, we can emulate all of that.
Speaker B: Are you excited by that future? Do you worry about that future?
Speaker A: I have certain worries about the future, but not that virtual touch.
Speaker B: Well, I agree with you. You described six stages in the evolution of information processing in the universe. As you started to describe. Can you maybe talk through some of those stages, from the physics and chemistry to DNA and brains and then to the. To the very end, to the very beautiful end of this process?
Speaker A: Well, it actually gets more rapid. So physics and chemistry, that's how we started.
Speaker B: From the very beginning of the universe.
Speaker A: We had lots of electrons and various things traveling around, and that took many billions of years, kind of jumping ahead here to some of the last stages where we have things like love and creativity. It's really quite remarkable that that happens. But finally, physics and chemistry created biology and DNA. And now you had actually one type of molecule that described the cutting edge of this process. And we go from physics and chemistry to biology, and finally biology created brainstor. I mean, not everything that's created by biology, has a brain, but eventually brains.
Speaker B: Came along and all of this is happening faster and faster.
Speaker A: Yeah, it created increasingly complex organisms. Another key thing is actually not just brains, but our thumb, because there's a lot of animals with brains even bigger than humans. Elephants have a bigger brain, whales have a bigger brain, but they've not created technology because they don't have a thumb. So that's one of the really key elements in the evolution of humans, this.
Speaker B: Physical manipulator device that's useful for puzzle solving in the physicals reality.
Speaker A: So I could think I could look at a tree and go, oh, I could actually trip that branch down and eliminate the leaves and carve a tip on it. And it would create technology, and you can't do that if you don't have a thumb.
Speaker B: Yeah.
Speaker A: So thumbs then created technology, and technology also had a memory, and now those memories are competing with the scale and scope of human beings. And ultimately we'll go beyond it. And then we're going to merge human technology with human intelligence and understand how human intelligence works, which I think we already do, and we're putting that into our human technology.
Speaker B: So create the technology inspired by our own intelligence, and then that technology supersedes us in terms of its capabilities and we ride along, or do you ultimately see it as we ride along?
Speaker A: But a lot of people don't see that. They say, well, you got humans and you got machines, and there's no way we can ultimately compete with humans. And you can already see that. Lee Sadal, who's the best go player in the world, says he's not going to play go anymore because playing go for human, that was the ultimate in intelligence because no one else could do that. But now a machine can actually go way beyond him. And so he says, well, there's no point playing it anymore.
Speaker B: That may be more true for games than it is for life. I think there's a lot of benefit to working together with AI in regular life. So if you were to put a probability on it, is it more likely that we merge with AI or AI replaces us?
Speaker A: A lot of people just think computers come along and they compete with them. We can't really compete, and that's the end of it. As opposed to them increasing our abilities. And if you look at most technology, it increases our abilities. I mean, look at the history of work. Look at what people did 100 years ago. Does any of that exist anymore? I mean, if you were to predict that all of these jobs would go away and would be done by machines, people would say, well, no one's going to have jobs and it's going to be massive unemployment. But I show in this book that's coming out, the amount of people that are working, even as a percentage of the population has gone way up.
Speaker B: We're looking at the x axis year from 1774 to 2024. And on the y axis, personal income per capita in constant dollars. And it's growing super linearly.
Speaker A: Yeah, 2021 constant dollars and it's gone way up. That's not what you would predict, given that we would predict that all these jobs would go away. But the reason it's gone up is because we basically enhanced our own capabilities by using these machines as opposed to them just competing with us. That's a key way in which we're going to be able to become far smarter than we are now by increasing the number of different parameters we can consider in making a decision.
Speaker B: I was very fortunate, I am very fortunate to be able to get a glimpse preview of your upcoming book, singularities nearer. And one of the themes, outside of just discussing the increasing exponential growth of technology, one of the themes is that things are getting better in all aspects of life. And you talk just about, just about this. So one of the things you're saying is with jobs. So let me just ask about that. There is a big concern that automation, especially powerful AI, will get rid of jobs. People will lose jobs. And as you were saying, the senses throughout history of the 20th century, automation did not do that. Ultimately, the question is, will this time be different?
Speaker A: Right? That is the question, will this time be different? And it really has to do with how quickly we can merge with this type of intelligence, whether lambda or GPT-3 is out there, and maybe it's overcome some of its key problems and we really have an enhanced human intelligence. That might be a negative scenario, but I mean, that's why we create technologies to enhance ourselves. And I believe we will be enhanced. We're not just going to sit here with 300 million modules in our Neocortex. We're going to be able to go beyond that because that's useful. But we can multiply that by ten hundred thousand, a million. And you might think, well, what's the point of doing that? It's like asking somebody that's never heard music, well, what's the value of music? I mean, you can't appreciate it until you've created it.
Speaker B: There's some worry that there will be a wealth disparity, a class or wealth disparity. Only the rich people will be basically the rich people will first have access to this kind of thing, and then because of this kind of thing, because the ability to merge will get richer exponentially faster.
Speaker A: And I say that's just like cell phones. I mean, there's like 4 billion cell phones in the world today. In fact, when cell phones first came out, you had to be fairly wealthy. They weren't very inexpensive, so you had to have some wealth in order to afford them.
Speaker B: Yeah, there were these big, sexy phones.
Speaker A: And they didn't work very well. They did almost nothing. So you can only afford these things if you're wealthy at a point where they really don't work very well.
Speaker B: So achieving scale and making it inexpensive is part of making the thing work well.
Speaker A: Exactly. So these are not totally cheap, but they're pretty cheap. You can get them for a few.
Speaker B: Hundred dollars, especially given the kind of things it provides for you. There's a lot of people in the third world that have very little, but they have a smartphone.
Speaker A: Yeah, absolutely.
Speaker B: And the same will be true with AI.
Speaker A: I mean, I see homeless people have their own cell phones.
Speaker B: Yeah. So your sense is any kind of advanced technology will take the same trajectory.
Speaker A: Right. It ultimately becomes cheap and will be affordable. I probably would not be the first person to put something in my brain to connect to computers because I think it will have limitations. But once it's really perfected, and at that point, it'll be pretty inexpensive, I think it'll be pretty affordable.
Speaker B: So in which other ways, as you outline your book, is life getting better? Because I think, well, I mean, I.
Speaker A: Have 50 charts in there where everything is getting better.
Speaker B: I think there's a kind of cynicism about, like, even if we look at extreme poverty, for example, for example, this.
Speaker A: Is actually a poll taken on extreme poverty. And the people were asked, has poverty gotten better or worse?
Speaker B: And the options are increased by 50%, increased by 25%, remain the same, decreased by 25%, decreased by 50%. If you're watching this or listening to this, try to try to vote for yourself.
Speaker A: 70% thought it had gotten worse. And that's the general impression. 88% thought it had gotten worse or remained the same. Only 1% thought it decreased by 50%. And that is the answer. It actually decreased by 50%.
Speaker B: So only 1% of people got the right optimistic estimate of how poverty is right.
Speaker A: And this is the reality. And it's true of almost everything you look at. You don't want to go back 100 years or 50 years. Things were quite miserable then. But we tend not to remember that.
Speaker B: So literacy rate increasing over the past few centuries across all the different nations, nearly to 100%. Across many of the nations in the.
Speaker A: World, it's gone way up. Average years of education have gone way up. Life expectancy is also increasing. Life expectancy was 48 in 1900 and.
Speaker B: Is over 80 now.
Speaker A: And it's going to continue to go up, particularly as we get into more advanced stages of simulated biology for life expectancy.
Speaker B: These trends are the same for at birth, age one, age five, age ten. So it's not just the infant mortality.
Speaker A: And I have 50 more graphs in the book about all kinds of things, even spread of democracy, which might bring up some sort of controversial issues. It still has gone way up.
Speaker B: Well, that one has gone way up, but that one is a bumpy road.
Speaker A: Right, exactly. And somebody might represent democracy and go backwards, but we basically had no democracies before the creation of the United States, which was a little over two centuries ago, which in the scale of human history isn't that long.
Speaker B: Do you think super intelligent systems will help with democracy? So what is democracy? Democracy is giving a voice to the populace and having their ideas, having their beliefs, having their views represented.
Speaker A: Well, I hope so. I mean, we've seen social networks can spread conspiracy theories which have been quite negative, for example, being against any kind of stuff that would help your health.
Speaker B: So those kinds of ideas have on social media, what you notice is they increase engagement, so dramatic division increases engagement. Do you worry about AI systems that will learn to maximize that division?
Speaker A: I mean, I do have some concerns about this, and I have a chapter in the book about the perils of advanced Aih. Spreading misinformation on social networks is one of them, but there are many others.
Speaker B: What's the one that worries you the most that we should think about to try to avoid?
Speaker A: Well, it's hard to choose. We do have the nuclear power that evolved when I was a child. I remember we would actually do these drills against a nuclear war. We'd get under our desks and put our hands behind our heads to protect us from a nuclear war. Seemed to work. We're still around, so.
Speaker B: You'Re protected, but.
Speaker A: That'S still a concern. There are key dangerous situations that can take place in biology. Someone could create a virus that's very. I mean, we have viruses that are hard to spread and they can be very dangerous. And we have viruses that are easy to spread to, but they're not so dangerous. Somebody could create something that would be very easy to spread and very dangerous and be very hard to stop. It could be something that would spread without people noticing, because people could get it, they'd have no symptoms, and then everybody would get it, and then symptoms would occur maybe a month later. So, I mean, and that actually doesn't occur normally, because if we were to have a problem with that, we wouldn't exist. So the fact that humans exist means that we don't have viruses that can spread easily and kill us, because otherwise we wouldn't exist.
Speaker B: Yeah, viruses don't want to do that. They want to spread and keep the host alive somewhat.
Speaker A: So you can describe various dangers with biology, also nanotechnology, which we actually haven't experienced yet, but there are people that creating nanotechnology, and I described that in the book.
Speaker B: Now you're excited by the possibilities of nanotechnology, of nanobots, of being able to do things inside our body, inside our mind. That's going to help. What's exciting, what's terrifying about nanobots, what's.
Speaker A: Exciting is that that's a way to communicate with our neocortex, because each neocortex is pretty small, and you need a small entity that can actually get in there and establish a communication channel. And that's going to really be necessary to connect our brains to AI within ourselves, because otherwise it would be hard for us to compete with it in.
Speaker B: A high bandwidth way.
Speaker A: Yeah. And that's key, actually, because a lot of the things like neuralink are really not high bandwidth yet.
Speaker B: So nanobots is the way you achieve high bandwidth. How much intelligence would those nanobots have?
Speaker A: Yeah, they don't need a lot, just enough to basically establish communication channel to one nanobot.
Speaker B: So it's primarily about communication between external computing devices and our biological thinking machine. What worries you about nanobots? Is it similar to, with the viruses?
Speaker A: Well, I mean, there's the great goo challenge. Yes. If you had a. A nanobot that wanted to create any kind of entity and repeat itself and was able to operate in a natural environment, it could turn everything into that entity and basically destroy all biological life.
Speaker B: So you mentioned nuclear weapons.
Speaker A: Yeah.
Speaker B: I'd love to hear your opinion about the 21st century and whether you think we might destroy ourselves, and maybe your opinion, if it has changed by looking at what's going on in Ukraine, that we could have a hot war with nuclear powers involved, and the tensions building and the seeming forgetting of how terrifying and destructive nuclear weapons are. Do you think humans might destroy ourselves in the 21st century? And if we do, how, and how do we avoid it?
Speaker A: I don't think that's going to happen, despite the terrors of that war. It is a possibility, but, I mean, I don't.
Speaker B: It's unlikely in your mind?
Speaker A: Yeah. Even with the tensions we've had with this one nuclear power plant that's been taken over, it's very tense, but I don't actually see a lot of people worrying that that's going to happen. I think we'll avoid that. We had two nuclear bombs go off in 45, so now we're 77 years later.
Speaker B: Yeah, we're doing pretty good.
Speaker A: We've never had another one go off through anger.
Speaker B: But people forget. People forget the lessons of history.
Speaker A: Well, yeah, I am worried about it. That is definitely a challenge.
Speaker B: But you believe that we'll make it out and ultimately, super intelligent AI will help us make it out as opposed to destroy us?
Speaker A: I think so. But we do have to be mindful of these dangers, and there are other dangers besides nuclear weapons.
Speaker B: So to get back to merging with AI, will we be able to upload our mind in a computer in a way where we might even transcend the constraints of our bodies? So copy our mind into a computer and leave the body behind.
Speaker A: Let me describe one thing I've already done with my father.
Speaker B: Yeah, it's a great story.
Speaker A: So we created a technology, this is public, came out, I think, six years ago, where you could ask any question, and the release product, which I think is still on the market, it would read 200,000 books and then find the one sentence in 200,000 books that best answered your question. It's actually quite interesting. You can ask all kinds of questions and you get the best answer in 200,000 books. But I was also able to take it and not go through 200,000 books, but go through a book that I put together, which is basically everything my father had written. So everything he had written had gathered, and we created a book, everything that Frederick Kurzweil had written. Now, I didn't think this actually would work that well, because stuff he'd written was stuff about how to lay out. I mean, he directed choral groups and music groups, and he would be laying out how the people should. Where they should sit and how to fund this, all kinds of things that really didn't seem that interesting. And yet when you ask a question, it would go through it, and it would actually give you a very good answer. So I said, well, who's the most interesting composer? And he said, well, definitely Brahms. And he would go on about how Brahms was fabulous and talk about the importance of music education.
Speaker B: So you could have essentially answered a conversation with him.
Speaker A: Can I have a conversation with him? Which was actually more interesting than talking to him, because if you talk to him, he'd be concerned about how they're going to lay out this property to give a coral group.
Speaker B: He'd be concerned about the day to day versus the big questions.
Speaker A: Exactly, yeah.
Speaker B: And you did ask about the meaning of life, and he answered love.
Speaker A: Yeah.
Speaker B: Do you miss him?
Speaker A: Yes, I do. You know, you get used to missing somebody after 52 years. And I didn't really have intelligent conversations with him until later in life. In the last few years, he was sick, which meant he was home a lot. And I was actually able to talk to him about different things, like music and other things. So I miss that very much.
Speaker B: What did you learn about life from your father? What part of him is with you now?
Speaker A: He was devoted to music, and when he would create something to music, it put him in a different world. Otherwise, he was very shy. And if people got together, he tended not to interact with people just because of his shyness. But when he created music, he was like a different person.
Speaker B: Do you have that in you, that kind of light that shines?
Speaker A: I mean, I got involved with technology at age five.
Speaker B: And you fell in love with it in the same way he did with music.
Speaker A: Yeah, I remember this actually happened with my grandmother. She had a manual typewriter, and she wrote a book, one life is not enough. It's actually a good title for a book I might write. And it was about a school she had created. Well, actually, her mother created it. So my mother's mother's mother created the school in 1868, and it was the first school in Europe that provided higher education for girls. It went through 14th grade. If you were a girl and you were lucky enough to get an education at all, it would go through, like, 9th grade. And many people didn't have any education as a girl. This went through 14th grade. Her mother created it. She took it over, and the book was about the history of the school and her involvement with it. When she presented it to me, I was not so interested in the story of the school, but I was totally amazed with this manual typewriter. I mean, here was something you could put a blank piece of paper into, and you could turn it into something that looked like it came from a book, and you could actually type on it, and it looked like it came from a book. It was just amazing to me, and I could see, actually, how it worked. And I was also interested in magic, but in magic, if somebody actually knows how it works, the magic goes away. The magic doesnt stay there if you actually understand how it works. But he was technology. I didnt have that word when I was five or six.
Speaker B: And the magic was still there for you.
Speaker A: The magic was still there even if you knew how it worked. So I became totally interested in this and then went around, collected little pieces of mechanical objects from bicycles, from broken radios. I would go through the neighborhood. This was an era where you would allow five or six year olds to roam through the neighborhood and do this. We don't do that anymore. But I didn't know how to put them together. I said, if I could just figure out how to put these things together, I could solve any problem. I actually remember talking to these very old girls, I think they were ten, and telling them, if I could just figure this out, we could fly, we could do anything. And they said, well, you have quite an imagination. And then when I was in third grade, so it was like eight, created a virtual reality theater where people could come on stage and they could move their arms, and all of it was controlled through one control box. It was all done with mechanical technology, and it was a big hit in my third grade class. And then I went on to do things in junior high school science fairs and high school science fairs, where I won the Westinghouse science talent search. So, I mean, I became committed to technology when I was five or six years old.
Speaker B: You've talked about how you use lucid dreaming to think, to come up with ideas as a source of creativity, because you maybe talked through that, maybe the process of how to. You've invented a lot of things. You've came up and thought through some very interesting ideas. What advice would you give? Or can you speak to the process of thinking, of how to think, how to think creatively?
Speaker A: Well, I mean, sometimes I will think through in a dream and try to interpret that, but I think the key issue that I would tell younger people is to put yourself in the position that what you're trying to create already exists, and then you're explaining how it works. Exactly.
Speaker B: That's really interesting. You paint a world that you would like to exist, you think it exists and reverse engineering, and then you actually.
Speaker A: Imagine you're giving a speech about how you created this. Well, you'd have to then work backwards as to how you would create it in order to make it work.
Speaker B: That's brilliant. And that requires some imagination, too, some first principles thinking. You have to visualize that world. That's really interesting.
Speaker A: And generally, when I talk about things, we're trying to invent, I would use the present tense as if it already exists, not just to give myself that confidence, but everybody else who's working on it. We just have to kind of do all the steps in order to make it actual.
Speaker B: How much of a good idea is about timing? How much is it about your genius versus that its time has come?
Speaker A: Timing is very important. I mean, thats really why I got into futurism. I didnt, I wasn't inherently a futurist. That was not really my goal. It's really to figure out when things are feasible. We see that now with large scale models, the very large scale models like GPT-3 it started two years ago. Four years ago, it wasn't feasible. In fact, they did create GPT-2 which didn't work. So it required a certain amount of timing having to do with this exponential growth of computing power.
Speaker B: So futurism in some sense, is a study of timing, trying to understand how the world will evolve and when will the capacity for certain ideas, and that's.
Speaker A: Become a thing in itself than to try to time things in the future. But really, its original purpose was to tie my products. I mean, I did OCR in the 1970s because OCR doesnt require a lot of computation.
Speaker B: Optical character recognition.
Speaker A: Yeah. So we were able to do that in the seventies, and I waited till the eighties to address speech recognition, since that requires more computation.
Speaker B: So you were thinking through timing when you're developing those things?
Speaker A: Yeah.
Speaker B: Has this time come?
Speaker A: Yeah.
Speaker B: And that's how you've developed that brain power to start to think in a futurist sense. When, how will the world look like in 2045 and work backwards and how it gets there.
Speaker A: But that has become a thing in itself, because looking at what things will be like in the future reflects such dramatic changes in how humans will live. That was worth communicating also.
Speaker B: So you developed that muscle of predicting the future and then apply it broadly and start to discuss how it changes the world of technology, how it changes the world of human life on earth. In Danielle, one of your books, you write about someone who has the courage to question assumptions that limit human imagination to solve problems. And you also give advice on how each of us can have this kind of courage.
Speaker A: Well, it's good that you picked that quote, because I think that does symbolize what Danielle is about, courage.
Speaker B: So how can each of us have that courage to question assumptions?
Speaker A: I mean, we see that when people can go beyond the current realm and create something that's new, I mean, take Uber, for example. Before that existed, you never thought that that would be feasible. And it did require changes in the way people work.
Speaker B: Is there practical advices you give in the book about what each of us can do to be a Danielle?
Speaker A: Well, she looks at the situation and tries to imagine how she can overcome various obstacles, and then she goes for it. And she's a very good communicator, so she can communicate these ideas to other people.
Speaker B: And there's practical advice of learning to program and recording your life and things of this nature. Become a physicist. So you list a bunch of different suggestions of how to throw yourself into this world.
Speaker A: Yeah, I mean, it's kind of a idea how young people can actually change the world by learning all of these different skills.
Speaker B: And at the core of that is the belief that you can change the world, that your mind, your body can change the world.
Speaker A: Yeah, that's right.
Speaker B: And not letting anyone else tell you otherwise.
Speaker A: That's very good. Exactly.
Speaker B: When we upload the story you told about your dad and having a conversation with him, we're talking about uploading your mind to the computer. Do you think we'll have a future with something you call afterlife? We'll have avatars that mimic increasingly better and better our behavior, our appearance, all that kind of stuff. Even those are perhaps no longer with us.
Speaker A: Yes. I mean, we need some information about them. I mean, think about my father. I have what he wrote. Now, he didnt have a word processor, so he didnt actually write that much. And our memories of him arent perfect. So how do you even know if youve created something thats satisfactory? Now, you could do a Frederick Kurzweil Turing test. He seems like Frederick Kurzweil to me. But the people who remember him, like me, don't have a perfect memory.
Speaker B: Is there such a thing as a perfect memory? Maybe the whole point is for him to make you feel a certain way.
Speaker A: Yeah, well, I think that would be the goal.
Speaker B: That's the connection we have with loved ones. It's not really based on very strict definition of truth. It's more about the experiences we share. And they get morphed through memory, but ultimately they make us smile.
Speaker A: I think we definitely can do that, and that would be very worthwhile.
Speaker B: So do you think we'll have a world of replicants, of copies? There'll be a bunch of raycourse walls. Like, I could hang out with one. I can download it for $5 and have a best friend, Ray. And you, the original cop, who wouldn't even know about it. Is that, do you think that world is, first of all, do you think that world is feasible and do you think there's ethical challenges there? Like, how would you feel about me hanging out with Ray Kurzweil and you not knowing about it?
Speaker A: Doesn't strike me as a problem.
Speaker B: Which.
Speaker A: You, the original, would you strike? Would that cause a problem for you?
Speaker B: No, I enjoy. I would really very much enjoy it.
Speaker A: No, not just hang out with me, but if somebody hanging out with you, a replicant of you.
Speaker B: Well, I think I would start. It sounds exciting. But then what if they start doing better than me and take over my friend group, and then, and then, because they may be an imperfect copy, or they're maybe more social or these kinds of things, and then I become like the old version. That's not nearly as exciting. Maybe they're a copy of the best version of me on a good day.
Speaker A: Yeah. But if you hang out with a replicant of me and that turned out to be successful, I'd feel proud of that person because it was based on me.
Speaker B: But it is a kind of death of this version of you.
Speaker A: Well, not necessarily. I mean, you can still be alive.
Speaker B: Right, but. And you would be proud. Okay, so it's like having kids and you're proud that they've done even more than you were able to do.
Speaker A: Yeah, exactly. It does bring up new issues, but it seems like an opportunity.
Speaker B: Well, that replicant should probably have the same rights as you do.
Speaker A: Well, that gets into a whole issue, because when a replicant occurs, they're not necessarily going to have your rights. And if a replicant occurs, as somebody who's already dead, do they have all the obligations that the original person had? Do they have all the agreements that they had?
Speaker B: So I think you're going to have to have laws that say, yes, there has to be. If you want to create a replicant, they have to have all the same rights as human rights.
Speaker A: Well, you don't know. Someone can create a replicant and say, well, it's a replicant. But I didn't bother getting their rights.
Speaker B: But that would be illegal. I mean, like, if you do that, you have to do that in the black market if you want to get an official replicant.
Speaker A: Okay, it's not so easy. Suppose you create multiple replicants. The original writes may be for one person and not for a whole group of people.
Speaker B: Sure. So there has to be at least one. And then all the other ones kind of share the rights. Yeah, I just don't think that that's very difficult to conceive for us humans the idea that you can create a.
Speaker A: Replicant that has certain, I mean, I've talked to people about this, including my wife, who would like to get back her father, and she doesn't worry about who has rights to what. She would have somebody that she could visit with and might give her some satisfaction, and they wouldn't, she wouldn't care about any of these other rights.
Speaker B: What does your wife think about multiple arraycourse walls? You had that discussion.
Speaker A: I wouldn't address that with her.
Speaker B: I think ultimately, that's an important question. Loved ones, how they feel about, there's something about love.
Speaker A: Well, that's the key thing, right? If the loved one's rejected, it's not going to work very well. So the loved ones really are the key determinant whether or not this works or not.
Speaker B: But there's also ethical rules. We have to contend with idea and we have to contend with that idea, with AI.
Speaker A: But what's going to motivate it is, I mean, I talk to people who really miss people who are gone, and they would love to get something back, even if it isn't perfect. And that's what's going to motivate this.
Speaker B: And that person lives on in some form. And the more data we have, the more we're able to reconstruct that person and allow them to live on.
Speaker A: Right. And eventually, as we go forward, we're going to have more and more of this data because we're going to have nanobots that are inside our neocortex, and we're going to collect a lot of data. In fact, anything that's data is always collected.
Speaker B: There is something a little bit sad which is becoming, or maybe it's hopeful, which is more and more common these days, which when a person passes away, you have their Twitter account. When you have the last tweet, they tweeted, like something they, and you can.
Speaker A: Recreate them now with large language models and so on. I mean, you can create somebody that's just like them and can actually continue to communicate.
Speaker B: I think that's really exciting because I think in some sense, like, if I were to die today, in some sense, I would continue on. If I continued tweeting, I tweet, therefore I am.
Speaker A: Yeah, well, I mean, that's one of the advantages of a replicant that can recreate the communications of that person.
Speaker B: Do you hope, do you think, do you hope humans will become a multi planetary species? You've talked about the phases, the six epochs, and one of them is reaching out into the stars in part, yes.
Speaker A: But the kind of attempts we're making now to go to other planetary objects doesn't excite me that much because it's not really advancing anything.
Speaker B: It's not efficient enough.
Speaker A: Yeah, and we're also putting out other human beings, which is a very inefficient way to explore these other objects. What I'm really talking about, in the 6th epoch, the universe wakes up. It's where we can spread our super intelligence throughout the universe. And that doesn't mean sending very soft, squishy creatures like humans.
Speaker B: The universe wakes up.
Speaker A: I mean, we would sense intelligence, masses of nanobots, which can then go out and colonize these other parts of the universe.
Speaker B: Do you think there's intelligent alien civilizations out there that our bots might meet?
Speaker A: My hunch is no. Most people say yes, absolutely. I mean, it's too big. And they'll cite the Drake equation, and I think in singularity is near. I have two analyses of the Drake equation, both with very reasonable assumptions, and one gives you thousands of advanced civilizations in each galaxy, and another one gives you one civilization. And we know of one. A lot of the analyses are forgetting the exponential growth of computation, because we've gone from where the fastest way I could send a message to somebody was with a pony, which was what, like a century and a half ago?
Speaker B: Yeah.
Speaker A: To the advanced civilization we have today. And if you accept what I've said, go forward a few decades, you can have absolutely fantastic amount of civilization compared to a pony. And that's in a couple hundred years.
Speaker B: Yeah. The speed and the scale of information transfer is just, is growing exponentially in a blink of an eye.
Speaker A: Now, think about these other civilizations. They're going to be spread out at cosmic times. So if something is, like, ahead of us or behind us, it could be ahead of us or behind us by maybe millions of years, which isn't that much. I mean, the world is billions of years old, 14 billion or something. So even a thousand years, if two or 300 years is enough to go from a pony to fantastic amount of civilization, we would see that. So, of other civilizations that have occurred, some might be behind us, but some might be ahead of us. If they're ahead of us, they're ahead of us by thousands, millions of years. And they would be so far beyond us, they would be doing galaxy wide engineering, but we don't see anything doing galaxy wide engineering.
Speaker B: Either they don't exist, or this very universe is a construction of an alien species. We're living inside a video game.
Speaker A: Well, that's another explanation that, yes, you've got some teenage kids and another civilization.
Speaker B: Do you find compelling the simulation hypothesis as a thought experiment, that we're living in a simulation?
Speaker A: The universe is computational, so we are an example in a computational world. Therefore it is a simulation, doesn't necessarily mean an experiment by some high school kid in another world, but it nonetheless is taking place in a computational world. And everything that's going on is basically a form of computation. So you really have to define what you mean by this whole world being a simulation.
Speaker B: Well, then it's the teenager that makes the video game. Us humans, with our current limited cognitive capability, have strive to understand ourselves, and we have created religions. We think of God, whatever that is. Do you think God exists? And if so, who is God?
Speaker A: I alluded to this before. We started out with lots of particles going around, and there's nothing that represents love and creativity. And somehow we've gotten into a world where love actually exists, and that has to do actually with consciousness, because you can't have love without consciousness. So to me, that's God. The fact that we have something where love, where you can be devoted to someone else and really feel that love, that's God. And if you look at the Old Testament, it was actually created by several different rabbinates in there. And I think they've identified three of them. One of them dealt with God as a person that you can make deals with, and he gets angry and he wreaks vengeance on various people, but two of them actually talk about God as a symbol of love and peace and harmony and so forth. That's how they describe God. So that's my view of God, not as a person in the sky that you can make deals with.
Speaker B: It's whatever the magic that goes from basic elements to things like consciousness and love. Do you think? One of the things I find extremely beautiful and powerful is cellular automata, which you also touch on. Do you think, whatever the heck happens in cellular automata, where interesting, complicated objects emerge, God is in there, too. The emergence of love in this seemingly privileged.
Speaker A: If the goal of creating a replicant is that they would love you and you would love them, there wouldn't be much point of doing it if that didn't happen.
Speaker B: But all of it. I guess what I'm saying about Celia automata is it's primitive building blocks, and they somehow create beautiful things. Is there some deep truth to that about how our universe works? Is the emergence from simple rules, beautiful, complex objects can emerge. Is that the thing that made us? Yeah, as we went through all the six phases of reality.
Speaker A: That's a good way to look at it. It does make some point to the whole value of having a universe.
Speaker B: Do you think about your own mortality? Are you afraid of it?
Speaker A: Yes, but I keep going back to my idea of being able to expand human life quickly enough in advance of our getting there longevity escape velocity, which we're not quite at yet, but I think we're actually pretty close, particularly with, for example, doing simulated biology. I think we can probably get there within, say, by the end of this decade, and that's my goal.
Speaker B: Do you hope to achieve the longevity escape velocity? Do you hope to achieve immortality?
Speaker A: Well, immortality is hard to say. I cant really come on your program saying ive done it. Ive achieved immortality because its never forever.
Speaker B: A long time, a long time of.
Speaker A: Living well, but wed like to actually advance human life expectancy, advance my life expectancy more than a year, every year. And I think we can get there within by the end of this decade.
Speaker B: How do you think we do it? So there's practical things and transcend the nine steps to living while forever. Your book, you describe just that. There's practical things like health, exercise, all those things.
Speaker A: I mean, we live in a body that doesn't last forever. There's no reason why it can't, though. And we're discovering things, I think that will extend it. But you do have to deal with, I mean, I've got various issues. I went to Mexico 40 years ago, developed salmonella. They created pancreatitis, which gave me a strange form of diabetes. It's nuts. Type one diabetes because that's an autoimmune disorder that destroys your pancreas. I don't have that. But it's also not type two diabetes because type two diabetes is your pancreas works fine, but your cells don't absorb the insulin. Well, I don't have that either. The pancreatitis, I had partially damaged my pancreas, but it was a one time thing. It didn't continue, and I've learned now how to control it. But so that's just something I had to do in order to continue to.
Speaker B: Exist since your particular biological system, you had to figure out a few hacks and the ideas that science would have to do that much better, actually.
Speaker A: Yeah. So, I mean, I do spend a lot of time just tinkering with my own body to keep it going. So I do think I'll last till the end of this decade and I think we'll achieve longevity escape velocity. I think that will start with people who are very diligent about this. Eventually it'll become sort of routine that people will be able to do it. So if you're talking about kids today, or even people in their twenties or thirties, it's really nothing. A very serious problem. I have had some discussions with relatives who were like, almost 100 and saying, well, we're working on it as quickly as possible, but I don't know if that's going to work.
Speaker B: Is there a case. This is a difficult question, but is there a case to be made against living forever? That a finite life, that mortality is a feature, not a bug, that living a shorter. So dying makes ice cream taste delicious, makes life intensely beautiful? More than most people believe that way.
Speaker A: Except if you present a death of anybody they care about or love, they find that extremely depressing. And I know people who feel that way 20, 30, 40 years later, they still want them back. So, I mean, death is not something to celebrate. But we've lived in a world where people just accept this. Life is short. You see it all the time on tv. Life's short, take advantage of it. And nobody accepts the fact that you could actually go beyond normal lifetimes. But anytime we talk about death or death of a person, even one death is a terrible tragedy. If you have somebody that lives to 100 years old, we still love them in return, and there's no limitation to that. In fact, these kinds of trends are going to provide greater and greater opportunity for everybody, even if we have more people.
Speaker B: So let me ask about an alien species or super intelligent AI 500 years from now that we'll look back and remember Ray Kurzweil, version zero before the replicant spread. How do you hope they remember you? In a hitchhiker's guide to the Galaxy summary of Ray Kurzweil. What do you hope your legacy is?
Speaker A: Well, I mean, I do hope to be around.
Speaker B: So that's some version of you. Yes. So do you think you'll be the same person around?
Speaker A: I mean, am I the same person I was when I was?
Speaker B: That's true. 20 or ten, you would be the same person in that same way. But, yes, we're different. We're different. All we have of that, all you have of that person is your memories, which are probably distorted in some way. Maybe you just remember the good parts. Depending on your psyche, you might focus on the bad parts, might focus on the good parts.
Speaker A: Right? But, I mean, I still have a relationship to the way I was when I was early, when I was younger.
Speaker B: How will you and the other super intelligent AI's remember you of today from 500 years ago. What do you hope to be remembered by this version of you before the singularity?
Speaker A: Well, I think it's expressed well in my books. Trying to create some new realities that people will accept. I mean, that's something that gives me great pleasure and greater insight into what makes humans valuable. I'm not the only person who's tempted to comment on that.
Speaker B: And optimism that permeates your work, optimism about the future. Ultimately, that optimism paves the way for building a better future.
Speaker A: Yeah, I agree with that.
Speaker B: So you asked your dad about the meaning of life, and he said, love. Let me ask you the same question. What's the meaning of life? Why are we here? This beautiful journey that we're on in phase four, reaching for phase five of this evolution of information processing, why?
Speaker A: I think I'd give the same answers as my father. Because if there were no love and we didn't care about anybody, there'd be no point existing.
Speaker B: Love is the meaning of life. The AI version of your dad had a good point. Well, I think that's a beautiful way to end it. Ray, thank you for your work. Thank you for being who you are. Thank you for dreaming about a beautiful future and creating it along the way. And thank you so much for spending your really valuable time with me today. This was awesome.
Speaker A: Well, it was my pleasure. And you have some great insights both into me and into humanity as well. So I appreciate that.
Speaker B: Thanks for listening to this conversation with Ray Kurzweil. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Isaac Asimov. It is change, continuous change, inevitable change, that is the dominant factor in society today. No sensible decision can be made any longer without taking into account not only the world as it is, but the world as it will be. This, in turn means that our statesmen, our businessmen, our everymande must take on a science fictional way of thinking. Thank you for listening and hope to see you next time.
