Speaker A: The following is a conversation with Grant Sanderson. He's a math educator and creator of three Blue one Brown, a popular YouTube channel that uses programmatically animated visualizations to explain concepts in linear algebra, calculus, and other fields of mathematics. This is the artificial intelligence podcast. If you enjoy it, subscribe on YouTube. Give us five stars on Apple Podcast, follow on Spotify, support on Patreon, or simply connect with me on Twitter at Lex Friedman spelled f r I d m A N. I recently started doing ads at the end of the introduction. I'll do one or two minutes after introducing the episode, and never any ads in the middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash app, the number one finance app in the App Store. I personally use cash app to send money to friends, but you can also use it to buy, sell and deposit bitcoin in just seconds. Cash app also has an investing feature. You can buy fractions of a stock, say $1 worth, no matter what the stock price is. Brokerage services are provided by Cash app Investing, a subsidiary of Square and member SIPC. I'm excited to be working with Cash app to support one of my favorite organizations called first, best known for their first robotics and Lego competitions. They educate and inspire hundreds of thousands of students in over 110 countries and have a perfect rating on charity Navigator, which means the donated money is used to maximum effectiveness. When you get cash app from the app store, Google Play and use code Lexpodcast, you'll get $10. And cash app will also donate $10 to first, which, again, is an organization that I've personally seen inspire girls and boys to dream of engineering a better world. And now here's my conversation with Grant Sanderson.
Speaker B: If there's intelligent life out there in the universe, do you think their mathematics is different than ours?
Speaker C: Jumping right in. I think it's probably very different. There's an obvious sense the notation is different. Right. I think notation can guide what the math itself is. I think it has everything to do with the form of their existence. Right.
Speaker B: Do you think they have basic arithmetic? Sorry, interrupt.
Speaker C: Yeah. So I think they count, right? I think notions like one, two, three, the natural numbers, that's extremely, well, natural. That's almost why we put that name to it. As soon as you can count, you have a notion of repetition, right? Because you can count by two, two times, or three times. And so you have this notion of repeating, the idea of counting, which brings you addition and multiplication. I think the way that we extend to the real numbers, there's a little bit of choice in that. So there's this funny number system called the surreal numbers that it captures the idea of continuity. It's a distinct mathematical object. You could very well model the universe in motion of planets with that as the backend of your math. And you still have the same interface with the front end of what physical laws you're trying to, or what physical phenomena you're trying to describe with math. And I wonder if the little glimpses that we have of what choices you can make along the way based on what different mathematicians have brought to the table, is just scratching the surface of what the different possibilities are. If you have a completely different mode of thought or a mode of interacting.
Speaker B: With the universe, and you think notation is a key part of the journey that we've taken through mathematic, I think.
Speaker C: That'S the most salient part that you'd notice at first. I think the mode of thought is going to influence things more than the notation itself, but notation actually carries a lot of weight when it comes to how we think about things, more so than we usually give it credit for. I would be comfortable saying, do you.
Speaker B: Have a favorite or least favorite piece of notation in terms of its effectiveness?
Speaker C: Yeah. Yeah. Well, so least favorite one that I've been thinking a lot about, that will be a video. I don't know when, but we'll see the number e. We write the function e to the x, this general exponential function with a notation e to the x. That implies you should think about a particular number, this constant of nature, and you repeatedly multiply it by itself. And then you say, oh, what's e to the square root of two? And you're like, oh, well, we've extended the idea of repeated multiplication. That's. That's all nice. That's all nice and well, but very famously, you have, like, e to the PI I, and you're like, well, we're extending the idea of repeated multiplication into the complex numbers. Yeah, you can think about it that way. In reality, I think that it's just the wrong way of, um, notationally representing this function, the exponential function, which itself could be represented a number of different ways. You can think about it in terms of the problem. It solves a certain very simple differential equation, which often yields way more insight than trying to twist the idea of repeated multiplication. Like, take its arm and put it behind its back and throw it on the desk and be like, you will apply to complex numbers. Right. That's nothing I don't think that's pedagogically helpful.
Speaker B: So the repeater multiplication is actually missing the main point, the power of e to the s. Yes.
Speaker C: I mean, what it addresses is things where the rate at which something changes depends on its own value, but more specifically, it depends on it linearly. So, for example, if you have a population that's growing, and the rate at which it grows depends on how many members of the population are already there, it looks like this nice exponential curve. It makes sense to talk about repeated multiplication because you say, how much is there? After one year, two years, three years, you're multiplying by something. The relationship can be a little bit different sometimes where, let's say you've got a ball on a string, like a game of tetherball going around a rope, and you say its velocity is always perpendicular to its position. That's another way of describing its rate of change as being related to where it is. But it's a different operation. You're not scaling it. It's a rotation. It's this 90 degree rotation. That's what the whole idea of complex exponentiation is trying to capture. But it's obfuscated in the notation. When what it's actually saying, like, if you really parse something like e to the PI I, what it's saying is choose an origin. Always move perpendicular to the vector from that origin to you. Okay. Then when you walk PI times that radius, you'll be halfway around. Like, that's what it's saying. It's kind of the. You turn 90 degrees and you walk. You'll be going in a circle. That's the phenomenon that it's describing. But trying to twist the idea of repeatedly multiplying a constant into that. I can't even think of the number of human hours, of intelligent human hours that have been wasted trying to parse that to their own liking and desire among scientists or electrical engineers or students everywhere. Which, if the notation were a little different or the way that this whole function was introduced from the get go, were framed differently, I think could have been avoided. Right.
Speaker B: And you're talking about the most beautiful equation in mathematics. But it's still pretty mysterious, isn't it? Like, you're making it seem like it's a notational.
Speaker C: It's not mysterious. I think the notation makes it mysterious. I don't think it's. I think the fact that it represents. It's pretty. It's not like the most beautiful thing in the world, but it's quite pretty. The idea that if you take the linear operation of a 90 degree rotation and then you do this general exponentiation thing to it, that what you get are all the other kinds of rotation, which is basically to say, if your velocity vector is perpendicular to your position vector, you walk in a circle. That's pretty. It's not the most beautiful thing in the world, but it's quite pretty.
Speaker B: The beauty of it, I think, comes from perhaps the awkwardness of the notation somehow still, nevertheless coming together nicely because you have, like several disciplines coming together in a single equation. Well, I think in a sense, historically speaking, that's true.
Speaker C: So the number e is significant. It shows up in probability all the time. It shows up in calculus all the time. It is significant. You're seeing it mated with PI, this geometric constant. And I like the imaginary number and such. I think what's really happening there is the way that e shows up is when you have things like exponential growth and decay, right? It's when this, um, relation that something's rate of change has to itself is a simple scaling. Right. Um, a similar law also describes circular motion. Because we have bad notation. We use the residue of how it shows up in the context of self reinforcing growth, like a population growing or compound interest. The constant associated with that is awkwardly placed into the context of how rotation comes about, because they both come from pretty similar equations. And so what we see is the e and the PI juxtaposed a little bit closer than they would be with a purely natural representation, I would think. Here's how I would describe the relation between the two. You've got a very important function we might call exp. That's like the exponential function. When you plug in one, you get this nice constant called e, that shows up in probability and calculus if you try to move in the imaginary direction. It's periodic and the period is tau. So those are these two constants associated with the same central function, but for kind of unrelated reasons. Right, and not unrelated, but like orthogonal reasons. One of them is what happens when you're moving in the real direction. One's what happens when you move in the imaginary direction and like, yeah, those are related. They're not as related as the famous equation seems to think it is. It's sort of putting all of the children in one bed, and they'd kind of like to sleep in separate beds if they had the choice. But you see them all there, and there is a family resemblance, but it's not that close.
Speaker B: So actually thinking of it as a function is the better idea. And that's a notational idea.
Speaker C: Yeah. And here's the thing. The constant e sort of stands as this numerical representative of calculus. Right. Calculus is the study of change. So at the very least, there's a little cognitive dissonance using a constant to represent the science of change.
Speaker B: Never thought of it that way. Yeah.
Speaker C: Right.
Speaker B: Yeah.
Speaker C: It makes sense why the notation came about that way, because this is the first way that we saw it. In the context of things like population growth or compound interest, it is nicer to think about as repeated multiplication. That's definitely nicer. But it's more that that's the first application of what turned out to be a much more general function that maybe the intelligent life your initial question asked about would have come to recognize as being much more significant than the single use case, which lends itself to repeated multiplication notation.
Speaker B: But let me jump back for a second to aliens and the nature of our universe. Okay? Do you think math is discovered or invented? So we're talking about the different kind of mathematics that could be developed by the alien species. The implied question is, yeah, is math discovered or invented? Is fundamentally everybody going to discover the same principles of mathematics?
Speaker C: So the way I think about it, and everyone thinks about it differently, but here's my take. I think there's a cycle at play where you discover things about the universe that tell you what math will be useful, and that math itself is invented, in a sense. But of all the possible maths that you could have invented, it's discoveries about the world that tell you which ones are. So a good example here is the pythagorean theorem. When you look at this, do you think of that as a definition, or do you think of that as a discovery?
Speaker B: From the historical perspective, it's a discovery. But that's probably because they were using physical object to build their intuition. And from that intuition came the mathematics. So the mathematics wasn't, in some abstract world, detached from physics. But I think more and more math has become detached from, you know, when you even look at modern physics, from string theory to even general relativity, I mean, all math behind the 20th and 21st century physics kind of takes a brisk walk outside of what our mind can actually even comprehend in multiple dimensions. For example, anything beyond three dimensions, maybe four dimensions.
Speaker C: No, no, no. Higher dimensions can be highly, highly applicable. I think this is a common misinterpretation, that if you're asking questions about a five dimensional manifold, that the only way that that's connected to the physical world is if the physical world is itself a five dimensional manifold, or includes them.
Speaker B: Wait a minute, wait a minute. You're telling me you can imagine a five dimensional manifold?
Speaker C: No, that's not what I said. I would make the claim that it is useful to a three dimensional physical universe, despite itself not being three dimensional.
Speaker B: So it's useful meaning to even understand a three dimensional world. It'd be useful to have five dimensional.
Speaker C: Manifolds, absolutely, because of state spaces.
Speaker B: But you're saying in some deep way, for us humans, it does always come back to that three dimensional world for the usefulness that the dimensional world. And therefore it starts with a discovery. But then we invent the mathematics that helps us make sense of the discovery. In a sense, yes.
Speaker C: I mean, just to jump off of the pythagorean theorem example, it feels like a discovery. You've got these beautiful geometric proofs where you've got squares and you're modifying the areas. It feels like a discovery. If you look at how we formalize the idea of 2d space as being two reals, all pairs of real numbers, and how we define a metric on it and define distance, you're like, hang on a second. We've defined distance so that the pythagorean theorem is true. So suddenly it doesn't feel that great. But I think what's going on is the thing that informed us what metric to put on two reals, to put on our abstract representation of 2d space came from physical observations. And the thing is, there's other metrics you could have put on it. We could have consistent math with other notions of distance. It's just that those pieces of math wouldn't be applicable to the physical world that we study, because they're not the ones where the pythagorean theorem holds. So we have a discovery, a genuine, bona fide discovery, that informed the invention, the invention of an abstract representation of 2d space that we call r two, and things like that. And then from there, you just study r two as an abstract thing that brings about more ideas and inventions and mysteries which themselves might yield discoveries. Those discoveries might give you insight as to what else would be useful to invent. And it kind of feeds on itself that way. That's how I think about it. So it's not an either or. It's not that math is one of these or it's one of the others. At different times, it's playing a different role.
Speaker B: So then let me ask the Richard Feynman question then, along that thread is, what do you think is the difference between physics and math? There's a giant overlap. There's a kind of intuition that physicists have about the world that's perhaps outside of mathematics. It's this mysterious art that they seem to possess, we humans generally possess. And then there's the beautiful rigor of mathematics that allows you to, I mean, just like, as we were saying, invent frameworks of understanding our physical world. So what do you think is the difference there, and how big is it?
Speaker C: Well, I think of math as being the study of, like, abstractions over patterns and pure patterns in logic. And then physics is obviously grounded in a desire to understand the world that we live in. I think you're going to get very different answers when you talk to different mathematicians, because there's a wide diversity in types of mathematicians. There are some who are motivated very much by pure puzzles. They might be turned on by things like combinatorics, and they just love the idea of building up a set of problem solving tools applying to pure patterns. There are some who are very physically motivated, who try to invent new math or discover math in veins that they know will have applications to physics or sometimes computer science. And that's what drives them. Like, chaos theory is a good example of something that's pure math. It's purely mathematical, a lot of the statements being made, but it's heavily motivated by specific applications to largely physics. And then you have a type of mathematician who just loves abstraction. They just love pulling into the more and more abstract things, the things that feel powerful. These are the ones that initially invented topology, and then later on get really into category theory and go on about infinite categories and whatnot. These are the ones that love to have a system that can describe truths about as many things as possible. Right? People from those three different veins of motivation into math are going to give you very different answers about what the relation at play here is, because someone like Vladimir Arnold, who is this, he's written a lot of great books, many about differential equations and such. He would say math is a branch of physics. That's how he would think about it. And of course, he was studying, like, differential equations related things, because that is the motivator behind the study of PDE's and things like that. But you'll have others who like, especially the category theorists, who aren't really thinking about physics necessarily. It's all about abstraction and the power of generality. And it's more of a happy coincidence that that ends up being useful for understanding the world we live in. And then you can get into, why is that the case? It's sort of surprising that that which is about pure puzzles and abstraction also happens to describe the very fundamentals of quarks and everything else.
Speaker B: So why do you think the fundamentals of quarks and the nature of reality is so compressible into clean, beautiful equations that are, for the most part, simple, relatively speaking, a lot simpler than they could be? So you have we mentioned somebody like Stephen Wolfram who thinks that sort of, there's incredibly simple rules underlying our reality, but it can create arbitrary complexity. But there is simple equations. I'm asking a million questions that nobody knows the answer to.
Speaker C: I have no idea. Why is it simple? It could be the case that there's a filtration at play. The only things that physicists find interesting are the ones that are simple enough. They could describe it mathematically, right? But as soon as it's a sufficiently complex system, like that's outside the realm of physics, that's biology or whatever, have you. And of course that's true, right? You know, maybe there's something where it's like, of course there will always be some thing that is simple when you wash away the, like, non important parts of whatever it is that you're studying. Just from an information theory standpoint, there might be some. You get to the lowest information component of it. But I don't know. Maybe I'm just having a really hard time conceiving of what it would even mean for the fundamental laws to be intrinsically complicated. Like some set of equations that you can't decouple from each other.
Speaker B: Well, no, it could be that sort of, we take for granted that the laws of physics, for example, are, for the most part the same everywhere or something like that. Right? As opposed to the sort of an alternative could be that the rules under which the world operates is different everywhere. It's like a deeply distributed system where just everything is just chaos. Not in a strict definition of kess, but meaning like just. It's impossible for equations to capture, for, to explicitly model the world as cleanly as the physical world does. I mean, we almost take it for granted that we can describe. We can have an equation for gravity, for action at a distance. We can have equations for some of these basic ways the planets move and just the low level at the atomic scale, how the materials operate at the high scale, how black holes operate, but it doesn't. It seems like it could be there's infinite other possibilities where none of it could be compressible into such equations. It just seems beautiful. It's also weird, probably to the point you're making that. It's very pleasant that this is true for our minds. So it might be that our minds are biased to just be looking at the parts of the universe that are comparable, and then we can publish papers on and have nice e equals empty squared equations.
Speaker C: Right. Well, I wonder, would such a world with uncompressible laws allow for the kind of beings that can think about the kind of questions that you're asking?
Speaker B: That's true, right?
Speaker C: Like an anthropic principle coming into play at some weird way here. I don't know. I don't know what I'm talking about at all.
Speaker B: Or maybe the universe is actually not so compressible. But I. The way our brain, the way our brain evolved, we're only able to perceive the compressible parts. I mean, we are, this is a sort of chomsky argument. We are just descendants of apes over, like, really limited biological systems. So it totally makes sense that we're really limited. Little computers, calculators that are able to perceive certain kinds of things, and the actual world is much more complicated.
Speaker C: Well, but we can do pretty awesome things. We can fly spaceships, and we have to have some connection of reality to be able to take our potentially oversimplified models of the world, but then actually twist the world to our will based on it. So we have certain reality checks that physics isn't too far afield simply based on what we can do.
Speaker B: Yeah, the fact that we can fly is pretty good.
Speaker C: It's great proof of concept that the laws we're working with are, are working.
Speaker B: Well, so I mentioned to the Internet that I'm talking to you, and so the Internet gave some questions. So I apologize for these. But do you think we're living in a simulation, that the universe is a computer, or the universe is a computation running on a computer?
Speaker C: It's conceivable. What I don't buy is you'll have the argument that, well, let's say that it was the case that you can have simulations, then the simulated world would itself eventually get to a point where it's running simulations. Then the second layer down would create a third layer down and on and on and on. So probabilistically, you just throw a dart at one of those layers. We're probably in one of the simulated layers. I think if there's some sort of limitations on the information processing of whatever the physical world is, it quickly becomes the case that you have a limit to the layers that could exist there, because the resources necessary to simulate a universe like ours clearly is a lot just in terms of the number of bits at play. And so then you can ask, well, what's more plausible? That there's an unbounded capacity of information processing in whatever the highest up level universe is, or that there's some bound to that capacity, which then limits the number of levels available? How do you play some kind of probability distribution on what the information capacity is? I have no idea. I don't. People almost assume a certain uniform probability over all of those meta layers that could conceivably exist when it's a little bit like a Pascal's wager on, like, you're not giving a low enough prior to the mere existence of that infinite set of layers.
Speaker B: Yeah, that's true, but it's also very difficult to contextualize the amount. So the amount of information processing power required to simulate our universe seems like amazingly huge, but you can always raise.
Speaker C: Two to the power of that. Yeah, like numbers get big and we're.
Speaker B: Easily humbled by basically everything around us. So it's very difficult to kind of make sense of anything, actually, when you look up at the sky and look at the stars and the immensity of it all to make sense of us, the smallness of us, the unlikeliness of everything that's on this earth coming to be, then you could basically, anything could be all laws of probability go out the window to me because I guess because the amount of information under which we're operating is very low. We basically know nothing about the world around us, relatively speaking. So when I think about the simulation hypothesis, I think it's just fun to think about. But it's also, I think there is a thought experiment of interesting to think of the power of computation where there the limits of a Turing machine, sort of the limits of our current computers. When you start to think about artificial intelligence, how far can we get with computers? And that's kind of where the simulation hypothesis is useful to me as a thought experiment. Is, is the universe just a computer? Is it just a computation? Is all of this just the computation and sort of the same kind of tools we apply to analyzing algorithms? Can that be applied? You know, if we scale further and further and further, will the arbitrary power of those systems start to create some interesting aspects that we see in our universe, or is something fundamentally different needs to be created?
Speaker C: Well, it's interesting that in our universe it's not arbitrarily large. The power that you can place limits on, for example, how many bits of information can be stored per unit area, all of the physical laws. You've got general relativity and quantum coming together to give you a certain limit on how many bits you can store within a given range before it collapses into a black hole. The idea that there even exists such a limit is at the very least thought provoking, when naively, you might assume, oh, well, technology could always get better and better. We could get cleverer and cleverer, and you could just cram as much information as you want into, like, a small unit of space. That makes me think it's at least plausible that whatever the highest level of existence is doesn't admit too many simulations or ones that are at the scale of complexity that we're looking at. Obviously, it's just as conceivable that they do and that there are many. But I guess what I'm channeling is the surprise that I felt upon learning that fact that there are. That information is physical in this way.
Speaker B: There's a finiteness to it. Okay, let me just even go off on that. From a mathematics perspective and the psychology perspective, how do you mix? Are you psychologically comfortable with the concept of infinity?
Speaker C: I think so.
Speaker B: Are you okay with it?
Speaker C: I'm pretty okay, yeah. Are you okay?
Speaker B: No, not really. It doesn't make any sense to me.
Speaker C: I don't know, like, how many words, how many possible words do you think could exist that are just like, strings of letters?
Speaker B: So that's a sort of mathematical statement. That's beautiful. And we use infinity in basically everything we do. Everything we do in science, math and engineering. Yes, but you said exist. The question is, you said letters or words.
Speaker C: I said words.
Speaker B: Words. To bring words into existence to me, you have to start saying them or writing them or listing them.
Speaker C: That's an instantiation. How many abstract words exist?
Speaker B: Well, the idea of abstract, the idea of abstract notions and ideas, I think.
Speaker C: We should be clear on terminology. I mean, you think about intelligence a lot like artificial intelligence. Would you not say that what it's doing is a kind of abstraction? Like, abstraction is key to conceptualizing the universe. You get this raw sensory data. I need something that every time you move your face a little bit and they're not pixels, but, like, analog of pixels on my retina change entirely, that I can still have some coherent notion of. This is Lex. I'm talking to Lex. Right. What that requires is you have a disparate set of possible images hitting me that are unified in a notion of lex. Yeah, right. That's a kind of abstraction. It's a thing that could apply to a lot of different images that I see. And it represents it in a much more compressed way, and one that's much more resilient to that. I think in the same way, if I'm talking about infinity as an abstraction, I don't mean non physical woo woo like ineffable or something. What I mean is, it's something that can apply to a multiplicity of situations that share a certain common attribute, in the same way that the images of your face on my retina share enough common attributes that I can put this single notion to it. Like, in that way, infinity is an abstraction, and it's very powerful. And it's only through such abstractions that we can actually understand the world and logic and things. And in the case of infinity, the way I think about it, the key entity is the property of always being able to add one more. No matter how many words you can list, you just throw an a at the end of one and you have another conceivable word. You don't have to think of all the words at once. It's that property, the, oh, I could always add one more that gives it this nature of infiniteness, in the same way that there are certain properties of your face that give it the lexness. Right. So infinity should be no more worrying than the. I can always add one more sentiment.
Speaker B: That's a really elegant, much more elegant way than I could put it. So thank you for doing that as yet another abstraction. And yes, indeed, that's what our brain does, that's what intelligent systems do, that's what programming does, that's what science does, is build abstraction on top of each other. And yet there is, at a certain point, abstractions that go into the quote woo. Right. Sort of. And because we're now, it's like, it's like we built this stack of, you know, the. The only thing that's true is the stuff that's on the ground. Everything else is useful for interpreting this. And at a certain point, you might start floating into ideas that are surreal and difficult and take us into areas that are disconnected from reality in a way that we could never get back.
Speaker C: What if, instead of calling these abstract, how different would it be in your mind if we called them general? And the phenomenon that you're describing is overgeneralization when you try to.
Speaker B: Over generalization. Yeah.
Speaker C: Have a concept or an idea that's so general as to apply to nothing in particular in a useful way, does that map to what you're thinking of when you think of, first of all.
Speaker B: I'm playing little just for the fun of it. Devil's advocate, I think our cognition, our mind is unable to visualize. So you do some incredible work with visualization and video. I think infinity is very difficult to visualize for our mind. We can delude ourselves into thinking we can visualize it, but we can't. I don't. I mean, I would venture to say it's very difficult. And so there's some concepts in mathematics, like maybe multiple dimensions, we could sort of talk about it, that are possible for us to truly intuit like. And it just feels dangerous to me to use these as part of our.
Speaker C: Toolbox of abstractions on behalf of your listeners. I almost fear we're getting too philosophical. No. Heck no.
Speaker B: Heck no.
Speaker C: But I think to that point, for any particular idea like this, there's multiple angles of attack. I think when we do visualize infinity, what we're actually doing, you write, dot, dot, dot, 1234, dot, dot, dot. Those are symbols on the page that are insinuating a certain infinity. What you're capturing with a little bit of design there is the. I can always add one more property. I'm just as uncomfortable with. You are if you try to concretize it so much that you have a bag of infinitely many things that I actually think of. No, not 1234, dot, dot, dot. 1234-5678 I try to get them all in my head and you realize, oh, your brain would literally collapse into a black hole. All of that. I honestly feel this with a lot of math that I try to read. I don't think of myself as particularly good at math in some ways. I get very confused often when I am going through some of these texts, often what I'm feeling in my head is like, this is just so damn abstract. I just can't wrap my head around it. I just want to put something concrete to it that makes me understand. And I think a lot of the motivation for the channel is channeling that sentiment of, yeah, a lot of the things that you're trying to read out there. It's just so hard to connect to anything that you spend an hour banging your head against a couple of pages and you come out not really knowing anything more other than some definitions, maybe, and a certain sense of self defeat. Right. One of the reasons I focus so much on visualizations is that I'm a big believer in. I'm sorry, I'm just really hampering on this idea of abstraction being clear about your layers of abstraction. It's always tempting to start an explanation from the top to the bottom, you give the definition of a new theorem. This is the definition of a vector space, for example. That's how we'll start a course. These are the properties of a vector space. First, from these properties, we will derive what we need in order to do the math of linear algebra, or whatever it might be. I don't think that's how understanding works at all. I think how understanding works is you start at the lowest level you can get it, where rather than thinking about a vector space, you might think of concrete vectors that are just lists of numbers, or picturing it as like an arrow that you draw, which is itself even less abstract than numbers, because you're looking at quantities like the distance of the x coordinate, the distance of the y coordinate. It's as concrete as you could possibly get. And it has to be if you're putting it in a visual, right?
Speaker B: It's an actual arrow.
Speaker C: It's an actual vector. You're not talking about a quote unquote vector that could apply to any possible thing. You have to choose one. If you're illustrating it, and I think this is the power of being in a medium like video, or if you're writing a textbook and you force yourself to put a lot of images, is with every image you're making a choice. With each choice, you're showing a concrete example. With each concrete example, you're aiding someone's path to understanding.
Speaker B: I'm sorry to interrupt you, but you just made me realize that that's exactly right. So the visualizations you're creating, while you're sometimes talking about abstractions, the actual visualization is an explicit, low level example.
Speaker C: Yes.
Speaker B: So there's an actual like in the code. You have to say what the vector is, what's the direction of the arrow, what's the magnitude. Yeah. So that's, you're going, the visualization itself is actually going to the bottom of the arrow.
Speaker C: And I think that's very important. I also think about this a lot in writing scripts where even before you get to the visuals, the first instinct is to. I don't know why, I just always do say the abstract thing. I say the general definition, the powerful thing, and then I fill it in with examples later. Always it will be more compelling and easier to understand when you flip that, and instead you let someone's brain do the pattern recognition. You just show them a bunch of examples. The brain is going to feel a certain similarity between them. Then by the time you bring in the definition or by the time you bring in the formula, it's articulating a thing that's already in the brain, that was built off of looking at a bunch of examples with a certain kind of similarity. And what the formula does is articulate what that kind of similarity is, rather than being a high cognitive load set of symbols that needs to be populated with examples later on, assuming someone's still.
Speaker B: With you, what is the most beautiful or awe inspiring idea you've come across in mathematics?
Speaker C: I don't know, man.
Speaker B: Maybe it's an idea you've explored in your videos, maybe not. What, like, just gave you pause?
Speaker C: What's the most beautiful idea, small or big? So I think often the things that are most beautiful are the ones that you have, like, a little bit of understanding of, but certainly not an entire understanding. It's a little bit of that mystery that is what makes it beautiful.
Speaker B: Almost the moment of the discovery for you personally, almost just that leap of aha. Moment.
Speaker C: So something that really caught my eye. I remember when I was little, there were these, like. I think the series was called, like, wooden books or something, these tiny little books that would have just a very short description of something on the left and then a picture on the right. I don't know who they're meant for, but maybe it's, like, loosely children or something like that. But it can't just be children because of some of the things I was describing. On the last page of one of them, somewhere tiny in there was this little formula that on the left hand had a sum over all of the natural numbers. It's like one over one to the s, plus one over two to the s, plus one over three to the s, on and on to an infinity. Then on the other side, had a product over all of the primes. And it was a certain thing had to do with all the primes. And like any good young math enthusiast, I'd probably been indoctrinated with how chaotic and confusing the primes are, which they are. And seeing this equation where on one side you have something that's as understandable as you could possibly get, the counting numbers, and on the other side is all the prime numbers. It was like this. Whoa, they're related like this. There's a simple description that includes all the primes getting wrapped together like this. This is like the Euler product for the zeta function. As I later found out, the equation itself essentially encodes the fundamental theorem of arithmetic, that every number can be expressed as a unique set of primes to me. Still, there's. I mean, I certainly don't understand this equation or this function all that well, the more I learn about it, the prettier it is. The idea that you can. This is sort of what gets you representations of primes, not in terms of primes themselves, but in terms of another set of numbers. They're like the non trivial zeros of the zeta function. And again, I'm very kind of in over my head in a lot of ways as I try to get to understand it. But the more I do, it always leaves enough mystery that it remains very beautiful to me.
Speaker B: So whenever there's a little bit of mystery just outside of your understanding, that, and by the way, the process of learning more about it, how does that come about? Just your own thought? Or are you reading?
Speaker C: Reading, yeah.
Speaker B: Or is the process of visualization itself revealing more to you?
Speaker C: Visuals help. I mean, in one time when I was just trying to understand, like, analytic continuation and playing around with visualizing complex functions, this is what led to a video about this function. It's titled something like visualizing the Riemann zeta function. It's one that came about because I was programming and tried to see what a certain thing looked like. And then I looked at it, I'm like, whoa, that's elucidating. And then I decided to make a video about it. But, I mean, you try to get your hands on as much reading as you can. In this case, I think if anyone wants to start to understand it, if they have a math background, like they studied some in college or something like that. The Princeton companion to math has a really good article on analytic number theory, and that itself has a whole bunch of references, and anything has more references, and it gives you this tree to start pawing through. I try to understand things visually as I go. That's not always possible, but it's very helpful when it does. You recognize when there's common themes, like, in this case, cousins of the Fourier transform, come into play and you realize, oh, it's probably pretty important to have deep intuitions of the Fourier transform, even if it's not explicitly mentioned in these texts, and you try to get a sense of what the common players are. But I'll emphasize again, I feel very in over my head when I try to understand the exact relation between the zeros of the Riemann zeta function and how they relate to the distribution of primes. I definitely understand it better than I did a year ago. I definitely understand it one 100th as well as the experts on the matter do, I assume. But the slow path towards getting there is fun. It's charming and like to your question, very beautiful.
Speaker B: And the beauty is in the what? In the journey versus the destination.
Speaker C: Well, it's that each thing doesn't feel arbitrary. I think that's a big part, is that you have these unpredictable. Yeah, these very unpredictable patterns, or these intricate properties of a certain function. But at the same time, it doesn't feel like humans ever made an arbitrary choice in studying this particular thing. So it feels like you're speaking to patterns themselves or nature itself. That's a big part of it, I think. Things that are too arbitrary, it's just hard for those to feel beautiful, because this is sort of what the word contrived is meant to apply to.
Speaker B: And when they're not arbitrary, it means it could be. You can have a clean abstraction and intuition that allows you to comprehend it.
Speaker C: Well, to one of your first questions, it makes you feel like if you came across another intelligent civilization, that they'd be studying the same thing, maybe with different notation, certainly. Yeah, but. Yeah, that's what I think. You talked to that other civilization. They're probably also studying the zeros of the Riemann zeta function, or like some variant thereof that is like a clearly equivalent cousin or something like that. But that's probably on their docket.
Speaker B: Whenever somebody does a lot of something amazing, I'm going to ask the question that you've already been asked a lot, that you'll get more and more asked in your life. But what was your favorite video to create?
Speaker C: Oh, favorite to create. One of my favorites is the title is, who cares about topology?
Speaker B: Do you want me to pull it up or. No?
Speaker C: If you want. Sure. Yeah. It is about. Well, it starts by describing an unsolved problem that's still unsolved in math, called the inscribed square problem. You draw any loop, and then you ask, are there four points on that loop that make a square? Totally useless, right? This is not answering any physical questions. It's mostly interesting that we can't answer that question, and it seems like such a natural thing to ask. Now, if you weaken it a little bit and you ask, can you always find a rectangle? You choose four points on this curve. Can you find a rectangle? That's hard, but it's doable. And the path to it involves things like looking at a torus, this surface with a single hole in it, like a doughnut, or looking at a Mobius strip in ways that feel so much less contrived to. When I first, as, like a little kid, learned about these surfaces and shapes, like a Mobius strip and a torus what you learn is, oh, this Mobius strip. You take a piece of paper, put a twist, glue it together, and now you have a shape with one edge and just one side. And as a student, you should think, who cares? Right? Like, how does that help me solve any problems? I thought math was about problem solving. So what I liked about the piece of math that this was describing that was in this paper by a mathematician named Vaughan, was that it arises very naturally. It's clear what it represents. It's doing something. It's not just playing with construction paper. And the way that it solves the problem is really beautiful. So kind of putting all of that down and concretizing it. I was talking about how when you have to put visuals to it, it demands that what's on screen is a very specific example of what you're describing. The construction here is very abstract in nature. You describe this very abstract kind of surface in 3d space. So then when I was finding myself in this case, I wasn't programming, I was using grapher that's like built into OS X for the 3d stuff to draw that surface. You realize, oh man, the topology argument is very non constructive. I have to make a lot of, you have to do a lot of extra work in order to make the surface show up. But then once you see it, it's quite pretty and it's very satisfying to see a specific instance of it. And you also feel like, ah, I've actually added something on top of what the original paper was doing, that it shows something that's completely correct. That's a very beautiful argument, but you don't see what it looks like. And I found something satisfying in seeing what it looked like. That could only ever have come about from the forcing function of getting some kind of image on the screen to describe the thing I was talking about.
Speaker B: So you almost weren't able to anticipate what it's going to look like.
Speaker C: I had no idea. I had no idea. And it was wonderful. It looks like a Sydney opera house or some sort of frank Gehry design, and it was, you knew it was going to be something. And you can say various things about it, like, oh, it touches the curve itself, it has a boundary that's this curve on the 2d plane. It all sits above the plane. But before you actually draw, it's very unclear what the thing will look like. And to see it, it's just pleasing. Right, so that was fun to make, very fun to share. I hope that it has elucidated for some people out there, where these constructs of topology come from, that it's not arbitrary play with construction paper.
Speaker B: I think this is a good example to talk a little bit about your process. You have a list of ideas that's the curse of having an active and brilliant mind. I'm sure you have a list that's growing faster than you can utilize.
Speaker C: Nail on the head. Absolutely.
Speaker B: But there's some sorting procedure depending on mood and interest and so on, but. Okay, so you pick an idea, then you have to try to write a narrative arc that sort of, how do I elucidate, how do I make this idea beautiful and clear and explain it? And then there's a set of visualizations that will be attached to it, sort of. You've talked about some of this before, but sort of writing the story, attaching the visualizations, can you talk through interesting, painful, beautiful parts of that process?
Speaker C: Well, the most painful is if you've chosen a topic that you do want to do, but then it's hard to think of, I guess, how to structure the script. This is sort of where I have been on one for the last two or three months, and I think that ultimately the right resolution is just set it aside and instead do some other things where the script comes more naturally. Because you sort of don't want to overwork a narrative. The more you've thought about it, the less you can empathize with the student who doesn't yet understand the thing you're trying to teach.
Speaker B: Who is the judger in your head? Sort of the person, the creature, the essence. That's saying this sucks, or this is good. And you mentioned kind of the student you're thinking about.
Speaker C: Um.
Speaker B: Can you, uh. Who is that? What is that thing? That's Chris. That's. That says the perfectionist. That says, this thing sucks. You need to work on that for another two, three months.
Speaker C: I don't know. I think it's my past self. I think that's the entity that I'm most trying to empathize with is like, you take who I was, because that's kind of the only person I know. Like, you don't really know anyone other than versions of yourself. So I start with the version of myself that I know who doesn't yet understand the thing, right? And then I just try to view it with fresh eyes, a particular visual or a particular script. Like, is this motivating? Does this make sense? Which has its downsides, because sometimes I find myself speaking to motivations that only myself would be interested in. I don't know, like, I did this project on quaternions where what I really wanted was to understand, what are they doing in four dimensions? Can we see what they're doing in four dimensions? Right. And I had a way of thinking about it that really answered the question in my head that made me very satisfied in being able to think about concretely with a 3d visual, what are they doing to a 4d sphere? And so I'm like, great, this is exactly what my past self would have wanted. And I make a thing on it, and I'm sure it's what some other people wanted, too. But in hindsight, I think most people who want to learn about quaternions are like robotics engineers or graphics programmers who want to understand how they're used to describe 3d rotations. And their use case was actually a little bit different than my past self. And in that way, I wouldn't actually recommend that video to people who are coming at it from that angle of wanting to know, hey, I'm a robotics programmer. How do these quaternion things work to describe position in 3d space? I would say other great resources for that. If you ever find yourself wanting to say, but hang on, in what sense are they acting in four dimensions, then come back. But until then, it's a little different.
Speaker B: Yeah, it's interesting because you have incredible videos on neural networks, for example, and from my sort of perspective, because I've probably, I mean, I looked at the serve my field, and I've also looked at the basic introduction of neural networks, like a million times from different perspectives. And it made me realize that there's a lot of ways to present it. So you are sort of, you did an incredible job. I mean, sort of the. But you could also do it differently. And also incredible. Like, to create a beautiful presentation of a basic concept requires sort of creativity, requires genius and so on, but you can take it from a bunch of different perspectives. And that video on neural networks made me realize that. And just as you're saying, you kind of have a certain mindset, a certain view, but if you take a different view from a physics perspective, from a neuroscience perspective, talking about neural networks, or from a robotics perspective, or, let's see, from a pure learning theory, statistics perspective, so you can create totally different videos, and you've done that with a few actually concepts where you have taken different cuts, like at the whirly equation, you've taken different views of that.
Speaker C: I think I've made three videos on it, and I definitely will make at least one more. Never enough, never enough.
Speaker B: So you don't think it's the most beautiful equation in mathematics?
Speaker C: Like I said, as we represent it, it's one of the most hideous. It involves a lot of the most hideous aspects of our notation. I talked about e, the fact that we use PI instead of tau, the fact that we call imaginary numbers imaginary and then, hence actually wonder if we use the eye because of imaginary. I don't know if that's historically accurate, but at least a lot of people, they read the I and they think imaginary. Right? Like, all three of those facts, it's like, those are things that have added more confusion than they needed to, and we're wrapping them up in one equation. Like, boy, that's just very hideous. Right? The idea is that it does tie together when you wash away the notation. Like, it's okay, it's pretty. It's nice, but it's not, like, mind blowing greatest thing in the universe, which is maybe what I was thinking of when I said, once you understand something, it doesn't have the same beauty. I feel like I understand Euler's formula, and I feel like I understand it enough to sort of see the version that just woke up that hasn't really gotten itself dressed in the morning, that's a little bit groggy, and there's bags under its eyes.
Speaker B: So you're past the dating stage.
Speaker A: You're now.
Speaker C: We're no longer dating. I'm still dating the zeta function. And she's beautiful and we have fun, and it's that high dopamine part. But maybe at some point, we'll settle into the more mundane nature of the relationship, where I see her for who she truly is, and she'll still be beautiful in her own way, but it won't have the same romantic pizzazz. Right.
Speaker B: Well, that's the nice thing about mathematics, I think as long as you don't live forever, there will always be enough mystery and fun with some of the equations.
Speaker C: Even if you do, the rate at which questions comes up is much faster than the rate at which answers come up.
Speaker B: So, if you could live forever, would you?
Speaker C: I think so, yeah.
Speaker B: So you don't think mortality is the thing that makes life meaningful?
Speaker C: Would your life be four times as meaningful if you died at 25?
Speaker B: So this goes to infinity, I think you and I. That's really interesting. So, what I said is infinite. Nothing, not four times longer, said Infinite. So the actual existence of the finiteness, the existence of the end, no matter the length, is the thing that may sort of, from my comprehension of psychology, it's such a deeply human, it's such a fundamental part of the human condition, the fact that we're mortal, that the fact that things end, it seems to be a crucial part of what gives them meaning.
Speaker C: I don't think, at least for me, it's a very small percentage of my time that mortality is salient, that I'm aware of the end of my life.
Speaker B: What do you mean by me? I'm trolling. Is it the ego? Is it the id? Or is it the superego, the reflective.
Speaker C: Self, the Wernicke's area that puts all this stuff into words.
Speaker B: Yeah. A small percentage of your mind that is actually aware of the true motivations that drive you.
Speaker C: But my point is that most of my life I'm not thinking about death, but I still feel very motivated to make things and to interact with people, experience love or things like that. I'm very motivated. And it's strange that that motivation comes while death is not in my mind at all. And this might just be because I'm young enough that it's not salient or.
Speaker B: It'S in your subconscious, or that you constructed an illusion that allows you to escape the fact of your mortality. Bye. Enjoying the moment? Sort of the existential approach.
Speaker C: Life could be gun to my head. I don't think that's it.
Speaker B: Yeah. Another sort of way to say gun to the head is sort of the deep psychological introspection of what drives us. I mean, that's in some ways to me. I mean, when I look at math, when I look at science, it's a kind of an escape from reality in a sense that it's so beautiful, it's such a beautiful journey of discovery that it allows you to actually, it allows you to achieve a kind of immortality, of explore ideas and sort of connect yourself to the thing that is seemingly infinite. Like the universe, right? That allows you to escape the limited nature of our little, of our bodies, of our existence.
Speaker C: What else would give this podcast meaning?
Speaker B: That's right.
Speaker C: If not the fact that it will.
Speaker B: End, this place closes in 40 minutes.
Speaker C: So much more meaningful for it. How much more? I love this room because we'll be kicked out.
Speaker B: So I understand. Just because you're trolling me doesn't mean I'm wrong. But I take your point. I take your point.
Speaker C: Boy, that would be a good twitter bio. Just because you're trolling me doesn't mean I'm wrong.
Speaker B: Yeah, and sort of difference in backgrounds. I'm a bit russian, so we're a bit melancholic and seem to maybe assign a little too much value to suffering, immortality, and things like that. Makes for a better novel, I think.
Speaker C: Oh, yeah, you need some sort of existential threat to drive a plot.
Speaker B: So when do you know when the video is done? When you're working on it?
Speaker C: That's pretty easy, actually, because, I mean, I'll write the script. I want there to be some kind of aha moment in there. And then hopefully the script can revolve around some kind of aha moment. And then from there, you know, you're putting visuals to each sentence that exists, and then you narrate it, you edit it all together. So, given that there's a script, the end becomes quite clear. And, you know, as I animate it, I often change the. Certainly the specific words, but sometimes the structure itself. Um, but it's a very, uh, deterministic process at that point. Um, it makes it much easier to predict when something will be done. How do you know when a script is done? It's like, for problem solving videos, that's quite simple. It's. It's once you feel like someone who didn't understand the solution now could. For things like neural networks, that was a lot harder because, like you said, there's so many angles at which you could attack it. Um, and there it's, uh, it's just at some point, you feel like this. This asks a meaningful question and it answers that question.
Speaker B: What is the best way to learn math for people who might be at the beginning of that journey? I think that's a question that a lot of folks kind of ask and think about, and it doesn't. Even for folks who are not really at the beginning of their journey, like they might be actually deep in their career of some type, they've taken college or taking calculus and so on, but still want to sort of explore math, what would be your advice? Instead of education at all ages, your.
Speaker C: Temptation will be to spend more time watching lectures or reading. Try to force yourself to do more problems than you naturally would. That's a big one. The focus time that you're spending should be on solving specific problems and seek entities that have well curated lists of problems.
Speaker B: So go into a textbook almost, and the problems in the back of a textbook kind of thing. Back of a chapter.
Speaker C: So if you can take a little look through those questions at the end of the chapter before you read the chapter. A lot of them won't make sense. Some of them might. And those are the best ones to think about. A lot of them won't. But just take a quick look and then read a little bit of the chapter and then maybe take a look again and things like that. And don't consider yourself done with the chapter until you've actually worked through a couple exercises. And this is so hypocritical because I put out videos that pretty much never have associated exercises. I just view myself as a different part of the ecosystem, which means I'm kind of admitting that you're not really learning, or at least this is only a partial part of the learning process if you're watching these videos. I think if someone's at the very beginning, I do think Khan Academy does a good job. They have a pretty large set of questions. You can work through just the very.
Speaker B: Basics, just picking up, getting comfortable at the very basic. Linear algebra, calculus, Epsilon.
Speaker C: Khan Academy programming is actually, I think, a great learn to program and let the way that math is motivated from that angle push you through. I know a lot of people who didn't like math got into programming in some way, and that's what turned them on to math. Maybe I'm biased because I live in the Bay Area, so I'm more likely to run into someone who has that phenotype, but I am willing to speculate that that is a more generalizable path.
Speaker B: So you yourself, kind of, in creating the videos, are using programming to illuminate a concept, but for yourself as well. So would you recommend somebody try to make a sort of almost like, try to make videos like you do as.
Speaker C: A way to learn? So one thing I've heard before, I don't know if this is based on any actual study. This might be like a total fictional anecdote of numbers, but it rings in the mind as being true. You remember about 10% of what you read, you remember about 20% of what you listen to, you remember about 70% of what you actively interact with in some way, and then about 90% of what you teach. This is a thing I heard. Again, those numbers might be meaningless, but they ring true, don't they? Right? I'm willing to say I learned nine times better if I'm teaching something than reading. That might even be a low ball. So doing something to teach or to actively try to explain things is huge for consolidating the knowledge outside of family and friends.
Speaker B: Is there a moment you can remember that you would like to relive because it made you truly happy or it was transformative in some fundamental way?
Speaker C: A moment that was transformative or made you truly happy? Yeah, I think there's times like music used to be a much bigger part of my life than it is now. When I was a teenager, and I can think of sometimes in playing music, there was one my brother and a friend and mine. So this slightly violates the family and friends, but it was the music that made me happy. They were just accompanying. We had played a gig at a ski resort such that you take a gondola to the top and did a thing. Then on the gondola ride down, we decided to just jam a little bit. It was just, I don't know, the gondola came over a mountain and you saw the city lights and were just jamming, playing some music. I wouldnt describe that as transformative, I dont know why. But that popped into my mind as a moment of, in a way that wasnt associated with people I love, but more with a thing. I was doing something that was just happy and it was just a great moment. I dont think I can give you anything deeper than that, though.
Speaker B: As a musician myself, id love to see, as you mentioned before, music enter back into your work, back into your creative work. I'd love to see that. I'm certainly allowing it to enter back into mine. And it's a beautiful thing for a mathematician, for a scientist to allow music to enter their work. I think only good things can happen.
Speaker C: All right. I'll try to promise you a music video by 2020, by 2020, by the end of 2020.
Speaker B: Okay. All right.
Speaker C: Give myself a longer window.
Speaker B: All right. Maybe we can collaborate on a band type situation. What instruments do you play?
Speaker C: The main instrument I play is violin, but I also love to dabble around on guitar and piano.
Speaker B: Beautiful. Me too. Guitar and piano. So in a mathematician's lament, Paul Lockhart writes, the first thing to understand is that mathematics is an art. The difference between math and the other arts, such as music and painting, is that our culture does not recognize it as such. So I think I speak for millions of people, myself included, in saying thank you for revealing to us the art of mathematics. So thank you for everything you do, and thanks for talking today.
Speaker C: Wow. Thanks for saying that, and thanks for having me on.
Speaker A: Thanks for listening to this conversation with Grant Sanderson. And thank you to our presenting sponsor. Cash app. Download it. Use code Lex podcast. You'll get $10, and $10 will go to first, a STEM education nonprofit that inspires hundreds of thousands of young minds to become future leaders and innovators. If you enjoy this podcast, subscribe on YouTube. Give it five stars on Apple Podcasts. Support it on Patreon or connect with me on Twitter. And now let me leave you with some words of wisdom from one of Grant's and my favorite people, Richard Feynman. Nobody ever figures out what this life is all about and it doesn't matter. Explore the world. Nearly everything is really interesting if you go into it deeply enough. Thank you for listening and hope to see you next time.
Speaker B: You our.
