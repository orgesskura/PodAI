Speaker A: You could buy literally whatever else you wanted. You could host things. Drugs. You could buy heroin, right from Afghanistan. The good stuff, hacking tools. You could hack for hire. You could buy murders for hire.
Speaker B: The following is a conversation with Chris Tarbell, a former FBI special agent and cybercrime specialist who tracked down and arrested Russ Albrecht, the leader of Silk Road, the billion dollar drug marketplace. And he tracked down and arrested Hector Monsegur, aka Sabu, of Lulsec and Anonymous, which are some of the most influential hacker groups in history. He is co founder of Naxo, a complex cybercrime investigation firm, and is a co host of a podcast called the Hacker and the Fed. This conversation gives the perspective of the FBI cybercrime investigator, both the technical and the human story. I would also like to interview people on the other side, the cyber criminals who have been caught and perhaps the cybercriminals who have not been caught and are still out there. This is Alex Friedman podcast. To support it. Please check out our sponsors in the description. And now, dear friends, here's Chris Tarbell. You are one of the most successful cybersecurity law enforcement agents of all time. You tracked and brought down Russ Albrecht, aka dread pirate Roberts, who ran Silk Road, and Sabu of Lulzsec and Anonymous, who was one of the most influential hackers in the world. So, first, can you tell me the story of tracking down Ross Ulbricht and Silk Road? Let's start from the very beginning, and maybe let's start by explaining what is the Silk Road?
Speaker A: It was really the first dark market website. You literally could buy anything there. Take that back. You couldn't. There's two things you couldn't buy there. You couldn't buy guns, because that was a different website, and you couldn't buy fake degrees so no one could become a doctor. But you could buy literally whatever else you wanted. You could host things. Drugs, you could buy heroin, write it from Afghanistan, the good stuff, hacking tools. You could hack for hire. You could buy murders for hire if you wanted someone killed. Now, so when I was an FBI agent, I had to kind of sell some of these cases, and this was a big drug case, you know, that's the way people saw Silk road. So internally to the FBI, how I had to sell it, I had to find the worst thing on there that I could possibly find. Uh, and I think one time I saw a posting for baby parts. So let's say that you, you know, had a young child and that needed a liver. You could literally go on there and ask for a six month old liver, uh, if you wanted to.
Speaker B: For, like, surgical operations versus something darker.
Speaker A: Yeah, I never saw anything that dark as far as people wanted to eat body parts. I did interview a cannibal once when I was in the FBI. That's another crazy story, but that one actually weirded me out. Sorry.
Speaker B: I just watched Jeffrey Dahmer documentary on Netflix, and it just changed the way I see human beings because it's a portrayal of a normal looking person doing really dark things and doing so not out of a place of insanity, seemingly, but just because he has almost, like, a fetish for that kind of thing. It's disturbing that people like that are out there. So people like that would then be using Silk Road. Not like that, necessarily, but people of different walks of life would be using Silk Road to primarily, what was the primary thing? Drugs.
Speaker A: It was primarily drugs, and that's where it started. It started off with Ross Ulbricht growing mushrooms out in the wilderness of California and selling them. But really, his was more of a libertarian viewpoint. And you could. Was like, you choose what you want to do for yourself and do it. And the way Silk road kind of had the anonymity is it used what's called tor, the onion router, which is an anonymizing function on the deep web. It was actually invented by the US Navy back in the mid nineties or so, but it also used cryptocurrency. So it was the first time, like, we saw this birth on the Internet of mixing cryptocurrency and an IP blocking software. So, you know, in cybercrime, you go after, one, the IP address and trace it through the network, or two, you go after the cache. And this one kind of blocked both.
Speaker B: Cash, meaning the flow of money, physical or digital, and then IP is some kind of identifying thing of the computer.
Speaker A: It's your telephone number for. On your computer. So, yeah, all computers have, you know, a unique four octet numbers. You know, it's 123, 123, 123, 123. And, you know, the computer uses DNS or domain name services to render that name. So if you were looking for, you know, CNN.com comma, your computer then translates that to that Ip address or that telephone number where it can find that information.
Speaker B: Didn't Silk Road used to have guns in the beginning? Or was that considered to have guns? Or was. Did it naturally emerge? And then rust realized, like, this is not good.
Speaker A: It went back and forth. I think there were guns on there, and he tried to police it. You know, he. He told himself that the captain of the boat. So he had to follow his rules. So, you know, I think he took off those posts eventually and moved guns elsewhere.
Speaker B: What was the system of censorship that he used of selecting what is okay and not okay?
Speaker A: I mean, him alone, he's the captain of the boat.
Speaker B: Do you know, by chance, if there was a lot of debates and criticisms internally amongst the criminals of what is and isn't allowed? I mean, it's interesting to see a totally different moral code emerge that's outside the legal code of society.
Speaker A: We did get the server and was able to read all of the chat logs that happened. I mean, all the records were there. I don't remember big debates. I mean, there was a clear leadership, and that was the final decision. That was the CEO of Silk Road.
Speaker B: And so primarily was drugs and primarily out of an ideology of freedom, which is if you want to use drugs, you should be able to use drugs.
Speaker A: You should put in your body what you want to put in your body.
Speaker B: And when you were presenting a case of why this should be investigated, you're trying to find, as you mentioned, the worst possible things on there. Is that what you were saying?
Speaker A: So we had arrested a guy named Jeremy Hammond, and he hit himself. He was a hacker. And when we arrested him, it was the second time he had been arrested for hacking. He used tordeh. And so that kind of brought us to a point. The FBI has a computer system where you look up things. You look up anything. I could look up your name or whatever. If you're associated with my case. And we were finding at the time a lot of things in you look it up, a case would end be like, oh, this is Tor. It just stopped. We couldn't get any further. So we had just had this big arrest of Sabu and took down anonymous. And sometimes in the FBI the way it used to. The old school FBI, when you had a big case and you're working seven days a week and 14 hours, 15 hours a day, you sort of take a break. The boss kind of said, yeah, I'll see you in a few months. Go. Go get to know your family a little bit, you know, and come back. But the group of guys I was with was like, let's find the next big challenge. And that's when we were finding, you know, case closed. It was Tor. Case closed, it was Tor. So said, let's take a look at Tor and let's see what we can do. Maybe we'll take a different approach. And Silk Road was being looked at by other law enforcement, but it was taking like a drug approach. Where I'm going to find a drug buyer who got, you know, the drug sent to them in the mail and let's arrest up. Let's go up the chain. But the buyers didn't know their dealers. They never met them.
Speaker B: And so you were taking a cybersecurity approach.
Speaker A: Yeah, we said, let's try to look at this from a cyber approach and see if we can gleam anything out of it.
Speaker B: So I'm actually indirectly connected.
Speaker A: Uh oh.
Speaker B: To. I'm sure I'm not admitting anything that's not already on my FBI file.
Speaker A: Oh, I can already tell you what you're going to tell me, though.
Speaker B: What's that?
Speaker A: That when you were at college, you wrote a paper and you're connected to the person that started.
Speaker B: You son of a bitch. You clever son of a bitch.
Speaker A: I'm an FBI agent or a former FBI agent. How would I not have known?
Speaker B: But I could have told you other stuff.
Speaker A: No, that's what you were about to tell me.
Speaker B: I was looking up his name because I forgot it. So one of my advisors for my PhD was Rachel Greenstadt, and she is married to Roger Dingle Dyne, which is the co founder of the Tor project. And I actually reached out to him last night to do a podcast together. I don't know is. No, it was a good. It was a good party trick. I mean, it's cool that you know this. And the timing of it, it was just, like, beautiful. But just to linger on the. On the tour project. So we understand. So tour is this black box that people disappear in. In terms of the. When you were tracking people, can you paint a picture of what Tors used in general? It's like when you talk about bitcoin, for example, a cryptocurrency, especially today, much more people use it for legal activity versus illegal activity. What about Tor?
Speaker A: Tor was originally invented by the US Navy so that spies inside countries could talk to spies and no one could find them. There was no way of tracing them, and then they released that information free to the world. So Tor has two different versions of. Not versions, two different ways it can be utilized. There's dot onion sites, which is like a normal website, a.com, but it's only found within the Tor browser. You can only get there if you know the whole address and get there. The other way Tor is used is to go through the Internet and then come out the other side if you want a different IP address, if you're trying to hide your identity. So if you were doing, like, say, cybercrime, I would have the victim computer and I would trace it back out to a Tor relay. And then because you don't have an active connection or what's called a circuit at the time, I wouldn't be able to trace it back. But even if you had an active circuit, I would have to go to each machine physically alive and try to rebuild that, which is literally impossible.
Speaker B: So what do you feel about Tor ethically, philosophically, as a human being on this world that spend quite a few years of your life and still trying to protect people?
Speaker A: So part of my time in the FBI was working on child exploitation, kitty porn, as they call it. That really changed my life in a way. And so anything that helps facilitate the exploitation of children fucking pisses me off. And that sort of jaded my opinion towards tor because that, because it helps facilitate those sites.
Speaker B: So this ideal of freedom that Russ Albrecht, for example, tried to embody is something that you don't connect with anymore because of what you've seen that ideal being used for.
Speaker A: I mean, the child exploitation is the specific example for it. And it's easy for me to sit here and say child porn, because no one listening to this is ever going to say that I'm wrong and that we should allow child porn, should because some people utilize it in a bad way, should it go away? No. I mean, I'm a technologist. I want technology to move forward. People are going to do bad things and they're going to use technology to help them do bad things.
Speaker B: Well, let me ask you, then we'll jump around a little bit. But the things you were able to do in tracking down information, and we'll get to it. There's some suspicion that this was only possible with mass surveillance, like with NSA, for example. First of all, is there any truth to that? And second of all, what do you feel are the pros and cons of mass surveillance?
Speaker A: There is no truth to that. And then my feelings on mass surveillance.
Speaker B: If there was, would you tell me? Probably not, but I love this conversation so much. But what do you feel about the given that you said child porn, what are the pros and cons of surveillance at a society level?
Speaker A: I mean, nobody wants to give up their privacy. I say that. I say no one wants to give up their privacy, but I mean, I used to have to get a search warrant to look inside your house, or I can just log onto your facebook and you've got pictures of all inside your house and what's going on. I mean, it's not so people like the idea of not giving up their privacy. But I. But they do it anyways. They're giving away their freedoms all the time. They're carrying watches that gives out their heartbeat to a weight of companies that are storing that. I mean, what's more personal than your heartbeat?
Speaker B: So I think people, en masse, really want to protect their privacy. And I would say most people don't really need to protect their privacy. But the case against mass surveillance is that if you want to criticize the government in a very difficult time, you should be able to do it. So when you need the freedom, you should have it. So when you wake up one day and realize there's something going wrong with the country I love, I want to be able to help. One of the great things about the United States of America is there's that individual revolutionary spirit so that the government doesn't become too powerful. You can always protest. There's always the best of the ideal of freedom of speech. You can always say fuck you to the man. And I think there's a concern of direct or indirect suppression of that through mass surveillance. You might not. Is that that little subtle fear that grows with time? That why, you know, why bother criticizing the government? It's going to be a headache. I'm going to get a ticket every time I say something bad, that kind of thing. So it can get out of hand, the bureaucracy grows, grows, and the freedoms slip away. Is that's the, that's the criticism, right.
Speaker A: I completely see your point, and I agree with it. I mean, but I mean, on the other side, people criticize the government of these freedoms, but I mean, tech companies are talking about destroying your privacy and controlling what you can say. I realize they're private platforms and you, they can decide what's on their platform, but, you know, they're taking away your freedoms of what you can say. And we've heard some things where maybe government officials were in line with, with tech companies to take away some of that freedom. That I agree with you, that gets scary.
Speaker B: Yeah. There's something about government that feels maybe because of the history of human civilization, maybe because tech companies are a new thing, but just knowing the history of abuses of government, there's something about government that enables the corrupting nature of power to take hold at scale more than tech companies, at least what we've seen so far.
Speaker A: I agree, I agree. But I mean, we haven't had a voice like we've had until recently. I mean, anyone that has a Twitter account now can speak and become a news article, you know, my parents didn't have that. Didn't have that voice. If they wanted to speak out against the government or do something, they had to go to a protest or organize a protest or, you know, do something along those lines. So, you know, we have more of a place to put our voice out now.
Speaker B: Yeah, it's incredible. But that's why it hurts. And that's why you notice it when certain voices get removed. The president of the United States of America was removed from one such or all such platforms. And that hurts.
Speaker A: Yeah, that's crazy to me. That's insane. That's insane that we took that away.
Speaker B: But let's return to silk growth and Russell Briggs. So how did your path with this very difficult, very fascinating case cross?
Speaker A: We were looking to open a case against Tor because it was a problem. All the cases were closing because Tor. So we went on tour, and we came up with 26 different onion dot onions that we targeted. We were looking for nexuses to hacking, because I was on a squad called Cy two, and we were like the premiere squad in New York that was working criminal cyber intrusions. And so, you know, any website that was offering hackers for hire or hacking tools for free, you know, or paid services, you know, like, now we're seeing ransomware as a paid service and phishing as a paid service. Anything that offered that. So we opened this case on. I think we called it. We said, you have to name cases. One of the fun thing in the FBI is when you start a case, you get to name it. You would not believe how much time is spent in coming up with the name. You know, Casey goes by. I think we called this onion peeler because.
Speaker B: So a little bit of humor, a little bit of wit, and some profundity to the language. Yeah, yeah, yeah. Cause you're gonna have to work with this for quite a lot.
Speaker A: So, yeah, this one had the potential of being a big one, you know, because I think. I think Silk Road was, like the 6th on the list for that case. But we all knew that was sort of the golden ring. If you could make the splash that that onion site was going down, then it would probably get some publicity, and that's part of law enforcement, is getting some publicity out of it that, you know, that makes others think not to do it.
Speaker B: I wish to say that Tor is the name of the project. The browser. What is the onion technology behind Tor?
Speaker A: Let's say you want to go to a dot onion site. You'll put in the dot onion you want to go to, and your computer will build communications with a Tor relay, which are all publicly available out there, but you'll encrypt it. You'll put a package around your data, and so it's encrypted and so can't read it. It goes to that. That first relay. That first relay knows about you, and then knows about the next relay down the chain. And so it takes your data and then encrypts that on the outside and sends it to the relay number two. Now, relay number two only knows about relay number one. It doesn't know who you are asking for this. And it goes through there, adding those layers on top, layers of encryption till it gets to where it is. That, and then even the onion service doesn't know, except for the relay it came from, who it's talking to. And so it peels back. That gives the information, puts another layer back on. And so it's layers like you're peeling an onion back of the different relays. And that encryption protects who the sender is and what information they're sending.
Speaker B: The more layers there are, the more exponentially difficult it is to decrypt it.
Speaker A: I mean, you get to a place where you don't have to have so many layers because it doesn't matter anymore. It's mathematically impossible to decrypt it. But the more relays you have, the slower it is. I mean, that's one of the big drawbacks on Tor, is how slow it operates.
Speaker B: So how do you peel the onion? So what are the different methodologies for trying to get some information from a cybersecurity perspective on these operations like the Silk Road?
Speaker A: It's very difficult. People have come up with different techniques. There's been techniques to put out in the news media about how they do it, running massive amounts of relays, and you're controlling those relays. I think somebody tried that once.
Speaker B: So there's a technical solution. And what about social engineering? What about trying to infiltrate the actual humans that are using the Silk road and trying to get in that way?
Speaker A: Yeah, I mean, I definitely could see the way of doing that. And in this case, in our takedown, we use that. There was one of my partners, Jared Derrigan. He was an HSI investigator, and he had worked his way up to be a system admin on the site. So that did gleam quite a bit of information because he was inside and talking to. At that time, we only know it as DPR or dread pirate Roberts. We didn't know who, who that was yet, but. But we had that open communication, you know, and one of the things, you know, the technical aspects on that is there was a jabber server. There was. That's a communication type of communication server that was being used. And we knew that Ross had his jabber set to Pacific time. So we had a pretty good idea what. What part of the. What part of the country he was in.
Speaker B: I mean, isn't that from DPR's perspective, from Russ's perspective? Isn't that clumsy?
Speaker A: He wasn't a. He wasn't a big computer guy.
Speaker B: Do you notice that aspect of, like, the technical savvy of some of these guys doesn't seem to be quite. Why weren't they good at this?
Speaker A: Well, the real techie savvy ones, we don't arrest, we don't get to them. We don't find them, we don't get to them.
Speaker B: Shout out to the techie criminals. They probably watching this.
Speaker A: I mean, yeah, I mean, you were getting the low hanging fruit. I mean, you're getting the ones that can be caught. I mean, you know, I'm sure we'll talk about it. But the anonymous case, there was a guy named AV unit. He still. I lose sleep over him because I. We didn't catch him. We caught everybody else. We didn't catch him. He's good, though. He pops up, too, once in a while on the Internet, and it pisses me off.
Speaker B: Yeah. What's his name again?
Speaker A: AV unit. That's all I know is his AV unit.
Speaker B: AV unit, yeah.
Speaker A: I got a funny story about him and who people think he is.
Speaker B: Can I actually. Can we go on that brief tangent?
Speaker A: Sure. I love tangents.
Speaker B: Well, let me ask you, since he's probably he or she. Do we know it's a he?
Speaker A: We have no idea.
Speaker B: Okay.
Speaker A: I mean, that's another funny story about hackers, the he she issue.
Speaker B: What's the funny story there?
Speaker A: Well, one of the guys in Lulzsec was. Was a. She was a 17 year old girl, and my source in the case, the guy sabu, that I arrested and part of in, you know, we sat side by side for nine months and then took down, you know, the case and all that. He was convinced she was a girl and said, you know, and he was in love with her almost. At one point, it turns out to be a 35 year old guy living in England.
Speaker B: Oh, so he was convinced?
Speaker A: Yes, he was absolutely convinced.
Speaker B: Based on what, exactly? By linguistic, like, human based linguistic analysis or what?
Speaker A: She. She. Whatever, you know, Kayla is what he went, which ended up being like a modification of his sister's name, the real guy's sister's name was so good at building the backstory, all these guys. And it's funny, these guys are part of a hacking crew. They social engineer the shit out of each other just to build. If one of them ever gets caught, they'll convince the everybody else that they're a brazilian ISp owner or something like that. And that's how I'm so powerful.
Speaker B: Well, yeah, that social engineering aspect is part of living a life of cybercrime or cybersecurity on the offensive or defensive. So, av unit, can I get also just a tangent of a tangent first?
Speaker A: That's my favorite tangent.
Speaker B: Okay. Is it possible for me to have a podcast conversation with somebody who hasn't been caught yet? And because they have the conversation, they still won't be caught, and is that a good idea? Meaning, is there a safe way for a criminal to talk to me on a podcast?
Speaker A: I would think so. I would think they. That someone could. I mean, someone who has been living a double life for long enough where you think they're not a criminal.
Speaker B: No, no, no. They would have to admit that. They would say, I am AV unit.
Speaker A: Oh, you would want to have a conversation with AV unit?
Speaker B: Yes. Is there a way? I'm just from an FBI perspective, technically speaking, because I. Let me explain my motivation. I think I would like to be able to talk to people from all walks of life. And understanding criminals, understanding their mind, I think, is very important. And I think there's fundamentally something different between a criminal who's still active versus one that's been caught. The mind, just from observing it changes completely. Once you're caught, you have a big shift in your understanding of the world. I mean, I do have a question about the ethics of having such conversations. But first, technically, is it possible if.
Speaker A: I was technically advising you, I would say, first off, don't advertise it. The fewer people you're going to tell that you're having this conversation with, the better. And, yeah, you could. You doing in person? Are you doing it in person?
Speaker B: Would be amazing. Yeah, but they. Their face would not be shown.
Speaker A: Face would not be shown. Yeah. I mean, you couldn't publish the show for a while. They'd have to put a lot of trust in you that you are not going to. You're gonna have to alter those tapes. I say tapes because it's old school. The opt. You know? Exactly. I'm sure a lot of people just said that, like, oh, shit, this old guy just said tape.
Speaker B: I heard VHS was in the 18 hundreds, I think.
Speaker A: But, yeah, yeah, you could do it. They'd have to have complete faith and trust in you that you destroy the originals after you've altered it.
Speaker B: What about if they don't have faith? Is there a way for them to attain security? So, like, for me to go through some kind of process where I meet them somewhere where, I mean, you're not.
Speaker A: Gonna do it without a bag over your head. I don't know if that's the life you wanna live.
Speaker B: I'm fine with a bag over my head. That's going to get taken out of context, but I just. I think it's a worthy effort. It's worthy to go through the hardship of that to understand the mind of somebody. I think fundamentally, conversations are a different thing than the operation of law enforcement. Understanding the mind of a criminal, I think, is really important.
Speaker A: I don't know if you're going to have the honest conversation that you're looking for. I mean, it may sound honest, but it may not be the truth. I found most times when I was talking to criminals, it's lies mixed with half truths. And you kind of, if they're good, they can keep that story going for long enough. If they're not, you kind of see the relief in them when you finally break that wall down.
Speaker B: That's the job of an interviewer. If the interviewer is good, then perhaps not directly, but through the gaps seeps out the truth of the human being. So not necessarily the details of how they do the operations and so on, and. But just who they are as a human being, what their motivations are, what their ethics are, how they see the world, what is good, what is evil? Do they see themselves as good? What do they see their motivation as? Do they have resentment? What do they think about love for the people within their small community? Do they have resentment for the government or for other nations or for other people? Do they have childhood issues that led to a different view of the world than others perhaps have? Do they have certain fetishes, like sexual and otherwise, that led to their construction of the world? They might be able to reveal some deep flaws to the cybersecurity infrastructure of our world. Not in detail, but, like, philosophically speaking, they might have. I know you might say it's just a narrative, but they might have a kind of ethical concern for the well being of the world, that they're essentially attacking the weakness of the cybersecurity infrastructure because they believe ultimately that would lead to a safer world. So the attacks will reveal the weaknesses. And if they're stealing a bunch of money, that's okay because that's going to enforce you to invest a lot more money in defending. Yeah, defending things that actually matter. You know, nuclear warheads and all those kinds of things. I mean, I could see, you know, it's fascinating to explore the mind of a human being like that because I think it will help people understand. Now, of course it's still a person that's creating a lot of suffering in the world, which is a problem. So do you think ethically it's a good thing to do?
Speaker A: I don't. I mean, I feel like I have a fairly high ethical bar that I have to put myself on and I don't think I have a problem with it. I would love to listen to it.
Speaker B: Okay, great.
Speaker A: I mean, not that I'm your ethical coacher here. Yeah, but.
Speaker B: Well, that's interesting. I mean, so because I thought you would have become jaded and exhausted by the criminal mind.
Speaker A: It's funny, you know, I'm, you know, fast forward in our story. I'm very good friends with Hector Montziger the Cebu, the guy I arrested. And he tells stories of what he did in his past. And I'm like, that Hector, you know, but then I listened to your episode with Brett Johnson and I was like this guy stealing money from the us government and welfare fraud and all this sort of things. He just pissed me off. And I don't know why I have that differentiation in my head. I don't know why. I think one's just, oh, Hector will be Hector. And then this guy just pissed me off.
Speaker B: Well, you didn't feel that way about Hector until you probably met him.
Speaker A: Well, I didn't know Hector. I knew Sabu. So I hunted down Sabu and I learned about Hector over those nine months.
Speaker B: We'll talk about later. Let's finish with. Let's return tangent to. Back to Tangent. Oh, one tangent up. Whose AV unit?
Speaker A: I don't know.
Speaker B: Interesting. So he's at the core of Anonymous. He's one of the critical people in Anonymous. What is known about him?
Speaker A: There's what's known in public and what was known because side with Hector. And he was sort of like the set things up guy. So if Lul Sec had their hackers, which was Cebu and Kayla, and they had their media guy, this guy, topiary, he lived up in the northern end of England and they had a few other guys. But AV unit was the guy that set up infrastructure. So if you need a VPN in Brazil or something like that. To pop through. One of the first things Hector told me after we arrested him is that heavy unit was a secret service agent. And I was like, oh, shit. Just because he kind of lived that lifestyle, he'd be around for a bunch of days, and then all of a sudden, gone for three weeks. And I tried to get more out of Hector that early on in that relationship. I'm sure he was a little bit guarded, maybe trying to social engineer me. Maybe he wanted that. Oh, shit. There's law enforcement involved in this. And not to say, I mean, I was in over my head with that case. Just the amount of work that was going on. So to track them all down, plus the 350 hacks that came in, about just military institutions, you know, it was swimming in the deep end. So it was just at the end of the case, I looked back and I was like, av unit. I could add them all, you know? Maybe that's the perfectionist in me.
Speaker B: Oh, Mandy. Well, reach out somehow. I can't. I won't say how.
Speaker A: Right.
Speaker B: We'll have to figure out.
Speaker A: Would you have him on?
Speaker B: Yeah.
Speaker A: Oh, my God. If you just let me know.
Speaker B: Just let me tell shit about you the whole time.
Speaker A: That's perfect. He probably doesn't even care about me, but.
Speaker B: Well, now he will.
Speaker A: Oh, yeah.
Speaker B: Because there's a certain pleasure of a guy who's extremely good at his job, not catching another guy who's extremely good.
Speaker A: At his job, obviously. Better. He got away. Better.
Speaker B: There you go. He's still eating at you. I love it. You or she.
Speaker A: If I can meet that guy one day, he or she, that'd be great. I mean, I have no power, so.
Speaker B: Yes, Silk road. Can you speak to the scale of this thing? Just for people who are not familiar, how big was it, and any other interesting things you understand about its operation when it was active.
Speaker A: So it was when we finally got looking through the books and, you know, the numbers came out as about $1.2 billion in sales. It's kind of hard with the fluctuation value of bitcoin at the time to come up with a real number. So you kind of pick a daily average, you know, and go across.
Speaker B: So most of the operation was done in bitcoin.
Speaker A: It was all done in bitcoin. You. You couldn't. You had escrow accounts on. You know, you came in and you put money in an escrow account, and, you know, the transaction wasn't done until the client got the drugs or whatever they had bought, and then the drug dealers had sent it in. There was some talk at the time that the cartel was starting to sell on there, so that started getting a little hairy there at the end.
Speaker B: What was your understanding of the relationship between organized crime like the cartels, and this kind of more ad hoc new age market that is the Silk Road?
Speaker A: I mean, it was all just chatter. It was just, you know. Cause like I said, Jared was on the inside, so we saw some of it from the admin side. And Ross had a lot of private conversations with the different people that he had advised him, but no one knew each other. I mean, the only thing, the only thing that they knew with the admins had to send an id to Ross, had to send a picture of their driver's license or passport, which I always found very strange, because if you are an admin on a site that sells fake ids, why would you send your real id? And then why would the guy running the site who profits from selling fake ids believe that it was? But fast forward tangent, they were all real ids. All the ids that we found on Ross computer as the admins were the real people's ids.
Speaker B: What do you make of that? Other clumsiness?
Speaker A: Yeah, low hanging fruit, I guess. I guess that's what it is. I mean. I mean, I would have bought, I mean, even Ross bought fake ids off the site. He had federal agents knock on his door, you know, and then he got a little cocky about it.
Speaker B: The landscape, the dynamics of trust is fascinating here. So you trust. Certain ideas are like, who do you trust in that kind of market? What was your understanding of the network of trust?
Speaker A: I don't think anyone trusts anybody. You know, I mean, I think Ross had his advisors of trust, but outside of that, I mean, he required people to send their id for their trust. He, you know, people stole from him. There was, there's open cases of that. It's a criminal world. You can't trust anybody.
Speaker B: What was his life like, you think?
Speaker A: Lonely. Can you imagine being trapped in something like that where your whole world focuses on that and you can't tell people what you do all day?
Speaker B: Could he have walked away.
Speaker A: Like someone else take over or the site just shut down?
Speaker B: Either one. Just you putting yourself in his shoes. The loneliness, the anxiety, the. Just the growing immensity of it. So walk away with some kind of financial stability.
Speaker A: I couldn't have made it past two days. I don't like loneliness. I mean, my wife's away. I probably call her 1012 times a day. We just talk about things, you know, I just, you know, something crossed my mind. I want to talk about it.
Speaker B: And I'm sure she like to talk to her, like, honestly about everything. So if you were running so crowded, you. You wouldn't be able to, like, hopefully.
Speaker A: I'd have a little protection. I'd only mentioned to her when we were in bed to have that marital connection, but who knows? I mean, she's going to question why the Ferrari is outside and things like that.
Speaker B: Yeah. Well, I'm sure you can come up with something. Why didn't he walk away? It's another question of, why don't criminals walk away in these situations?
Speaker A: Well, I mean, I don't know every criminal mind, and some do. I mean, AV unit walked away. I mean, not to go back to that son of a bitch, but there's.
Speaker B: A theme to this.
Speaker A: But, you know, Ross started counting his dollars. I mean, he really kept track of how much money he was making, and it started, you know, getting exponentially.
Speaker B: Growth.
Speaker A: I mean, he. I mean, if he would have stayed at it, he would have probably been one of the richest people in the world.
Speaker B: And do you think he liked the actual money or the fact of the number growing?
Speaker A: I mean, have you ever held a bitcoin?
Speaker B: Yeah.
Speaker A: Oh, you have? Well, he never.
Speaker B: What do you mean? Hold a bitcoin?
Speaker A: Can't hold it. It's not real. It's not like I can give you a briefcase of bitcoin. Right. Or something like that. He liked the idea of it growing. He liked the idea. I mean, I think it started off as sharing this idea, but then he really did turn to, like, I am the captain of this ship, and that's what goes. And he was making a lot of money. And again, my interactions with Ross was about maybe five or 6 hours over a two day period. I knew DPR. Cause I read his words and all that. I didn't really know Ross. Um, there was a journal found on his computer, and so it sort of kind of gave me a little inside. Um, so I don't like to do a playbook for criminals, but I'll tell you right now, don't write things down. Um, there was a big fad about people. Like, remember kids going around shooting people with paintballs and filming it? I don't know why you would do that. Why would you videotape yourself committing crime and then publish it? Like, if there's one thing I've taught my children, don't record yourself doing bad things. It never goes back. Goes well.
Speaker B: So you actually give advice on the other end of logs being very useful for the defense perspective, for, you know, information is useful for being able to figure out what the attacks were all about.
Speaker A: Logs are the only reason I found Hector, monsieur. I mean, the. The one time his VpN dropped during a fox hack, and I. He says he did. It wasn't even hacking. He just was sent a link and he clicked on it. And in 10 million lines of logs, there was one IP address that stuck out.
Speaker B: This is fascinating. We'll explore several angles of that. So what was the process of bringing down Ross and the Silk Road?
Speaker A: All right, so. That's a long story. You want the whole thing? You want to break it up?
Speaker B: Let's start at the beginning.
Speaker A: Once we had the information of the chat logs and all that from the server, we found.
Speaker B: What's the server? What's the chat log?
Speaker A: So the dot onion was running the website. The Silk Road was running on a server in Iceland.
Speaker B: How did you figure that out? That was one of the claims that the NSA.
Speaker A: Yeah, that's. That's. That's the one there that we said that. Yeah. I wouldn't tell you if it was that. It's on the Internet. I mean, the Internet has their conspiracy theories and all that, so.
Speaker B: But you figure out that's the part of the thing you do, you. It's puzzle pieces. You have to put them together.
Speaker A: Yeah.
Speaker B: And look for different pieces of information and figure out. Okay, so you figure out the servers.
Speaker A: In Iceland, we get a copy of it, and so we start getting clues off of that.
Speaker B: Wait, the physical copy of the server?
Speaker A: Yeah, we flew. You fly over there. So you. You go, if you've been Iceland. If you've never been, you should definitely go to Iceland. Iceland.
Speaker B: Is it beautiful or.
Speaker A: I love it. I love it. It was. What? So I'll tell you this. So sorry. Tangents.
Speaker B: I love this.
Speaker A: Yeah. So I went to Iceland for the anonymous case, then I went to Iceland for the Silk road case, and I was like, oh, shit. All cybercrime goes through Iceland. It was just my sort of thing. And I was over there for, like, the third time, and I said, if I ever can bring my family here, like, so there's a place called thingavar, and I'm sure I'm fucking up the name. The Icelandics are pissed right now, but it's where the. The north american continental plate and the european continental plate are pulling apart, and it's being filled in with volcanic material in the middle. And it's so cool. I was like, one day I'll be able to afford to bring my family here. And once I left, just, like, the.
Speaker B: Humbling and the beauty of nature.
Speaker A: Just everything, man, it was a different world. It was insane how great Iceland is. And so we went back and we rented a van and we took friends and we drove around the entire country. Absolutely. Like a beautiful place. Like, Reykjavik's nice, but get out of Reykjavik as quick as you can and see the countryside.
Speaker B: How is this place even real?
Speaker A: Well, it's so new. I mean, that's so. You know, our rivers have been going through here for millions of years and flattened everything out and all that. These are. These are new. This is new land being carved by these rivers. You can walk behind a waterfall in one place. It's the most beautiful place I've ever been.
Speaker B: Do you understand why this is a place where a lot of hacking is being done?
Speaker A: Because the energy is free and it's cool. So you have a lot of servers going on there. Server farms. The energy has come up out of the ground, geothermal, and then it keeps all the servers nice and cool. So why not keep your computers there at a cheap rate?
Speaker B: I'll definitely visit for several reasons, including to talk to AV unit.
Speaker A: Yeah, he'll get you there.
Speaker B: Well, the servers are there, but they don't probably live there. I mean, that's interesting. I mean, the Pacific, the PSD, the time zones, there's so many fascinating things to explore here. But so you got to that.
Speaker A: I mean, the european Internet cable goes through there, so, you know, across the Greenland and down through Canada and all that. So they have backbone access with cheap energy and free cold weather, you know.
Speaker B: And beautiful.
Speaker A: Oh, and beautiful. Yes.
Speaker B: So, chat logs on that server, what are the. What was in the chat logs?
Speaker A: Everything. He kept them all. That's another issue. If you're running a criminal enterprise, please don't keep all. Again, I'm not making a guidebook of how to commit your perfect crime. But, you know, every chat he ever had and everyone's chat, it was. It was like going into Facebook. Of criminal activity.
Speaker B: Yeah, I've just looking at texts with Elon Musk being part of the conversations. I don't know if you're familiar, but they've been made public for the court cases. Going through was going through is going through was going through with Twitter. I don't know where it is, but it made me realize that, oh, okay. I'm generally. That's my philosophy on life is like anything I text or email or say publicly or privately, I should be proud of. So I tried to kind of do that, because you basically, you say, don't keep chat logs, but it's very difficult to erase chat logs from this world. I guess if you're a criminal, that should be, like, you have to be exceptionally competent at that kind of thing. To erase your footprints is very, very difficult.
Speaker A: Can't make one mistake. All it takes is one mistake of keeping it. But, yeah, I mean, not only do you have to be. Whatever you put in a chat log or whatever put in an email, it has to hold up, and you have to stand behind it publicly when it comes out, but it hasn't. If it comes out ten years from now, you have to stand behind it. I mean, we're seeing that now in today's society.
Speaker B: Yeah. But that's a responsibility you have to take really, really seriously if, like, if I was a parent and advising teens, like, you kind of have to teach them that. I know there's a sense, like, no, we'll become more accustomed to that kind of thing, but in reality, nope. I think in the future, we'll still be held responsible for the weird shit we do.
Speaker A: Yeah. A friend of mine, his daughter got kicked out of college because of something she posted in high school. And the shittiest thing for him, but great for my kids. Great lesson. Look over there, and you don't want that happen to you.
Speaker B: Yeah. Okay. So in the chat logs was useful information. Like breadcrumbs. Of what? Of information that you can then pull out.
Speaker A: Yeah. Great evidence and stuff. You know, I mean, obviously evidence, too. Yeah, a lot of evidence. Here's a sale of this much heroin because, you know, Ross ended up getting charged with czar status on certain things, and that's. It's a certain weight in each type of drug. And that you had, like, I think it's. It's four or five employees of your empire, and that you made more than $10 million. And so it's. It's. It's. You know, it's just like, what the narco traffickers get charged with or, you know, anybody out of Columbia, you know, so.
Speaker B: And that was primarily what he was charged with during. When he was arrested, is the drug.
Speaker A: Yeah. And he got charged with some of the hacking tools, too.
Speaker B: Okay. Because he's in prison, what, for two life sentences plus 40 years and no possibility of parole.
Speaker A: In the federal system, there's no possibility of parole when you have life. The only way you get out is if the president pardons you.
Speaker B: There's always a chance.
Speaker A: There is. I think it was close. I heard rumors there was close.
Speaker B: Well, right. So it depends. It's fascinating, but given the political, the ideological ideas that he represented and espoused, it's not out of the realm of possibility.
Speaker A: Yeah, I mean, I've been asked before who, you know, who does he get out of prison first, or does Snowden come back into America? I don't know. I have no idea.
Speaker B: Just became a russian citizen.
Speaker A: I saw that. I've heard a lot of good, weird theories about that one.
Speaker B: Well, actually, on another tangent, let me ask you. Do you think Snowden is a good or a bad person?
Speaker A: A bad person.
Speaker B: Can you make the case that he's a bad person?
Speaker A: There's ways of being a whistleblower, and there's rules set up on how to do that, and he didn't follow those rules. I mean, I'm red, white and blue, so I'm pretty.
Speaker B: So you think his actions were anti american?
Speaker A: I think the results of his actions were anti american. I don't know if his actions were anti american.
Speaker B: Do you think he could have anticipated the negative consequences of his action? Should we judge him by the consequences or the ideals of the intent of his actions?
Speaker A: I think we all get to judge him based our own beliefs, but I believe what he did was wrong.
Speaker B: Can you steel man the case that he is actually a good person and good for this country, for the United States of America, as a flag bearer for the whistleblowers, the check on the power of government.
Speaker A: Yeah, I mean, I'm not big government type guy, so even that sounds weird coming from a government guy for so many years. But there's rules in place for a reason. I mean, he put, you know, some of our best capabilities. He made them publicly available. It really kind of set us back in the. And this is in my world at all, but the offensive side of cybersecurity.
Speaker B: Right. So he revealed stuff that he didn't need to reveal in order to make the point.
Speaker A: Correct.
Speaker B: So if you can imagine a world where he leaked stuff that revealed mass surveillance efforts and not reveal other stuff, like you said, is the mass surveillance. I mean, that's the thing that, of course, there's, in the interpretation of that there's fear mongering, but at the core, that was a real shock to people, that it's possible for government to collect data at scale.
Speaker A: It's surprising to me that people are that shocked by it.
Speaker B: Well, there's conspiracies and then there's, like, actual evidence that that is happening. I mean, it's a reality. There's a lot of reality that people ignore, but when it hits you in the face, you realize, holy shit, we're living in a new world. This is the new reality, and we have to deal with that reality. Just like you work in cybersecurity. I think it really hasn't hit most people how fucked we all are in terms of cybersecurity. Okay, let me rephrase that. How many dangers there are in a digital world, how much under attack we all are, and how more intense the attacks are getting and how difficult the defense is and how important it is and how much we should value it and all the different things we should do at the small and large scale to defend. Like, most people really haven't woken up. They think about privacy from tech companies. They don't think about attacks. Cyber attacks.
Speaker A: People don't think they're a target. And that message definitely has to get out there. I mean, you know, if you have a voice, you're a target. If the place you work, you might be a target. You know, your husband might work at someplace, you know, because now people are working from home. So they're gonna target, you know, target you to get access to his network.
Speaker B: In order to get in that same way. The idea that the us government, or any government could be doing mass surveillance on its citizens is one that was a wake up call, because you could imagine the ways in which that could be. Like, you could abuse the power of that to control a citizenry for political reasons and purposes.
Speaker A: Absolutely. You could abuse it. I think during the part of the Snowden League saw that two NSA guys were moderating their girlfriends, and there's rules in place for that. Those people should be punished for abusing that. But how else are we going to hear about, you know, terrorists that are in the country talking about birthday cakes? And, you know, that was a case where that. That was the trip word that. That, you know, we're going to go bomb New York City's subway.
Speaker B: Yeah, it's complicated, but it just feels like there should be some balance of transparency. There should be a check in that power, because like, you, you know, in the name of the war on terror, you can sort of sacrifice. There is a trade off between security and freedom, but it just feels like there's a giant slippery slope on the sacrificing of freedom in the name of security.
Speaker A: I hear you. We live in a world where. Well, I live in a world where I had to tell you exactly when I arrested someone. I had read a 50 page document of how I arrested you and all the probable cause I have against you and all that. Well, you know, bad guys are reading that. They're reading how I caught you and they're changing their way, they're doing things, they're changing their mo. They're doing it to be more secure. If we tell people how we're monitoring, what we're surveilling, we're going to lose that. I mean, the terrorists are just going to go a different way. And I'm not trying to. Again, I'm not big government, I'm not trying to say that it's cool that we're monitoring. The us government's monitoring everything. Big techs monitoring everything. They're just monetizing it versus possibly using it against you.
Speaker B: But there is a balance in those 50 pages. They have a lot of value. They make your job harder, but they prevent you from abusing the power of the job. Yeah, there's a balance. That's a tricky balance. So the chat logs in Iceland gave you evidence of the heroin and all the large scale czar level drug trading. What else did it give you in terms of the how to catch?
Speaker A: I gave us infrastructure. So the onion name was actually running on a server in France. So if you like. And it only commuted through a back channel, a VPN, to connect to the Iceland server. There was a bitcoin like vault server that was also in Iceland. And I think that was so that the admins couldn't get into the bitcoins, the other admins that were hired to work on the site. So you could get into the site, but you couldn't touch the money. Only Ross had access to that. And then, you know, another. Another big mistake on Ross's part is he had the backups for everything at a data center in Philadelphia. Don't put your infrastructure in the United States. I mean, again, let's not make a playbook.
Speaker B: But, you know, I think these are low hanging fruit that people of competence would know already.
Speaker A: I agree.
Speaker B: But it's interesting that he wasn't competent enough to make. So he was incompetent in certain ways.
Speaker A: Yeah. I don't think he was a mastermind of setting up an infrastructure that would protect his online business because, you know, keeping chat logs, keeping a diary, putting infrastructure where it shouldn't be, um, bad decisions.
Speaker B: How did, uh, you figure out that he's in San Francisco?
Speaker A: So we had that part with Jared, that he was on the west coast.
Speaker B: And then who again, is Jared?
Speaker A: Jared Derriegan was a. He was a partner, um, in, uh, he, he was a DHS agent. Um, worked for HSI Homeland security investigations in Chicago. Uh, he started his Silk Road investigation because he was working at O'Hare and a weird package came in. Come to find out, he traced it back to Silk Road. So he started working a Silk road investigation long before I started my case. And he made his way up undercover, all the way to be an admin on Silk Road. So he was talking to Ross on a Jabra server, a private Jabra server, private chat communication server. And we noticed that Ross's time zone on that Jabra server was set to the west coast. So we had Pacific time on there. So we had a region 120, fourth of the world was covered of where we thought we might be.
Speaker B: And from there, how do you get to San Francisco?
Speaker A: There was another guy, an IR's agent that was part of the team, and he used a powerful tool to find his clue. He used the world of Google. He simply just went back and googled around for Silk Road. At the time it was coming up and found some posts on some help forums that this guy was starting an onion website and wanted some cryptocurrency help. And if you could help him, please reach out to Ross dot albrechtmail.com. in my world, that's a clue. So.
Speaker B: Okay, so that's as simple as that.
Speaker A: Yeah. And the name he used on that post was Frosty.
Speaker B: Yeah. So you had to connect Frosty and other uses in Frosty. And here's a Gmail. And the Gmail has the name.
Speaker A: The Gmail posted that I need help under the name Frosty on this forum.
Speaker B: So what's the connection of Frosty elsewhere?
Speaker A: The person logging into the Philadelphia backup server, the name of the computer was Frosty. Yeah, another clue in my world.
Speaker B: And that's it. The name is there. The connection to the Philadelphia server and then to Iceland is there. And so the rest is small details in terms of, uh. Or is there interesting details?
Speaker A: No. I mean, there's some electronic surveillance that find Ross Ulbricht living in a house. And is there, you know, is a computer at his house attaching to, you know, does it have tor traffic at the same time that DPR is on another big clue, matching up timeframes again.
Speaker B: Just putting your email out there, putting your name out there like that, like what I see from that, just at the scale of that market, it just makes me wonder how many criminals are out there that are not making these low hanging fruit mistakes and are still successfully operating it. To me, it seems like you could be a criminal much it's much easier to be a criminal on the Internet. What else to you is interesting to understand about that case? Avros and Silk Road and just the history of it from your own relationship with it, from a cyber security perspective, from an ethical perspective, all that kind of stuff. Like when you look back, what's interesting to you about that case?
Speaker A: I think my views on the case have changed over time. I mean, it was my job back then, so I just looked at it as of, I'm going after this. I sort of made a name for myself in the bureau for the anonymous case. And then this one was just. I mean, this was a bigger deal. I mean, they flew me down to DC to meet with the director about this case. The United States was going to announce this case, the arrest. Unfortunately, the government shut down two days before, so it was just us. And that's really the only reason I had any publicity out of it, is because the government shut down. And the only thing that went public was that affidavit with my signature at the end. Otherwise it would have just been the attorney general and the president announcing the rest of this big thing and you wouldn't have seen me.
Speaker B: Did you understand that this was a big case?
Speaker A: Yeah, I knew at the moment.
Speaker B: Was it because of the scale of it or what it stood for?
Speaker A: I just knew that the public was going to react, react in a big way like the media was now. Did I think that it was going to be on the front page of every newspaper the day after the arrest? No, but I could sense it. Like, I went like three or four days without sleep when I was out in San Francisco to arrest Ross. I had sent three guys to Iceland to. So it was a three prong approach for the takedown. It was get Ross, get the bitcoins and seize the site. Like, we didn't want someone else taking control of the site and we wanted that big splash of that banner. Like, look, look, the government found this site. Like, you might not want to think about doing this again. So.
Speaker B: And you were able to pull off all three.
Speaker A: Maybe that's my superpower. I'm really good about putting smarter people on than I am together on the right things. You know, that's the only way to do it in the business I formed. That's what I did. I hired only smarter people than me. And I, you know, I'm not that smart, but, you know, smart enough to know who the smart people are in.
Speaker B: The team was able to do all three.
Speaker A: Yeah, we were able to get all three done. Yeah, and the one guy, one of the guys, main guys I sent to Iceland, man, he was so smart. Like, I sent another guy from the FBI to. To France to get that part, and he couldn't do it. So the guy in Iceland did it from. From Iceland. They had to pull some stuff out of memory on a computer. You know, it's live process stuff. I'm sure you've done that before, but.
Speaker B: I'm sure you did. Look, look what you're doing, like a multi layer interrogation going on. Was there a concern that somebody else would step in and control the site?
Speaker A: Absolutely. We didn't have insight on who exactly I'd control.
Speaker B: So it turns out that Russ had, like, dictatorial control. So it wasn't easy to delegate to somebody else.
Speaker A: He hadn't. I think he had some sort of ideas. I mean, his diary talked about walking away and giving it to somebody else, but he didn't. He couldn't give up that control on.
Speaker B: Anybody, apparently, which makes you think that power corrupts. And his ideals were not as strong as he espoused about, because if it was about the freedom of being able to buy drugs if you want to, then he surely should have found ways to delegate that power.
Speaker A: Well, he changed over time. You could see it in his writings that he changed. People will argue back and forth that there was never murders on Silk Road when we were doing the investigation. To us, there were six murders. So there. There was. The way we see him, saw him at the time was Ross ordered people to be murdered, people stole from him and all that. It was sort of an evolution from, oh, man, I can't deal with this. I can't do it. It's too much to. The last one was like the guy said, well, he's got three roommates. It's like, we'll kill them, too.
Speaker B: Was that ever proven in court?
Speaker A: No, the murders never went forward because there was some stuff problems in that case. So there was a separate case in Baltimore that they had been working on for a lot longer. And so during the investigation, that caused a bunch of problems, because now we have multiple federal agencies case against the same thing.
Speaker B: How do you decide not to push forward the murder investigations?
Speaker A: So there was a deconfliction meeting that happened in DC. I didn't happen to go to that meeting, but Jared went. This is before I ever knew Jared. And we have, like, televisions where we can just sit in a room and sit in on the meeting. But it's all secured network and all that, so we can talk openly about secure things. And we sat in on the meeting, and people just kept saying the term sweat equity. I've got sweat equity. Meaning that they had worked on the case for so long that they deserve to take them down. And by this time, you know, no one knew about us, but we told them at the meeting that, well, we had found the server, and we have a copy of it, and we have the infrastructure. And these guys had just had communications, undercovers. They didn't really know what was going on. And this wasn't my first deconfliction meeting. We had a huge deconfliction meeting during the anonymous case.
Speaker B: What's the deconfliction meeting?
Speaker A: Agents within your agency or other other federal agencies have an open investigation that if you expose your case or took down your case, would hurt their case or the other.
Speaker B: Oh, so you kind of have a. It's like the rival gangs meet at the table in a smoke filled room.
Speaker A: And less bullets at the end, but, yes.
Speaker B: Boy, with the sweat equity.
Speaker A: Yeah.
Speaker B: So, I mean, there's careers at stake, right? Yeah. You hate that idea.
Speaker A: Yeah. I mean, why would you. Why is that a stake? Just because you've worked on it long enough, longer than I have, that means you get. You. You did better.
Speaker B: Yeah.
Speaker A: That's insane. To me, that's rewarding bad behavior.
Speaker B: And so that one. The part of the sweat equity discussion was about murder. And this was, here's a chance to actually bust them, given the data you have from Iceland and all that kind of stuff.
Speaker A: So why they wanted us just to turn the data over to them.
Speaker B: To them?
Speaker A: Yeah. Thanks. Thanks for getting us this far. Here it is. I mean, it came to the point where they sent us, like, they had a picture of what they thought Ross was, and it was an Internet meme. It really was a meme. It was a photo that we could look up like it was insane.
Speaker B: All right, so there's different degrees of competence all across the world between different people? Yes. Okay. Does part of you regret because you pushed forward the heroin and the drug trade? We never got to the murder discussion.
Speaker A: I mean, the only regretting is that the Internet doesn't seem to understand. They just kind of blow that part off, that he literally paid people to have people murdered. It didn't result in a murder. And I thank God no one resulted in a murder.
Speaker B: But that's where his mind was.
Speaker A: His mind and where he wrote in his diary was that I had people killed. And here's the money. He paid it. It. He paid a large amount of bitcoins for that murder.
Speaker B: Those murders didn't just even think about it, he actually took action. But the murders never happened. He took action by paying the money.
Speaker A: Correct. And the people came back with results. He thought they were murdered.
Speaker B: That said, can you understand and steal me on the case for the drug trade on Silk Road? Like, can you make the case that it's a net positive for society?
Speaker A: So there was a time period of when we found out the infrastructure and when we built the case against Ross. I don't remember exactly. Six weeks, a month, two months, I don't know, somewhere in there. Um, but then at Ross ascendancy, there was a father that stood up and talked about his son dying. And I went back and kind of did the math. And it was between those time periods of when we knew we could shut it down, we could have pulled the plug on the server and gone. And when Ross was arrested, his son died from buying drugs on Silk Road. And I still think about that father a lot.
Speaker B: But if we look at the scale, at the war on drugs, let's just. Even outside of Silk Road, do you think the war on drugs by the United States has caused, has alleviated more suffering or caused more suffering in the world?
Speaker A: That might be above my pay scale. I mean, I understand the other side of the argument. I mean, people said that I don't have to go down to the corner to buy drugs. I'm not going to get shot on the corner buying drugs or something. I can just have them sent to my house. People are going to do drugs anyways. I understand that argument from my personal standpoint. If I made it more difficult for my children to get drugs, that I'm satisfied.
Speaker B: So your personal philosophy is that if we legalize all drugs, including heroin and cocaine, that that would not make for a better world?
Speaker A: I don't know. Personally, I don't believe legalizing all drugs would make. Make for a better world.
Speaker B: Can you imagine that it would. Do you understand that argument?
Speaker A: Sure. I mean, as I've gotten older, I've started to. I like to see both sides of an argument. And when I can't see the other side, I. That's when I like, really like to dive into it and I can see the other side. I can see the why people would say that, but I don't want to be my race children in a world where drugs are just free for use.
Speaker B: And then the other side of it is with Silk Road. Did taking down Silk Road, did that increase or decrease the number of drug trading criminals in the world?
Speaker A: It's unclear online I think it increased. I think that's one of the things I think about a lot with Silk Road was that no one really knew. I mean, there was thousands of users, but then after that, it was on the front page of the paper and there was millions of people that knew about Tor and onion sites. It was an advertisement. I thought crypto was going to crash right after that. People now see that bad people are doing bad things with crypto. That'll crash. I'm obviously wrong on that one. And I thought Ross was sentenced to two life sentences plus 40 years. No one's going to start up. These dark markets exploded after that. Some of them started as opportunistic. I'm going to take those escrow accounts and I'm going to steal all the money that came in. There were that, but there were a lot of dark markets that popped up after that. Now we put the playbook out there.
Speaker B: Yeah. And also there's a case for. Do you ever think about not taking down, if you have not taken down the Silk Road, you could use it because it's a market. It itself is not necessarily the primary criminal organization. It's a market for criminals. So it could be used to track down criminals in the physical world. So if you don't take it down, given that it was how centralized it was, it could be used as a place to find criminals. Right.
Speaker A: The dealers, the drug dealers take it down.
Speaker B: The dealers, yeah. So if you have the car, get the cartels, start, get too involved, you go after the dealers.
Speaker A: It would have been very difficult because.
Speaker B: Of tor and all that, because all.
Speaker A: The productions, anonymity, decloaking, all that would have been drastically more difficult. And a lot of people in upper management, the FBI didn't have the appetite of running something like that. That would have been the FBI running a drug market. How many, how many kids, how many fathers would have to come in and said, my kid bought while the FBI was running a site, a drug site. My kid died. So I didn't know anybody in the FBI, in management, they would have the appetite to let us run what was happening on Silk Road. Because remember, at that time, we still believe in six people are dead. We're still investigating where all these bodies. That's pretty much why we took down Ross when we did. We had to jump on it fast.
Speaker B: What else can you say about this complicated world that has grown of the dark web?
Speaker A: I don't understand it. I like, it would have been something for me. I thought it was going to collapse, but, I mean, it's just gotten bigger in what's going out there now. I'm really surprised that it hasn't grown into other networks or people haven't developed other networks.
Speaker B: You mean, like, instead of Tor?
Speaker A: Yeah, Tor is still the main one out there. I mean, there's some. There's a few others, and I'm not going to put an advertisement out for them, but, you know, I thought that market would have grown.
Speaker B: Yeah. My sense was, when I interacted with Tory, was that there's huge usability issues. But that's for, like, legal activity. Yeah, because, like, if you care about privacy, it's just not as good of a browser. Like, it's to look at stuff.
Speaker A: No, it's way too slow. It's way too slow. But, I mean, you can't even, like. I know some people would use it to, like, view movies. Like Netflix. You can only view certain movies in certain countries. You can use it for that, but it's. It's too slow even for that.
Speaker B: So were you ever able to hold in your mind the landscape of the dark web? Like, what. What's going on out there? It's. To me, as a human being, it's just difficult to understand the digital world. Like, these anonymous usernames, like, doing anonymous activity. It's just. It's hard to. What am I trying to say? It's hard to visualize it in the way I can visualize. Like, I've been reading a lot about Hitler. I can visualize meetings between people, military strategy, deciding on certain evil atrocities, all that kind of stuff. I can visualize the people. There's agreements, handshakes, stuff signed groups built, like, in the digital space, with bots, with anonymity. Anyone human can be multiple people. It's just.
Speaker A: Yeah, it's all lies. It's all lies. Yeah.
Speaker B: It feels like I can't trust anything.
Speaker A: No, you can't. You honestly can't. And, like, you can talk to two different people, and it's the same person. Like. Like, there's so many different. You know, Hector had so many different identities online that you know of things that, you know, the lies to each other. I mean, he lied to people inside his group just to use another name to spy on, make sure what they. You know, we're talking shit behind his back or weren't doing anything. It's all lies. And people that can keep all those lies straight. It's unbelievable.
Speaker B: Me, Ross Ulbricht represents the very early days of that. That's why the. The competence wasn't there. Just imagine how good the people are now the kids that grow up.
Speaker A: Oh, they've learned from his mistakes.
Speaker B: Just the extreme competence. You just see how good people are at video games. Like, the level of play in terms of video games. Like, I used to think I sucked. Now I'm not even a. And, like, I'm not even in the, like, consideration of calling myself shitty at video games. I'm not even. I'm, like, non existent. I'm like the mold.
Speaker A: Yeah, I stopped playing. So embarrassing.
Speaker B: It's embarrassing.
Speaker A: It's like wrestling with your kid and he finally beat you. He's like, well, fuck that. I'm not wrestling with my kid any, ever again.
Speaker B: And in some sense, hacking at its best and its worst is a kind of game. And you can get exceptionally good at that kind of game game.
Speaker A: And you get the accolades of it. I mean, there's, you know, there's power that comes along if you have success. Look at the kid that was hacking into Uber and Rockstar games. He put it out there that he was doing it. I mean, he used the name. Whatever hacked into Uber was his screen name. He's very proud of it. I mean, one building Evans against himself. But, you know, he wanted that slap on the back, like, look at what a great hacker you are.
Speaker B: Yeah. What do you think is in the mind of that guy? What do you think is in the mind of Russ? Do you think they see themselves as good people? Do they think they acknowledge the bad they're doing onto the world?
Speaker A: So that Uber hacker, I think that's just, you thing, not realizing what consequences are. I mean, based on his actions, Ross was a little bit older. I think Ross truly is a libertarian. He was. Truly had his beliefs that he could provide the gateway for other people to live that libertarian lifestyle and put in their body what they want. I don't think that was a front or a lie.
Speaker B: What's the difference between DPR and Russ? He said, I have never met Ross until I have only had those two days of worth of interaction. It's just interesting, given how long you've chased him and then having met him, what was the difference to you as a human being?
Speaker A: He was a human being. He was. He was, you know, he was an actual person. He was nervous when I. When we arrested him. So one of the things that. That I learned through my law enforcement career is if I'm going to be the case agent, I'm going to be the one in charge of, you know, dealing with this person. I'm not putting handcuffs on him. Somebody else is going to do that. Like, I'm going to be there to help him. You know, I'm your conduit to help. And so, you know, right after someone's arrested, you obviously have had them down for weapons to make sure for everybody's safety. But then I just. Just put my hand on their chest, just feel their heart, feel their breathing. You're gonna. It's, I'm sure it's the scariest day, but then to have that human contact kind of settles people down and you kind of. Let's start thinking about this. I'm gonna tell you, you know, I'm gonna be open and honest with you. You know, there's a lot of cops out there and federal agents, cops that just go to the hard ass tactic. You don't get very far with that. You don't get very far being a mean asshole to somebody, you know, be compassionate, be human, and it's going to go a lot further.
Speaker B: So given everything he's done, you were still able to have compassion for him?
Speaker A: Yeah, we took him to the jail and we. So he was after hours, so he didn't get to see a judge that day. So you stick. We stuck him in the San Francisco jail. I hadn't slept for about four days because I was dealing with people in Iceland, bosses in DC, bosses in New York, so. And I was in the. In San Francisco, so timeframe, like, like the Iceland people were calling me when I was supposed to be sleeping. It was insane. But I still went out that night while Ross sat in jail and bought him breakfast. I said, what do you want for breakfast? I'll have a nice breakfast for you. Cause we picked him up in the morning and took him over to the FBI to do the FBI booking, the fingerprints and all that. And I got him breakfast. I mean, and you don't get paid back for that sort of thing. I'm not looking, but out of my own.
Speaker B: Did he make special requests for breakfast?
Speaker A: Yeah, he asked for certain things.
Speaker B: Can you mention, is that top secret FBI?
Speaker A: It's not top secret granola bars, like. And, you know, but I mean, he already had lawyered up, so we, you know, which is his right, he can do that. So I knew we weren't going to work together, you know, like I did with Hector. But I mean, this is the last day.
Speaker B: Most of the conversations have to be them with lawyers.
Speaker A: From that point on, I can't question him when he asked for a lawyer or if I did, it couldn't be used against him. So we just had conversation where I talked to him. You know, he could, you know, could. Could say things to me, but then I would remind him that he asked for a lawyer, and he'd have to waive that and all that. But we didn't talk about his case so much. We just talked about, like, human beings.
Speaker B: Did he, with his eyes, with his words, reveal any kind of regret, or did you see a human being changing, understanding something about themselves in the process of being caught?
Speaker A: No, I don't think that. I mean, he did offer me $20 million to let him go when we were driving. When we were driving to the jail.
Speaker B: Oh, no.
Speaker A: And I asked him what I was gonna. We were gonna do with the agent that sat in the front seat.
Speaker B: The money really broke him, huh?
Speaker A: I think so. I think he kind of got caught up in how much money it was and how, you know, when crypto started, it was pennies, and by the time he got arrested was $120 and, you know, 177,000 bitcoins. Even today, you know, that's a lot of bitcoins.
Speaker B: So you really could have been. If you continued to be one of the richest people in the world?
Speaker A: I possibly could have been. If I took that 20 million, then I could have been living. We could have this conversation in Venezuela.
Speaker B: In a castle. In a palace.
Speaker A: Yeah. Until it runs out, and then the government storms the castle.
Speaker B: Yeah. Have you talked to Russ since?
Speaker A: No. No, I'd be open to it. I don't think he probably wants to hear from me.
Speaker B: And do you know where in which prison he is?
Speaker A: I think he's somewhere out in Arizona. I know he was in the one next to super Max for a little while, like, the. The high security one that's, like, shares the fence with super Max, but I don't think he's there anymore. I think he's out in Arizona. I haven't seen in a while.
Speaker B: I wonder if you can do interviews in prison. That'd be nice.
Speaker A: Some. Some people are allowed to, so I don't. I've not seen an interview with him. I know people have wanted to interview him about books and that sort of thing.
Speaker B: Right. Because the story really blew up. Did it surprise you how much the story and many elements of it blew up movies?
Speaker A: It did surprise me. Like it. My wife's uncle, who I didn't. I've been married my wife for 22 years now. I don't think he knew my name, and he was excited about that. He reached out when Silk Road came out, so that was surprising to see.
Speaker B: Did you think the movie on the topic was good.
Speaker A: I didn't have anything to do with that movie. I've watched it once. It was kind of cool that Jimmy Simpson, you know, was my name in the movie. But outside of that, I thought it sort of missed the mark on some things.
Speaker B: When Hollywood, I don't think they understand what's interesting about these kinds of stories. And there's a lot of things that are interesting, and they missed all of them. So, for example, I recently talked to John Carmack, who's a world class developer and so on. So Hollywood would think that the interesting thing about John Carmack is some kind of like shitty, like a parody of a hacker or something like that, that would show like really crappy emulation of some kind of Linux terminal thing. The reality is like the technical details for 5 hours with him, for 10 hours with him is what people actually want to see. Even people that don't program, they want to see a brilliant mind. The details that they're not, even if they don't understand all the details, they want to have an inkling of the genius there. That's just one way I'm saying like that you want to reveal the genius, the complexity of that world in interesting ways. And to make a Hollywood almost parody caricature of it, it just destroys the spirit of the thing. So one, the operation FBI is fascinating. Just tracking down these people on the cybersecurity front is fascinating. The other is just how you run tour, how you run this kind of organization, the trust issues of the different criminal entities involved, the anonymity, the, the low hanging fruit, the being shitty at certain parts. In, on the technical front, all those are fascinating things. And you know, that's, that's what a movie should reveal. Should probably be a series, honestly, a Netflix series than the movie.
Speaker A: Yeah, they want an FX show or something like that. Kind of gritty, you know?
Speaker B: Yeah, yeah, gritty, exactly. Gritty. I mean, shows like Chernobyl from HBO made me realize, okay, you can do a good job of a difficult story and like reveal the human side, but also reveal the technical side and have some deep, profound understanding. On that case, on the bureaucracy of a soviet regime. In this case, you could reveal the bureaucracy, the chaos of a criminal organization, of a law enforcement organization. I mean, there's so much to, like, explore. It's fascinating.
Speaker A: Yeah, I like Chernobyl when I rewatch it. I can't watch episode three, though, the animal episode. They go around shooting all the dogs and all that. I gotta skip that part.
Speaker B: You're a big softie.
Speaker A: Aren't you? I really am.
Speaker B: Yeah.
Speaker A: I'm sure I'll probably cry at some point.
Speaker B: I love it. I love it.
Speaker A: Listen, don't get me talking about that episode you made about your grandmother. Oh, my God. That was rough.
Speaker B: Just to linger on this ethical versus legal question, what do you think about people like Aaron Schwartz? I don't know if you're familiar with him. He was somebody who broke the law in the name of an ethical ideal. He downloaded and released academic publications that were behind a paywall, and he was arrested for that and then committed suicide. And a lot of people see him, certainly in the MIT community, but throughout the world, as a hero. Because you look at the way knowledge, scientific knowledge, is being put behind paywalls, it does seem somehow unethical. And he basically broke the law to do the ethical thing. Now, you could challenge it, maybe it is unethical, but, you know, there's a gray area. And to me, at least, it is ethical. To me, at least, he is a hero. Because I'm familiar with the paywall created by the institutions that hold these publications. They're adding very little value. So it is basically holding hostage the work of millions of brilliant scientists for some kind of, honestly, a crappy capitalist institution. Like they're not actually making that much money. It doesn't make any sense to me. It should. To me, it should all be open public access. There's no reason it shouldn't be. All publication should be. So he stood for that ideal and was punished harshly for it. That's the other criticism, was too harshly, and of course, deeply, unfortunately, that also led to a suicide because he was also tormented on many levels. I mean, do you, are you familiar with him? What do you think about that line between what is legal and what is ethical?
Speaker A: So it's tough. It's a tough case. I mean, the outcome was tragic, obviously. Unfortunately, when you're in law enforcement, you have to, your job is to enforce the laws. I mean, if you're told that you have to do a certain case, you know, and there is a viable violation of at the time, you know, 18 USC 10, 10 30 computer hacking, you have to press forward with that. I mean, you have to charge, you bring the case to the unicorn office, and whether they're going to press charges or not, you know, you can't, you can't really pick and choose what you press and don't press forward. I never felt that at least that flexibility, not in the FBI. I mean, maybe if, when you're a street cop and you pull somebody over, you can let them go with a warning.
Speaker B: So in the FBI, you're sitting in a room, but you're also, you're also a human being. You have compassion. You arrested Ross. And the hand on the chest, I mean, that's, that's a human thing. So there's a.
Speaker A: But I'm. I can't be the jury for whether it was a good hack or a bad hack. It's all, someone, a victim has come forward and said, we're the victim of this. And I agree with you, because, again, I let the basis of the Internet was to share academic thought. I mean, that's where the Internet was.
Speaker B: Born to, but it's not, it's not up to you. So the, the role of the FBI is to enforce the law.
Speaker A: Correct. And, you know, there's. There's a limited number of tools on our, on our Batman belt that we can use, you know, not to get into all the aspects of the Trump case and Mar a Lago and the documents there. I mean, the FBA has so many tools they can use, and a search warrant is the only way they could get in there. I mean, that's it. There's no other legal document or legal way to enter and get those documents.
Speaker B: What do you think about the FBI and Mar a Lago and the FBI taking the documents for Donald Trump?
Speaker A: It's a tough spot. It's a really tough spot. The FBI has gotten a lot of black eyes recently, and I don't know if it's the same FBI that I remember when I was there.
Speaker B: Do you think they deserve it? In part. Part. Was it done clumsily, their rating of the former president's residence?
Speaker A: Yeah, it's tough. It's tough because, again, they're only limited to what they're allowed. What they're legally allowed to do in a search warrant is the only legal way of doing it. I have my personal and political views on certain things. I think it might be surprising to some where those political point stand.
Speaker B: But you told me offline that you're a hardcore communist. That was very strange, very surprising to me.
Speaker A: Well, that's only. You try to bring me into the Communist Party.
Speaker B: Exactly. I was trying to recruit you, giving you all kinds of flyers. Okay, but you said people in the FBI just following the law, but there's a chain of command and so on. What do you think about the conspiracy theories that people, some small number of people inside the FBI, conspired to undermine the presidency of Donald Trump?
Speaker A: If you would have asked me when I was inside. And before all this happened, I would say it could never happen. I don't believe in conspiracies. You know, there's too many people involved. Somebody's going to come out with some sort of information. But I mean, from the more the stuff that comes out, it's surprising that, you know, agents are being fired because of certain actions that are taken inside of and being dismissed because of politically motivated actions.
Speaker B: So do you think it's explicit or just pressure? Just, do you think there could exist just pressure at the higher ups that has a political leaning and you kind of maybe don't explicitly order any kind of thing, but you just kind of pressure people to lean one way or the other and then create a culture that leans one way or the other based on political leanings.
Speaker A: You would really, really hope not. But, I mean, that seems to be the narrative that's being written.
Speaker B: But when you were operating, you didn't feel that pressure?
Speaker A: Man, I was such at a low level, you know, I had no aspirations of being a boss. I wanted to be a case agent my entire life.
Speaker B: So you love the puzzle of it, the chase.
Speaker A: I love solving things. Yeah. To be management and manage people and all that. No desire whatsoever.
Speaker B: What do you think about Mark Zuckerberg on Joe Rogan's podcast saying that the FBI warned Facebook about potential foreign interference and then Facebook inferred from that that they're talking about Hunter Biden laptop story and thereby censored it. What do you think about that whole story again?
Speaker A: You asked me when I was in the FBI, I wouldn't believed it from being on the inside. I wouldn't believe these things. But there's a certain narrative being written that is surprising to me that the FBI is involved in these stories.
Speaker B: So. But the interesting thing there is that's the FBI is saying that they didn't really make that implication. They're saying that there's interference, activity happening. Just watch out. And it's a weird relationship between the FBI and Facebook. You could see from the best possible interpretation that the FBI just wants Facebook to be aware because it is a powerful platform, a platform for viral spread of misinformation. So in the best possible interpretation of it, it makes sense for FBI to send some information saying, like we were seeing some shady activity.
Speaker A: Absolutely.
Speaker B: But it seems like all of that somehow escalated to a political interpretation.
Speaker A: I mean, yeah, it sounded like there was a wink wink with it. I don't know if Mark meant for that to be that way again. Are we being social engineered or was that a true expression that Mark had.
Speaker B: And I wonder if the wink wink is direct or is just culture. You know, maybe certain people responsible on the Facebook side lean have a certain political lean, and then certain people on the FBI side have a political lean when they're interacting together. And it's like, literally has nothing to do with a giant conspiracy theory, but just with a culture that has a particular political lean during a particular time in history. And so, like, maybe it could be hunter Biden laptop one time, and then it could be whoever, Donald Trump junior's laptop another time.
Speaker A: It's a tough job. I mean, if you're the liaison, if you're the FBI's liaison to Facebook, there are certain people that I'm sure they were offered a position at some point. It seems there's FBI agents that go, I know of a couple that's gone to Facebook. There's a really good agent that now leads up their child exploitation stuff. Another squad mate runs their internal investigations, both great investigators. So, you know, there's good money, especially when you're an FBI agent that's capped out at a, you know, a 1310 or whatever pay scale you're capped out at. It's alluring to be, you know, maybe want to please them and be asked to join them.
Speaker B: Yeah. And over time, that corrupts. I think there has to be an introspection in tech companies about the culture that they develop, about the political ideology. The bubble. It's interesting to see that bubble. I've asked myself a lot of questions. I've interviewed the Pfizer CEO what seems now a long time ago, and I've gotten a lot of criticism, the positive comments, but also criticism from that conversation. And I did a lot of soul searching about the kind of bubbles we have in this world. And it makes me wonder, pharmaceutical companies, they all believe they're doing good. And I wonder because the. The ideal they have is to create drugs that help people and do so at scale. And it's hard to know at which point that can be corrupted. And it's hard to know when it was corrupted and if it was corrupted and where and which drugs and which companies and so on. And I don't know. I don't know. That complicated. It seems like inside a bubble, you can convince yourself of anything is good. People inside the Third Reich regime were able to convince themselves. I'm sure many just. Bloodlands is another book. I've been recently reading about it, and the ability of humans to convince they're doing good when they're clearly murdering and torturing people in front of their eyes is fascinating. They're able to convince themselves they're doing good. It's crazy. Like, there's not even an inkling of doubt. Yeah, I don't know what to make of that. So it has taught me to be a little bit more careful when I enter into different bubbles to be skeptical about what's taken as an assumption of truth. Like, you always have to be skeptical about, like, what's assumed is true. Is it possible it's not true? You know, if you're doing, if you're talking about the America, it's assumed that, you know, in certain places that surveillance is good. Well, let's. Let's question that. That's that assumption. Yeah. And I also. It inspired me to question my own assumptions that I hold this true constantly. Constantly.
Speaker A: It's tough, but you don't grow. I mean, do you want to be just static and not grow? You have to question yourself on some of these things if you want to grow as a person.
Speaker B: Yeah, for sure. Now, one of the tough things actually being a public personality when you speak publicly is you get attacked all along the way as you're growing. And I'm, in part, a big softy as well, if I may say. And those heart. It hurts. It hurts, it hurts.
Speaker A: Do you pay attention to it?
Speaker B: Yeah, yeah, yeah, yeah. It's very hard. Like, I have two choices. One, you can shut yourself off from the world and ignore it. I never found that compelling. This kind of idea of, like, haters gonna hate. Yeah. Like, this idea that anyone with a big platform or anyone's ever done anything was always gotten hate. Yeah, okay, maybe. But, like, I still want to be vulnerable, wear my heart on my sleeve, really show myself. Like, open myself to the world, really listen to people. And that means every once in a while, somebody will say something that touches me in a way that's like, what if they're right?
Speaker A: Do you let that hate influence you? I mean, can you be bullied into a different opinion than you think you really are just because of that hate?
Speaker B: No. No, I believe not. But it hurts in a way that's hard to explain. Like, yeah, it just. It gets to, like, it shakes. Your faith in humanity actually, is probably why it hurts. Like, people that call me a Putin apologist or a Zelensky apologist, which I'm currently getting almost an equal amount of, but it hurts. It hurts because. It hurts because it damages slightly my faith in humanity to be able to see the love that connects us and then to see that I'm trying to find that, and that's. I'm doing my best in the limited capabilities. I have to find that. And so to call me something like a bad actor, essentially, from whatever perspective, it just makes me realize, well, people don't have empathy and compassion for each other. It makes me question that for a brief moment, and that. That's like a crack, and it hurts.
Speaker A: How many people do this to your face?
Speaker B: Very few.
Speaker A: It's online emuscles, man. They're just flexible.
Speaker B: I have to be honest that it's. It happens.
Speaker A: Yeah.
Speaker B: Because I've hung around with. With rogan enough. When your platform grows, there's people that will come up to Joe and say stuff to his face that they forget. They still. They forget he's actually a real human being. They'll make accusations about him.
Speaker A: So does that cause him to wall himself off more?
Speaker B: No, he's pretty gangster on that. But, yeah, it still hurts if you're human, if you really feel others. I think that's also the difference with Joe and me. He has a family that he deeply loves, and that's an escape from the world, for there's a loneliness in me that's. I'm always longing to connect with people and with, like, regular people and just to learn their stories and so on. And so if you open yourself up that way, the things they tell you can really hurt in every way. Like, just having me going to Ukraine, just seeing so much loss and death, some of it is like, is, I mean, unforgettably haunting. Not in some kind of political way, activist way, or who's right, who's wrong way, but just, like, man, like, so much pain. You see, it just stays with you.
Speaker A: When you see a human being bad to another human, you can't get rid of that in your head. You can't imagine that we can treat each other like that. That's the hard part, I think. I mean, that, for me, it is. When I saw parents, like, when I did the child exploitation stuff, when they rented their children out, they literally rented infant children out to others for sexual gratification. Like, I don't know how a human being could do that to another human being. And that sounds like the kind of thing you're going through. I mean, I went through a huge funk when I did those cases afterwards. I should have talked to somebody, but in the FBI, you have to keep that machismo up, or they're gonna take your gun away from you.
Speaker B: Well, I think that's examples of evil that that's like the worst of human nature. But I just.
Speaker A: Because I have war is just as bad.
Speaker B: I mean, somehow war, it's somehow understandable given all the very intense propaganda that's happening. So it's. You can understand that there is love in the heart of the soldiers on each side, given the information they're given. There's a lot of people on the russian side believe they're saving these ukrainian cities from nazi occupation. Now there is stories, there is a lot of evidence of people for fun murdering civilians. Now that that is closer to the things you've experienced of, like, evil, of evil embodied. And I haven't interacted with that directly with people who, for fun, murdered civilians.
Speaker A: But, you know, it's there in the world. I mean, you're not naive to it.
Speaker B: Yes, but if you experience that directly, if somebody shot somebody for fun in front of me, that would probably break me. Yeah. Like, seeing it yourself, knowing that it exists is different than seeing yourself. Now, I've interacted with the victims of that, and they tell me stories. And you see their homes destroyed, destroyed for no good military reason. It's civilians with civilian homes being destroyed that really lingers with you. But some. Yeah, the people that are capable of.
Speaker A: That, that goes with the propaganda. I mean, if you were to build a story, you have to, you know, you have to have on the other side, you know, the homes are going to be destroyed, the non military targets are going to be destroyed.
Speaker B: To put it in perspective, I'm not sure a lot of people understand the deep human side or even the military strategy side of this war. There's a lot of experts outside of the situation that are commenting on it with certainty. And that kind of hurts me because I feel like there's a lot of uncertainty. There's so much propaganda. It's very difficult to know what is true. Yeah. So my whole hope was to travel to Ukraine, to travel to Russia, to talk to soldiers, to talk to leaders, to talk to real people that have lost homes, that have lost family members, that who this war has divided, who this war changed completely, how they see the world, whether they have love or hate in their heart, to understand their stories. I've learned a lot on the human side of things by having talked to a lot of people there, but it has been on the ukrainian side for me, currently. Traveling to the russian side is more difficult. Let me ask you about your now friend. Can we go as far as to say his friend in Sabu and hector Masgur? What's the. What's the story? What's your long story with him? Can you tell me about what is Lalsec, who is Sabu and who's Anonymous? What is Anonymous? Where's the right place to start that story?
Speaker A: Probably anonymous. Anonymous was, it still is, I guess, a decentralized organization. They call themselves headless, but once you look into them a little ways, they're not really headless. The power struggle comes with a, whoever has a hacking ability. That might be you're a good hacker or you have a giant botnet used for ddos, so you're going to wield more power if you can control where it goes. Anonymous started doing their hacktivism stuff in 2010 or so. The word hack was in the media all the time then. And then right around then there was a federal contractor named HB Gary Federerdeh, the CEO is Aaron Barr. And Aaron Barr said he was going to come out and de Anonymize Anonymous. Hes going to come out and talk at black Hat or Defcon or one of those and say who they are. He figured it out, or he figured it out based on when people were online, when people were in IRc, when tweets came out, there was no scientific proof behind it or anything. So hes just going to falsely name people that were in anonymous. So anonymous went on the attack, they went and hacked in HPA federal and they turned his life upside down. They took over his Twitter account and all that stuff pretty quickly.
Speaker B: I have very mixed feelings about all of this, okay? I get like, part of me admires the positive side of the hacktivism, okay? Is there no room for admiration there of the fuck you to the man?
Speaker A: Not at the time. Again, it was a violation, 18 USC 1030. So it was my job. That's what I, you know, so at the time, no. In retrospect, sure, yeah.
Speaker B: But what was the philosophy of the hacktivism? Was it the philosophically? Were they at least expressing it for the good of humanity or.
Speaker A: No, they outwardly said that they were going to go after people that they thought were corrupt. So they were judging jury on corruption. They were to go after. Once you get inside and realize what they were doing, they were going after people that they had an opportunity to go after. So maybe someone had a zero day, and then they searched for servers running that zero day, and then from there, let's find a target. I mean, one time they went after a toilet paper company. I still don't understand what that toilet paper company did, but it was an opportunity to make a splash.
Speaker B: Is there somewhere for the joke for.
Speaker A: The Lulz, it developed into that. So I think the hacktivism and the anonymous stuff wasn't so much for the Lowells, but from that HP Gary Federal hack. Then there were six guys that worked well together, and they formed a crew, a hacking crew, and they kind of split off into their own private channels. And that was Lulzsec, or laughing at your security, was their motto.
Speaker B: So that's l u l z s e C. Lulz sec.
Speaker A: Of course it is Lulzsec.
Speaker B: And who founded that organization?
Speaker A: So Kayla and Sabu were the hackers of the group. And so they really did all the work on HP Gary. So they're.
Speaker B: These are code names.
Speaker A: Yeah, they're online names. They're knicks. And so, you know, they. That's all they knew each other as. They talked as those names, and they worked well together. And so they formed a hacking crew. And that's when they started the. At first, they didn't name it this, but it was the 50 days of Lulz where they would just release major, major breaches, and it stirred up the media. I mean, it put hacking on in the media every day. They had 400 or 500,000 Twitter followers, you know, and it was kind of interesting. But then they started swinging at the beehive, and they took out some FBI affiliated sites, and then they started fuck FBI Fridays, where every. Every Friday they would release something. And we waited it for baited breath. I mean, they had us hook, line and sinker pissed. We were waiting to see what was going to be dropped. Every Friday. It was. It's a little embarrassing looking back on it now.
Speaker B: This is in the early 2010s.
Speaker A: Yeah. This was 2010, 2011 around there.
Speaker B: Can I actually linger on Anonymous? What do you still understand? What the heck is anonymous?
Speaker A: Just a place where you hang out. I mean, it's just. It started on four chan, went to eight chan, and it's really just anyone. You could be an anonymous right now if you wanted to. Just, you're in there hanging out in the channel now. You're probably not going to get much cred until you work your way up and prove who you are. Someone vouches for you, but anybody can be an anonymous and you can leave anonymous.
Speaker B: What's the leadership of anonymous? Do you have a sense that there.
Speaker A: Is a leadership, there's a power play now? There's not someone that says, this is what we're doing. Oh, we're doing.
Speaker B: I love the philosophical and the technical aspect of all of this, but I think there is a slippery slope to where for the laws, you can actually really hurt people. That's this, that's the terrifying thing when you attach. I'm actually really terrified of the power of the lull. It's the fun thing somehow becomes a slippery slope. I haven't quite understood the dynamics of that. But even in myself, if you just have fun with the thing, you lose track of the ethical grounding of the thing. And so, like, it feels like hacking for fun can just turn it, like, literally lead to nuclear war. Like, literally destabilize, yada, yada, yada.
Speaker A: Nuclear war. I could see it. Yeah.
Speaker B: So I've been more careful with the law. Yeah, I've been more careful about that. And I wonder about it, because in Internet speak, somehow ethics can be put aside through the slippery slope of language. I don't know, everything becomes a joke. If everything is a joke, then everything is allowed. And everything is allowed, then you don't have a sense of what is right and wrong. You lose sense of what is right and wrong.
Speaker A: You still have victims. I mean, you're laughing at someone. Someone's the butt of this joke, you know, whether it's major corporations or the individuals. I mean, some of the stuff they did was just, you know, relacing people's pii and their personal identifying information and stuff like that. I mean, is it a big deal? I don't know, maybe, maybe not. But, you know, if you could choose to not have your information put out, there probably wouldn't.
Speaker B: Do you have a sense of what anonymous is today? Has it ever been one stable organization, or is it a collection of hackers that kind of emerge for particular tasks? For particular, like hacktivism tasks and that kind of stuff?
Speaker A: It's a collection of people that has some hackers in it. I, there's not a lot of big hackers in it. I mean, there'll some that have come bounce in and bounce out. Even back then, there's probably just as many reporters in it, people, the media in it with the hackers at the time, just trying to get the inside scoop on things. You know, some, giving the inside scoop. You know, we arrested a guy, reported they gave over the username and password to his newspaper and, you know, just so he could break the story. He trusted them.
Speaker B: Speaking of trust, reporters, boy, there's good ones. There's good ones, there are, but boy, do I have a complicated relationship with them.
Speaker A: How many stories about you are completely true?
Speaker B: You can just make stuff up on the Internet. And one of the things that, I mean, there's so many fascinating psychological, sociological elements of the Internet. That, to me, one of them is that you can say that Lex is a lizard. Right? And if it's not funny, so lizard is kind of funny. What should we say? Lex has admitted to being an agent of the FBI. Okay. You can just say that. Right? Right. And then the response that the Internet will be like, oh, is that true? I didn't realize that. They won't go, like, provide evidence, please. Right. They'll just say, like, oh, that's weird. I didn't. I kind of thought he might be kind of weird. And then it piles on. It's like, hey, hey, hey, guys. Like, here's a random dude on the Internet just said a random thing. You can't just, like, pile up as.
Speaker A: And then Johnny 6969 is now a source that says.
Speaker B: And then, like, the thing is, I'm a tiny guy, but when it grows, if you're, like, have a big platform, I feel like newspapers will pick that up, and then they'll start to build on a story, and you never know where that story really started. It's so cool. I mean, to me, actually, honestly, it's kind of cool that there's a viral nature of the Internet that can just fabricate truth completely. I think we have to accept that new reality and try to deal with it somehow. You can't just complain that Johnny 69 can start a random thing. I think in the best possible world, it is the role of the journalist to be the adult in the room and put a stop to it versus look for the sexiest story so that there could be clickbait that can generate money. Journalism should be about sort of slowing things down, thinking deeply through what is true or not and showing that to the world. I think there's a lot of hunger for that, and I think that would actually get the most clicks in the end.
Speaker A: I mean, it's that same pressure I think we're talking about with the FBI and with the tech companies about controllers. I mean, the editors have to please and get those clicks. I mean, they're measured by those clicks. So, you know, I'm sure the journalists, the true journalists, the good ones out there want that, but they want to stay employed, too.
Speaker B: Can actually ask you, really, as another tangent, the Jared and others, they're doing undercover. Undercover. In terms of the tools you have for catching cybersecurity criminals, how much of it is undercover?
Speaker A: Undercover is a high bar to jump over. You have to do a lot to start an undercover in the FBI. There's a lot of thresholds so it's not your first investigative tool. Step. You have to identify a problem and then show that the lower steps can't get you there. Um, but, I mean, I think we. We had an undercover going on in the squad about all times. When one was being shut down or taken down, we were spinning up another one. Um, so it's a good tool to have, um, you know and utilize. Um, there are a lot of work. I don't think, if you run one, you'll never run another one in your life.
Speaker B: Oh, so it's like, psychologically, is it? There's a lot of work, just technically, but also psychologically. Like, you have to really, uh, it's.
Speaker A: 24/7 you're inside that world. Like, you have to know what's going on and what's happening. I mean, you. You know, you're taking on. You have to remember who you are when you're. Because you're. You're a criminal online. You have to go to a special school for it, too.
Speaker B: Was that ever something compelling to you?
Speaker A: I went through the school, but I'm a pretty open and honest guy, and so it's tough for me to build that wall of lies. It's. Maybe I'm just not smart enough to keep all the lies straight.
Speaker B: Yeah, but a guy who's good at building up a wall of lies would say that exact same thing.
Speaker A: Exactly.
Speaker B: It's so annoying the way truth works in this world. It's like people have told me because I'm trying to be honest and transparent. That's exactly what an agent would do. Right. But I feel like an agent would not wear a suit and tie.
Speaker A: I wore a suit and tie every day. I was a suit and tie guy.
Speaker B: You were?
Speaker A: Yeah, every day. I remember one time I wore shorts in, and the sac came in, and this was when I was. I was a rock star at the time in the bureau, and I had shorts in, and I said, sorry, ma'am, I apologize for my attire. And she goes, you could wear bike shorts in here, I wouldn't care. That sounds nice. I never wore the bike shorts, but.
Speaker B: Yeah, but see, I don't see a suit and ties constraining. I think it's liberating and sorts. It shows that you're taking the moment seriously.
Speaker A: Well, not just that people wanted it. I mean, people expected. When you knock, you are dressed like a perfect FBI agent. When someone knocks on their door, that's what they want to see. They want to see what Hollywood built up is, what an FBI agent is. You show up like my friend Ilwan, he was dressed always in t shirts and shorts. People aren't gonna take him serious. They're not gonna give him what they want.
Speaker B: I wonder how many police I can just show up and, like, say I'm from the FBI and start interrogating them, like, at a bar, probably, like, oh, definitely.
Speaker A: If they've had a few drinks, you can definitely. Well, but people are gonna recognize you. That's the only problem. That's another thing you start taking out of big, big cases. You can't work cases anymore in the FBI. Your face gets out there.
Speaker B: Your name, too. Yeah, well, actually, let me ask you about that before we return to our friend Sabu. You've tracked and worked on some of the most dangerous people in this world. Have you ever feared for your life?
Speaker A: So I had to make a really, really shitty phone call one time. I was sitting in the bureau, and this was right after Silk road. And Jared called me. He was back in Chicago, and he called me and said, hey, your name and your kid's name are on a website for an assassination. They're paying to have you guys killed. Now, these things happen on the black market. They come up, you know, and, you know, people debate whether they're real or not, but we have to take it serious. Someone's paying to have me killed. Me. So I had to call my wife, and we have a word. And that if I said this word, and we only said it one time to each other, if I said this, would. This is serious. Drop what you're doing and get to the kids. And so I had to drop the word to her, and I could feel the breath come out of her because she thought her kids were in danger. At the time, they were. I wasn't in a state of mind to drive myself. So an agent on the squad, a girl named Evelina, she drove me, lights and sirens, all the way to my kids school. And we had locked. I called the school. We were in a lockdown. Nobody should get in or out, especially someone with a gun. The first thing they did was let me in the building with a gun. So I was a little disappointed with that. My kids were, I think, kindergarten, in fifth grade, or somewhere around there. Maybe they're closer. Second, I'm not sure where, but all hell broke loose, and we had to, from there, go move into a safe house. I live in New York City. NYPD surrounded my house. The FBI put cameras outside my house. You couldn't drive in my neighborhood without, like, your license plate being read, hey, why is this person here, why is that person there? I got to watch my house on an iPad while I sat at my desk. But, you know, again, I put my family through that and it scared the shit out of them. And that's. To be honest, I think that's sort of my mother in law's words were, I thought you did cybercrime crime. And because during Silk Road, I didn't tell my family what I was working on, you know, I'll talk about that. Sort of like, I want to escape that. I don't want to be there. You know, I remember that, like, so when I was in the FBI, like, driving in, I used to go in at 430 every morning, um, because I like to go to the gym before I hit. Go to the desk, so be at the desk at seven, so in the gym at five, a couple hours, and then go. The. The best time I had was that drive in in the morning where I could just be myself. I listened to a sports podcast out of DC, and they talked about sports and, you know, the nationals and whatever it was, the capitals, you know, it was great to not think about Silk Road for ten minutes, so. But that was my best time. But, but, yeah, again, so, yeah, I've had that. Moving to the safe house, I left my mp5 at home. That's the. The bureau's machine gun. Showed my wife to just pull, pull and spray, so.
Speaker B: But how often did you or work and live with fear in your heart?
Speaker A: It was only that time. I mean, for actual physical security then. I mean, after the anonymous stuff, I, you know, I really tightened down to my cybersecurity. You know, I don't have social media. I don't have pictures of me and my kids online. I don't really, if I go to a wedding or something, I say I don't take my picture with my kids, you know, if you're going to post it someplace or something like that. So that sort of security I have. Um, but, you know, just like everybody, you start to relax a little bit and security breaks down. Cause it's not convenient, but it's also.
Speaker B: Part of your job. So you're. You're much better at, um. Let me. Your job now and your job before, so you're probably much better at taking care of the low hanging fruit, at least.
Speaker A: I understand the threat, and I think that's what a lot of people don't understand, is understanding what the threat against them is. So. So I'm aware of that and what possibly. And I think about it, you know, I think about things I do remember. So you tripped a memory in my mind. I remember a lot of times, and I had a gun on my hip. I still carry a gun to this day. Opening my front door and being concerned what was on the other side. Leave. Walking out of the house because I couldn't see it. I remember those. 04:00, head into the cardinal. I was literally scared.
Speaker B: Yeah. I mean, having seen some of the things you've seen, it makes you perhaps question how much evil there's out there in the world. How many dangerous people there are there out there. Crazy people, even.
Speaker A: There's a lot of crazy. There's a lot of evil. Most people, I think, get into, like, cybercrime or just opportunist, not necessarily evil. They don't really know. Maybe think about the victim. They just do as. It's a crime of opportunity. You know, I don't label that as evil.
Speaker B: And one of the things about America that I'm also very happy about is that rule of law, despite everything we talk about, there is. It's tough to be a criminal in the United States. So, like, if you walk outside your house, you're much safer than you are in most other places in the world.
Speaker A: You're safer, and the system's tougher. I mean, Lulzsec, six guys, one guy in the United States, five guys, other places. Hector was facing 125 years. Those guys got slaps on the wrist and went back to college. Different laws, different places.
Speaker B: So who's Hector? Tell me the story of Hector. So this law sec organization was started. So Hector was before that in. He was. He was in part anonymous. He was all. He was doing all kinds of hacking stuff. But then he launched law sec.
Speaker A: He's old school hacker. I mean, he learned how to hack, and I don't want to tell his story, but he learned to hack because he grew up in the lower east side of New York and picked up some NYPD computers that were left on the sidewalk for trash.
Speaker B: Yeah.
Speaker A: Taught himself how to.
Speaker B: He doesn't exactly look like a hacker. For people who don't know, he looks. I don't know exactly what he looks like, but not like a technical. Not what you would imagine, but perhaps that's. That's. That's a Hollywood portrayal.
Speaker A: Yeah. I think you get in trouble these days saying that what a hacker looks like. I don't know if they have a traditional look. Just like I said, Hollywood has an idea of an FBI looks like. I don't think you can do that anymore. I don't think you can say that anymore.
Speaker B: Well, he certainly has a big personality and charisma and all that kind of stuff.
Speaker A: Stuff that's taboo.
Speaker B: I can see him selling me anything that's taboo, convincing me of anything.
Speaker A: You know, the two different people. There's Sabu and there's Hector. Hector is a sweet guy. He likes to have intellectual conversations and like, that's just the thing. He'd rather, you know, just sit there and have a one on one conversation with you. But Sabu, that's a ruthless motherfucker.
Speaker B: And you first met Sabu?
Speaker A: I was tracking Sabu. That's all I knew was that buu I didn't know Hector.
Speaker B: So when did your paths cross in terms of tracking? When did you first take on the case?
Speaker A: The spring of eleven.
Speaker B: So it was through anonymous?
Speaker A: Through anonymous. Well, really kind of low sec. We were. Low sec was a big thing. And it was pushed out to all the cyber 56 field offices in the FBI. Most of them have cyber squads or cyber units. And so, you know, it was being pushed out there and it was in the news every day, but it really wasn't ours. So that we didn't have a lot of victims in our AOR area of responsibility and so we just kind of pay attention to it. Then I got a tip that a local hacker in New York had broken into AOL. And so Olivia, Olivia Olson and I, another agent who, she's still in, she's a supervisor out in LA. She's a great agent. We went all around New York looking for this kid just to see what we can find and ended up out in Staten island at his grandmother's house. She didn't know where he was, obviously, why would she? But I left my card. He gave me a call that night, started talking to me and I said, let's just meet up tomorrow at the McDonald's across from 26 fed. And he came in and three of us sat there and talked and gave me his stuff. He started telling me about all the felonies he was committing those days, including that break into Aole. And then he finally says, you know, you know, I can give you Sabu. And Sabu to us was the Kaiser, so say back. And he was our guy, you know, he was the guy that was in the news that was pissing us off. So.
Speaker B: So he was port a part of the FBI Fridays.
Speaker A: Sabu was. Yeah. Oh, he let it. Yeah, he was the leader of fuck FBI Fridays. So yeah.
Speaker B: What was one of the more memorable F triple FSD? I said, what? How do you get why? How and why do you go after the beehive? That's kind of intense.
Speaker A: You get you on the news, it gets you. It's the, it's the lulz. It's funnier to go after the big ones, you know, and they weren't getting, like, real FBI. They weren't breaking into FBI mainframes or anything, but they, you know, they were, you know, affiliate sites or anything that had to do. A lot of law enforcement stuff was coming out, so. But, you know, we looked back, and so if this kid knew that Cebu, maybe there was a chance we could use him to lure Cebu out. But we also said, well, maybe this kid knows Cebu in real life. And so we went and looked through the ips, and 10 million ips, we find one, and it belonged to him. And so that, that day, someone had doxxed Cebu, and we were a little afraid he was going to be on the run. We had a surveillance team, and FBI surveillance teams are awesome. Like, you cannot even tell their FBI agents. It's. It's an. It's. They are really that good. I mean, there's baby strollers and all, whatever you wouldn't expect an FBI agent to have.
Speaker B: So that's a little like the movies a little bit.
Speaker A: Yeah. I mean, it is true, but. And, but they fit into the area. So now they're on the lower east side, which is, you know, you know, a baby stroller might not fit in there as well as, you know, somebody laying on the ground or something like that. They really get. Play the character and get into.
Speaker B: So now I can never trust a baby stroller again.
Speaker A: Yeah, well, yeah, probably shouldn't every.
Speaker B: Every baby, I'm just like, look at.
Speaker A: Stare at them suspiciously, especially if the mom's wearing cargo pants while she pushes it.
Speaker B: So, yeah, so if it's like, a very stereotypical mom. Stereotypical baby, I'm gonna be very suspicious. I'm gonna question the baby.
Speaker A: That baby's wired.
Speaker B: Be careful.
Speaker A: You know, we raced out there and, like, our squad's not even full. There's only a few guys there. And like I said, I was a suit guy, but that day I had shorts and a t shirt on. I had a white t shirt on, and I only bring it up because Cebu makes fun of me to this day. So I had a bulletproof vest and a white t shirt on, and that was it. I shorts too, and all that. But, um, race over to there. We didn't have any equipment. Um, we brought our bosses, bosses boss. He stopped off at NYPD, got us like a ballistic shield. Uh, and a battering ram if we needed it. Um, and then we get to Hector's house, Sabu's house, and he's on the 6th floor. Um, and so normally, you know, we're the, the cyber dork squad. We'll hop in the elevator. Six floors is a long ways to go up and bulletproof vest in a ballistic shield. But we had been caught in an elevator before on a search, so we didn't. Took the stairs. We get to the top, tad winded, but knock on the door and this big towering guy opens the door just slightly and he sees the green vest with big yellow letters. FBI. And he steps outside. Can I help you? Tries to social engineer us, but eventually we get our way inside the house. I noticed a few things that are kind of out of place. There's a laptop charger and a flashing modem. And I said, do you have a computer here? And he says, no, there's no computer here. So we knew the truths and then the half lies and all that sort of thing. So it took us about another 2 hours. And finally he gave up. He was that buu. He was the guy we were looking for. And so we sat there and we kind of showed him sort of the evidence we had against him. And, you know, from his words, we sat there and talked, talked like two grown adults. And, you know, I gave him the options and he said, well, let's, let's talk about working together.
Speaker B: So he chose to become an informant.
Speaker A: I don't think he chose that night, but that's where it kind of went to. So the, we brought him down to the FBI that night, which was. It was a funny trip because I'm sitting in the backseat of the cardinal with him, and I was getting calls from all over the US from different FBI agents saying that we arrested the wrong guy. I was like, I don't think so. And they're like, why do you think so? I was like, because he says it's him. And they still said, nope, the wrong guy. So I said, well, we'll see how it plays out.
Speaker B: That's so interesting. Because it's a strange world. Such a strange world because it's tough to. Because you still have to prove it's the same guy.
Speaker A: Right.
Speaker B: Right. Cause the anonymity.
Speaker A: Yeah. I mean, we had his laptop by that, you know, by that point. Yeah, that helped. I gave him a clue in my world.
Speaker B: Yeah, yeah.
Speaker A: But, yeah, if he would have fought it, I mean, that definitely would have come in as evidence that other FBI agents are saying it's not him. You have to disclose that stuff.
Speaker B: So he had a lot of stuff on him. What was he facing? If he was facing 125 years, 125 years in prison.
Speaker A: Now, that's if you took every charge we had against him and put him consecutively. No one ever gets charged that. But, yeah, essentially it would have been 125 years. Fast forward to the end. He got thanked by the judge for his service after nine months, and he walked out of the court of Freeman.
Speaker B: But that's being. While being an informant.
Speaker A: Yes. Well, so the word informant here really is that good. It's not fitting that technically, I guess, that's what he was. But he didn't know the other people was all in on. He knew Knicks and all that. He really gave us the insight of what was happening in the hacker world. Like I said, he was an old school hacker back when hackers didn't work together with Anonymous. He was on cult of dead cow and those type guys way back, and he was around for that. He's like an encyclopedia of hacking. But, you know, we just, like, his.
Speaker B: Prime was in the nineties for terror hack.
Speaker A: But, yeah, he kind of came back when. When Anonymous started going after Mastercard and PayPal and all that, do the WikiLeaks stuff.
Speaker B: But even. Even that little interaction, being an informant, he probably made a lot of enemies. How do you protect a guy like that?
Speaker A: He made enemies after it was revealed.
Speaker B: Yeah.
Speaker A: How does the FBI protect him?
Speaker B: Yeah.
Speaker A: Good luck.
Speaker B: I mean, perhaps I'll talk to him one day, but is that guy afraid.
Speaker A: For his life again?
Speaker B: I think it doesn't seem like it.
Speaker A: He has very good security for himself, cybersecurity, but he doesn't like the negative things said about him online. I don't think anybody does. But I think it's so many years of the Internet kind of bitching at you and all that. You get calloused. It's just Internet bitching.
Speaker B: And also, the. The hacking world moves on very quickly.
Speaker A: He.
Speaker B: He is kind of. Yeah, like, they're. There have their own wars to fight now, and he's not part of those wars anymore.
Speaker A: There's still people out there that bitch and moan about him. But. But, yeah, I think it's less. I think, you know, and he has a good message out there of, you know, trying to keep kids from making the same mistakes he made. He tries to really preach that.
Speaker B: How do people get into this line of work? Is there all kinds of ways being not your line of work? His line of work, just all the stories you've seen of people that are in anonymous and lulzsec and so, quote, and all the cyber criminals you've interacted with. What's, what's the profile of a cyber criminal?
Speaker A: I don't think there's a profile anymore. You know, I used to be able to say, you know, the kid in your mom's basement or something like that, but it's not true anymore. You know, like, it's, it's, it's wide and it's like, I've arrested. I've arrested people that you wouldn't expect would be cyber criminals.
Speaker B: And it's in the United States. It's international, it's everything.
Speaker A: Oh, it's international. I mean, we're seeing a lot of the big hack hackers now. The big arrest for hackers in England, surprisingly, you know, there's, you know, you're not going to see. There's a lot of good hackers, like, down in Brazil, but I don't think Brazil law enforcement is as good as hunting them down. So you're not going to see the big arrests.
Speaker B: How much state sponsored cyber attacks are there, do you think?
Speaker A: More than you can imagine. What do you want to say? An attack, successful attack, or just a.
Speaker B: Yemenite probing, probing for information, just, like, feeling, you know, testing that there's where the attack factors are, trying to collect all the possible attack.
Speaker A: Put a windows seven machine on the Internet, forward facing, and put a. Put a packet sniffer on there and look at where the driver comes from. I mean, in 24 hours, you are going to fill up a hard drive with packets just coming at it.
Speaker B: Yeah.
Speaker A: I mean, it's not hard to know. I mean, it's just constantly probing for entry points into things. You know, you could, you could go mad. Putting up honey pot draws intrusions. Should I see what Metro.
Speaker B: See what's out there?
Speaker A: Yeah, and it doesn't go anywhere. It maybe has fake information and stuff like that. You know, it's just kind of to see what's going on and judge what's happening. Get a, you know, lick your finger and test the wind of what's happening these days.
Speaker B: The funny thing about, like, because I'm at MIT, that attracted even more attention for the. Not for the laws, but for the technical challenges. It seems like people enjoy hacking MIT. It's just the amount of traffic MIT was getting for that in terms of just the sheer number of attacks from different places, is crazy. Yeah. Like, just like that. Putting up a machine, seeing what comes.
Speaker A: NASA used to be the golden ring. Now everybody got NASA that, like, the early nineties. If you could hack NASA, that was the now. Yeah. MIT is a big one.
Speaker B: Yeah. It's fun. It's fun to see respect because I think in that case, it comes from a somewhat good place because they're not getting any money from MIT. It's more for the challenge. Let me ask you about that, about this world of cybersecurity. How big of a threat are cyber attacks for companies and for individuals? Like, let's lay out, where are we in this world? What's out there?
Speaker A: It's the wild, wild west. And it's. I mean, I. People want the idea of security, but it's inconvenient, so they don't. They push back on it. And there are a lot of opportunistic nation state, financially motivated hackers. Hackers for the lulls. You got three different tiers there, and they're on the prowl. They have tools. They have really good tools that are.
Speaker B: Being used against us and at what scale. So when you're thinking of. I don't know, what's. Let's talk about companies first. So say you're talking to a mid tier. I wonder what the most interesting business is. So, Google, we can look at large tech companies, or we can look at medium sized tech companies and, like, you were sitting in a room with a CTO, with a CEO, and the question is, how fucked are we and what should we do? What's the low hanging fruit? What's. What are the different strategies and those companies should consider?
Speaker A: I mean, the problem is they want a push button. They want to. They want a out of the box solution that I'm secure. You know, they want to tell people.
Speaker B: They'Re secure, but, and that's very challenging to have.
Speaker A: It's impossible. But, like, if I could, if someone had it, they'd be a billionaire. You know, they'd be beyond a billionaire, you know, because that's what everybody wants. So it's, you know, you can buy all the tools you want. It's configuring them the proper way. And there's. If anyone's trying to tell you that there's one solution that fits all, they're stakeholders. Salesman. And there's a lot of people in cybersecurity that are stakeholders. Helisman.
Speaker B: Yeah, and I feel like there's tools, if they're not configured correctly, they just introduce. They don't increase security significantly, and they introduce a lot of pain for the people. They decrease efficiency of the actual work you have to do. We had I was a Google for a time, and I think mostly I want to give props to their security efforts, but user data, so, like, data that belongs to users is like the holy, like, the amount of security they have around. That is incredible. So most anytime I had to work with anything even resembling user data. So I never got a chance to work with actual user data, anything resembling that. First of all, you have no access to the Internet. It's impossible to even come close to the access to the Internet. And there's so much pain to actually, like, interact with that data where it. I mean, it's. It was extremely inefficient in places where I thought it didn't have to be that inefficient. The security was too much. But I have to give respect to that because you, in that case, you want to err on the side of security, but that's Google. They were doing a good job of.
Speaker A: This reputational harm if it got out. I mean, Google, you know, why is Google Drive free? You know, because they want your data. They want you to park your data there. So, you know, if the. If they got hacked or leaked information, the reputational harm would be tremendous.
Speaker B: But, you know, for a company that's nothing. It's really hard to do that. And the company is not as big as Google or not as tech savvy as Google. Might have a lot of trouble doing that kind of stuff. Instead of increasing security, they'll just decrease the efficiency.
Speaker A: Well, yeah, so there's a big difference between it and security. And unfortunately, these mid side companies, they try to stack security into their IT department. Your IT department is about business continuity. They're about trying to move business forward. They want your users to get the data they need to do their job so the company can grow security is not that they don't want you to get the data. They, you know, but there's. There's fine tuning you can do to, you know, ensure that. I mean, as simple as, like, having good onboarding procedures for employees. Like, like, you come into my company, you don't need access to everything. Maybe you need access to something for one day. Turn the access on. Don't leave it on. I mean, I was the victim of the OPm hack, the office of Personnel Management, because old credentials from a third party vendor were sitting there inactive, and the chinese government found those credentials and were able to log in and steal all my information.
Speaker B: So a lot could be helped if you just control the credentials, the access, the access control, how long they last, and people who have. Who need access to a certain thing, only get access to that thing and not nothing else. And then it just gets refreshed like that.
Speaker A: Access control, like we said, setting up people leaving, people leaving the company, get rid of their, they don't need control. Two factor authentication, that's a big thing. It's, I mean, I sound like a broken record because this isn't anything new. This isn't rocket science. The problem is we're not implementing it. If we are, we're not doing it correctly because these guys are taking us well.
Speaker B: Two factor authentication is a good example of something that I just was annoyed by for the longest time because, yes, it's very good, but like, it's, it seems that it's pretty easy to implement horribly to where it's like it's not convenient at all. For the, for the legitimate user to, it should be trivial to do. Like to authenticate yourself twice should be super easy.
Speaker A: If security, if it's slightly inconvenient for you, it's think about how inconvenient it is for a hacker and how this is going to move on to the next person.
Speaker B: Yes, yes. In theory, when implemented extremely well.
Speaker A: Yeah.
Speaker B: But I just don't think so. I think actually if it's inconvenient, it shows that system has been thought through a lot.
Speaker A: Do you know why we need two factor authentication? People using the same password across the same site. So when one site is compromised, people just take that username and password, it's called credential stuffing, and just stuff it across the Internet. So if ten years ago, when we told everybody, don't use the same fucking password across the Internet, across vulnerable sites, maybe two factor wouldn't be needed.
Speaker B: Yeah. So you wouldn't need two factor if everyone did a good job with passwords.
Speaker A: Yeah.
Speaker B: Right. But I'm saying, like, the two factor authentication, it should, it should be super easy to authenticate myself in some, with some other device really quickly. Like there should be, it should be frictionless, like you just hit.
Speaker A: Okay, okay.
Speaker B: And anything that belongs to me. Yeah, and like I should. It should very importantly be easy to set up what belongs to me. I don't know, the full complexity of the cyber attacks these platforms are under. They're probably under insane amount of attacks.
Speaker A: Yeah, you've got it right there that people have no idea, these large companies, how often they're attacked, you know, on a per second basis, and they have to fight all that often and pick out the good traffic in there. So, yeah, I would, I, there's no way I'd want to run a large tech company.
Speaker B: What about protecting individuals for individuals? What, what's good advice to try to protect yourself from this increasingly dangerous world of cyber attacks.
Speaker A: Again, educate yourself that you understand that there is a threat. First you have to realize that then you're going to step up and you're going to do stuff a little bit more. Sometimes, I guess, think I take that to a little bit extreme. I remember one time my mom called me and she was screaming that I woke up this morning and I just clicked on a link and now my phone is making weird noises. And I was like, throw your phone in a glass of water. Just put it in a glass of water right now. And she's. I made my mom cry. It was not a pleasant thing. So sometimes I go to a little extremes on those ones, but, but understanding there's a risk and making it a little bit more, a little more difficult to become a victim. I mean, just understanding certain things, you know, simple things like, you know, as we add more Internet of the things to people's houses, I mean, how many Wi Fi networks do people have? It's normally just one. And you're bumping your phones and giving your password to people to come to visit, set up a guest network, set up something you can change every 30 days. Simple little things like that. You know, I hate to remind you, but change your passwords. I mean, I feel like I'm a broken record again, but just make it more difficult for others to victimize you.
Speaker B: And then don't use the same password everywhere.
Speaker A: That, that, yes.
Speaker B: I mean, I still know people that do that.
Speaker A: I mean, ask FM got popped last week, two weeks ago, and that's 350 million username and passwords with connected Twitter accounts, Google accounts, all the different social media accounts. That is a treasure trove for the next two and a half, three years of just using those credentials everywhere, even if it's not the right password. You learn people's password styles. Bad guys are making portfolios out of people. We're figuring out how people generate their passwords and kind of, you know, figuring. And then it's easier to crack their password. You know, we're making a dossier on each person. It's 350 million dossiers. Just in that one hack, Yahoo, there was a hat, half a billion.
Speaker B: So the, the thing a hacker would do with that is try to find all the link, low hanging fruit, like how some kind of program that. Yeah. Evaluates the strength of the passwords and then finds the weak ones. And that means that this person is probably the kind of person that would use the same password across from all.
Speaker A: Of multiple, or even just write a program into that. Remember the ring hack a couple a year ago? That's all it was is credential stuffing. So ring, the security system by default had two factor, but didn't turn it on. And they also had don't try unlimited tries to log into my account. You can lock it out after ten by default, not turned on because it's not convenient for people. Ring was like, I want people to stick these little things up and have security in their house, but cyber security security don't make it inconvenient. Then people won't buy our product. That's how they got hacked. They want to say that it's insecure and got hacked into reputational harm right there for ring. But they didn't. It was just credential stuffing. People bought username and passwords on the black market and just wrote a bot that just went through ring and used every one of them. Maybe 1% hit. But that's a big hit to the number of ring users you know, you can use.
Speaker B: Also password managers to make. To make the changing of the passwords easier.
Speaker A: You can choose the difficulty, the number of special characters, the length of it, and all that.
Speaker B: My favorite things on websites yell at you for your password being too long or having too many special characters. Or like, yeah, you're not allowed to have this special character or something.
Speaker A: You can only use these three special characters. Do you understand how password cracking works? If you specifically tell me what special characters I can use?
Speaker B: I honestly just want to have a one on one meeting late at night with the engineer that programmed that, because that's like an intern. I just wanted to have a sit down meeting.
Speaker A: Yeah, I made my parents switch banks once because the security was so poor. I was like, you can't have money here.
Speaker B: But then there's also like, the zero day attacks, like I mentioned before, the QNIP Nas that got hacked. Luckily, I didn't have anything private on there there. But it really woke me up to like, okay, so, like, if you take.
Speaker A: Everything extremely seriously, unfortunately for the end users, there's nothing you do about zero day. It's, you know, there's this. You have no control over that. I mean, it's the engineers that made the software don't even know about it. Now let's talk about one days. So there's a patch now out there for the security. So if you're not updating your systems for these security badges if it's just not on you. My father in law has such an old iPhone, you can't security patch it anymore. So, you know, and I tell him, I said, this is what you're missing out on. This is what you're exposing yourself to. Because we talked about that powerful tool, how we found rossalbergmail.com. well, bad guys are using that, too. It used to be called Google dorking. Now I think it's named kind of Google hacking by the community. You can go in, you know, and find a vulnerability, read about the white paper. What's wrong with that? That software. And then you can go on the Internet and find all of the computers that are running that outdated software. And there's your list. There's your target list. Yeah, I know the vulnerabilities that are running, again, not making a playbook here, but, you know, that's how easy it is to. To find your targets. And that's what. That's what the bad guys are doing.
Speaker B: Then the reverse is tough. It's much tougher but still doable, which is like, first find the target. If you have specific targets to, you know, hack into a Twitter account, for example, much harder. That's probably social engineering, right? That's probably the best way.
Speaker A: Probably. If you. If you want something specific to that, I mean, if you really want to go far, you know, if you're targeting a specific person, you know, how hard is it to get into their office and put a, you know, a little device, USB device in line with their mouse, who checks how their mouse is plugged in? And you can, for $40 on the black market, you can buy a key logger that just USB. Then the mouse plugs right into it. It looks like an extension on the mouse. If you can even find it. You can buy the stuff with a mouse inside of it and just plug it into somebody's computer as there's a key logger that lives in there and calls home, sends everything you want. So, I mean. And it's cheap.
Speaker B: Yeah. In grad school, a program to build a bunch of keyloggers. It was fascinating tracking mouse just for. I was doing as part of the research I was doing to see if by the dynamics of how you type and how you move the mouse, you can tell who the person is. It's called active authentication, or it's basically biometrics. That's not using bio just to see how identifiable that is. It's fascinating to study that, but it's also fascinating how damn easy it is to install all key loggers. So I think in natural, what happens is you realize how many vulnerabilities there are in this world. You do that when you understand bacteria and viruses, you realize they're everywhere. And the same way with, I'm talking about biological ones. And then you realize that all the vulnerabilities that are out there. One of the things I've noticed quite a lot is how many people don't log out of their computers. Just how easy physical access the systems actually is. Like in a lot of places in this world, and I'm not talking about private homes, I'm talking about companies, especially large companies. It seems quite trivial in certain places that I've been to, to walk in and have physical access to a system. And that's depressing to me.
Speaker A: It is. I laugh because one of my partners at Naxo that I work at now, he worked at a big company. Like you would know the name as soon as I told you. I'm not going to say it, but the guy who owned the company and the company has his name on it didn't want to ever log into a computer. Just annoyed the shit out of him. So they hired a person that stands next to his computer when he's not there and that's his physical security.
Speaker B: That's good. That's pretty good, actually.
Speaker A: Yeah. I mean, I guess if you could afford to do that, at least you're.
Speaker B: Taking your security seriously. I feel like there's a lot of people in that case would just not have a login.
Speaker A: Yeah, no, the security team there had to really work around to make that work non compliant with company policy.
Speaker B: See, but that's. That's interesting. The key log, there's a lot of. There's just a lot of threats.
Speaker A: Yeah.
Speaker B: I mean, a lot of ways to get in.
Speaker A: Yeah. I mean, so you can't sit around and worry about someone physically gaining access to your computer with keylogger and stuff like that. You know, if you're traveling to a foreign country and you work for the FBI, then yeah, you do. You pick little. You know, sometimes some countries you would bring a fake laptop just to see if they stole it or accessed it.
Speaker B: I really want, want, especially in this modern day, to just create a lot of clones in myself that generate Lex sounding things and just get. Put so much information out there. Actually dox myself all across the world.
Speaker A: And then you're not a target, I guess. Just put it out there. I've always said that though. Like we do these searches in FBI houses and stuff. Like that. If someone just got like a box load of like ten terabyte drives and just encrypted at them. Oh my God. Do you know how long the FBI would spin their wheels trying to get that data off there? Be insane also.
Speaker B: So just give them.
Speaker A: You don't even know which one you're looking for.
Speaker B: Yeah, that's true. That's true. So it's like me printing like a treasure map to a random location. Just get people to go on goose chases. Yeah. What about operating system? What have you found? I. What's the most secure and what's the least secure operating system? Windows? Linux? Is there no universal?
Speaker A: There's no universal security. I mean it changed you. People used to think Macs were the most secure just because they just weren't out there. But now kids have had access to them. So, you know, I know you're a Lennox guy, I like Linux too, but you know, it's tough to have run a business on Linux. You know, people want to move more towards the Microsoft's and the Googles just because they, it's easier to communicate with other people that maybe aren't computer guys. So you have to just take what's best, what's easiest and secure the shit out of it as much as you can and just think about it.
Speaker B: What are you doing these days at Naxo?
Speaker A: So we just started Naxo. So I left the government and went to a couple of consultancies and I started working. Really all the people I worked good in the government with, I brought them out with me. And now you used to work for.
Speaker B: The man and now you're the man.
Speaker A: Exactly. So, but now we formed a partnership and it's, it's just a, it's a new cybersecurity firm that we, our launch party is actually on Thursday so it's going to be exciting.
Speaker B: Do you want to give more details about the party so that somebody can hack into it?
Speaker A: No, I don't know. Gonna tell you where it is. You can come if you want, but don't, don't, don't bring the hackers.
Speaker B: Well that's.
Speaker A: Hector will be there.
Speaker B: I can't believe you invited me because you also say insider threaten is, is the, is the biggest threat. By the way, can you explain what the insider threat is?
Speaker A: The biggest insider threat in my life is my children. My, my son's big into Minecraft and will download executables mindlessly and just run them on the network. So he.
Speaker B: You recommend against marriage and family and kids?
Speaker A: No, nope.
Speaker B: I secure from a security perspective.
Speaker A: From a security perspective, absolutely. But no, I just. Segmentation. I mean, we do it in all businesses for years. Started studying segmenting networks, different networks. I just do it at home. My kids on his own network. Um, it makes it a little bit easier to see what they're doing, too. You can monitor traffic and then also throttle bandwidth if, uh. If you're. Your Netflix isn't playing fast enough or buffers or something. So you can obviously change that a little, too.
Speaker B: You know they're going to listen to this, right? They're going to get your tricks.
Speaker A: Yeah, that's true. They'll definitely will listen. But there's nothing more humbling than your family. You think you've done something big and you go on a big podcast and talk to Les Freeman. They. They don't. They don't care.
Speaker B: Damn. Unless. Unless you're on tick tock or you'll.
Speaker A: Show up on a YouTube feed or something like that, and I'll be like.
Speaker B: Oh, yeah, this guy's boring.
Speaker A: My son does a podcast for his school, and it's still. I still can't get him to tell, like, so. So one of the. Hector and I just started a podcast talking about cybersecurity. We do a podcast called Hacker in the Fed. It just came out yesterday. So first episode. So, yeah, we got 13. 13,000 1300 down downloads the first day. So pretty. We were at the top of Hacker News, which is a big website in.
Speaker B: Our world, so it's called Hacker and the Fed.
Speaker A: Hacker and the Fed's name is.
Speaker B: So go download and listen to Hacker and the Fed. I can't wait to see what. Because I don't think I've seen a video of you two together, so I can't wait to see what the. The chemistry is like. I mean, it's not weird that you guys used to be enemies and now.
Speaker A: You'Re friends, so, yeah, I mean, we just did some. A trailer and all that. And the. Our producer, we have a great producer guy named Phineas, and he kind of pulls things out of me. And I said. I said, I got one. My relationship with Hector is, you know, we're very close friends now. And I was like, oh, I arrested one of my closest friends.
Speaker B: Yeah.
Speaker A: Which is a very strange relationship. Yeah, it's weird, you know, but he. He says that I changed his life. I mean, he was going down a very dark path, and I gave him an option that one night, and he. He made the right choice. I mean, he's. He now does penetration testing. He does a lot of good work, and, you know, he's turned his life around.
Speaker B: Do you worry about cyber war in the 21st century?
Speaker A: Absolutely. If there is a global war, it'll start with cyber. If it's not already started.
Speaker B: Do you feel like there's a boiling. The dramas of war are beating what's happening in Ukraine with Russia. It feels like the United States becoming more and more involved in the conflict in that part of the world. And China is watching very closely, is starting to get involved geopolitically and probably in terms of cyber. Do you worry about this kind of thing happening in the next decade or two, like, where it really escalates? People in the 1920s were completely terrible at predicting the World War Two, too. Do you think we're at the precipice of war potentially?
Speaker A: I think we could be. I mean, I would hate to just be, you know, just fear mongering out there. You know, Covid's over, so the next big thing in the media is war and all that, but, I mean, there's some flags going up that are very strange to me.
Speaker B: Is there ways to avoid this?
Speaker A: I hope so. I hope smarter people than I are figuring it out. I hope people are playing their parts in talking to the right people, because that's the war is the last thing I want.
Speaker B: Well, there's two things to be concerned about on the cyber side. One is the actual defense on the technical side of cyber, and the other one is the panic that might happen when something like some dramatic event happened because of cyber, some major hack that becomes public. I'm honestly more concerned about the panic because I feel like if people don't think about this stuff, the panic can hit harder. Like, if they. If they're not conscious about the fact that we're constantly under attack, I feel like it'll come like a much harder surprise.
Speaker A: Yeah, I think people will be really shocked on things. I mean, so we talked about low SEC today, and low SEc was 2011. They had access into a water, the water supply system of a major US city. They didn't do anything with it. They were sitting on it in case someone got arrested and they were going to maybe just expose that it's insecure. Maybe they were going to do something to fuck with it. I don't know. But, you know, that. That's. That's 2011. You know, I don't think it's gotten a lot better since then.
Speaker B: And there's probably nation states or major organizations that are sitting secretly on hacks.
Speaker A: Like a hundred percent, 100% they're sitting secretly waiting to expose things. I mean, I. Again, I don't want to scare the shit out of people, but people have to understand the cyber threat. I mean there are, you know, there are. There are thousands of nation state hackers in some countries. I mean, we have them too. We have offensive hackers.
Speaker B: You know, the. The terrorist attacks of 911. There's planes that actually hit actual buildings and it was visibly clear and you can trace the information. With cyber attacks, say something that would result in a major explosion in New York City. How the hell do you trace that? Like, if it's well done, it's going to be extremely difficult. The problem is there's so many problems, one of which the us government in that case has complete freedom to blame anybody they want.
Speaker A: True.
Speaker B: And then to go start war with anybody, anybody that actually see that's. Sorry, that's one cynical take on it, of course.
Speaker A: No, but you're going down the right path. I mean, the guys that the flu, planes in the buildings wanted attribution. They took credit for it. When we see the cyber attack, I doubt we're going to see attribution. Maybe the victim side, the us government on this side, might come out and try to blame somebody, you know, like you've brought up. Like they could blame anybody they want. There's not really a good way of verifying that.
Speaker B: Can I just ask for your advice? So in my personal case, am I being tracked? How do I know? How do I protect myself? Should I care?
Speaker A: You are being tracked. I wouldn't say you're being tracked by the government. You're definitely being tracked by big tech.
Speaker B: No, I mean me personally, Lex, and an escalated level. So like, like you mentioned, there's an FBI file on people. Sure, I'd love to see what's in that file. Who did I have the argument? Oh, let me ask you. FBI. Yeah. How's the cafeteria food in FBI?
Speaker A: At the academy? It's bad.
Speaker B: Yeah.
Speaker A: What about like at headquarters?
Speaker B: Headquarters?
Speaker A: Little bit better. Cause that's where the director, I mean he eats up on the 7th floor.
Speaker B: Have you been like a Google? Have you been Silicon Valley, those cafeteria, like those.
Speaker A: I've been to the Google in Silicon Valley. I've been to the Google in New York.
Speaker B: Yeah. The food is incredible.
Speaker A: It is great.
Speaker B: So FBI is worse?
Speaker A: Well, when you're going through the academy, they don't let you outside of the building, so you have to eat it. And I think that's the only reason people eat it. It's pretty bad. I got it. Okay, but there's also a bar inside the FBI academy. People don't know that.
Speaker B: Alcohol bar?
Speaker A: Yes, alcohol bar. And if you. As long as you've passed your pt and going, well, you're allowed to go to the bar.
Speaker B: Nice. It feels like if I was a hacker, I would be going after, like, celebrities because they're a little bit easier. Like, celebrity celebrities. Like Hollywood.
Speaker A: The Hollywood nudes were a big thing there for a long time, but not even.
Speaker B: Yeah, I guess nudes, that's what they went after.
Speaker A: I mean, all those guys, they socialize. They did. They. They social engineered apple to get backups, to get the recoveries for backups. And then they just pulled all their news and, I mean, whole websites were dedicated to that.
Speaker B: Yeah, see, that. See, I wouldn't do that kind of stuff. It's very creepy. I would go. If I was a hacker, I would go after, like, major, like, powerful people and, like, tweet something from their account and, like, something that, like, positive, like loving. But, like, for the. For the law, the obvious, that it's a troll.
Speaker A: God, you get busted so quick by what? A bad hacker.
Speaker B: Really? But why?
Speaker A: Because hackers never put things out about love.
Speaker B: Oh, you mean, like, this is clearly.
Speaker A: Yeah, this is clearly Lex.
Speaker B: What the fuck?
Speaker A: About love? And every podcast he does, I would.
Speaker B: Just be like, no. Oh, God damn it. Now somebody's gonna do it. You'll blame me. It wasn't me. Looking back at your life, is there something you really.
Speaker A: I'm only 44 years old. I'm already looking back.
Speaker B: Is there stuff that you regret?
Speaker A: Evie? Unit.
Speaker B: Yes.
Speaker A: Got away.
Speaker B: That was the one that got away.
Speaker A: Yeah. I mean, it took me a while into my law enforcement career to learn about the compassionate side. And it took Hector monsterger to make me realize that criminals aren't really criminals. They're human beings that really humanized the whole thing. For me, sitting with him for nine months, I think that's maybe why I had a lot more compassion when I arrested Ross. Probably wouldn't have been so compassionate if it was before Hector, but, yeah, he changed my life and showed me that humanity side of things.
Speaker B: So would it be fair to say that all the criminals, or most criminals, are just people that took a wrong turn at some point? Point. They all have the capacity for good and for evil in them.
Speaker A: I'd say 99% of the criminals that I've interacted with. Yes, the people with the child exploitation. No, I don't have any place in my heart for them.
Speaker B: What advice would you give to people in college people in high school trying to figure out what they want to do with their life, how to have a life they can be proud of, how to have a career they can be proud of, of all that kind of stuff.
Speaker A: In the us budget that was just put forward, there's $18 billion for cybersecurity. We're about a million people short of where we really should be in the industry, if not more. If you have want job security and want to work and see exciting stuff, head towards cybersecurity. It's a good career. One thing I dislike about cybersecurity right now is they expect you to come out of college and have ten years experience in protecting and knowing every different python script out there and everything available. You know, the industry needs to change and let the lower people in in order to broaden and get those billion jobs filled. But as far as their personal security, just remember, it's all going to follow you. I mean, you know, there's laws out there now that you have to turn over your social media accounts in order to have certain things. They just changed that in New York state, if you want to carry a gun, you have to turn over your social media to figure if you're a good social character. So hopefully you didn't say something strange in the last few years and it's going to follow you forever. I bet Ross Ulbricht would tell you the same thing when not don't put rossallbergmail.com on things because it's going to last forever.
Speaker B: Yeah. People sometimes, for some reason, they interact on social media as if they're talking to a couple of buddies. Like just shooting shit and mocking and like, you know, what is that? Busting each other's chops, like making fun of yourself. Like being. Especially gaming culture like, people who stream.
Speaker A: Thank God that's not recorded. Oh my God, the things people say on those streams.
Speaker B: Yeah, but a lot of them are recorded.
Speaker A: Yeah.
Speaker B: So there's a whole twitch thing where people stream for many hours a day. And I mean, just outside of the very offensive things they say, they just swear a lot. They're not the kind of person that I would want to hire. I want to want to work with. Now, I understand that some of us might be that way privately. I guess when you're shooting shit with friends, like playing a video game and talking shit to each other, maybe. But like, that's all out there. You have to be conscious of the fact that that's all out there. And it's just not, it's not a good. Look, it's not like you're. You should. It's complicated because I'm, like, against hiding.
Speaker A: Who you are, but you're an asshole. You should hide some of it.
Speaker B: Yeah, but, like, I just feel like it's going to be misinterpreted when you talk shit to your friends while you're playing video games. It doesn't mean you're an asshole because you're an asshole to your friend. But that's how a lot of friends show love.
Speaker A: Yeah. An outside person can't judge how I'm friends with you if I want to be. This is our relationship. If that person can say that I'm an asshole to them, then that's fine, I'll take it. But you can't tell me I'm an asshole to them just because you saw my interaction. I agree with that.
Speaker B: They'll take those words out of context, and now that's considered who you are is dangerous, and people take that very nonchalantly. People treat their behavior on the Internet very, very carelessly. That's definitely something that people need to learn and take extremely seriously. Also, I think taking that seriously will help you figure out who you. What you really stand for. If you use your language carelessly, you'd never really ask, like, what do I stand for? I feel like it's a good opportunity when you're ahead young to ask, like, what are the things that are okay to say? What are the things? What are the ideas I stand behind? Like what? Especially if they're controversial and I'm willing to say them because I believe in them versus just saying random shit for the. For the laws. Because for the random shit for the laws. Keep that from off the Internet. That said, man, I was an idiot for most of my life. And I'm constantly learning and growing, and I'd hate to be responsible for the kind of person I was in my teens. In my twenties, I didn't do anything offensive, but it just changed as a person. Like, I used to. I guess I probably still do, but I used to, you know, I used to read so much existential literature. That was a phase. There's, like, phases.
Speaker A: Yeah. You grow and evolve as a person, that changes you in the future. Yeah. I thank God there wasn't social media when I was in high school. Thank God. Oh, my God. I would never be gotten the FBI.
Speaker B: Would you recommend that people consider a career at a place like the FBI?
Speaker A: I loved the FBI. I never thought I would go anyplace else but the FBI. I thought I was going to retire with the gold watch and everything from the FBI. That was my plan. No, but you know what it is? It's a.
Speaker B: It's an excellent.
Speaker A: You get a gold badge. You actually get your badge in loose site and youre a creds they put in lucid and all that.
Speaker B: So does it, does it, by the way, just on a tangent, since we like those, does it hurt you that the FBI, by certain people, is distrusted or even hated 100%?
Speaker A: It kills me. I've never, until recently, not sometimes be embarrassed about the FBI sometimes, which is really, really hard for me to say because I love that place. I love the people in it. I love the brotherhood that you have with, you know, all the guys in your squad, guys and girls. I just use guys, you know. You know, we. I developed a real drinking problem there because we were so social of going out after. After work and, you know, continuing on. It really was a family, you know, so I do miss that. But, yeah, I mean, if somebody can become an FBI agent, I mean, it's pretty fucking cool, man. The day you graduate and walk out of the academy with a gun and a bat badge and, you know, the. The power to charge someone with a misdemeanor for flying a United States flag at night, that's awesome.
Speaker B: So there is a part of, like, representing and loving your country, and especially if you're doing cybersecurity. So there's a lot of technical savvy in the different place in the FBI.
Speaker A: Yeah, I mean, there. There's different pieces sometimes, you know, you'll see an older agent that's done, you know, not cybercrime. Come over to cybercrime at the end so he can get a job once he goes out. But there's also some. Some guys that come in, you know, I won't name his name, but there was a guy, I mean, I think he was a hacker when he was a kid, and now he's been an agent now he's way up in management. Great guy. I love this guy. And he knows who he is, if he's listening, that he had some skills. But we also lost a bunch of guys that had some skills because we had one guy in the squad that he had to leave the FBI because his wife became a doctor and she got her residency down in Houston and she couldn't move. He wasn't allowed to transfer, so he decided to keep his family versus the FBI. So there's some stringent rules in the FBI that need to be relaxed a little bit.
Speaker B: Yeah. I love hackers turned like, leaders. Like, one of my quickly becoming good friends is mudge. It was a big hack in the nineties, and then now was recently Twitter, chief security officer, CSO. But he had a bunch of different leadership positions, including being my boss at Google. But originally a hacker. It's cool to see hackers become, like, leaders.
Speaker A: I just wonder what would cause him to stop doing it, why he would then take a managerial route for high tech companies.
Speaker B: I think a lot of those guys. So this is the nineties. They really were about the freedom. There's a philosophy to it. I think the hacking culture evolved over the years, and I think when it leaves you behind, you start to realize, like, oh, actually what I want to do is I want to help the world, and I can do that in legitimate routes and so on. But that's the story. That. And, yeah, I would love to talk to him one day, but I wonder how common that is, too. Like, young hackers turn. Turn good. You're saying it, like, pulls you in. If you're not careful, it can really pull you in.
Speaker A: Yeah, it's, you know, you're good at it. You become powerful, become, you know, everyone's slapping on the back and say, what a good job and all that, you know, at a very young age.
Speaker B: Yeah.
Speaker A: So, yeah, I would love to get into my buddy's mind on why he stopped hacking and moved on. That's gonna be a good conversation.
Speaker B: In his case, maybe. Maybe it's always about a great woman involved, a family. And so, on that grounds, you. Because, like, we have. There is a danger to hacking, that once you're in a relationship, once you have family, maybe you're not willing to partake in. What's your story? What? From childhood? What are some fond memories?
Speaker A: You have fond memories.
Speaker B: Where did you grow up?
Speaker A: Well, I don't give away that information.
Speaker B: In the United States.
Speaker A: Yeah, yeah, yeah. In Virginia.
Speaker B: What are some rough moments? What are some beautiful moments that you remember?
Speaker A: I had a very good family growing up. The, like, rough moment. And I'll tell you a story that just happened to me two days ago, and it fucked me up, man. It really didn't. You'll be the first. I've never told anything. I tried to tell my wife this two nights ago, and I couldn't get it out. So my father, he's a disabled veteran, or he was a disabled veteran. He was in the army and got hurt and was in a wheelchair his whole life. For all my growing up, he was my biggest fan. He just wanted to know everything about you know what was going on in the FBI? My stories. I was a local cop before the FBI. And I got to a high speed car chase, you know, foot chase and all that and kicking doors in. He wanted to hear those stories. And at some points, I was kind of too cool for school and, ah, dad, I just want a break and all that and things going on. We lost my dad during COVID not because of COVID but it was around that time, but it was right when Covid was kicking off. And so he died in the hospital. Bye. Himself. And I didn't get to see him then. And then my mom had some people visiting her the other night, and Tom and Karen Rogerberg. And I'll say they're my second biggest fans, right behind my dad. They always asking about me and my career. And they read the books and seen the movie. They'll even tell you that Silk Road movie was good. They'll lie to you on that. They came over and. And I helped them with something. And my mom called me back a couple days later and she said, I appreciate you helping them. I know fixing someone's Apple phone over the phone really isn't what you do for a living. It's kind of beneath you and all that, but I appreciate it. And she said, oh, they loved hearing the stories about Silk Road and all those things. And she goes, your dad, he loved those stories. I just wish he could have heard him. He even would tell me. He would say, you know, maybe. Maybe Chris will come home and I'll get him drunk and he'll tell me the stories, but. And then she goes, maybe one day and in heaven you can tell him those stories. And I fucking lost it. I literally stood in my shower sobbing like a child, like, just thinking about, like, all my dad wanted was those stories.
Speaker B: Yeah.
Speaker A: And now I'm on a fucking podcast telling stories to the world, and I didn't tell him. Yeah, so did you ever have, like.
Speaker B: A long heart to heart with him about, like, about such stories?
Speaker A: He was in the hospital one time, and I went through. And I want to know about his history, like, his life, what he did. And I think he maybe sensationalized some of it. But that's what you want. Your dad's your hero, so you want to hear those things.
Speaker B: It's a good story teller.
Speaker A: Um, yeah. Again, I don't know what was true or not true, but, you know, some of it was really good. Um, and it was just good to hear his life. But, you know, we lost him, and. And now those stories are gone.
Speaker B: You miss them?
Speaker A: Yeah.
Speaker B: What did he teach you about what it means to be a mandev?
Speaker A: So my dad, um, he was an engineer, and so part of his job, we worked for, um, Vermont power and electric or whatever it was. I mean, he. When he first got married to my mom and all that, um, like, he flew around in a helicopter checking out, like, power lines and dams. He used to swim inside to scuba into dams to check to make sure, like, they were functioning properly and all that. Pretty cool shit.
Speaker B: Yeah.
Speaker A: And then he couldn't walk anymore. I probably would have killed myself if my life switched like that so bad. And my dad probably went through some dark points, but he had that from me, maybe. And so to get through that struggle, to teach me, like, you know, you press on, you have a family. People count on you. You do what you got to do. That was. That was big. Yeah.
Speaker B: I'm sure you make him proud, man.
Speaker A: I I'm sure I do, but I don't think he knew that. That I knew that.
Speaker B: Well, you get to pass on that love to your kids now.
Speaker A: I try. I try, but I can't impress them as much as my dad impressed me. I can try all I want, but.
Speaker B: Well, what do you think is the role of love? Because you gave me some grief. You busted my balls a little bit for talking about love a lot. What do you think is the role of love and the human condition?
Speaker A: I think it's the greatest thing. I think everyone should be searching for it. If you don't have it, find it. Get it as soon as you can. I love my wife. I really do. I had no idea what love was until my kids were born. My son came out, and this is a funny story. He came out and I just wanted to be safe and be healthy and all that. And I said to the doctor, I said, ten and ten, doc. Ten fingers, ten toes, everything good? And he goes, nine and nine. I was like, what the fuck? Oh, this is gonna suck. Okay, we'll deal with it. And all that. He was talking about the Apna card or some score about breathing and color and all that, and I was like, oh, shit. But no one told me this, but. So I'm just sobbing. I couldn't even cut the umbilical cord. Like, just fell in love with my kids when I saw them. And that, to me, really is what love is like just for them, man.
Speaker B: And I see that through your career, that love developed, which is awesome. The being able to see the humanity in people.
Speaker A: I didn't when I was young, the foolishness of youth. I needed to learn that lesson hard when I was young. In my career, it was just about career goals, and resting people became stats. You rest someone, you get a good stat, you get an attitude, maybe the boss likes it and you get a better job or you move up the chain. It took a real change in my life to see that humanity and I.
Speaker B: Can'T wait to listen to your talk, which is probably hilarious and insightful given the life of the two of you lived and given how much you've changed each other's lives. I can't wait to listen. Brother. Thank you so much. This is a huge honor that you're amazing person with an amazing life. This was an awesome conversation dude.
Speaker A: Huge fan. I love the podcast. Glad I could be here. Thanks for the invite. So exercising the brain too. It was great.
Speaker B: Great conversation and the heart too, right?
Speaker A: Oh yeah, yeah, you got, you got some tears there at the end.
Speaker B: Thanks for listening to this conversation with Chris Tarbell. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Benjamin Franklin. They who can give up essential liberty liberty to obtain a little temporary safety deserve neither liberty nor safety. Thank you for listening and hope to see you next time.
