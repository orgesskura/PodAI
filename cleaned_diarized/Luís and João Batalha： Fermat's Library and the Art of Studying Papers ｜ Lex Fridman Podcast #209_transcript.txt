Speaker A: The following is a conversation with Luis and Joao Batala, brothers and co founders of Fermat's library, which is an incredible platform for annotating papers as they write on the Fermat's library website, Justice Pierre de Fermat scribbled his famous last theorem in the margins. Professional scientists, academics and citizen scientists can annotate equations, figures, ideas and write in the margins. Fermat's library is also a really good Twitter account to follow. I highly recommend it. They post little visual factoids and explorations that reveal the beauty of mathematics. I love it. Quick mention of our sponsors, ScIF, Simplisafe, indeed netsuite and four sigmatic. Check them out in the description to support this podcast. As a side note, let me say a few words about the dissemination of scientific ideas. I believe that all scientific articles should be freely accessible to the public. They currently are not. In one analysis, I saw more than 70% of published research articles are behind a paywall. In case you don't know, the funders of the research, whether that's government or industry, aren't the ones putting up the paywall. The journals are the ones putting up the paywall while using unpaid labor from researchers for the peer review process. Where is all that money from the paywall going in this digital age? The costs here should be minimal. This cost can easily be covered through donation, advertisement, or public funding of science. The benefit versus the cost of all papers being free to read is obvious, and the fact that they're not free goes against everything science should stand for, which is the free dissemination of ideas that educate and inspire. Science cannot be a gated institution. The more people can freely learn and collaborate on ideas, the more problems we can solve in the world together, and the faster we can drive old ideas out and bring new, better ideas in. Science is beautiful and powerful, and its dissemination in this digital age should be free. This is the Lex Friedman podcast and heres my conversation with Luis and Joao Batala. Luis, you suggested an interesting idea. Imagine if most papers had a backstory section, the same way that they have an abstract, so knowing more about how the authors ended up working on a paper can be extremely insightful. And then you went on to give a backstory for the Feynman QED paper. This is all in a tweet, by the way. We're doing tweet analysis today. How much of the human backstory do you think is important in understanding the idea itself that's presented in the paper or in general?
Speaker B: I think this gives way more context to the work of scientists. I think a lot of people have this almost kind of romantic misconception that the way a lot of scientists work is almost as the sum of eureka moments, where all of the sudden they sit down and start writing two papers in a row. And the papers are usually isolated. And when you actually look at it, the papers are chapters of a way more complex story. And the Feynman QED paper is a good example. So Feynman was actually going through a pretty dark phase before writing that paper. He lost enthusiasm with physics and doing physics problems. And there was one time when he was in the cafeteria of Cornell, and he saw a guy that was throwing plates in the air, and he noticed that when the plate was in the air, there were two movements there. The plate was wobbling, but he also noticed that the Cornell symbol was rotating, and he was able to figure out the equations of motions of those plates. And that led him to think a little bit about electron orbits in relativity, which led to the paper about quantum electrodynamics. So that kind of reignited his interest in physics and ended up publishing the paper that led to his Nobel Prize, basically. And I think there are a lot of really interesting backstories about papers that readers never get to know. For instance, we did, a couple of months ago, an AMA around a paper, a pretty famous paper, the Gantz paper, with Ian Goodfellow. And so we did an AMA where everyone could ask questions about the paper. And Ian was responding to those questions, and he was also telling the story of how he got the idea for that paper in a bar. So that was also an interesting backstory. I also read a book by Cedric Villany. Cedric Valani is this mathematician, the Fields medalist. And in his book, he tries to explain how he got from, like, a PhD student to the Fields medal, and he tries to be as descriptive as possible about every single step, how he got to the Fields medal. And it's interesting also to see just the amount of random interactions and discussions with other researchers, sometimes over coffee, and how it led to, like, fundamental breakthroughs and some of his most important papers. So I think it's super interesting to have that context of, of the backstory.
Speaker A: Well, the Ian Goodfellow story is kind of interesting, and perhaps that's true for Feynman as well. I don't know if it's romanticizing the thing, but it seems like just a few little insights and a little bit of work does most of the leap required. Do you have a sense that for a lot of the stuff, you've looked at just looking back through history, it wasn't necessarily the grind of like Andrew Wiles with the famous last theorem, for example. It was more like a brilliant moment of insight. In fact, Ian Goodfellow has a kind of sadness to him almost, in that at that time, in machine learning, like at that time, especially for Gans, you could code something up really quickly on a single machine, and almost do the invention, go from idea to experimental validation. In a single night, a single person could do it. And now there's kind of a sadness that a lot of the breakthroughs you might have in machine learning kind of require large scale experiments. So it was almost like the early days. So I wonder how many low hanging fruit there are in science and mathematics and even engineering, where it's like you could do that little experiment quickly. Like, you have an insight in a bar, why is it always a bar, but you have an insight at a bar, and then just implement and the world changes.
Speaker B: It's a good point. I think it also depends a lot on the maturity of the field. When you look at a field like mathematics, it's a pretty mature field, a field like machine learning, it's growing pretty fast and it's actually pretty interesting. I looked up the number of new papers on archive with the keyword machine learning. Like 50% of those papers have been published in the last twelve months. So you can see just the sense 50, so you can see the magnitude of growth in that field. And so I think as fields mature, those types of moments, I think naturally are less frequent. It's just a consequence of that.
Speaker C: The other point that is interesting about the backstory is that it can really make it more memorable in a way. And by making it more memorable, it kind of sediments the knowledge more in your mind. I remember also reading the sort of the backstory to Dijkstra's shortest path algorithm, where he came up with it essentially while he was sitting down at a coffee shop in Amsterdam. And he came up with that algorithm over 20 minutes. And one interesting aspect is he didn't have any pen or paper at the time, and so he had to do it all in his mind, that there's only so much complexity that you can handle if you're just thinking about it in your mind. And that, like, when you think about the simplicity of Dijkstra's shortest path finding algorithm, it's, you know, knowing that backstory helps sediment that algorithm in your mind so that you don't forget about it as easily.
Speaker A: It might be from you that I saw a meme about Dijkstra. It's like he's trying to solve it and he comes up with some kind of random path, and then it's like my parents aren't home. And then he does figures out the algorithm for the shortest path. It's right through words to convey memes. But that's hilarious. I don't know if it's in post that we construct stories that romanticize it. Apparently with Newton, there was no apple. Especially when you're working on problems that have a physical manifestation or a visual manifestation, it feels like the world could be an inspiration to you. So it doesn't have to be completely on paper. Like, you could be sitting at a bar and all of a sudden see something and a pattern will spark another pattern, and you can visualize it and rethink a problem in a particular way. Of course, you can also load the math that you have on paper and always carry that with you. So when you show up to the bar, some little inspiration could be the thing that changes it. Is there any other people almost on the human side, whether it's physics, with Feynman, Dirac, Einstein, or computer science touring anybody else, any backstories that you remember that jump out? Because I'm also referring to, not necessarily these stories where something magical happens, but these are personalities. They have big egos. Some of them are super friendly. Some of them are like, self obsessed, some of them have anger issues. Some of them. How do I describe Feynman? But he appears to have appreciation of the beautiful in all its forms. He has a wit and a cleverness and a humor about him. Does that come into play in terms of the construction of the science?
Speaker C: Well, I think you brought up Newton. Newton is a good example also to think about his backstory, because there's a certain backstory of Newton that people always talk about. But then there's a whole another aspect of him that is also a big part of the person that he was. But he was really into alchemy, and he spent a lot of time thinking about that and writing about it, and he took it very seriously. He was really into Bible interpretation, trying to predict things based on the Bible. And so there's also a whole backstory then. And of course, you need to look at it in the context and the time when Newton lived, but it adds to his personality. And it's important to also understand those aspects that maybe people are not as proud to teach to little kids, but it's important. It was part of who he was. And maybe without those, who knows what he would have done otherwise.
Speaker A: The cool thing about alchemy, I don't know how it was viewed at the time, but it almost like, to me, symbolizes dreaming of the impossible. Like, most of the breakthrough ideas kind of seem impossible until they're actually done. It's like achieving human flight. It's not completely obvious to me that alchemy is impossible or like putting myself in the mindset of the time and perhaps even still everything, that some of the most incredible breakthroughs would seem impossible. And I wonder, the value of believing, almost like focusing and dreaming of the impossible such that it actually is possible in your mind. And that in itself manifests whether the accomplishing that goal or making progress in some unexpected direction. So alchemy almost symbolizes that for me.
Speaker C: I distinctly remember having the same thought of thinking, you know, when I learned about atoms and that they have protons and electrons, I was like, okay, to make gold, you just take whatever has an atomic weight below it and then shove another proton in there, and then you have a bunch of gold. So, like, why don't people do that? It seemed like, conceptually is like, you know, this sounds feasible, you might be.
Speaker A: Able to do it, and you can actually. It's just very, very expensive.
Speaker C: Yeah, yeah, exactly, exactly. So in a sense, we do have alchemy, and maybe even back then, it wasn't as crazy that he was so into it. But people just don't like to talk about that as much. Yeah. But Newton in general was a very interesting fella.
Speaker A: Anybody else come to mind, in terms of people that inspire you, in terms of people that you just are happy that they have once or still exist on this earth?
Speaker C: I think. I mean, Freeman Dyson, for me.
Speaker B: Yeah, Freeman Dyson. I've had a chance to actually exchange a couple of emails with him. It was probably one of the most humble scientists that I've ever met, and that had a big impact on me. We were trying. We were actually trying to convince him to annotate a paper on Fermat's library. And I sent him an email asking him if you could annotate a paper. And his response was something like, I have very limited knowledge. I just know a couple of things about certain fields. I'm not sure if I'm qualified to do that. That was his first response. And this was someone that should have won a Nobel Prize and worked on a bunch of different fields, did some really, really great work, and then just the interactions that I had with him, every time I asked him a couple of questions about his papers and he always responded, saying, I'm not here to answer your questions. I just want to open more questions. And so that had a big impact on me. It was like, just an example of an extremely humble yet accomplished scientists. And Feynman was also a big, big inspiration in the sense that he was able to be extremely talented and scientist, but at the same time, socially, he was also really smart from a social perspective, and he was able to interact with people. He was also a really good teacher and also did awesome work in terms of explaining physics to the masses and motivating and getting people interested in physics. And that, for me, was. Was also a big inspiration.
Speaker A: Yeah, I like the childlike curiosity of some of those folks. Like you mentioned, Freeman, I have Daniel Kahneman. I got a chance to meet and interact with some of these truly special scientists. What makes them special is that even in older age, they're still, like, there's still that fire of childlike curiosity that burns. And some of that is, like, not taking yourself so seriously that you think you figured it all out, but almost like thinking that you don't know much of it. And that's like, step one in having a great conversation or collaboration or exploring a scientific question. It's cool how the very thing that probably earned people the Nobel Prize, or I do, or work that's seminal in some way, is the very thing that still burns even after they've won the prize. It's cool to see. And they're rare humans, it seems.
Speaker B: And to that point, I remember, like, the last email that I sent to Freeman Dyson was, like, in his last birthday, he was really into number theory and primes. So what I did is I took a photo of him, a picture, and then I turned that into, like, a giant prime number. So I converted the picture into a bunch of one and eights, and then I moved some numbers around until it was a prime, and then I sent him that.
Speaker A: Also, the visual, like, it still looked like the picture, it was made up of a prime. That's tricky to do. That's hard to do.
Speaker B: It looks harder than it actually is. So the way you do it is you convert the darker regions into eights and the lighter regions in ones, and.
Speaker A: Then there's just keep flipping.
Speaker B: Yeah, numbers. But there's, like, some primality tests that are cheaper from a computational standpoint, but what it tells you is it excludes numbers that are not prime. Then you end up with a set of numbers that you don't know if they are prime or not. And then you run the full primality test on that. So you just have to keep iterating on that. And it's funny because when he got the picture, he was like, how did you do that? It was super curious to. And then we got into the details, and again, it was already 90, I think 92 or something. And that curiosity was still there. So you could really see that in some of these scientists.
Speaker A: So could we talk about Fermat's library?
Speaker C: Yeah, absolutely.
Speaker A: What is it? What's the main goal? What's the dream?
Speaker C: It is a platform for annotating papers. In its essence, academic papers can be one of the densest forms of content out there and generally pretty hard to understand at times. The idea is that you can make them more accessible and easier to understand by adding these rich annotations to the side. We can just imagine a PDF view on your browser, and then you have annotations on each side, and then when you click on them, a sidebar expands and then you have annotations that support latex and markdown. The idea is that you can, say, explain a tougher part of a paper where there's a step that is not completely obvious, or you can add more context to it, and then over time, papers can become easier and easier to understand and can evolve in a way. But it really came from myself, Luigi, and two other friends. We've had this long running habit of kind of running a journal club amongst us. We come from different backgrounds. I studied cs, we studied physics, and so we read papers and present them to each other. And then we tried to bring some of that online, and that's when we decided to build Vermont's library. Then over time, it grew into something with a broader goal. And really what we're trying to do is try to help move science in the right direction. That's really the ultimate goal of and where we want to take it now.
Speaker A: So there's a lot to be said. So first of all, for people who haven't seen it, the interface is exceptionally well done. Execution is really important here.
Speaker C: Absolutely.
Speaker A: The other thing, just to mention, for a large number of people, apparently, which is new to me, don't know what latex is, so it's spelled like latex, so be careful googling it if you haven't before. So I don't even know the correct terminology.
Speaker C: Typesetting language.
Speaker A: It's a typesetting language where you're basically program writing, a program that then generates something that looks, from a typography perspective. Beautiful.
Speaker C: Absolutely.
Speaker A: And so a lot of academics use it to write papers. I think there's, like, a bunch of communities that use it to write papers. I would say it's mathematics, physics, computer science.
Speaker B: Yeah, that's.
Speaker C: Yeah, that's the.
Speaker A: Because I'm collaborating currently on a paper with two neuroscientists from Stanford, and they don't know what. So I'm using Microsoft Word and Mendeley and, like, all of those kinds of things. And it's. And I'm being very zen, like, about the whole process. But it's fascinating. It's a little heartbreaking, actually, because it actually, it's funny to say, but we'll talk about open science. Actually, the bigger mission behind it from our library is really opening up the world of science to everybody is these silly two facts of one community uses latex and another uses word, is actually a barrier between them. It's, like, boring and practical in a sense, but it makes it very difficult.
Speaker B: To collaborate just on that. I think there are some people that should have received a Nobel Prize but will never get it. And I think one of those is Donald Knuth, because of tech and latex, because it had a huge impact in terms of just making it easier for researchers to put their content out there, making it uniform as much as possible.
Speaker A: Oh, you mean like a Nobel Peace Prize?
Speaker B: Maybe a Nobel Peace Prize. Maybe a Nobel Prize, yeah, I think so.
Speaker A: I mean, he, at a very young age, got the Turing award for his work in algorithms and so on. So, like, an incredibly, like, when I think it's in, it might be even the sixties, but I think it's the seventies. So when he was really young, and then he went on to do, like, incredible work with his book. And, yeah, with tech that people don't know.
Speaker B: And going back just one on the reason why we ended up, because I think this is interesting, the reason why we ended up using the name Fermat's library, this was because of Fermat's last theorem. And Fermat's last theorem is actually a funny story. So Pierre de Fermat was, like, a lawyer, and he wrote on a book that he had a solution to Ferman's last theorem, but that didn't fit the margin of that book. And so, for mass, Leis theorem basically states that there's no solution. If you have integers a, b, and c, there's no solution to a to the power of n plus b to the power of n equals to c to the power of. If n is bigger than two, so there's no solutions. And he said that, and that problem remained open for almost 300 years, I believe, and a lot of the most famous mathematicians tried to tackle that problem. No one was able to figure that out until Andrew Wiles, I think, was in the nineties, was able to publish the solution, which was, I believe, almost 300 pages long. And so it's kind of an anecdote that there's a lot of knowledge and insights that can be trapped in the margins, and there's a lot of potential energy that you can release if you actually spend some time trying to digest that. And that was the origin story for the name.
Speaker A: Yes. You can share the contents of the margins with the world.
Speaker B: Exactly.
Speaker A: That could inspire a solution or a communication that then leads to a solution.
Speaker B: And if you think about papers, papers are, as Juan was saying, probably one of the densest pieces of text that any human can read. And you have these researchers, like some of the brightest minds in these fields, working on new discoveries and publishing these work on journals that are imposing them restrictions in terms of the number of pages that they can have to explain a new scientific breakthrough. So at the end of the day, papers are not optimized for clarity and for a proper explanation of that content because there are so many restrictions. So there's, as I mentioned, there's a lot of potential energy that can be freed if you actually try to digest a lot of the contents of papers.
Speaker A: Can you explain some of the other things? So, margins Librarian, Journal club.
Speaker C: So, Journal club is what a lot of people know us for, where every week we release an annotated paper in all sorts of different fields, physics, cs, math. Margins is the same software that we use to run the journal club and to host the annotations, but we've made that available for free to anybody that wants to use it. And so folks use it at universities and for running journal clubs. And so we've just made that freely available. And then librarian is a browser extension that we developed that is sort of an overlay on top of archive. So it's about bringing some of the same functionality around comments, plus adding some extra niceties to archive, like being able to very easily extract the references of a paper that you're looking at, or being able to extract the bibtec in order to cite that paper yourself. So it's an overlay on top of archive.
Speaker B: The idea is that you can have that commenting interface without having to leave archive.
Speaker A: It's kind of incredible. I didn't know about it, and once I've learned of it, it's like, holy shit, why isn't it more popular, given how popular archive is, like, everybody should be using it. Archive sucks in terms of its interface. Or let me rephrase that, it's limited in terms of its interface.
Speaker C: Archive is a pretty incredible project, and it is, in a way, the growth has been completely linear over time. If you look at, like, number of papers published on archive, like, you know, it's just been, it's pretty much a straight line for the past 20 years, especially for, you know, like, if you're coming from a startup background and then you were trying to do archive, you'd probably try, like, all sorts of growth acts and like, try to then maybe like, have paid features and things like that, and that would kind of maybe ruin it. And so there's, there's a subtle balance there, and I don't know what, what, what aspects you can change about it.
Speaker B: Yeah, for some tools in science, it just takes time for them to grow. Archive is just turned 30, I believe. And for people that don't know, archive is this kind of online repository where people put preprints, which are versions of the papers, before they actually make it to journals.
Speaker A: Arxiv.
Speaker B: Exactly, for people who don't know.
Speaker A: And it's actually a really vibrant to publish your papers in the aforementioned communities of mathematics and computer science.
Speaker B: It started with mathematics and physics, and then over the last 30 years, it evolved. And now actually computer science, now it's a more popular category than physics and math on archive.
Speaker A: And there's also, which I don't know very much about, like a biology, medical version of that.
Speaker B: Bioarchive. Yeah, biorxiv.
Speaker C: More recent.
Speaker B: It's interesting because if you look at these platforms for preprints, they actually play a super important role, because if you look at a category like math, for some papers in math, it might take close to three years after you click upload paper on the journal website, and the paper gets published on the website of the journal. So this is literally the longest upload period on the Internet. And during those three years, their content is just locked. And so that's why it's so important for people to have websites like archive, so that you can share that before it goes to the journal with the rest of the world. That was actually on archive, that perelman published the three papers that led to the proof of the Poincare conjecture. And then you have other fields, like machine learning, for instance, where the field is evolving at such a high rate that people don't even wait before the papers go to journals, before they start working on top of those papers. So they publish them on archive, then other people see them, they start working on that. And archive did a really good job at building that core platform to host papers. But I think there's a really, really big opportunity in building more features on top of that platform apart from just hosting papers. So collaboration annotations, like having other things apart from papers like code and other things, because, for instance, in the field like machine learning, there's a really big, as I mentioned, people start working on top of preprints, and they are assuming that preprint is correct, but you really need a way, for instance, to maybe it's not peer review, but distinguish what is good work from bad work on archive. How do you do that? Like a commenting interface, like librarian, it's useful for that so that you can distinguish that in a field that is growing so fast as machine learning, and then you have platforms that focus, for instance, on just biology. Biorxiv is a good example. Biorxiv is also super interesting because there's actually an interesting experiment that was run in the sixties. So in the sixties, the NIH supported this experiment called the Information Exchange Group, which at the time was a way for researchers to share biology preprints via mail or using libraries. And that project in the 1960s got canceled six years after it started, and it was due to intense pressure from the journals to kill that project because they were fearing competition from the preprints for the journal industry. Crick was one of the famous scientists that opposed to the information exchange group. And it's interesting because right now, if you analyze the number of biology papers that appear first as preprints, it's only 2% of the papers. And this was almost 50 years after that first experiment. So you can see, like, that pressure from the journals to cancel that initial version of a pre print repo had a tremendous impact on the number of papers that are showing up in biology as preprints. So it delayed a lot that revolution, but now platforms like Biorxiv are doing that work, but there's still a lot of room for growth there. And I think it's super important because those are the papers that are open that everyone can read.
Speaker A: Okay, so, but if we just look at the entire process of science as a big system, can we just talk about how it can be revolutionized? So you have an idea, depending on the field, you want to make that idea concrete. You want to run a few experiments in computer science. There might be some code, there'd be a data set for, you know, some of the more sort of biology, psychology. You might be collecting the data set that's called, you know, a study. Right? So that's part of that. That's part of the methodology. And so you are putting all that into a paper form and then you have some results, and then you, you submit that to a place for review through the peer review process. And there's a process where I. How would you summarize the peer review process? But it's, it's really just like a handful of people look over your paper and comment, and based on that, decide whether your paper is good or not. So there's a whole broken nature to it. At the same time, I love the peer review process when I buy stuff on Amazon, like for, like the commenting system, whatever that is. So, okay, so there's a bunch of possibilities for revolutions there. And then there's the other side, which is the collaborative aspect of the science, which is people annotating, people commenting. Sort of the low effort collaboration, which is a comment. Sometimes, as you've talked about, a comment can change everything, but, you know, or a higher effort collaboration, like more like maybe annotations, or even like contributing to the paper. You can think of like collaborative updating of the paper over time. So there's all these possibilities for doing things better than they've been done. Can we talk about some ideas in this space, some ideas that you're working on, some ideas that you are not yet working on but should be revolutionized? Because it does seem that archive and open review, for example, are like the Craigslist of science. Like, yeah, okay, I'm very grateful that we have it, but it just feels like it's like ten to 20 years. Like it doesn't feel like that's a feature. The simplicity of it is a feature. It feels like it's a bug. But then again, the pushback there is Wikipedia has the same kind of simplicity to it, and it seems to work exceptionally well in the crowdsourcing aspect of it. Sorry, there's a bunch of stuff going on on the table. Let's just pick random things that we can talk about.
Speaker B: Wikipedia. For me, it's the cosmological constant of the Internet. I think we are lucky to live in the parallel universe where Wikipedia exists, because if someone had pitched me Wikipedia, like a publicly edited encyclopedia a couple of years ago, like, it would be, I don't know how many people would have said that that would have survived.
Speaker C: I mean, it makes almost no sense. It's like having a Google Doc that everybody on the Internet can edit and like they'll be like the most reliable source for knowledge.
Speaker A: I don't know how many, but hundreds of thousands of topics.
Speaker C: Yeah, it's insane.
Speaker B: It's insane. And like you have, and then you have users, like there's one single user that edited one third of the articles on Wikipedia. So you have these really, really big power users that are a substantial part of what makes Wikipedia successful. And so no one would have ever imagined that that could happen. And so that's one thing I completely agree with what you just said.
Speaker A: I also, sorry to interrupt briefly. Maybe let's inject that into the discussion of everything else. I also believe I've seen that with sack overflow, that one individual or a small collection of individuals contribute or revolutionize most of the community. Like if you create a really powerful system for archive or like open review, it made it really easy and compelling and exciting for one person who's a ten x contributor to do their thing, that's going to change everything. It seems like that was the mechanism that changed everything for Wikipedia, and that's the mechanism that changed everything. For stack overflow is gamifying or making it exciting, or just making it fun or pleasant or fulfilling in some way. For those people who are insane enough to answer thousands of questions or write thousands of factoids and research them and check them all those kinds of things, or read thousands of papers.
Speaker C: Yeah, no, stack overflow is another great example of that. And it's just, and those are both two incredibly productive communities that generate a ton of value and capture almost none of it. Right. And it's, in a way, it's almost like counter, it's very counterintuitive that people, that these communities would exist and thrive. And it's really hard to, there aren't that many communities like that.
Speaker A: So how do we do that for science? Do you have ideas there? Like, what are the biggest problems that you see? You're working on some of them.
Speaker B: Just on that, there are a couple of really interesting experiments that people are running. And an example would be like the polymath projects. So this is kind of a social experiment that was created by Tim Gowers, fields medalist. And his idea was to try to prove that is it possible to do mathematics in a massively collaborative way on the Internet? So he decided to pick a couple of problems and test that. And they found out that it actually is possible for specific types of problems, namely problems that you're able to break down in little pieces and go step by step. You might need, as with open source, you might need people that are just kind of reorganizing the house every once in a while, and then people throw a bunch of ideas, and then you make some progress, then you reorganize, you reframe the problem and you go step by step. But they were actually able to prove that it is possible to collaborate online and do progress in terms of mathematics. And so I'm confident that there other avenues that could be explored here.
Speaker A: Can we talk about peer review, for example?
Speaker B: Absolutely. I think in terms of the peer review, I think it's important to look at the bigger picture here of what the scientific publishing ecosystem looks like. For me, there are a lot of things that are wrong about that entire process. So if you look at what publishing means in a traditional journal, you have journals that pay authors for their articles, and then they might pay reviewers to review those articles, and finally they pay people to or distributors to distribute the content. In the scientific publishing world, you have scientists that are usually backed by government grants that are giving away their work for free in the form of papers, and then you have other scientists that are reviewing their work. This process is known as the peer review process, again for free. And then finally we have government backed universities and libraries that are buying back all that work so that other scientists can read. So this is, for me, it's bizarre. You have the government that is funding the research, is paying the salaries of the scientists, it's paying the salaries of the reviewers, and it's buying back all that product of their work again. And I think the problem with this system, and it's why it's so difficult to break this suboptimal equilibrium, is because of the way academia works right now and the way you can progress in your academic life. And so in a lot of fields, the competition in academia is really insane. So you have hundreds of PhD students there, are trying to get to a professor position, and it's hyper competitive. And the only way for you to get there is if you publish papers, ideally in journals with a high impact factor.
Speaker A: In computer science, it's often conferences are also very prestigious or actually more prestigious than journals now.
Speaker B: Interesting.
Speaker A: So that's the one discipline where, I mean, that has to do with the thing we've discussed in terms of how quickly the field turns around. But like neurips, CVPR, those conferences are more prestigious, or at the very least as prestigious as the journals. But doesn't matter. The process is what it is.
Speaker B: So for people that don't know, the impact factor of a journal is basically the average number of citations that a paper would get if it gets published on their journal. But so you can really think that the problem with the impact factor is that it's a way to turn papers into accounting units. And let me unpack this, because the impact factor is almost like a nobility title because papers are born with impact even before anyone reads them. So the researchers, they don't have the incentive to care about if this paper is going to ever a long term impact on the world. What they care, their end goal is the paper to get published so that they get that value upfront. So for me, that is one of the problems of that. And that really creates a tyranny of metrics. Because at the end of the day, if you are a dean, what you want to hire is researchers that publish papers on journals with high impact factors, because that will increase the ranking of your university and will allow you to charge more for tuition, so on and so forth, especially when you are in super competitive areas, that people will try to gamify that system and misconduct starts showing up. There's a really interesting book on this topic called gaming the metrics. It's a book by a researcher called Mario Biagioli. It goes a lot into how the impact factor and metrics affect science negatively. And it's interesting to think, especially in terms of citations. If you look at the early work of looking at citations, there was a lot of work that was done by a guy called Eugene Garfield. And this guy, the early work, in terms of citation, they wanted to use citations from the descriptive point of view. So what they wanted to create was a map, and that map would create a visual representation of influence. So citations would be links between papers, and ideally, what they would show they would represent is that you read someone else's paper and it had an impact on your research. They weren't supposed to be counted.
Speaker C: I think this inspired Larry and Sergey's exactly for Google.
Speaker B: Exactly. I think they even mentioned that. But what happens is, as you start counting citations, you create a market. And the same way, and the work of Eugene Garfield was a big inspiration for Larry and Sergey, for the pagerank algorithm that led to the creation of Google. And they even recognized that. And if you think about it the same way, there's a gigantic market for search engine optimization SEO, where people try to optimize the page rank and how I a web page, will rank on Google. The same will happen for papers. People will try to optimize the impact factors and the citations that they get. And that creates a really big problem. And it's super interesting to actually analyze. If you look at the distribution of the impact factors of journals, you have nature. Nature, I believe it's in the low forties, and then you have, I believe science is high thirties. And then you have a really good set of good journals that will fall between ten and 30, and then you have a gigantic tale of journals that have impact factor below two. And you can really see two economies here. You see the universities that are maybe less prestigious, less known, that where the faculty are pressured to just publish papers regardless of the journal. What I want to do is increase the ranking of my university. And so they end up publishing as many papers as they can in, like, journals with low impact factor. And unfortunately, this represents a lot of the global south. And then you have the luxury good economy. So, for instance, and there are also problems here in the luxury good economy. So if you look at the journal like Nature. So with impact factor of like in the low forties, there's no way that you're going to be able to sustain that level of impact factor by just grabbing the attention of scientists. What I mean by that is, like for the journals, the articles that Kat published in Nature, they need to be New York Times great, so they need to make it to the, you know, to the, to the big media, they need to be captured by the big media. And because that's the only way for you to capture enough attention to sustain that level of citations. And that of course, creates problems because people then will try to again, gamify the system and have titles or abstracts that are bigger, make claims that are bigger than what actually can be sustained by the data or the content of the paper, and you'll have clickbait titles or clickbait abstracts. And again, this is all a consequence of metrics and science, or metrics. And this is a very dangerous cycle that I think it's very hard to break. But it's happening in academia, in a lot of fields right now.
Speaker A: Is it fundamentally the existence of metrics or the metrics just need to be significantly improved? Because like I said, the metrics used for Amazon for purchasing, I don't know, computer parts, it's pretty damn good in terms of selecting which are the good ones, which are not. In that same way, if we had Amazon type of review system, in the space of ideas, in the space of science, it feels like those metrics would be a little bit better, sort of, when it's significantly more open to the crowdsourced nature of the Internet, of the, of the scientific Internet, meaning, as opposed to like, my biggest problem with peer review has always been that it's like five, six, seven people, usually even less. And it's often nobody's incentivized to do a good job in the whole process, meaning it's anonymous in a way that doesn't incentivize. Like, doesn't gamify or incentivize great work. And also, it doesn't necessarily have to be anonymous. Like, there has to be. The entire system doesn't encourage actual sort of rigorous review, for example. Like, open review does kind of incentivize that kind of process of collaborative review, but it's also imperfect. But it just feels like the thing that Amazon has, which is like thousands of people contributing their reviews to a product, it feels like that could be applied to science, where the same kind of thing you're doing with for Maz library, but doing at a scale that's much larger. It feels like that should be possible given the number of grad students, given the number of general public that's getting. Like, for example, I personally, as a person who got an education in mathematics and computer science, like, I can. I can be a quote, unquote, like reviewer on a lot bigger set of things than is my exact expertise. If I'm one of thousands of reviewers, if I'm the only reviewer, one of five, then I better be like an expert in the thing. But if I, and I've learned this with COVID which is like, you can just use your basic skills as a data analyst and to contribute to the review process on a particular little aspect of a paper and be able to comment, be able to sort of draw in some references that challenge the ideas presented or to enrich the ideas that are presented. Or, you know, it just feels like crowdsourcing. The review process would be able to allow you to have metrics in terms of how good a paper is that are much better representative of its actual impact in the world, of its actual value to the world, as opposed to some kind of arbitrary, gamified version of its impact.
Speaker C: I agree with that. I think we. There's definitely the possibility, at least for a more resilient system than what we have today. And I think that's kind of what you're describing, Alex. To an extent, we kind of have a little bit of a Heisenberg uncertainty principle. When you pick a metric, as soon as you do it, then maybe it works as a good heuristic for a short amount of time, but soon enough people would start gamifying. But then you can definitely have metrics that are more resilient to gamification, and they'll work as a better heuristic to try to push you in the, in the best direction.
Speaker A: But I guess the underlying problem you're saying is there's a shortage of positions in academia.
Speaker B: That's a big problem for me.
Speaker A: Yeah. And so they're going to be constantly gamifying the metrics.
Speaker C: It's a bit of a zero sum game.
Speaker B: It's very competitive. It's a very competitive field, and that's what usually happens in very competitive fields.
Speaker C: Yeah. Yeah.
Speaker B: But I think some of the peer review problems scale helps, I think. And it's interesting to look at what you're mentioning, breaking it down maybe in my smaller parts, and having more people jumping in, but this is definitely a problem. And the peer review problem, as I mentioned, is correlated with the problem of academic career progression. And it's all intertwined, and that's why I think it's so hard to break it. There are a couple of really interesting things that are being done right now. There are a couple of, for instance, journals that are overlay journals on top of platforms like archive and Biorxiv that want to remove the more traditional journals from the equation. So essentially a journal is just a collection of links to papers. And what they are trying to do is removing that middleman and trying to make the review process a little bit more transparent and not charging universities. There are a couple of more famous ones. There is one discrete analysis in mathematics. There's one called the Quantum Journal, which we're actually working with them. We have a partnership with them for the purpose that kat published in Quantum Journal. They also get the annotations on formats and they are doing pretty well. They've been able to grow substantially. The problem there is getting to critical mass. So it's again, convincing the researchers, and especially the young researchers that need that impact factor, need those publications to have citations to not publish on the traditional journal and go on an open journal and publish their work there. I think there are a couple of really high profiled scientists, people like Tim Gowers, that are trying to incentivize, like famous scientists that already have tenure and that don't need that to publish that, to increase the reputation of those journals so that other maybe younger scientists can start publishing on those as well. And so that you can try to break that vicious cycle of the more traditional journals.
Speaker A: I mean, another possible way to break this cycle is to, like, raise public awareness and just by force, like ban paid journals, like what exactly. Are they contributing to the world? Like, basically making it illegal to forget the fact that it's mostly federally funded? So that's. That's. That's a super ugly picture, too. But, like, why should knowledge be so expensive? Like, where everyone is working for the public good, and then there's these gatekeepers that, you know, most people can't read most papers without having to pay money, and that's. That doesn't make any sense. Like, that. That should be illegal.
Speaker C: I mean, that's what you're saying is exactly right. I mean, for instance, right? I went to school here in the US. We studied in Europe. And you would sit, like, you'd ask me all the time to download papers and send it to him because he just couldn't get it. And, like, papers that he needed for his research. And so.
Speaker A: But he's a student. Like, he's.
Speaker C: Yeah, he's a grad student.
Speaker A: He was a grad student. But that, you know, I'm even referring to just regular people.
Speaker C: Oh, yeah. Okay. That too.
Speaker A: And I think during 2020, because of COVID a lot of journalists put down the walls for certain kind of coronavirus related papers. But, like, that just gave me an indication that, like, this should be done for everything. It's absurd. Like, people should be outraged that there's these gates, because so the moment you dissolve the journals, then there will be an opportunity for startups to build stuff on top of archive. It'd be an opportunity for, like, for my library to step up, to scale up to something much even larger. I mean, that was the original dream of Google, which I always admired, which is make the world information accessible. Actually, it's interesting that Google hasn't. Maybe you guys can correct me, but they have put together Google Scholar, which is incredible, and the scanning of books, but they haven't really try to make science accessible in the following way. Like, besides doing Google scholar, they haven't delved into the papers. Right.
Speaker C: Which is especially curious, given what Louise was saying.
Speaker B: Right.
Speaker C: That's kind of in their genesis. There's this research that was very connected with all papers, reference each other, and building a network out of that.
Speaker B: Interesting enough. Google. I think there was a. There was not intended. Google was like, the Google social network that got canceled, was used by a lot of researchers.
Speaker A: Yes, it was.
Speaker B: I think was just kind of a side effect. But a lot of people ended up migrating to Twitter. But it was not on purpose. But, yeah, I agree with you. Like, they haven't gone past Google scholar.
Speaker A: And that said, Google Scholar is incredible. People who are not familiar. It's one of the best aggregation of all the scientific work that's out there, and especially the network that connects all of them, what sites, what, and also trying to aggregate all of the versions of the papers that are available there and trying to merge them in a way that one particular work, even though it's available in a bunch of places, counts as, you know, like a central hub of what that work is across the multiple versions. But that almost seems like a fun pet project of a couple of engineers within, within Google, as opposed to a serious effort to make the world science accessible.
Speaker B: But going back to just the journals, when you're talking about that, Lex, I believe that in that front, I think we might be past the event horizon. So I think the model, the business model for the journals doesn't make sense. They are a middle layer that is not adding a lot of value and you see a lot of motions. Whereas in Europe, a lot of the papers that are funded by the European Union, they will have to be open to the public. And I think there's a lot of.
Speaker C: Bill Gates to like what the Gates foundation funds, they demand that it's accessible to everybody.
Speaker A: Oh, interesting.
Speaker B: So I think it's a question of time before that wall kind of falls. And that is going to open a lot of possibilities. Because imagine if, if you had like the layer of that gigantic layer of papers all available online, that unlocks a lot of potential as a platform for people to build things on top of that.
Speaker C: But to what you're saying, it is weird. Like you can literally go and listen to any song that was ever made on your phone, right? You open Spotify and you might not even pay for it. You might be on the free version and you can listen to any song that was ever made. Pretty much. But there's like, you don't have access to a huge percentage of academic papers, which is just like this fundamental knowledge that we're all funding, but you as an individual don't have access to it. And somehow the problem for music got solved, but for papers, it's still like.
Speaker A: It'S just not yet. It could be ad supported all those kinds of things, and then hopefully that would change the way we do science. The most exciting thing for me is, especially once I started like making videos and this silly podcast thing, I started to realize like, that if you want to do science, one of the most effective ways is to do like, couple the paper with a set of YouTube videos, like explaining it.
Speaker B: That also seems like there's a lot of room for disruption there. What is the paper 2.0 going to look like? I think like latex and the PDF seems like it's interesting if you look at the first paper that got published in nature, and if you look at the paper that got published in Nature today, if you look at the two side by side, they are fundamentally the same. And even though, like, the paper that gets published today, you know, you get even, even code, like right now, people put like code like on a PDF. And there are so many things that are related to papers today. You have data, you have code, you might need videos to better explain the concepts. So I think for me, it's natural that there's going to be also an evolution there, that papers are not going to be just static PDF's or latex. There's going to be a next interface.
Speaker A: So in academia, a lot of things that you're judged by is often quantity, not quality. I wonder if there's an opportunity to have, like, I tend to judge people by the best work they've ever done, as opposed to, I wonder if there's a possibility for that to encourage sort of focusing on the quality and not necessarily in paper form, but maybe a subset of a paper, a subset of idea, almost even a blog post or an experiment. Like, why does it have to be published in a journal to be legitimate?
Speaker B: And it's interesting that you mentioned that. I also think, like, yeah, it's, why is that the only format? Why can't a blog post, or we were even experimenting with these a few months ago, or can you actually publish something or a new scientific breakthrough or something that you've discovered in the form of a set of tweets? The Twitter thread, why can't that be possible? And we were experimenting with that idea. We ran a couple of, like, some people submitted a couple of those, like, I think the limit was three or four tweets. Maybe it's a new way to look at a proof or something, but I think it just serves to show that there should be other ways to publish scientific discoveries that don't fit the paper format well.
Speaker A: But so even with the Twitter thread, it would be, it would be nice to have some mechanism of formalizing it and making it static, making it into an NFT, maybe like a concrete thing that you can reference with a link. That's unique because, I mean, everything we've been saying, all of that while being true, it's also true that the constraints and the formalism of a paper works well. It, like, forces you. Constraints forces you to narrow down your thing and literally put it on paper. But, you know, I agree, make concrete. And that's why, I mean, it's not broken. It just could be better. And that's the main idea. I think there's something about writing, whether it's a blog post or Twitter thread or a paper that's really nice to concretize a particular little idea that can then be referenced by other ideas. Then it can be built on top of with other ideas. So let me ask you, read quite a few papers, you've annotated quite a few papers. Let's talk about the process itself. How do you advise people read papers? Or maybe you want to broaden it beyond just papers, but just read concrete pieces of information to understand the insights that lay within.
Speaker C: I would say for papers specifically, I would bring back kind of what Luis was talking about is that it's important to keep in mind that papers are not optimized for ease of understanding. And so, right. There's all sorts of restrictions in size and format and language that they can use. And so it's important to keep that in mind. And so that if you're struggling to read a paper, that might not mean that the underlying material is actually that hard. And so that's definitely something that, especially for us, that we read papers. And most of the times it'll be papers that are completely outside of our comfort zone, I guess. And so it'd be completely new areas to us. So I always try to keep that in mind.
Speaker A: So there's usually a certain kind of structure, like abstract introductions, methodology, depending on the community and so on. Is there something about the process of, like, how to read it, whether you want to skim it, to try to find the parts that are easy to understand and nothing reading it multiple times. Is there any kind of hacks that you can comment on?
Speaker B: I remember, like, Feynman had this kind of hack when he was reading papers where he would basically, I think, I believe he would read the conclusion of the paper, and we would try to just see if he would be able to figure out how to get to the conclusion in like a couple of minutes by himself. And he would read a lot of papers that way. And I think Fermi also did that. And Fermi was known for doing a lot of back of the envelope calculations, so he was a master at doing that. In terms of, especially when reading a paper, I think a lot of times people might feel discouraged about the first time you read it. You know, it's very hard to grasp or you don't understand a huge fraction of the paper. And I think it's, having read a lot of papers in my life, I think I've in peace with, like, the fact that you might spend hours where you're just reading a paper and jumping from paper to paper, reading citations, and like, your level of understanding of sometimes of the paper is very close to 0%. And all of a sudden I, you know, everything kind of makes sense in your mind. And then, you know, you have this quantum jump where all of a sudden you understand the big picture of the paper. And I, and this is an exercise that I have to, when reading papers, and especially, like, more complex papers, like, okay, you don't understand because you're just going through the process and just keep going and like, and it might feel super chaotic, especially if you're jumping from reference to reference. You might end up with 20 tabs open and you're reading a ton of other papers. But it's just trusting that process that at the end you'll find light. And I think for me, that's a good framework. When reading a paper, it's hard because you might end up spending a lot of time and it looks like you're lost. But that's the process to actually understand what they're talking about in the paper.
Speaker A: Yeah, I think that process I enjoy. I've found a lot of value in the process, especially for things outside my field, reading a lot of related work sections and kind of going down that path of getting a big context of the field, because what's, especially when they're well written, there's opinions injected into the related work, like what work is important, what is not. And if you read multiple related work sections that cite or don't cite each other, like the papers, you get a sense of where the field, where the tensions of the field are, where the field is striving. And that helps you put into context, like whether the work is radical, whether it's overselling itself, whether it's underselling itself, all those things. And added on top of that, I find that often the related work section is the most kind of accessible and readable part of a paper because it's kind of, it's brief to the point it's trying, like summarizing. It's almost like a Wikipedia style article. The introduction is supposed to be a compelling story or whatever, but it's often like overselling. There's like an agenda in the introduction. The related work usually has the least amount of agenda, except for the few like, elements where you're trying to talk shit about previous work, where you're trying to sell that you're doing much better. But other, other than that, when you're just painting where the field came from or where the field stands, that's really valuable. And also, again, just to agree with Feynman and the conclusion, but I get a lot of value from the breadth. First search, read the conclusion, then read the related work, and then go through the references in the related work, read the conclusion, read the related work, and just go down the tree until you like, hit dead ends or run out of coffee. And then through that process, you go back up the tree. And now you can see the results in their proper context. Unless, of course, the paper is truly revolutionary, which even that process will help you understand that is, in fact, truly revolutionary. You've also, you talked about just following your Twitter thread in a depth first search. You talked about that you read the book on Grisha Perlman, Gregory Perelman, and then you were, you had a really nice Twitter thread on it and you were taking notes throughout. So at a high level, is there suggestions you can give on how to take good notes, whether it's we're talking about annotations or just for yourself to try to put on paper ideas as you progress through the work in order to then, like, understand the work better.
Speaker C: For me, I always try not to underestimate how much you can forget within six months after you've read something.
Speaker A: Oh, I thought you were going to say five minutes, but, yeah, six months is good. Yeah.
Speaker C: Or even shorter. And so that's something that I always try to keep in mind. And it's often, I mean, every once in a while, I'll read back a paper that I annotated on Fermat, I'll read through my own annotations. And it's. And I've completely forgotten what I had written. But it's interesting because in a way, after you just understood something, you're kind of the best possible teacher that can teach your future self after you've forgotten it. You're kind of your own best possible teacher at that moment. And so it can be great to, to try to capture that.
Speaker A: It's brilliant. You just made me kind of realize it's really nice to put yourself in the position of teaching an older version of yourself that returns to this paper, almost like thinking literally, that's under explored.
Speaker B: But it's super powerful because you were the person that if you look at the scale from one, not knowing anything about the topic and tend like you are the one that progressed from one to ten and you know, which steps you struggled with. So you're really the best person to help yourself make that transition from one to ten. And a lot of the times, like, I really believe that the framework that we have to like expose ourselves to like be talking to like us when we were an expert, when we were taking that class and we knew everything about quantum mechanics, and then six months later you don't remember half of the things. How could we make it easier for tweak? Have those conversations between you and your past expert self? I think there might be. It's an underexplored idea. I think notes on paper are probably not the best way. I'm not sure if it's a combination of video audio, where you have a guided framework that you follow to extract information from yourself so that you can later kind of revisit to make it easier to remember. But that's. I think it's an interesting idea worth exploring that not. I've. I haven't seen a lot of people kind of trying to distill that problem.
Speaker A: Yeah, I'm creating the kind of tools I find. If I record, it sounds weird, but I'll take notes. But if I record audio, like little clips of thoughts like rants, that's really effective at capturing something that notes can't, because when I replay them, for some reason it loads my brain back into where I was when I was reading that in a way that notes don't like, when I read notes, I'll often be like, what, what was I, what was I thinking there? But when I listened to the audio. Yeah, it brings you right back to that place. So there might. And maybe with video, with visual, that might be even more powerful.
Speaker B: I think so, yeah.
Speaker C: And I think just the process of, you know, verbalizing it.
Speaker A: Yes.
Speaker C: That alone kind of makes you have to structure your thought and put it in a way that somebody else could come and understand it. And just the process of that is useful to organize your thoughts and. Yeah, just, just that alone.
Speaker A: Does the FAMAs Library Journal club have a video component or.
Speaker C: No, not natively. We sometimes will include videos, but it's always embedded.
Speaker A: Do people build videos on top of it to explain the paper? Because you're doing all the hard work of understanding deeply the paper, we haven't.
Speaker B: Seen that happening too much, but we were actually playing around with the idea of creating some sort of podcast version where we try to distill the paper on an audio format that not. Maybe you could have access might be trickier, but there are definitely people that could be interested in the paper and that topic, but are not willing to read it. But they might listen to a 30 minutes episode on that paper. Yes, you could reach more people and you might even bring the authors to the conversation, but it's tricky, especially for like, more technical papers. We've thought about doing that, but we haven't, like converge, if you have any.
Speaker A: I'm going to take that as a small project, to take one of your, one of the formats, almost like half advertisement and half as a challenge for myself to take one of the annotated papers and like use it as a basis for creating a quick video. I've seen, like, hopefully I'm saying the name correctly, but machine learning, street talk, I think that's the name of the show. The, that I recommend highly. That's the right thing. But they, they do exactly that, which is multiple hour breakdown of a paper with video component, sometimes with authors. People love it. It's very effective.
Speaker B: There's, there's also, I've seen, I haven't seen the entire in its entirety, but I've seen like the, the founder of Comma AI, George. Yeah, I've seen him like just taking a paper and then I, you know, distilling the paper and coding it sometimes during 10 hours. And he was able to get a lot of people interested in that and viewing him.
Speaker A: So I'm a huge fan of that. Like, George is a personality. I think a lot of people, like, listen to this podcast for the same reason. It's not necessarily the contents. They like to listen to a silly Russian who has a childlike brain and mumbles and all those like, struggle with ideas, right? And George is a madman who people just enjoy. Like, how is he going to struggle in implementing this particular paper? How is he going to struggle with this idea? It's fun to watch, and that actually pulls you in. The personality is important there.
Speaker B: True, but there's, you know, I agree with you, but they're also, it's visible. Like it's, there's an extraordinary ability that is there, like is talented and you need to have, there's a craft. And this guy definitely has talent and he's doing something that is not easy. And I think that also draws the attention of people.
Speaker A: Oh, yeah.
Speaker B: And like the other day we were actually, we ran into this YouTube channel of this guy that was restoring art, right? And it was basically just a video of him. Like, the production is really like really well done and it's just him taking really old pieces of art, like, and then paintings and then restoring them, but is really good at that. And he describes that process, and that draws attention, draws the attention of people, regardless of your craft, be it like annotating a paper or like restoring writers excellence.
Speaker A: Yeah. Like, George is incredibly good at programming. Like, quick, like, you know, those competitive programmers, like top coder and all those kinds of stuff. He has the same kind of element where the brain just jumps around really quickly, and that's, yeah, just like, it's more, yeah, it's motivating. But, but you're right in, in watching people who are good at what they do, it's motivating, even if the thing you're trying to do is not what they're doing, it's just, like, contagious when they're really good at it. And the same kind of analysis with the paper, I think so not just like the final result, but the process.
Speaker B: Yeah.
Speaker A: Struggling with it. That's really interesting.
Speaker C: Yeah, I think, I mean, I think twitch proved that, like, you know, that there's really a market for, for that, for watching people do things that they're really good at. And, and you will just watch it. You will enjoy that. That might even spike your interest in that specific topic and. Yeah, and people, people will enjoy watching sometimes hours on end of great craftsman.
Speaker A: Do you mind if we talk about some of the papers? Do any papers come to mind that have been annotated on Fermat's library?
Speaker C: The papers that we annotated can be about completely random topics, but that's part of what we enjoy as well. It forces you to explore these topics that otherwise maybe you'd never run into. And so the ones that come to mind, to me are fairly random, but one that I really enjoyed learning more about is a paper written by a mathematician, actually, Tom Apostol, and about a tunnel in greek island off the coast of Turkey.
Speaker A: I read this already.
Speaker C: It's random. Okay, so what's interesting about this tunnel? So this tunnel was built in the 6th century BC, and I, and it was built in the island of Samos, which is, as I said, off the coast of Turkey. And they had the city on one side, and they had a mountain, and then they had a bunch of springs on the other side, and they wanted to bring water into the city. Building an aqueduct would be pretty hard because of the way the mountain was shaped. And it would also, you know, if they, if they were under a siege, like, they could just easily destroy that aqueduct, and then the water wouldn't have any water supply, the city wouldn't have any water supply. And so they decided to build a tunnel and they decided to try to do it quickly. And so they started digging from both ends at the same time through the mountain.
Speaker B: Right.
Speaker C: And so, like, when you start thinking about this, it's, it's a fairly difficult problem. And this is like 6th century BC, so you had very limited access to, you know, the mathematical tools that you had at the time were very limited. And so what this paper is about is about the story of how they built it and about the fact that for about 2000 years, kind of the accepted, the accepted explanation of how they built it was actually wrong. And so this tunnel has been famous for a while. There are a number of historians that talked about it since ancient Egypt. And the method that they described for building it was just wrong. And so these researchers went there and were able to figure that out. And so basically, kind of the way that they thought they had built it was basically, if you can imagine looking at the mountain from the top and you have the mountain and then you have both entrances. And so what they, what they thought and what this is, what the ancient historians described is that they effectively tried to draw a right angle triangle with the two entrances at each end of the hypotenuse. And the way they did is like they would go around the mountain and kind of walking in a grid fashion. And then you can figure out the two sides of, of the triangle. And then after you have that triangle, you can effectively draw two smaller triangles at each entrance that are proportional to that big triangle. And then you kind of have arrows pointing in each way.
Speaker A: Got it.
Speaker C: And then, you know, at least that these, that you have a line going through the mountain that connects both entrances. The issue with that is like once you go to this mountain and you start thinking of doing this, you realize that, especially given that the tools that they had at the time, that your error margin would be too small, you wouldn't be able to do it. Just the fact of trying to build this triangle in that fashion, the error would accumulate and you would end up missing. You'd start building these tunnels and they would miss each other.
Speaker A: So the task ultimately is to figure out really perfectly, as close as possible the direction you should be digging. First of all, that it's possible to have a straight line through and then what that direction would be. And then you are trying to infer that by constructing a right triangle by doing. I'm not exactly sure about how to do that rigorously. Like by tracing the mountain. By walking along the mountain. How to. You said grids.
Speaker C: Yeah, you kind of walk as if you were in a, in a grid and so you just walk in right.
Speaker A: Angles, but then you have to walk really precisely then.
Speaker B: Exactly.
Speaker C: You have to use tools to measure.
Speaker A: This and then the terrain is probably.
Speaker C: Yeah, very mess.
Speaker A: So this makes more sense in 2D. In 3D gets even weirder. So. Okay, gotcha.
Speaker C: But so this method was described by like an ancient egyptian historian, I think hero of Alexandria. And then for about, like. Yeah, for about 2000 years, that's, that's how like, that's how we thought that they'd built this tunnel. And then these researchers went there and found out that actually they must have had to use other methods. And then in this paper they describe these other methods and of course they can't know for sure, but they presented a bunch of plausible alternatives. The one that for me is the most plausible is that what they probably must have done is to use something that is similar to an iron sight on a rifle, the way you can line up your rifle with a target off in the distance by having an iron sight. And they must have done something similar to that effectively with three sticks. And that way they were able to line up sticks along the side of the mountain that were all on the same height and so that then you could get to the other side and you could. And then you could draw that line. So this, for me is the most plausible way that they might have done that, but then they described this in detail and other possible approaches in this paper.
Speaker A: So this is a mathematician doing this?
Speaker C: Yeah, this is a mathematician that did.
Speaker A: This, which I suppose is the right mindset instead of skills required to solve an ancient problem, right?
Speaker B: Yeah, mathematicians and engineers, a lot of.
Speaker A: Things because they didn't have computers or drones or lidar back then or whatever technology you would use. Modern day for the civil engineering.
Speaker C: Yeah. Another fascinating thing is that, like, you know, after, effectively after the downfall of the roman civilization, people didn't build tunnels for about 1000 years. We go 1000 years without tunnels and then only in late middle ages that we start doing them again. But here is the tunnel, 6th century BC, incredibly limited mathematics, and they build it in this way. And it was a mystery for a long time exactly how they did it. And then these mathematicians went there and basically with no archaeology background were able to figure it out.
Speaker A: How do annotations for this paper look like? What's a successful annotation for paper like this?
Speaker B: Yes.
Speaker C: So sometimes you're for this paper, sometimes adding some more context on a specific part. Like sometimes they mentioned, for instance, these instruments that were common in ancient Greece and ancient Rome for building things. And so in some of those annotations, I described these instruments in more detail and how they worked, because sometimes it can be hard to visualize these. Then this paper, I forget exactly when this was published, I believe maybe the seventies, but then there was further research into this tunnel and other interesting aspects about it. I add those to that paper as well. There's historical context that I also go into there. For instance, the fact that, as I said, that effectively after the downfall of the roman empire, no tunnels were built. That's something that I added to the paper as well. Yeah.
Speaker A: So when other people look at the paper, how do they usually consume the annotations? It's like, is there a commenting feature? Is, I mean, like, this is a really enriching experience, the way you read a paper. What aspects do people usually talk about that they value from this?
Speaker C: So, yeah, so anybody can just go on there and either add a new annotation or add a comment to an existing annotation. And so you can start kind of a thread within an existing annotation. And that's something that happens relative frequency. And then because I was the original author of the initial annotation, I get pinged. And so oftentimes I'll go back and add on to that thread.
Speaker A: How'd you pick the paper? I mean, first of all, this whole process is really exciting. I'm going to, especially after this conversation, I'm going to make sure I participate much more actively on papers that I know a lot about and on paper I know nothing about.
Speaker B: I should bother annotate the paper.
Speaker A: I would love to. I also, I mean, I realized that there's a, like, it's an opportunity for people like me to publicly annotate a paper.
Speaker B: Like, or do an AMA around the paper.
Speaker A: Yeah, exactly. But, yeah, but like, be in the conversation about a paper. It's like a place to have a conversation about an idea. The other way to do it that's much more ad hoc is on Twitter. Right. But this is more like formal. And you could actually probably integrate the two. They have a conversation about the conversation. So the Twitter is the conversation about a conversation, and the main conversation is in this space of annotations.
Speaker B: There's an interesting effect that we see sometimes with the annotations on our papers is that a lot of people, especially if the annotations are really well done, people sometimes are afraid of adding more annotations because they see that as a kind of a finished work, and so they, they don't want to pollute that. Or, and especially if it's like a silly question, this is. I don't think that's good. I think, you know, we should, as much as possible, try to lower the barrier for someone to jump in and ask questions. I think it only, most of the times it adds value, but it's some feedback that we got from users and readers. Not exactly sure how to kind of fight that, but.
Speaker A: Well, I think if I serve as inspiration in any way is by asking a lot of dumb questions and saying a bunch of dumb shit all the time. And hopefully that inspires the rest of other folks to do the same, because that's the only way to knowledge, I think, is to be willing to ask the dumb questions.
Speaker B: And there are papers that are like, we have a lot of papers on Fermat's where it's just one page or really short papers, and we have, like, the shortest paper ever published in a math journal, like, with just a couple of words. One of my favorite papers on the platform is actually a paper written by Enrico Fermi. And the title of the paper is, I think it's my observations at Trinity. So basically, Fermi was part of the Manhattan project. So he was in New Mexico when they exploded the first atomic bomb. And so he was a couple of miles away from the explosion, and he was probably one of the first persons to calculate the energy of the explosion. And so the way he did that was he took a piece of paper and he tore down a piece of paper in little pieces. And when the bomb exploded, the Trinity bomb was the name of the bomb. Like, he waited for the blast to arrive at where he was, and then he threw those pieces of paper in the air, and he calculated the energy based on the displacement of the paper, the pieces of paper. And then he wrote a report, which was classified until, like, a couple of years ago, one page report, like, calculating the energy of the explosion.
Speaker A: That's so badass.
Speaker B: And we actually went there and kind of unpacked, and I think you just mentioned basically the energy, and we actually went. One of the annotations is like explaining how he did that.
Speaker A: I wonder how accurate he was.
Speaker B: It was maybe, I think, like 20 or 25% off. Then there was another person that actually calculated the energy based on images after the explosion at the rate and the rate at which the mushroom of the explosion expanded. And it's more accurate to calculate the energy based on that. And I think it was like 20, 20% off. But it's really interesting because Fermi was known for all these being a mass at these back of the envelope calculations. The Fermi problems are well known for that. And it's super interesting to see that just one page report. And it was also actually classified. And it's interesting because a couple months ago, when the Beirut explosion happened, there was a video circulating of a bride that was doing a photo shoot when the explosion in Beirut happened. And so you can see a video of her with the wedding dress, and then the explosion happens, and the blast arrives at where she was. She was a couple of miles away from the glass. And you can see, like, the displacement of the dress as well. And I actually looked, and that video went viral on Twitter. And I actually looked at that video. And based. I used the same techniques that Fermi used to calculate the energy of the explosion based on the displacement of the dress. And you could actually see where. Where she was at the distance from the explosion, because there was a store behind her, and you could look the name of the store. And so I calculated that it was the distance. And then you can, based on the distance where she was from the explosion and also on the displacement of the dress, because when the blast happens, you can see the dress going back and then going back to the original position. And by just looking at how much the dress moved, you can estimate the energy of the explosion.
Speaker A: I assume you published this on Twitter.
Speaker B: It was just a Twitter thread, but actually a lot of people share that, and it was picked up by a couple of news outlets.
Speaker A: But I was hoping it would be like a formal title and it would be an archive.
Speaker B: No, no, no. Maybe submitted just the Twitter. Twitter thread, but it was interesting because it was exactly the same method that Fermi used.
Speaker A: Is there something else that jumps to mind? Like what? Is there something. I know, like, in terms of papers. I know the bitcoin paper is super popular. Is there something interesting to be said about any of the white papers in the cryptocurrency space?
Speaker C: Yeah. The bitcoin paper was the first paper that we put on for months.
Speaker A: And why that choice as the first paper?
Speaker C: A while ago? And it was one of the papers that I read and then kind of explained it to Luigi and our two other friends that do this journal club with us. And I did some research in cryptography as an undergrad. And so it was a topic that I was interested in, but even for me, I had that background. But reading the bitcoin paper, it took me a few reads to really kind of wrap my head around it. It uses very spartan, precise language. In a way. It's like you feel like you can't take any word out of it without something falling apart, and it's all there. I think it's a beautiful paper, and it's very well written, of course, but we wanted to try to make it accessible so that anybody that maybe is an undergrad in computer science could go on there and know that you have all the information in that page that you're going to need to understand the mechanics of bitcoin. I explain the basic public key cryptography that you need to know in order to understand it. Explain what are the properties of a hash function and how they are useful in this context. Explain what a Merkle tree is. So a bunch of those basic concepts that maybe if you're reading it for the first time and you're an undergrad and you don't know those terms, you're going to be discouraged, because maybe now I have to go and Google around until I understand these before I can make progress in the paper. And this way it's all there. So there's a magic to also to the fact that over time, more people went on there and added further annotations. So the idea that the paper gets easier and more accessible over time, but you're still looking at the original content the way the author intended it to be. But there's just more context and the toughest bits, more in depth explanations.
Speaker B: Okay. I think, like, there's just so many interesting papers there. Like, I remember reading the paper that was written by Freeman Dyson on the, like, the, the first time that he explained, or he came up with the concept of the Dyson sphere, and he put that out like it's, again, it's one page paper. And what he explained was that eventually, if civilization develops and grows, there's going to be a point when the resources on the planet are not enough for the energy requirements of that civilization. So if you want to go, the next step is you need to go to the next star and extract energy from that star. And the way to do it is you need to build some sort of cap around the star that extracts the energy. So he theorized this idea of the, the Dyson sphere, and he went on to kind of analyze how he would build that, the stability of that sphere. Like, if something happens, if there's like a small oscillation with that fear collapse into the star, or no, what would happen? And even went on to kind of say that a good way for us to look for signs of intelligent life out there is to look for signals of these Dyson spheres. And because, you know, according to the law of second law of thermodynamics, like, there's going to be some. A lot of infrared radiation that is going to be emitted as a consequence of extracting energy from the star. And we should be able to see those signals of, like, infrared if we look at the sky. But all these, like, from the introduction of the concept, like the how to build a Dyson sphere, the problems of, like, having a Dyson sphere, how to detect how that could be used as a signal for intelligent life.
Speaker A: Wait, really? That's all in the paper?
Speaker B: All in one, like one page paper. And it's like, it's. For me, it's beautiful. It's like, where was this published? I don't remember.
Speaker A: It's fascinating that papers like that could be. I mean, the guts it takes to put that all together in a paper form, you know, that that kind of challenges our previous discussion of paper. I mean, papers can be beautiful. You can play with the format. Right.
Speaker B: But there's a lot to unpack there. That's like. That's the starting point. But it's beautiful that you're able to put that in one page and then people can build on top of that.
Speaker A: But the key ideas are there.
Speaker B: Yeah, exactly.
Speaker A: What about. Have you looked at any of the big seminal papers throughout the history of science? Like, you look at simple, like, Einstein papers, have any of those been annotated?
Speaker C: Yeah, yeah, no, we have some more seminal papers that people will have heard about. We have the DNA double Elex paper on there. We have the Higgs boson paper. Yeah. There's papers that we know that they're not going to be finding out about them because of us, but it's papers that we think should be more widely read and that folks would benefit from having some annotations there. So we also have a number of.
Speaker B: Those, a lot of discovery papers for fundamental particles and all that. We have a lot of those on from us. Library. I would like to. We haven't annotated that one, but I'd like to. On the Riemann hypotheses. That's a really interesting paper as well, but we haven't annotated that one. But there's a lot of more historical landmark papers on the platform.
Speaker A: Have you done pun correct conjecture with Perlman?
Speaker B: That's too much. That's too much for me. But it's interesting that, and going back to our discussion the Poincare paper was published on archive, and it was not on a journal like the three papers. And.
Speaker A: Yeah, what do you make of that? I mean, he's such a fascinating human being. Exactly. I mentioned to you offline that I'm going to Russia. He's somebody. I'm really trying to interview him. Yeah, well, so I definitely will interview him. And I believe I will. I believe I can. I just don't know how to. I know where he lives. So here. Okay. My hope is, my conjecture is that if I just show up to the house and look desperate enough or threatening enough, or some combination of both, that the only way to get rid of me is to just get the thing done. That's the hope.
Speaker B: It's actually interesting that you mentioned that, because after a couple of weeks ago, I was searching for stuff about Paramount online and ended up on this Twitter account of this guy that claims to be Perelman's assistant. And he has been posting a bunch of pictures next to Peruman. You can see Peramon in a library, and he's next to him taking a selfie or permanent walking on the street. And maybe you could reach out to this assistant, then I'll send you this Twitter account.
Speaker A: Maybe you're onto something.
Speaker B: No, but going back to permanent, it's super interesting, because the fact that he published the proofs on archive was also a way for him to. Because he really didn't like the scientific publishing industry. And the fact that you had to pay to get access to articles and that was a form of protest. And that's why he published those papers there. I mean, I think Perelman is just a fascinating character. And for me, it's this kind of ideal of platonic ideal of what a mathematician should be. It's someone that just cares about, deeply cares about mathematics. You know, it cares about fair attribution of disregards, money. And the fact that he published on archive is a good example.
Speaker A: What about the Fields medal? That he turned down the fields metal? What do you make of that?
Speaker B: Yeah, I mean, if you look at the reasons why he rejected the fields medal. So Paramond did a postdoc in the US, and when he came back to Russia, do you know how good his English is? I think it's fairly good.
Speaker A: I think it's pretty good.
Speaker B: I think it's really good, especially given.
Speaker C: Lectures in american universities.
Speaker B: But I haven't been able to listen to anything.
Speaker A: Well, certainly not listen, but I haven't been able to get anybody, because I know a lot of people have been to those lectures, I'm not able to get a sense of like, yeah, but how strong is the accent? What are we talking about here? Is this going to have to be in Russian? Is it going to have to be in English? It's fascinating, but he writes the papers.
Speaker B: In English, so, like, there's, there's, but there's so many, like, such a fascinating character and there are a couple of examples like him. Like at, I think, 28 or 29, he proved like a really famous conjecture called the solk conjecture. I believe it was like in a very short four page proof of that. It was a really big breakthrough. Then he went to Princeton to give a lecture on that. And after the lecture, the chair of the math department at Princeton, a guy called Peter Sarnock, went up to Perilman, was trying to recruit him, trying to offer him a position at Princeton. And at some point he asked for Perelman's resume. And Perelman responded saying, just gave a lecture on like this really tough problem. Why do you need my resume? I'm not going to send you. I just proved my value. But going back to the Fields medal, when Perelman went back to Russia, he arrived at a time where the salary of postdocs was so much off in regards to inflation that they were not making any money. People didn't even bother to pick up the checks at the end of the month because they were just ridiculous. But thankfully, he had some money that he had gained while he was doing his postdoc. So he just concentrated on the Poincare conjecture problem, which when he took that, he took it after it was reframed by this mathematician called Richard, Richard Hamilton, which posed the problem in a way that it turned into this super math Olympiad problem with perfect boundaries, well defined, and that was perfect for Perilman to attack. And so he spent like seven years working on that. And then in 2002, he started publishing those papers on archive, and people started jumping on that, reading those papers. And there was a lot of excitement around that. A couple of years later, there were two researchers, I believe they were from Harvard, that took Perelman's work. They sanded some of the edges and they republished that, saying that based on Perelman's work, they were able to figure out the Poincare conjecture. And then there was at the time, at the International Conference of Mathematics in 2011, 2006, I believe that's when they were going to give out the Fields medal. There was a lot of debate of like, oh, we should get the credit for solving this big problem. And for Perilman, it felt really sad that people were even considering that he was not the person that solved that. And the claims that those researchers, when they published after Paramount, they were false claims that they were the ones, they just sended a couple of edges. Perelman did all the really hard work. And so just the fact that they doubted that Peramon had done that was enough for him to say, I'm not interested in this price. And that was one of the reasons why he rejected the fields metal. He also rejected the clay prize. So the poncare conjecture was one of the millennium prices. There was a million dollar prize associated with that problem. And that had to do with the fact that for them to attribute that prize, I think it had to be published on a journal. Yes, the proof. And again, Perelman's principles of, like, interfered here, and he also just didn't care about the money. He's like, Clay, I think, was a businessman, and he's like, doesn't have to do anything with mathematics. I don't care about this. That's one of the reasons why I rejected.
Speaker A: Yeah, it's hard to convert into words, but at MIT, I'm distinctly aware of the distinction between, when I enter a room, there's a certain kind of music to the way people talk when we're talking about ideas, versus what that music sounds like when we're talking, when it's, like, bickering in the space of, like, whether it's politics or funding or egos, it's a different sound to it. And I'm distinctly aware of the two. And I kind of sort of, to me personally, happiness. What was just, like, swimming around the one that, like, is the political stuff or the money stuff and all that, or egos. And I think that's probably what prominent is as well. Like, the moment he senses there's any. As with the fields metal, like, the moment you start to have any kind of drama around credit assignment, all those kinds of things, it's almost not that it's important who gets the credit. It's like the drama in itself gets in the way of the exploration of the ideas or the fundamental thing that makes science so damn beautiful.
Speaker B: And you can really see that this is also a product of that russian school of, like, doing science. And you can see that. That people were, during the cold war, a lot of mathematicians, they were not making any money. They were doing math for the sake of math, like, for the intellectual pleasure of, like, solving a difficult problem.
Speaker A: Yeah.
Speaker B: And, you know, even. Even if it was a flawed system and there were a lot of problems with that, there's these, they were able to actually achieve this and there were a lot of imperilment for me, is the perfect product of that. He just cared about, like working on tough problems. He didn't care about anything else. It was just meth, you know, pure math.
Speaker A: Yeah, there's a, like, for the broader audience. I think another example of that is like professional sports versus Olympics. I've, especially in Russia, I've seen that clear distinction where because the state manages so much of the Olympic process in Russia, as people know, with the steroids. Yes, yes, yes. But outside of the steroids thing is like the athlete can focus on the pure artistry of the sport. Like, like not worry about the money, not just in the way they talk about it, the way they think about it, the way they define excellence versus, like in the, perhaps a bit of a capitalist system in United States with american football, with baseball, with basketball. So much of the discussion is about money. Now, of course, at the end of the day, it's about excellence and artistry and all that. But when the culture is so richly grounded in discussions of money and sort of this capitalistic, like merch and businesses and all those kinds of things, it changes the nature of the activity in a way that's hard again, to describe in words. But when it's a purely about the activity itself, it's almost like you quiet down all the noise, enough to hear the signal, enough to hear the beauty. Like whenever you're talking about the money, that's when the marketing people come and the business people, the non creators come and they fill the room and there's, they create drama and they know how to create the drama and the noise, as opposed to the people who are truly excellent at what they do, the person in their arena. Right? Like when you remove all the money and you just let that thing shine, that's when true excellence can come out. And that was, of the few things that worked with the communist system, the Soviet Union, to me at least, as somebody who loves sport and loves mathematics and science, that worked well removing the money from the picture. You know, not that I'm not that I'm saying poverty is good for science. There's some level in which not worrying about money is good for science. It's a weird, I'm not exactly sure what to make of that because capitalism works really damn well. But it's tricky how to find that balance.
Speaker C: One, one fields medalist that is interesting to look at, and I think you mentioned it earlier, but is Cedric Villany, which might be the only fields medalist that is also a politician now. But so it's this, it's this brilliant french mathematician that won the Fields medal. And after that, he decided that one of the ways that he could have, could have the biggest leverage, kind of, is in pushing science in the direction that he thinks science should go, would be to try to go into politics. And so that's what he did. And he has ran, I'm not sure if he has won any election.
Speaker B: I think he's running for mayor, for.
Speaker C: Mayor of Paris or something like that. But it's this brilliant mathematician that before winning the Fields medal, had only been just a brilliant mathematician. But after that, he decided to go into politics to try to have an impact and try to change some of the things that he would complain about before. So there's that component as well.
Speaker A: Yeah. And I've always thought mathematics and science should be like James Bond would, in my eyes, I think, be sexier if he did math like we should, as a society, put excellence in mathematics at the same level as being able to kill a man with your bare hands. Like, those are both useful features. Like, that's admirable. It's like, oh, like, that makes you, like, that makes the person interesting. Like, being extremely well read about history or philosophy, being good in mathematics, being able to kill a man with a bare hands, those are all the same in my book. So I think all are useful for action stars, and I think a society will benefit for giving more value to that. Like, one of the things that bothers me about american culture is the. I don't know the right words to use, but, like, the nerdiness associated with science. I don't think nerd is a good word in american culture because it's seen as weakness. There's images that come with that, and it's fine, you could be all kinds of shapes and colors and personalities, but, like, to me, having sophisticated knowledge and science being good at math doesn't mean you're weak. In fact, it could be the very opposite. And so, it's an interesting thing because it was very much differently viewed in the Soviet Union. So I know for sure as an existence proof that it doesn't have to be that way. But it.
Speaker B: I also feel like we lack a lot of role models in terms, if you ask people to mention one mathematician that they know that is alive today, I think a lot of people would struggle to answer that question.
Speaker A: And I also think I love Neil degrasse Tyson. Okay. But there is. Having more role models is good. Like different kinds of personalities. He. He has kind of fun, and. And it's very. It's a. Like, Bill Nye, the science guy, I don't know if you guys know him. So, like, that spectrum that. Yeah, but there. There's not, like, Feynman is no longer there. Those kinds of personality. Even Carl Sagan? Yeah, like, a seriousness that's, like, not.
Speaker B: Playful, like, not apologetical.
Speaker A: Yeah, exactly. Not apologetic about being knowledgeable. Like. Like, in fact, like the kind of energy where you feel self conscious about not having thought about some of these questions. Right. Just like, when I see James Bond, I feel bad about that. I don't have never killed a man. Like, I need to make sure I fix that right. That's the way I feel the same way. I want to feel like that way with Carl Sagan talks. I feel like I need to have that same kind of seriousness about science. Like, if I don't know something, I want to know it. Well, what about Terrence Tao? He's kind of a superstar. What are your thoughts about him, Drew?
Speaker B: He's probably one of the most famous mathematicians alive today, and probably, I mean, regardless of, like, is, of course, one fields metal is really smart and talented mathematician. It's also, like, a big inspiration for us, at least for some of the work that we do with Fermat's library. So Terence Stau is known for having a big blog, and he's pretty open about his research, and also he tries to make his work as public as possible through his blog posts. In fact, there's a really interesting problem that got solved a couple of years ago. So Tao was working on a problem, on an airdosh problem, actually. So Paul Erdos was this mathematician from Hungary, and he was known for, like, the airdosh for a lot of things. But one of the things that he was also known was for the air dosh problems. So he was always, like, creating these problems and usually associating prizes with those problems. And a lot of those problems are still open, like, and some of them will be open for, like, maybe a couple hundred years. And I think that's actually an interesting hack for him to collaborate with future mathematicians. His name will keep coming up for future generations. But so Tao was working on one of these problems called the Air Dodge discrepancy, and he published a blog post on, like, about that problem, and he reached, like, a dead end. And then all of a sudden, there was this guy from Germany that wrote a comment on his blog post saying, okay, so this problem is like a sudoku flavor and some of the machinery that we're using to solve Sudoku. Sudoku could be used here. And that was actually the key to solve the airdo discrepancy problem. So there was a comment on his blog, and I think that, for me, is an example of how to do, again, going back to collaborative science online and the power that it has. But Tawi is also pretty public about some of the struggles of being a mathematician. And even he wrote about some of the unintended consequences of having extraordinary ability in a field. And he used himself as an example. When he was growing up, he was extremely talented in mathematics from a young age. Like, Tao was a person. He won a medal in, like, one of the IMO's at the age I think was a gold medal at the age of ten or something like that. And so he mentioned that when he was growing up, like, and especially in college, when he was in a class that he enjoyed, it didn't. It just came very natural for him and he didn't have to work hard to just ace the class. And when he found that the class was boring to, like, it didn't work. And he barely passed. Barely passed. I think in college, he almost fell two classes. And he was talking about that and how he brought those studying habits, or like, in existence of studying habits when he went to Princeton for his PhD, and in Princeton, when he started kind of delving into more complex problems in classes, he struggled a lot because he didn't have those habits. Like, he wasn't taking notes and he was. He wasn't studying hard when he. When he faced problems and he almost failed out of his PhD. He almost failed his PhD exam. And it talks about, like, having this conversation with his advisor and the advisor pointing out, like, you're not. This is not working. You might have to get out of the program. And, like, how that was kind of a turning point for him and, like, it was super important in his career. So I think Tao is also, like this figure that, apart from being just an exceptional mathematician, is also pretty open about what it takes to be a mathematician and some of the struggles of these type of careers. And I think that's super important in many ways.
Speaker A: He's a contributor to open science and open humanity. He's being an open human, true. By communicating. Scott Aronson is another in computer science world who's very different style. Very different style. There's something about a blog that is authentic and real and just gives us a window into the mind and soul of these brilliant folks. So it's definitely a gift. Let me ask you about Fermat's library on Twitter, which, I mean, I don't know how to describe it. People should definitely just follow Fermat's library on Twitter. I keep following and unfollowing for my library because it's so it gives, when I follow, it leads me down rabbit holes often that are very fruitful but time consuming. But anyway, so the posts you do on Twitter are just these beautiful, are things that reveal some beautiful aspects of mathematics. Is there, is there something you could say about the approach there? And maybe broadly what you find beautiful about mathematics and then more specifically, how you convert that into a rigorous process of revealing that in tweet form?
Speaker B: That's a good point. I think there's something about math that a lot of the mathematical content and papers are like little proofs, has, in a way, sort of an infinite half life. What I mean by that is that if you look at, like, Euclid's elements, it's as valid today as it was when it was created, like 2000 years ago. And that's not true for a lot of other scientific fields. And so in regards to Twitter, I think there's also a very. It's a very underexplored platform from a learning perspective. I think if you look at content on Twitter, it's very easy to consume, it's very easy to read, and especially when you're trying to explain something. We humans get a dopamine hit if we learn something new. And that's a very, very powerful feeling. And that's why people go to classes when you have a really good professor looking for those dopamine hits. And that's something that we try to explore when we're producing content on Twitter. Imagine if you would on a line to a restaurant, you could go to your phone to learn something new instead of going to a social network. And I think it's very hard sometimes to provide that feeling because you need to sometimes digest content and put it in a way that it feeds 280 characters. And it requires a lot of sometimes time to do that. Even though it's easy to consume, it's hard to make. But once you are able to provide that eureka moment to people, that's very powerful. They get that dopamine hit and you create this feedback cycle and people come back for more. And in Twitter, compared to, like, you know, an online course or a book, you have a 0% dropout. So people will read the content, the content. So that it's like, it's part of the creators, like, the person that is creating the content. If you're able to actually get that feedback cycle, it's super, super powerful.
Speaker A: Yeah, but some of this stuff is like, how the heck do you find that? And I don't know why it's so appealing. This is from. What is it a couple days ago? I'll just read out the number. 2345-6789 is the largest prime number with consecutive increasing digits. I mean, that is so cool. That's like some weird, like, glimpse into some deep, universal truth, even though it's just the number. I mean, that's, like, so arbitrary. Like, why? Why is it so pleasant that that's a thing? But it is in some way. It's almost like it is a little glimpse at some much bigger, like, and.
Speaker B: I think, especially if we're talking about science, there's something unique about you go, and with a lot of the tweets, you go sometimes from a state of not knowing something to knowing something. And that is very particular to science, math, physics. And that, again, is extremely addictive. And that's how I feel about that. And that's why I think people engage so much with our tweets and go into rabbit holes, and then they start with prime numbers, and all of a sudden, you are spending hours reading number theory things, and you go into Wikipedia and you lose a lot of time there.
Speaker A: Well, the variety is really interesting, too. There's human things, there's physics things, there's numeric things, like I just mentioned. But there's also more rigorous mathematical things. There's stuff that's tied to the history of math and the proofs, and there's visual. There's animations that are looping animations that are incredible, that reveal something. There's Andrew Wiles on being smart. This is just me now. Like, ignoring you guys is just going through.
Speaker C: Yeah, we're a bit like math drug dealers. We're just trying to get you hooked. We're trying to give you that hit and trying to get you hooked.
Speaker A: Yes, some people are brighter than others, but I really believe that most people can really get to quite a good level of mathematics if they're prepared to deal with these psychological issues of how to handle the situation of being stuck. Yeah, yeah, there's some truth to that.
Speaker B: That's truth, I feel that's like, really. It's some truth in terms of research and also about startups. You're stuck a lot of the time before you get to a breakthrough, and it's difficult to endure that process like, being stuck because you're not trained to be in that position, I feel. Yeah, that's.
Speaker A: Yeah, most people are broken by the stuckness or, like, they're destroyed. Like, I've been very cognizant of the fact that more and more social media becomes a thing. Like, distractions become a thing, that that moment of being stuck is your mind wants to go do stuff that's unrelated to being stuck, and you should be stuck. I'm referring to small stuck nesses. Like, you're, like, trying to design something and it's a dead end, basically. Little dead ends.
Speaker B: Mm hmm.
Speaker A: Dead ends of programming dead ends and trying to think through something. And then your mind wants to, like. Like. Like, this is the problem with this, like, work life balance. Culture is, like, take a break. Like, as if taking a break will solve everything. Sometimes it solves quite a bit, but, like, sometimes you need to sit in the stuckness and suffer a little bit and then take a break, but you definitely need to be. And, like, most people quit from that psychological battle of being stuck. And so success is people who persevere through that.
Speaker B: Yeah, yeah. And in the creative process, that's also true. I was, the other day, I was, I think, was reading about, what is his name? Ed Sheeran. Like, the musician was talking a little bit about the creative process and was using this analogy of a faucet, like, where when you turn on a faucet, it has, like, the dirty water coming out in the beginning, and you just have to, you know, keep trusting that at some point your clean, clean, clear water will come out, but you have to endure that process. Like, in the beginning, it's going to be dirty water and just, you know, embrace that.
Speaker A: Yeah, actually, this, the entirety of my YouTube channel and this podcast, I've been following that philosophy of dirty water. Like, I've been, you know, I do believe that, like, you have to get all the crap out of your system first. And sometimes it's all. Sometimes it's all crappy work. I tend to be very self critical, but I do think that quantity leads to quality. For some people, it does for my, the way my mind works is, like, just keep putting stuff out there, keep creating, and the quality will come as opposed to sitting there waiting, not doing anything until the thing seems perfect, because.
Speaker B: The perfect may never come, but just on our Twitter profile, and sometimes when you look on some of those tweets, they might seem like, pretty. Why is this interesting? It's so raw. It's just a number. But I really believe that especially with math or physics, it is possible to get everyone to love math or physics. Even if you think you hate it. It's not a function of the student or the person that is on the other side. I think it's just purely a function of how you explain hidden beauty that they hadn't realized before. It's not easy, but I think it's like a lot of the times it's on the creator side to be able to show that beauty to the other person.
Speaker C: I think some of that is native to humans. We just have that curiosity. And you look at small toddlers and babies and them trying to figure things out, and there's just something that is born with us that we, we want for that understanding. We want to figure out the world around us. And so, yeah, it shouldn't be like whether or not people are going to enjoy it. I also really believe that everybody has that capacity to fall in love with math and physics.
Speaker A: You mentioned startup. What do you think it takes to build a successful startup?
Speaker C: That it's what, what Louise was saying, that you need to be able to endure being stuck. And I think the best way to put it is that startups don't have a linear reward function. You oftentimes don't get rewarded for effort. In most of our lives, we go through these processes that do give you those small rewards for effort. In school. You study hard, generally you'll get a good grade and then you get like good grades, or you get grades every semester. And so you're slowly getting rewarded and pushed in the right direction for startups. And startups are not the only thing that is like this, but for startups, it's, you can put in a ton of effort into something and then get no reward for it.
Speaker B: Right?
Speaker C: It's like Sisyphus Boulder, where you're pushing that boulder up the mountainous and you get to the top and then it just rolls all the way back down. And so that's something that I think a lot of people are not equipped to deal with and can be incredibly demoralizing, especially if that happens more than a few times. But I think it's absolutely essential to power through it, because by the nature of startups, it's oftentimes you're dealing with, with non obvious ideas and things that might be contrarian. And so you're going to run into that a lot. You're going to do things that are not going to work out and you need to be prepared to deal with that. But we're not coming out of college. You're just not equipped.
Speaker B: I'm not sure if there's a way to train people to deal with those nonlinear reward functions, but it's definitely, I think, one of the most difficult things to about doing a startup and also happens in research. Sometimes we're talking about the default studies being stuck. You just try things, you get zero results, you close doors, you constantly closing doors until you find something. And that is a big thing.
Speaker A: What about this point when you're stuck, there's a decision whether if you have a vision to persist through with this direction that you've been going along, or what a lot of startups do or businesses is pivot. How do you decide whether like to give up on a particular flavor of the way you've imagined the design and to like adjust it or completely like alter it?
Speaker C: I think that's a core question for startups that I've asked of myself. Exactly. And like, I've never been able to come up with a great framework to make those decisions. I think that's really at the core of, yeah, out of a lot of the toughest questions that people that started a company have to deal with, I.
Speaker B: Think maybe the best framework that I was able to figure out is like when you run out of ideas, you just, you know, you're exploring something is not working, you try in a different angle, you know, you try a different business model. When you run out of ideas, like you don't have any more cards, just switch and yeah, it's not perfect because you have a lot of stories of startups is like people kept pushing and then, you know, that paid off and then you have philosophies is like fail fast and pivot fast. So it's, you know, it's hard to, you know, balance these two worlds and understand what is the best framework.
Speaker A: And I mean if you look at from Miles library, you're maybe you can correct me, but it feels like you're operating in a space where there's a lot of things that are broken and, or could be significantly improved. So it feels like there's a lot of possibilities for pivoting or like how do you revolutionize science, how do you revolutionize the aggregation, the annotation, the commenting, the community around information knowledge, structured knowledge? I mean that's kind of what like stack overflow and stack exchange has struggled with to come up with a solution. And they've come up, I think, with an interesting set of solutions that are also, I think, flawed in some ways, but they're much, much better than the alternatives. But there's a lot of other possibilities. If we just look at papers as we talked about, there's so many possible revolutions and there a lot of money to be potentially made in those revolutions. Plus, coupled with that, the benefit to humanity. And so like, you're sitting there like, I don't know how many people are legitimately, from a business perspective, playing with these ideas. It feels like there's a lot of ideas here.
Speaker B: True, there is.
Speaker A: Are you right now grinding in a particular direction? Like, is there like a five year vision that you're thinking in your mind?
Speaker C: For us, it's more like a 20 year vision in the sense that we've consciously tried to make the decision of. So we run. Fermat says it's a side project and it's a separate in the sense, like, it's not what we're working on full time, but our thesis there is that we actually think that's a good thing, at least for this stage of Vermont's library. And also because some of these projects, if you're coming from a startup framework, you probably try to fit every single idea into something that can change the world within three to five years. And there's just some problems that take longer than that. We were talking about archive, and I'm very doubtful that you could grow like archive into what it is today within two or three years, no matter how much money you throw at it. There's just some things that can take longer, but you need to be able to power through the time that it takes. But if you look at it as, okay, this is a company, this is a startup, we have to grow fast, we have to raise money. Then sometimes you might forego those ideas because of that, because they don't have very well fit into the typical startup framework. For us, for Matz, it's something that we're okay with having it grow slowly and maybe taking many years. And that's why we think it's not a bad thing that it is a side project, because it makes it much more acceptable in a way to be able to be okay with that.
Speaker A: That said, I think what happens is if you keep pushing new little features, new little ideas, I feel like there's like certain ideas will just become viral and then you just won't be able to help yourself, but it'll revolutionize things. It feels like there needs to be not needs to be, but there's opportunity for viral ideas to change science.
Speaker C: Absolutely.
Speaker A: And maybe we don't know what those are yet. It might be a very small kind of thing.
Speaker B: Maybe you don't even know if. Should this be a for profit company doing this?
Speaker A: That's the Wikipedia question.
Speaker B: Yeah. There are a lot of questions, like really fundamental questions about this space that we've talked about.
Speaker C: I mean, you take Wikipedia and you try to run it as a startup, and by now it has a paywall. You'd be paying $9.99 a month to read more than 20 articles.
Speaker A: That's one view.
Speaker C: Yeah.
Speaker A: The other, the ad driven model. So they rejected the ad driven model. I don't know if we could. I mean, this is a difficult question. You know, if archive was supported by ads, I don't know if that's bad for archive. If Fermat's library was supported by ads. I don't know. I don't. I'm not. It's not trivial to me. I'm unlike, I think a lot of people, I'm not against advertisements. I think ads, when done well, are really good. I think the problem with Facebook and all the social networks are the way the lack of transparency around the way they use data and the lack of control the users have over their data, not the fact that data is being collected and used to sell advertisements. It's a lack of transparency, lack of control. If you do a good job of that, I feel like it's really nice way to make stuff free.
Speaker C: It's like stack overflow, right? Yeah. I think they've done a good job with that, even though, as we said, like, they're capturing very little of the value that they're putting out there. Right. But it makes it a sustainable company and they're providing a lot of. It's a fantastic and very productive community.
Speaker A: Let me ask a ridiculous tangent of a question, Louise. You wrote a paper on Game of Thrones, Battle of Winterfell, just as a side little. I'm sorry. Noticed. I'm sure you've done a lot of ridiculous stuff like this. I just noticed that particular one. By ridiculous, I mean ridiculously awesome. Can you describe the approach in this work, which I believe is a legitimate publication?
Speaker B: So going back to the original, like, when we were talking about the backstory of papers and the importance of that. So this is actually, you know, this was when the last season of the show was airing. This was a. During a company lunch. In the last season, there's a really big battle against the forces of evil and the forces of good. And this is called the Battle of Winterfell. And in this battle there are these two armies and there's a very particular thing that they have to take into account is that in the army of dead, if someone dies in the army of the living, like, that person is gonna, you know, be reborn as a soldier in the army of the dead. And so that was an important thing to take into account.
Speaker A: And the initial conditions, as you specified, it's about 100,000 on each side.
Speaker B: Exactly. So I was able to, like, based on some images, like on previous episodes, to figure out what was the size of the armies. And so what I want, what we wanted to, what we were theorizing was, like, how many soldiers does, like, a soldier on the army of the living has to kill in order for them to be able to destroy the army of the dead without, like, losing? Because every time one of the good soldiers dies, gonna turn into, like, the other side. And so it's. So we were theorizing that, and I wrote a couple of differential equations, and I was able to figure out that, based on the size of the armies, I think was the ratio had to be, like, 1.7. So it had to kill, like, 1.7 soldiers of, like, the army of the dead in order for them to win the battle.
Speaker A: Well, yeah, that's. That's science. It is. It's. It's most powerful. And this is also somehow a pitch for, like, a hiring pitch, in a sense. Like, this is the kind of important science you do at life.
Speaker B: Exactly. Well, turned out to be, you know, as is for people that have watched these shows, is like, they know that every time you try to predict something that is going to happen, you're going to fail miserably. And that's what happened. So it was not at all important for the show, but we ended up putting that out, and there was a lot of people that shared it, I think, with some elements of the show, the cast of the show that actually retweeted that and shared that. It was fun.
Speaker A: I would love if this kind of calculation happened during the making of the show, or, you know, I love it. Like, in, for example, I now know Alex Garland, the director of Ex Machina, and I love it. And he doesn't seem to be some. Not many people seem to do this, but I love it when directors and people who wrote the story really think through the technical details, like, whether it's knowing, like, how things, even if it's science fiction, if you were to try to do this, how would you do this? Like, Stephen Wolfram and his son were collaborating with the movie arrival in designing the alien language of how you communicate with aliens. Like, how would you really have a math based language that could span the alien and being and the human being. So I love it when they have that kind of rigor.
Speaker B: The Martian was also big on that. Like, the book in the movie was all about, like, can we actually, is this plausible? Can this happen? It was all about that.
Speaker C: And that can really bring you in, like, sometimes those small details. I mean, the guy that wrote the martian book is another book that is also filled with those, like, things that when you realize that, okay, these are grounded in science, can just really bring you in.
Speaker B: Yeah.
Speaker C: He has a book about a colony.
Speaker B: On the colony on the moon. And he goes about, like, all the details that would be required about setting up a colony in the moon and things that you wouldn't think about, like the fact that it's hard to bring air to the moon, so they wouldn't. How do you make that breathable, that environment breedable? You need to bring oxygen, but you probably wouldn't bring nitrogen. So what you do is instead of having an atmosphere that is 100% oxygen, you, like, decrease the pressure so that you have the same ratio of oxygen on earth, but lowering the pressure here. And so things like water boils at a lower temperature, so people would have coffee and the coffee would be colder. Like, there was a problem in this environment, in the moon. And these are small things in the book, but I studied physics, so when I read these, that throws me into, like, tangents. And I start researching that and it's like, I really like to read books and watch movies when they go to that level of detail about science.
Speaker C: Yeah, I think Interstellar was one where they also consulted heavily with. With a number of, I think even resulted in a couple of papers. A couple of papers about, like, the black hole visualizations and. Yeah, yeah. But there's, and there's even more examples of interesting science around, like these fantasy we were reading at some point, like these guys that were trying to figure out if the Tolkien's Middle earth, if it was round, if it was like.
Speaker B: A sphere based on the map.
Speaker C: Based on the map and some of the references in the books. And so, yeah, we actually, I think.
Speaker B: We tweeted about that.
Speaker C: Yeah, we did.
Speaker B: Based on the distance between the cities, you can actually prove that that could be like a map of a sphere or like a spheroid, and you can actually calculate the radius of that planet.
Speaker A: That's fascinating. I mean, yeah, that's fascinating. But there's something about calculating the number, like, exactly the calculation you did for the battle Winterfell is something fascinating about that, because that's not like being. That's very mathematical versus, like, grounded in physics. And that's really interesting. I mean, that's like injecting mathematics into fantasy. There's something I see magical about that.
Speaker B: And that, for me, that's why I think it's also, when you look at things like. Like Fermat's last theorem, like, problems that are very kind of self contained and simple to study, I think, like, that's the same with that paper. It's very easy to understand the boundaries of the problem, you know, and. And that, for me, that's why those. That's why math is so appealing. And those, like, problems are also so appealing to the general public. It's not that they look simple or that people think that they are easy to, like, solve, but I feel that a lot of the times, they are almost intellectually democratic because everyone understands the starting point. You know, you look at Fermat's last theorem, everyone understands, like, this is the universe of the problem. And the same, maybe with that paper, everyone understands, okay, these are the starting conditions. And, yeah, the fact that it becomes intellectually democrat, and I think that's a huge motivation for people, and that's why so many people gravitate towards these, like, Riemann hypotheses or Fermat's last theorem, or that simple paper, which is, like, just one page. It was very simple.
Speaker A: And I just talked to somebody. I don't know if you know who he is, Jocko Willink, who is this person who, among many things, loves military tactics? So he would probably either publish a follow on paper, maybe you guys should collaborate, but he would see the fundament, the basic assumptions that you started that paper with as flawed. Because, you know, there's, like, dragons, too, right? There's like. Like, you have to integrate tactics, because not. It's not. It's not a homogeneous system. It's not.
Speaker B: I don't take into account the dragons. And, like.
Speaker A: And he would say tactics fundamentally change the dynamics of the system. And so, like, that's what happened. So. Yeah, so, at least from a scientific perspective, he was right, but he never published, so there you go. Let me ask the most important question. You guys are from Portugal? Both Portugal. So who is the greatest soccer player, footballer of all time?
Speaker B: Yeah, I think we're a little bit biased on this topic, but, I mean, Maradona, I have a huge. I have a tremendous respect for what. Here we go.
Speaker C: We can convince you.
Speaker B: I have tremendous respect for what Ronaldo has achieved in his career. And I think soccer is one of those sports where I think you can get to maybe be one of the best players in the world if you just have, like, natural talent. And even if you don't put a lot of hard work and discipline into soccer, you can be one of the best players in the world. And I think Ronaldo is kind of like, of course he's naturally talented, but he also.
Speaker A: Keanu Ronaldo should say the football from.
Speaker B: Exactly. From Portugal and not the brazilian in this case. And so. And Ronaldo put, like, came from nothing. He is known from being probably one of the hardest working athletes in the game. And I see that sometimes a lot of these discussions about the best player, a lot of people tend to gravitate towards, like, you know, this person is naturally talented, and the other person has to work hard, and so. And so as if it was bad if he had to work hard to be good at something. And I think that, you know, I think so many people fall into that trap, and the reason why so many people fall into that trap is because if you're saying that someone is good and achieved a lot of success by working hard as opposed to achieving success because he has some sort of God given natural talent, that you can't explain why the person was born with that. What does it tell you about you? It tells you that maybe if you work hard on a lot of fields, you could have. Could accomplish a lot of great things. And I think that's hard to digest for a lot of people.
Speaker A: And in that way, Ronaldo is inspiring that, I think. So you find hard work aspiring, but he's way too good looking.
Speaker B: No, I like the part of the hard work of him being, like, one of the hardest working athletes in soccer.
Speaker A: So he is, to you, the greatest of all time. Is he up there? Is. He will be number. Okay. Do you agree with this?
Speaker C: Wholeheartedly disagree.
Speaker A: Well, I definitely disagree. I mean, I like him very much. He works hard. I admire, you know, like, he's an incredible goal scorer. Right. I. So, first of all, Leo Messi. And there was some confusion. Cause I've kept saying Maradona is my favorite player, but I think Leo has surpassed them. So it's Messi, then Maradona, then Pele for me. But the reason is, there's certain aesthetic definitions of beauty that I admire. Whether it came by hard work or through God given talent or through anything, it doesn't really matter to me. There's certain aesthetic, like, genius when I see it to me. And especially, it doesn't have to be consistent. It is in the case of Messi, in case in the Ronaldo. But just even moments of genius, which is where Maradona really shines.
Speaker B: Even if that doesn't translate into, like, results and goals being scored.
Speaker A: Right, right. And that's the challenge. I'm like, they did that. Because that's where people that tell me that Leo Messi has never, even on strong teams, have led the national team. People, as far as the World cup. Right. As really important. And to me, no, it's the moment, like, winning to me was never important. What's more important is the moments of genius. But you're talking to the human story and. Yeah, Christiano Ronaldo definitely has a beautiful human story.
Speaker B: Yeah. And I think you can't. For me, it's hard to decouple those two. I don't just look at, you know, the list of achievements, but I like how he got there and how he keeps pushing the boundaries at, like, almost 40.
Speaker A: Yeah.
Speaker B: And how that sets up an example. Like, maybe ten years ago, I wouldn't have ever imagined that, like, one of the top players in the world could be a top player at like, 37 or.
Speaker A: But so. And there's an interesting tent. The human story is really important. But, like, if you look at Ronaldo, he's like, he's somebody like kids could aspire to be. But at the same time, I also like Maradona, who, like, is a tragic figure in many ways. Like the, you know, the drugs, the temper, all of those things. That's beautiful, too. Like, I don't necessarily think, to me, the flaws, the flaws of are beautiful, too. In athletes, I don't think you need to be perfect. I agree. From a personality perspective, those flaws are also beautiful. But, yeah, there is something about hard work and there's also something about being an underdog and being able to carry a team. That's an argument from Maradona. I don't know if you can make that argument for Messi and Ronaldo either, because they've all played on superstar teams for most of their lives. So I don't know how, you know, it's difficult to know how they would do when they had to work, like, did what Maradona had to do to carry a team on his shoulders.
Speaker B: True.
Speaker A: And Pele did as well, depending on the context.
Speaker B: Maybe you could argue that with the portuguese national team. But we have a good team. Yeah, but maybe what Maradona did with Naples and a couple other teams, it's seemed incredible to the beauty of the.
Speaker C: Game that we're talking about all these different players that have, or especially if you're comparing Messi and Ronaldo that have such different styles of play and also even their bodies are so different, but these two very different players can be at the top of the game. And that's not, that's the, there are not a lot of other sports where you, where you have that, you know, like you have kind of a mental image of a basketball player and like, the top basketball players kind of fit that mental image and they look a certain way and, but for soccer, there's some, there's, it's, it's not so much like that. And that's, I think that's, that's beautiful, but that really adds something to the.
Speaker A: Sport of, well, do you play soccer yourself? Have you played that in your life? What do you find beautiful about the game?
Speaker B: Yeah, I mean, it's one of the, I'd say it's the biggest sport in Portugal. And so growing up, we played a lot.
Speaker A: Did you see the paper from DeepMind? I didn't look at it where they're, like, doing some analysis on soccer strategy.
Speaker C: Interesting. I saved that paper. I haven't read it yet. It's actually, when I was in college, I actually did some research on applying machine learning and statistics in sports. And in our case, we're doing it for basketball. But what they're effectively trying to do was, have you ever watched moneyball? So they're trying to do something similar, in this case, basketball, taking a statistical approach to basketball. The interesting thing there is that baseball is much more about having these discrete events that happen kind of in similar conditions. And so it's easier to take a statistical approach to it, whereas basketball, it's a much more dynamic game. It's harder to measure, it's hard to replicate these conditions. And so you have to think about it in a slightly different way. And so we were doing work on that and working, like with the Celtics to analyze the data that they had. Like they had these cameras in the arena, they were tracking the players, and so you, so they have, they had a ton of data, but they didn't really know what to do with it. And so we were doing work on that. And soccer is maybe an even a step further. It's a game where you don't have as many. In basketball, you have a lot of field goals and so you can measure success. Soccer, it's right, it's more of a Poisson process, almost, where it's like you have a goal, like, or two in a game.
Speaker A: In terms of metrics, I wonder if there's a way, and I've actually have thought about this in the past, never coming up with any good solution. If there's a way to definitively say whether it's messier or not, they're the greatest of all time. Like, honestly, sort of measure interesting. Like convert the game of soccer into metrics. Like you said, baseball. But like those moments of genius, like path, like, you know, if it's just about goals or passes that led to goals, that feels like it doesn't capture the genius of the play.
Speaker C: There'll be like, you know, like you kind of do you have more metrics, for instance, in chess, right. And you can try to understand how hard of a move that was. You know, there's like, Bobby Fischer has this move that, like that. It's, I think it's called the move of the century. Wherever you have to go so deep into the tree to understand that that was the right move and you can quantify how hard it was. So it'd be interesting to try to think of those type of metrics. But say, yeah, for soccer, computer vision.
Speaker A: Unlocks some of that for us. That's one possibility.
Speaker B: I have a cool idea, a computer vision product, Lex, that you could build for soccer.
Speaker C: Let's go.
Speaker A: I'm taking notes.
Speaker B: If you could detect the ball and imagine that it seems like, like totally doable right now, but like, if you could detect when the ball enters one of the goals and like, just had like, you know, a crowd cheering for you when you're playing soccer with your friends every time you score a goal, or you had like the Champions League song going on. Yeah, and like, having that, like, you go play soccer with your friends, just turn that on and there's like a computer vision, like, program analyzing. Detects the ball, detects the ball every time there's a goal. Like if you miss, like there's a, you know, the fans are reacting to, and then it should be pretty simple by now. It's like, I think there's an opportunity just throwing that.
Speaker A: I'm gonna go all out. By the way, I did, I've never released, I was thinking of just putting on GitHub, but I did write exactly that, which is the trackers for the players, for the, for the bodies of the player. Is this is the hard part, actually, the detection of player bodies and the ball is not hard. What's hard is very, like, robust tracking through time of each of those. So, like, so I wrote a tracker that's pretty damn good.
Speaker B: This is that open source. You open source.
Speaker A: I know. I've never released it. Interesting, because I felt like I need to. This is the perfection thing, because I knew it was going to be like, it's gonna pull me in. And it wasn't really that done. And so I've never actually been part of a GitHub project where it's like, really active development, and I didn't want to make it. I knew there's a non zero probability that will become my life for like a half a year, that just how much I love soccer and all those kinds of things. And ultimately it will be all for just the joy of analyzing the game, which I'm all for.
Speaker B: I remember you also, like, in one of the episodes, you mentioned that you did also a lot of eye tracking analysis on, like, Joe Rogan's.
Speaker A: That was the research side of my life.
Speaker B: Interesting. And you have that library, right? You kind of downloaded all the episodes?
Speaker A: Yep. Allegedly. Of course I didn't. If you're a lawyer and listening to this.
Speaker B: No, I was listening to the episode where you mentioned that, and I was actually, there was something that I might ask you for access to that, to allegedly that library. But I was doing some. Not regarding, like, eye tracking, but I was playing around with analyzing the distribution of silences on one of the Joe Rogan episodes. Like, I did that for the Elon conversation, where it's like you just take all the silences after Joe asks a question and Elon responded, and you plot that distribution and see how that looks like.
Speaker A: Yeah, I think there's a huge opportunity, especially long form podcasts, to do that kind of analysis. Bigger than Joe.
Speaker B: Exactly. It has to be a fairly unedited podcast so that you don't get the silence.
Speaker A: So one of the benefits I have, like, doing this podcast is like, what we're recording today is there's individual audio being recorded.
Speaker B: Makes it easier.
Speaker A: Like, I have the raw information when it's published, it's all combined together and individual video feeds. So even when you're listening, which I usually do, I only show one video stream, I'll know I can track your blinks and so on. But ultimately, the hope is you don't need that raw data, because if you don't need the raw data for whatever analysis you're doing, you can then do a huge number of pod. Cause there's so, it's quickly growing now. The number, especially comedians, there's quite a few comedians with long form podcasts, and they have a lot of facial expressions. They have a lot of fun and all those kinds of things. And it's prone for analysis.
Speaker B: There's so many interesting things. That idea actually sparked because I was watching a Q and a by Steve Jobs, and I think it was at MIT, and then people did a talk there, and then the Q and a started and people started asking questions. I was working while listening to it, and someone asked a question, and he goes on a 22nd silence. Before answering the question, I had to check if the video hadn't paused or something. And I was thinking about, like, if that is a feature of a person, like, how long, on average, you take to respond to a question, and if it's like, that's fascinating, has to do with how thoughtful you are, and if that changes over time.
Speaker A: But it also could be this really fascinating metric, because it also could be, it's certainly a feature of a person, but it's also a function of the question. Like, if you normalize to the person, you can probably infer a bunch of stuff about the question. So it's a nice flag. It's a really strong signal, the length of that sound relative to the usual silence they have. So one, the silence is a measure of how thoughtful they are, and two, the particular silence is a measure how.
Speaker B: Thoughtful the question was.
Speaker A: Thoughtful the question was. It's really interesting.
Speaker B: I mean, yeah, yeah, I just analyzed Elon's episode, but I think there's, like, room for exploration there.
Speaker C: I feel like the average for comedians would be like, I mean, the time would be so small because you're trained to, like, I would think, think you're reacting to Hitler. You're reacting to all sorts of things. You have to be, like, so quick.
Speaker A: Yeah, but some of the greatest comedians are very good at sitting in the silence. I mean, there's Lucy K. They play with that because you have a rhythm. Like Dave Chappelle, a comedian who did Joe's show recently, he has, especially when he's just having a conversation and he does long pauses. It's kind of cool. Cause it's one of the ways to have people hang in your word is to play with the pauses, to play with the silences and the emphasis. And, like, mid sentence, there's a bunch of different things that it'd be interesting to really analyze. But still, soccer, to me, is that one fascinating. I just want to. Conclusive, definitive statement about, because, like, there are so many soccer highlights of both Messi and Ronaldo, I just feel like the raw data is there in the.
Speaker C: Side.
Speaker A: Because you don't have that with Pillay. Mardona just. Yeah, true, but here's a huge amount of high dev data, then the annoying, the difficult thing. And this is really hard for tracking. And this is actually where I kind of gave up. Well, I didn't really give much effort, but I gave up to the way that highlights, or usually football match are filmed is they switch to camera so they'll do a different switch of perspective. So you have to. It's a really interesting computer vision problem. When the perspective is switched, you still have a lot of overlap about the players, but the perspective is sufficiently different that you have to recompute everything thing. So there's two ways to solve this. One is doing it the full way where you're constantly doing the slam problem, you're doing a 3d reconstruction the whole time, and projecting into that 3d world. But there could be some hacks that I wonder, some trick where you can hop, like when the perspective shifts, do a high probability tracking hops from one object to another. And I thought, especially in exciting moments when you're passing players, like you're doing a single ball dribble across players and you switch perspective, which is when they often do when you're making a run on goal. If you switch a perspective, it feels like that's going to be really tricky to get right automatically.
Speaker C: But in that case, for instance, I feel like if somebody released that data set, or it's like, like you just have all like these, this data set, a massive data set of all these games from say Ronaldo and Messi, like, and just, you just add that in like whatever CSV format and some publicly available dataset like that. I feel like people would just, there would be so many cool things that you could do with it and you just set it free and then like the world would like do its thing and then like interesting things would come out of it.
Speaker A: By the way, I have this data set. So the two things I did of this scale is soccer. So it's body pose and ball tracking for soccer, and then it's pupil tracking and blink tracking for it was Joe Rogan and a few other podcasts that I did. So those are the two data sets I have.
Speaker B: Do you analyze any of your podcasts?
Speaker A: No. I think I really started doing this podcast after, after doing that work, and it's difficult to. Maybe I'd be afraid of what I find. I'm already annoyed with my own voice and video, like editing it, but perhaps that's the honest thing to do, because one useful thing about doing computer vision about myself is like I know what I was thinking at the time. So you can start to connect the particular, the behavioral peculiarities of like the way you blink, the way you squint, the way you close your eyes. Like talking about details, there's, it's like, for example, I just closed my eyes. Is that a blink or no? Like, figuring that out in terms of timing, in terms of the blink dynamics is tricky. It's very doable. I think there's universal laws about what is a blink and what is a closed eye and all those things. Plus makeup and eyelashes. I actually have annoyingly long eyelashes. So I remember when I was doing a lot of this work, I would cut off my eyelashes, which when, like, especially it was funny, like female colleagues were like, what the fuck are you doing? Like, no, keep the eyelashes. But because it got in the way, made the computer vision a lot more difficult.
Speaker B: But super interesting topics.
Speaker C: Yeah, but speaking about the one, still on the topic of the datasets for sports, there's one paper and I actually annotated on Fermat and it was published in nineties. Nineties, I believe, nineties or eighties, I forget. But the researcher was effectively looking at the hot end phenomena in basketball, right? So whether like the fact that you just made a field goal, if you know, if on your next attempt, if you're more likely to make it or not. And it was super interesting because I mean, he pulled like I think 100 undergrads and I think from Stanford and Cornell and asking people like, do you think that's, that you have a higher likelihood of making your free throw if you just made one? And I think it's like 68, 68% said yes, they believe that. And then he looked at the data and this was back in, as I said, a few decades ago. And so I think he had the data set of about, he looked at it specifically for free throws and he had a data set of about 5000 free throws. And effectively what he found was that specifically in the case of free throws, he didn't, for the aggregate data, he didn't find that. He couldn't really spot that correlation, that hot and correlation. So if you made the first one, you weren't more likely to make the second one. What he did find was that they were just better at the second one because you just got like maybe a tiny practice and you just attempted once and then, and then you're going to be better at the next one. And then I went and there's a data set on Kaggle that has like 600,000 free throws and I reran the same computations and confirmed, like, you can see a very clear pattern that they're just better at their second free throw.
Speaker A: That's interesting, because I think there's similar. That kind of analysis is so awesome because I think with tennis, they have a fault. Like, when you serve, they have analysis of, like, are you more most likely to miss the second serve if you missed first? Obviously, I think that's the case. So that integrates. That's so cool. When psychology is converted into metrics in that way. And in sports, it's especially cool because it's such a constrained system that you can really study human psychology because it's repeated, it's constrained. So many things are controlled, which is something you rarely have in the wild psychological experiments. So it's cool. Plus, everyone loves it. Like, sports is really cool to analyze.
Speaker C: People actually care about the results.
Speaker A: Yeah, I still think, well, like, I. And I will definitely publish this work on Messi versus Ronaldo, and I'd love to read it. Objective. Fully objective.
Speaker B: I'd love to.
Speaker C: Peer review.
Speaker A: Yeah, this is very true. This is not past peer review. Let me ask sort of an advice question to young folks. You've explored a lot of fascinating ideas in your life. You built a startup, worked on physics, worked in computer science. What advice would you give to young people today in high school, maybe early college, about life, about career, about science and mathematics?
Speaker B: I remember, like, I read, like, I remember reading that Poncare was once asked by a french journal about his advice for young people and what was his teaching philosophy, and he said that, like, one of the most important things that parents should teach their kids is how to be enthusiastic in regards to, like, the mysteries of the world. And that he said, like, striking that balance was actually one of the most important things between, like, in education, you know, you want to have your kids be enthusiastic about the mysteries of the world, but you also don't want to traumatize them. Like, if you really force them into something. And I think, like, especially if you're young, I think you should be curious, and I think you should explore that curiosity to the fullest, to the point where you even become almost as an expert on that topic. And you might start with something that it's small. Like, you might start with you're interested in numbers and how to factor numbers into primes, and then all of a sudden, you go and you're lost in number theory, and you discover cryptography, and then all of a sudden, you're buying bitcoin. And I think you should really try to fulfill this curiosity and you should live in a society that allows you to fulfill this curiosity, which is also important. And I think you should do this not to get to some sort of status or fame or money, but I think this is the way, this iterative process, I think this is the way to find happiness, and I think this also allows you to find the meaning for your life. I think it's all about being curious and being able to fulfill that curiosity and that path to fulfilling your curiosity.
Speaker A: Yeah, the star small and let the fire build this kind of interesting way to think about it.
Speaker B: And you never know where you're going to end up. For Mars is just a really good example. We started by doing this as an internal thing that we did in the company, and then we started putting out there, and now a lot of people follow it and know about it, and.
Speaker A: You still don't know where from Mars library is going to end up, actually.
Speaker B: True. Exactly. Yeah, I think that would be my piece of advice, with very limited experience, of course, but.
Speaker C: Yeah, yeah, I agree. I agree.
Speaker A: I mean, is there something in particular, Joao, from the computer science versus physics perspective, do you regret not doing physics? Do you regret not doing computer science? Which one is the. The wiser, the better human being? This is Messi versus Ronaldo. Those are very. I don't know if you would agree, but they're kind of different disciplines.
Speaker B: True.
Speaker C: Yeah, very much so. I actually, I had that question in my mind. I took physics classes as an undergrad or like, besides what I had to take. And it's definitely something that I considered at some point.
Speaker B: And.
Speaker C: I do feel like later in life that might be something that I'm not sure if regret is the right word, but it's kind of something that I can imagine in an alternative universe, what would have happened if I gone into physics? I try to think that, well, it depends on what your path ends up being, but that it's not super important. Right. Like, exactly what you decide to major on. Like, I think there's, I think Tim Urban, like, the blogger, had a good visualization of this where it's like, you know, like he has a picture where you have all sorts of paths that he could pursue in your life, and then maybe you're in the middle of it. And so there's maybe some paths that are not accessible to you, but like, the tree that is still in front of you and gives you a lot of optionality. And so there's two lessons to learn from that.
Speaker A: Like, we have a huge number of options now. And probably you're just one to reflect, like, to try to derive wisdom from the one little path you've taken so far may be flawed because there's all these other paths you could have taken. So it's like. So one, it's inspiring that you can take any path now, and two, it's like the path you've taken so far is just one of many possible ones. But it does seem that, like, physics and computer science both open a lot of doors and a lot of different doors. It's very interesting.
Speaker B: It is like, in this case, especially in our case, because I could see the difference. I studied, I went to college in Europe and Joao went to college here in the US. So I could see the difference in, like, the european system is more rigid in the sense that when you decide to study physics, you don't have a lot, especially in the early years, you don't have a lot of. You can't choose to take, like, a class from, like, computer science course or something like that. Don't have a lot of freedom to explore in that sense in university, as opposed to here in the US, where you have more freedom. And I think that's important. I think that's what constitutes a good kind of educational system, is one that gravitates towards the interests of a student as you progress. But I think in order for you to do that, you need to explore different areas. And I felt like if I had a chance to take, say, more computer science class when I was in college, I would have probably have taken those classes, but I ended up focusing maybe too much in physics. And I think here, at least, my perception is that you can explore more fields.
Speaker A: But there is a kind of. It's funny, but physics can be difficult. So I don't see too many computer science people than exploring into physics. It's all like, the one. Not the one, but one of the beneficial things of physics. It feels like it. What was it, Rutherford that said, like, basically that physics is the hard thing and everything is easy. So, like, there's a certain sense, once you've figured out some basic, like, physics, that it's not that you need the tools of physics to understand the other disciplines, it's that you're empowered by having done difficult shit. I mean, the ultimate, I think, is probably mathematics there.
Speaker B: Yeah, true.
Speaker A: So maybe just doing difficult things and proving to yourself that you can do difficult things, whatever those are.
Speaker B: That's net positive, I believe.
Speaker A: Net positive, yeah.
Speaker B: And I think, like, I. Before I started company, I had, like, I worked in the financial sector for a bit and like, I think having a physics background, I was, I felt I was not afraid of like learning like finance things. And I think like, when you come from those backgrounds, you are generally not afraid of stepping into other fields and learning about those because, yeah, I feel they've learned a lot of difficult things and, yeah, that's an added benefit, I believe.
Speaker A: This was an incredible conversation. Luis, Joao, we started with, who do we start with? Feynman ended up with Messi and Ronaldo. So this is like the perfect conversation. It's really an honor that you guys would waste all this time with me today. It was really fun.
Speaker B: Thanks for, thank you so much for having us.
Speaker C: Yeah, thank you so much.
Speaker A: Thanks for listening to this conversation with Luis and Joabatala. And thank you to skiff simplisafe, indeed netsuite and four sigmatic. Check them out in the description to support this podcast. And now let me leave you with some words from Richard Feynman. Nobody ever figures out what life is all about and it doesn't matter. Explore the world. Nearly everything is really interesting if you go into it deeply enough. Thank you for listening. I hope to see you you next time you.
