{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws21tckHZ4Mk"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community llama-cpp-python transformers torch sentence-transformers faiss-gpu openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUwlLJa6Zn_H",
        "outputId": "047882ed-c0c7-4c36-aa37-a83b81dd718d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The main topic of the transcripts revolves around biological systems, regeneration, unconventional cognition, and the implications of these topics for understanding life and intelligence. The interviewer is Lex Fridman, and the interviewee is Michael Levin, a biologist.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.chat_models import ChatOpenAI\n",
        "import openai\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "openai.api_key = \"sk-mDDbQXk0nqPVUKjReeOIgiBoIyyjANlaXcERYJqyM6T3BlbkFJ5V6MdFRVmWcxIG2n0JyM1woTAUDps1dWqv6uYvnKsA\"\n",
        "\n",
        "transcript_file = \"/content/325-transcript.txt\"\n",
        "\n",
        "# 1. Load the document\n",
        "loader = TextLoader(transcript_file)\n",
        "documents = loader.load()\n",
        "\n",
        "# 2. Split texts\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 3. Create embeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# 4. Create FAISS vector store\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "# 5. Set up retriever\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "# 6. Set up OpenAI LLM\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",  # or \"gpt-3.5-turbo\" if you prefer\n",
        "    openai_api_key=openai.api_key\n",
        ")\n",
        "\n",
        "# 7. Create a prompt template\n",
        "template = \"\"\"\n",
        "You are an assistant that provides answers to questions based on\n",
        "a given context.\n",
        "\n",
        "Answer the question based on the context. If you can't answer the\n",
        "question, reply \"I don't know\".\n",
        "\n",
        "Be as concise as possible and go straight to the point.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# 8. Set up the output parser\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# 9. Combine the retriever, prompt, model, and parser into a chain\n",
        "chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever,\n",
        "        \"question\": itemgetter(\"question\"),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | parser\n",
        ")\n",
        "\n",
        "# 10. Query the system\n",
        "query = \"What is the main topic of the transcripts and who are the interviewer and the interviewee?\"\n",
        "result = chain.invoke({\"question\": query})\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
