Transcription for Jaron Lanier： Virtual Reality, Social Media & the Future of Humans and AI ｜ Lex Fridman Podcast #218.mp3:
Full transcript: The following is a conversation with Jaron Lanier, a computer scientist, visual artist, philosopher, writer, futurist, musician, and the founder of the field of virtual reality. To support this podcast, please check out our sponsors in the description. As a side note, you may know that Jaron is a staunch critic of social media platforms. Him and I agree on many aspects of this, except perhaps I am more optimistic about it being possible to build better platforms and better artificial intelligence systems that put long term interests and happiness of human beings. First, let me also say a general comment about these conversations. I try to make sure I prepare well, remove my ego from the picture, and focus on making the other person shine as we try to explore the most beautiful and insightful ideas in their mind. This can be challenging when the ideas that are close to my heart are being criticized. In those cases, I do offer a little pushback, but respectfully and then move on, trying to have the other person come out looking wiser in the exchange. I think there is no such thing as winning in conversations, nor in life. My goal is to learn and to have fun. I ask that you dont see my approach to these conversations as weakness. It is not. It is my attempt at showing respect and love the other person. That said, I also often just do a bad job of talking, but you probably already knew that, so please give. Me a pass on that as well. This is the Lex Friedman podcast and here is my conversation with Jaron Lanier. You're considered the founding father of virtual reality. Do you think we will one day spend most orlando, all of our lives in virtual reality worlds? I have always found the very most valuable moment in virtual reality to be the moment when you take off the headset and your senses are refreshed and. You perceive physicality afresh, you know, as if you were a newborn baby, but. With a little more experience. So you can really notice just how. Incredibly strange and delicate and peculiar and. Impossible the real world is. So the magic is, and perhaps forever will be in the physical world. Well, that's my take on it. That's just me. I mean, I think. I don't get to tell everybody else. How to think or how to experience virtual reality. And at this point, there have been. Multiple generations of younger people who've come along and liberated me from having to. Worry about these things. But I should say also even in what I called it mixed reality back. In the day, and these days it's. Called augmented reality, but with something like a HoloLens. Even then, one of my favorite things. Is to augment a forest, not because I think the forest needs augmentation, but. When you look at the augmentation next. To a real tree, the real tree. Just pops out as being astounding. It's interactive, it's changing slightly all the. Time if you pay attention, and it's hard to pay attention to that. But when you compare it to virtual reality, all of a sudden you do. And even in practical applications, my favorite early application of virtual reality, which we prototyped going back to the eighties when I was working with doctor Joe Rosen at Stanford Med, near where we are. Now, we made the first surgical simulator. And to go from the fake anatomy. Of the simulation, which is incredibly valuable. For many things, for designing procedures, for training, for all kinds of things, then to go to the real person, boy, it's really something like surgeons really get. Woken up by that transition. It's very cool. So I think the transition is actually. More valuable than the simulation. That's fascinating. I never really thought about that. It's almost. It's like traveling elsewhere in the physical space can help you appreciate how much you value your home once you return. Well, that's how I take it. I mean, once again, people have different attitudes towards it. All are welcome. What do you think is the difference between the virtual world and the physical meat space world that you are still drawn for you personally, still drawn to the physical world? Like there clearly then, is a distinction. Is there some fundamental distinction or is it the peculiarities of the current set. Of technology in terms of the kind. Of virtual reality that we have now? It's made of software, and software is terrible stuff. Software is always the slave of its own history, its own legacy. It's always infinitely, arbitrarily messy and arbitrary. Working with it brings out a certain. Kind of nerdy personality in people, or. At least in me, which I'm not that fond of. And there are all kinds of things about software I don't like, and so that's different from the physical world. It's not something we understand, as you just pointed out. On the other hand, I'm a little mystified when people ask me, well, do you think the universe is a computer? And I have to say, well, I mean, what on earth could you possibly. Mean if you say it isn't a computer? If it isn't a computer, it wouldn't follow principles consistently and it wouldn't be. Intelligible, because what else is a computer ultimately? And we have physics, we have technology, so we can do technology, so we can program it. So I mean, of course it's some kind of computer. But I think trying to understand it. As a Turing machine is probably a foolish approach. Right? That's the question. Whether it performs this computer we call the universe performs the kind of computation that can be modeled as a universal Turing machine. Or is it something much more fancy? So fancy, in fact, that it may be beyond our cognitive capabilities to understand. Turing machines are kind of. I call them teases in a way, because, like, if you have an infinitely. Smart programmer with an infinite amount of time, an infinite amount of memory and. An infinite clock speed, then they're universal, but that cannot exist. So they're not universal in practice, and. They actually are, in practice, a very. Particular sort of machine within the constraints. Within the conservation principles of any reality that's worth being in, probably. And so I think universality of a particular model is probably a deceptive way to think, even though at some sort of limit. Of course. Something like that's got to be true at some sort of high enough limit, but it's just not accessible to us. So what's the point? Well, to me, the question of, like, whether we're living inside a computer or a simulation is interesting in the following way. There's a technical question is here, how difficult is it to build a machine, not that simulates the universe, but that makes it sufficiently realistic that we wouldn't know the difference, or better yet, sufficiently realistic that we would kind of know the difference, but we would prefer to stay in the virtual world anyway. I want to give you a few different answers. I want to give you the one. That I think has the most practical importance to human beings right now, which is that there's a kind of an. Assertion sort of built into the way the question's usually asked that I think. Is false, which is a suggestion that. People have a fixed level of ability to perceive reality in a given way. And actually people are always learning, evolving, forming themselves. We're fluid, too. We're also programmable, self programmable, changing, adapting. And so my favorite way to get at this is to talk about the. History of other media. So, for instance, there was a peer. Review paper that showed that an early wire recorder playing back an opera singer. Behind a curtain was indistinguishable from a real opera singer. And so now, of course, to us. It would not only be distinguishable, but it would be very blatant because the recording would be horrible. But to the people at the time. Without the experience of it, it seemed plausible. There was an early demonstration of extremely. Crude video teleconferencing between New York and. DC in the thirties, I think so that people viewed as being absolutely realistic. And indistinguishable, which to us would be horrible. And there are many other examples. Another one of my favorite ones is in the Civil War era, there were. Itinerant photographers who collected photographs of people. Who just looked kind of like a few archetypes. So you could buy a photo of. Somebody who looked kind of like your loved one to remind you of that person. Because actually photographing them Washington, inconceivable. And hiring a painter was too expensive, and you didn't have any way for the painter to represent them remotely anyway. How would they even know what they looked like? So these are all great examples of how in the early days of different. Media, we perceive the media as being really great. But then we evolved through the experience of the media. This gets back to what I was saying. Maybe the greatest gift of photography is that we can see the flaws in a photograph and appreciate reality more. Maybe the greatest gift of audio recording is that we can distinguish that operation. Singer now from that recording of the. Opera singer on the horrible wire recorder. So we shouldn't limit ourselves by some assumption of stasis. That's incorrect. So that's the first thing. That's my first answer, which is, I think, the most important one. Now, of course, somebody might come back. And say, oh, but you know, technology can go so far, there must be some point at which it would surpass. That's a different question. I think that's also an interesting question. But I think the answer I just. Gave you is actually the more important answer to the more important question. That's profound. Yeah. The second question, which you're now making me realize is way different. Is it possible to create worlds in which people would want to stay instead of the real world? Well, like unmask, like, large numbers of people. What I hope is, you know, as. I said before, I hope that the experience of virtual worlds helps people appreciate. This physical world we have and feel tender towards it and keep it from. Getting too fucked up. That's my hope. Do you see all technology in that way? So basically, technology helps us appreciate the more sort of technology free aspect of life. Well, media technology, you can stretch that. Let me say, I could definitely play. McLuhan and turn this into a general theory. It's totally doable. The program you just described is totally doable. In fact, I will psychically predict that. If you did the research, you could find 20 PhD theses that do that already. I don't know, but they might exist. But I don't know how much value there is in pushing a particular idea that far. Claiming that reality isn't a computer in some sense seems incoherent to me because we have. We can program it, we have technology. It has, it seems, to obey physical laws. What more do you want from it. To be a computer? I mean, it's a computer of some kind. We don't know exactly what kind. We might not know how to think about it. We're working on it. But sorry to draw, but you're absolutely right. Like, that's my fascination with the AI as well, is it helps in the case of AI, I see as a set of techniques that help us understand ourselves, understand us humans, in the same way, virtual reality, and you're putting it brilliantly. It's a way to help us understand reality, appreciate and open our eyes more richly to reality. That's certainly how I see it. And I wish people who become incredibly. Fascinated, who go down the rabbit hole of the different fascinations with whether we're in a simulation or not. Orlando, you know, there's a whole world of variations on that. I wish they'd step back and think. About their own motivations and exactly what they mean. You know, what? And I think the danger with these things is. So if you say, is the universe. Some kind of computer? Broadly, it has to be, because it's. Not coherent to say that it isn't. On the other hand, to say that. That means, you know, anything about what kind of computer, that's something very different. And the same thing is true for the brain. The same thing is true for anything where you might use computational metaphors. Like, we have to have a bit. Of modesty about where we stand. And the problem I have with these framings of computation as these ultimate cosmic questions is that it has a way. Of getting people to pretend they know. More than they do. Can you maybe this is a therapy session. Psychoanalyze me for a second. I really like the Elder Scrolls series. It's a role playing game. Skyrim, for example. Why do I enjoy so deeply just walking around that world? And then there's people and you could talk to and you can just, like it's an escape. But, you know, my life is awesome. I'm truly happy. But I also am happy with the. The music that's playing in the mountains and carrying around a sword and just that. I don't know what that is. It's very pleasant, though, to go there, and I miss it sometimes. I think it's wonderful to love artistic creations. It's wonderful to love contact with other people. It's wonderful to love play and ongoing. Evolving meaning and patterns with other people, I think it's a good thing. You know, I'm not, I'm not, like. Anti tech, and I'm certainly not anti digital tech. I'm anti, as everybody knows by now. I think the, you know, manipulative economy. Of social media is making everybody nuts and all that. So I'm anti that stuff. But the core of it, of course. I worked for many, many years on trying to make that stuff happen because. I think it can be beautiful. Like, I I don't like. Why not? And by the way, there's a thing about humans, which is. We'Re problematic. Any kind of social interaction with other people is gonna have its problems. People are political and tricky. And, like, I love classical music, but. When you actually go to a classical music thing and it turns out, oh, actually, this is like a backroom power deal kind of place and a big. Status ritual as well, and that's kind of not as fun. That's part of the package. And the thing is, it's always going. To be, there's always going to be a mix of things. I don't think the search for purity is going to get you anywhere. So I'm not worried about that. I worry about the really bad cases where we're making ourselves crazy or cruel enough that we might not survive. And I think the social media criticism rises to that level. But I'm glad you enjoy it. I think it's great. And I like that. You basically say that every experience has both beauty and darkness, as in with classical music. I also play classical piano, so I appreciate it very much. But it's interesting. I mean, every, and even the darkness is a man's search for meaning. With Viktor Franco in concentration camps, even there, there's opportunity to discover beauty. And so it's, that's, that's the interesting thing about humans, is the capacity to discover beautiful in the darkest of moments. But there's always the dark parts, too. Well, I mean, it's. Our situation is structurally difficult. We are. Structurally. No, it is. It's true. We perceive socially we depend on each. Other for our sense of place and. Perception of the world. I mean, we're dependent on each other, and yet there's also a degree in which we're inevitably, we inevitably let each other down. We are set up to be competitive as well as supportive. I mean, our fundamental situation is complicated and challenging. And I wouldn't have it any other way. Okay, let's talk about one of the most challenging things. One of the things I unfortunately am very afraid of being human. Allegedly, you wrote an essay on death and consciousness in which you write a note. Certainly the fear of death has been one of the greatest driving forces in the history of thought and in the formation of the character of civilization. And yet it is under acknowledged. The great book on the subject, the denial of Death by Ernest Becker, deserves a reconsideration. I'm russian, so I have to ask you about this. What's the role of death in life? See, you would have enjoyed coming to our house. Cause my wife is russian. And we also have. We have a piano of such spectacular qualities, you would have freaked out. But anyway, we'll let all that go. So the context in which I remember. That essay, sort of, this was from. Maybe the nineties or something, and I used to publish in a journal called. The Journal of Consciousness Studies, because I was interested in these endless debates about. Consciousness and science, which certainly continue today. And I was interested in how the. Fear of death and the denial of. Death played into different philosophical approaches to consciousness. Because I think, on the one hand, this sort of sentimental school of dualism. Meaning the feeling that there's something apart from the physical brain, some kind of. Soul or something else, is obviously motivated. In a sense by a hope that whatever that is will survive death and continue. And that's the very core aspect of. A lot of the world religions. Not all of them, not really, but most of them. The thing I noticed is that the. Opposite of those, which might be the sort of hardcore, no, the brain's a computer and that's it. In a sense, we're motivated in the. Same way with a remarkably similar chain. Of arguments, which is, no, the brain's a computer, and I'm going to figure it out in my lifetime and upload it. Upload myself and I'll live forever. That's interesting. Yeah, that's the implied thought, right? Yeah. And so it's kind of this, in a funny way, the same thing. It's peculiar to notice that these people who would appear to be opposites in character and cultural references and their ideas. Actually are remarkably similar. And to an incredible degree, the sort of hardcore computationalist idea about the brain. Has turned into medieval Christianity together. Like, there are the people who are. Afraid that if you have the wrong. Thought, you'll piss off the super AI's. Of the future who will come back. And zap you and all that stuff. It's like, it's really turned into medieval. Christianity all over again. This is so the Ernest Becker's idea that death, the fear of death, is the warm at the core, which is like, that's the core motivator of everything we see humans have created. The question is if that fear of mortality is somehow core is like a prerequisite. You just moved across this vast cultural chasm that separates me from most of. My colleagues, in a way, and I can't answer what you just said on the level without this huge deconstruction. Yes. Should I do it? Yes. What's the chasm? Okay, let us travel across this vast. Okay. I don't believe in AI. I don't think there's any AI. There's just algorithms. We make them, we control them. Now, they're tools. They're not creatures. Now, this is something that rubs a. Lot of people the wrong way. And don't I know it. When I was young, my main mentor. Was Marvin Minsky, who's the principal author. Of the computer as creature rhetoric that we still use. He was the first person to have the idea at all, but he certainly. Populated the AI culture with most of its tropes, I would say, because a lot of the stuff people will say. Oh, did you hear this new idea about AI? And I'm like, yeah, I heard it in 1978. Sure. Yeah, I remember that. So Marvin was really the person. And Marvin and I used to argue all the time about this stuff because I always rejected it. And of all of his, of all of his. I wasn't formally his student, but I. Worked for him as a researcher. But of all of his students and student like people, of his young adoptees, I think I was the one who. Argued with him about this stuff in particular, and he loved it. Yeah, I would have loved to hear that conversation. It was fun. Did you ever converge to a place? Oh, no, no. So the very last time I saw him, he was quite frail. And I was in Boston, and I. Was going to the old house in. Brookline, his amazing house, and one of our mutual friends said, hey, listen, Marvin's so frail. Don't do the argument with him. Don't argue about AI. And so I said, but Marvin loves that. And so I showed up and he's. Like, he was frail. He looked up and he said, are you ready to argue? He's such an amazing person. Um, it's hard to summarize this because it's decades of stuff. The first thing to say is that nobody can claim absolute knowledge about whether somebody or something else is conscious or not. This is all a matter of faith. And, in fact, um, I think the. Whole idea of faith needs to be updated. So it's not about God, but it's just about stuff in the universe, right? We have faith in each other being conscious. And then I used to frame this. As a thing called the circle of empathy in my old papers. And then it turned into a thing. For the animal rights movement, too. I noticed Peter Singer using it. I don't know if it was coincident or. But anyway, there's this idea that you. Draw a circle around yourself, and the. Stuff inside is more like, you might. Be conscious, might be deserving of your empathy, of your consideration. And the stuff outside the circle isn't. And outside the circle might be a rock or. I don't know. And that circle is fundamentally based on faith. Well, your faith in what is and what isn't. The thing about the circle is it. Can'T be pure faith. It also has. It's also a pragmatic decision. And this is where things get complicated. If you try to make it too big, you suffer from incompetence. If you say, I don't want to. Kill a bacteria, I will not brush my teeth. I don't know. Like, what do you do? There's a competence question where you do have to draw the line. People who make it too small become cruel. People are so clannish and political and. So worried about themselves ending up on. The bottom of society that they are. Always ready to gang up on some designated group. And so there's always these people who are being tried. We're always trying to shove somebody out of the circle. So aren't you shoving AI outside the circle? Well, give me a second. All right, so there's a pragmatic consideration here, and the biggest questions are probably. Fetuses and animals lately, but AI is getting there. Now with AI, I think, and I've had this discussion so many times, people. Would say, but aren't you afraid if you exclude AI, you'd be cruel to some consciousness? And then I would say, well, if you include AI, you make yourself. You exclude yourself from being able to be a good engineer or designer, and so you're facing incompetence immediately. So, like, I really think we need. To subordinate algorithms and be much more skeptical of them. Your intuition. You speak about this brilliantly with social media, how things can go wrong. Isn't it possible to design systems that show compassion, not to manipulate you, but give you control and make your life better? If you so choose, to, like, grow together with systems and the way we grow with dogs and cats, with pets, with significant others, in that way they grow to become better people. I don't understand why that's fundamentally not possible. You're saying oftentimes you get into trouble by thinking, you know what's good for people. Well, look, there's this question of what framework we're speaking in. Do you know who Alan Watts was? So Alan Watts once said, morality is like gravity, that in some absolute cosmic sense, there can't be morality, because at some point it all becomes relative. And who are we anyway? Like, morality is relative to us tiny creatures. But here on earth, we're with each other. This is our frame. And morality is a very real thing, same thing with gravity. At some point you get into interstellar. Space, and you might not feel much. Of it, but here we are on earth. And I think in the same sense, I think this identification with a frame that's quite remote cannot be separated from. A feeling of wanting to feel sort of separate, separate from and superior to other people or something like that. There's an impulse behind it that I. Really have to reject, and we're just. Not competent yet to talk about these kinds of absolutes. Okay, so I agree with you that a lot of technologists sort of lack this basic respect, understanding, and love for humanity. There's a separation there. The thing I'd like to push back against, it's not that you disagree, but I believe you can create technologies and you can create a new kind of technologist, engineer that does build systems that respect humanity. Not just respect, but admire humanity, that have empathy for common humans, have compassion. I mean, no, no, no. I think. Yeah, I mean, I think musical instruments. Are a great example of that. Musical instruments are technologies that help people connect in fantastic ways. And that's a great example. My invention or design during the pandemic period was this thing called together mode. Where people see themselves seated sort of in a classroom or a theater instead of in squares, and it allows them to semi consciously perform to each other. As if they have proper eye contact, as if they're paying attention to each other nonverbally. And weirdly, that turns out to work. And so it promotes empathy, so far. As I can tell. I hope, I hope it is of. Some use to somebody. The AI idea isn't really new. I would say it was born with Adam Smith's invisible hand, with this idea that we build this algorithmic thing, and it gets a bit beyond us, and then we think it must be smarter than us. And the thing about the invisible hand is, absolutely everybody has some line they. Draw where they say, no, no, no, we're going to take control of this thing. They might have different lines, they might. Care about different things, but everybody ultimately. Became a Keynesian because it just didn't work. It really wasn't that smart. It was sometimes smart, and sometimes it failed. And so if you really, people who really, really, really want to believe in. The invisible hand is infinitely smart, screw up their economies terribly. You have to recognize the economy as a subservient tool. Everybody does when it's to their advantage. They might not when it's not to their advantage. That's kind of an interesting game that happens. But the thing is, it's just like that with our algorithms. You can have a Chicago economic philosophy about your computer, say, no, no, no, my things come alive. It's smarter than anything. I think that there is a deep loneliness within all of us. This is what we seek. We seek love from each other. I think AI can help us connect deeper, like this. This is what you criticize social media for. I think there's much better ways of doing social media that doesn't lead to manipulation, but instead leads to deeper connection between humans, leads to you becoming a better human being. And what that requires is some agency on the part of AI to be almost like a therapist, I mean, a companion. It's not telling you what's right. It's not guiding you as if it's an all knowing thing. It's just another companion that you can leave at any time. You have complete transparency, control over. There's a lot of mechanisms that you can have that are counter to how current social media operates that I think is subservient to humans or. No, deeply respects human beings and is empathetic to their experience and all those kinds of things. I think it's possible to create AI systems like that. And I think they, I mean, that's a technical discussion of whether they need to have something that looks like more like AI versus algorithms, something that has identity, something that has a personality, all those kinds of things. AI systems. And you've spoken extensively how AI systems manipulate you within social networks. And that's a, the biggest, the biggest problem isn't necessarily that there's advertisement, that, you know, social networks present you with advertisements that then get you to buy stuff. That's not the biggest problem. The biggest problem is they then manipulate you. You're, they alter, like, your human nature to get you to buy stuff or to get you to do whatever the advertiser wants. Maybe you can correct. Yeah, I don't see it quite that. Way, but we can work with that as an approximation. Sure. So my, I think the actual thing is even sort of more ridiculous and stupider than that. But that's, that's okay. Let's. So my question is, let's not use the word AI, but how do we fix it? Oh, fixing social media, that diverts us into this whole other field, in my view, which is economics, which I always thought was really boring, but we have. No choice but to turn it to economists if we want to fix this. Problem, because it's all about incentives. But I've been around this thing since it started, and I've been in the meetings where the social media companies sell. Themselves to the people who put the most money into them, which are usually the big advertising holding companies and whatnot. And there's this idea that I think is kind of a fiction, and maybe it's even been recognized as that by everybody, that the algorithm will get really. Good at getting people to buy something. Because I think people have looked at. Their returns and looked at what happens, and everybody recognizes it's not exactly right. It's more like a cognitive access blackmail payment at this point, just to be connected. You're paying the money. It's not so much that the persuasion algorithms. So Stanford renamed its program, but it used to be called engage. Persuade. The engage part works. The persuade part is iffy. But the thing is that once people are engaged, in order for you to. Exist as a business, in order for. You to be known at all, you put money into. That's dark. Oh, no, that's dark. It doesn't work. But they have to. But they're still. It's a giant cognitive access blackmail scheme at this point. So because the science behind the persuade part, it's not entirely, it's not entirely a failure, but it's not what there's. We play make believe that it works. More than it does. The damage doesn't come honestly, as I've said in my books, I'm not anti advertising. I actually think advertising can be demeaning and annoying and banal and ridiculous and. Take up a lot of our time with stupid stuff. Like, there's a lot of ways to criticize that advertising that's accurate, and it can also lie and all kinds of things. However, if I look at the biggest. Picture, I think advertising, at least as. It was understood before social media, helped. Bring people into modernity in a way. That overall actually did benefit people overall. And you might say, am I contradicting myself? Because I was saying you shouldn't manipulate people. Yeah, I am probably here. I mean, I'm not pretending to have. This perfect, airtight worldview without some contradictions. I think there's a bit of a contradiction there. So, you know, well, looking at the long arc of history, advertisement has in some parts benefited society. Yeah. Because they funded some efforts that perhaps. Yeah, I mean, I think, like, there's a, there's a thing where sometimes I think it's actually been of some years now. Let's. Where the damage comes is a different thing, though. Social media, algorithms on social media have. To work on feedback loops where they. Present you with stimulus. They have to see if you respond to the stimulus. Now, the problem is that the measurement. Mechanism for telling if you respond in. The engagement feedback loop is very, very crude. It's things like whether you click more or occasionally if you're staring at the. Screen more, if there's a forward facing camera that's activated, but typically there isn't. So you have this incredibly crude back channel of information. And so it's crude enough that it only catches sort of the more dramatic responses from you. And those are the fight or flight responses. Those are the things where you get. Scared or pissed off or aggressive or horny. These are these ancient, what are sometimes. Called the lizard brain circuits or whatever. These fast response, old, old evolutionary business circuits that we have that are helpful. In survival once in a while, but are not us at our best. They're not who we want to be, they're not how we relate to each other. They're this old business. But it. So then, just when you're engaged using. Those intrinsically, totally aside from whatever the. Topic is, you start to get incrementally just a little bit more paranoid, xenophobic, aggressive, you know, you get a little stupid and like, you become a jerk. And it happens slowly. It's not like everybody's instantly transformed, but. It does kind of happen progressively where. People who get hooked kind of get. Drawn more and more into this pattern of being at their worst. Would you say that people are able to, when they get hooked in this way, look back at themselves from 30 days ago and say, I am less happy with who I am now, or I'm not happy with who I am now versus who I was 30 days ago? Are they able to self reflect when you take yourself outside of the lizard break? Sometimes. I wrote a book about people suggesting. People take a break from their social media to see what happens and maybe. Even actually, the title of the book was just arguments to delete your account. Ten arguments. Although I always said, I don't know that you should. I can give you the arguments. It's up to you. I'm always very clear about that. But, you know, I get like, I don't have a social media account, obviously, and I, it's not that easy for. People to reach me. They have to search out an old. Fashioned email address on a super crappy, antiquated website. It's actually a bit. I don't make it easy. And even with that, I get this. Huge flood of mail from people who. Say, oh, I quit my social media. I'm doing so much better. I can't believe how bad it was. But the thing is, what's, for me. A huge flood of mail would be. An imperceptible trickle from the perspective of Facebook. Right? And so I think it's rare for. Somebody to look at themselves and say, oh, boy, I sure screwed myself over. It's a really hard thing to ask of somebody. None of us find that easy. Right. Well, the reason I, it's hard. The reason I ask this is, is it possible to design social media systems that optimize for some longer term metrics of being happy with yourself? Personal growth. I don't think you should try to engineer personal growth or happiness. I think what you should do is. Design a system that's just respectful of. The people and subordinates itself to the. People and doesn't have perverse incentives, and. Then at least there's a chance of something decent happening. You have to recommend stuff. Right? So, but, so you're saying, like, be respectful. What does that actually mean engineering wise? Like people. Yeah, curation. People have to, people have to be responsible. Algorithms shouldn't be recommending, algorithms don't understand enough to recommend. Algorithms are crap in this era. I mean, I'm sorry, they are like, and I'm not saying this as somebody. As a critic from the outside, I'm. In the middle of it. I know what they can do. I know the math, I know what the corpora are, you know, I know the best ones. Our office is funding GPT-3 and all these things that are, that are, you know, at the, at the edge of what's possible and they do not have yet. I mean, it still is statistical, emergent pseudo semantics. It doesn't actually have deep representation emerging of anything. It's just not like, I mean, that. I'm speaking the truth here and you know it. Well, let me push back on this. This. There's several truths here. So you're speaking to the way certain companies operate currently. I don't think it's outside the realm of what's technically feasible to do. There's just not incentive like companies are not. Why fix this thing? I am aware that, for example, the YouTube search and discovery has been very helpful to me and there's a huge number of. There's so many videos that it's nice to have a little bit of help. Have you done. But I'm still in control. Let me ask you something. Have you done the experiment of letting YouTube recommend videos to you, either starting. From a absolutely anonymous, random place where. It doesn't know who you are or from knowing who you or somebody else is, and then going 15 or 20 hops? Have you ever done that? And just let it go, top video. Recommend and then just go 20 hops? No, I have not. I've done that many times now. I have. Because of how large YouTube is and how widely it's used, it's very hard. To get to enough scale to get a statistically solid result on this. I've done it with high school kids, with dozens of kids doing it at a time. Every time I've done an experiment, the. Majority of times after about 17 or 18 hops, you end up in really weird, paranoid, bizarre territory. Because ultimately that is the stuff the. Algorithm rewards the most because of the feedback crudeness I was just talking about. I'm not saying that the video never recommends something cool. I'm saying that its fundamental core is one that promotes a paranoid style that promotes increasing irritability, that promotes xenophobia, promotes fear, anger, promotes selfishness, promotes separation between people. And I would encourage. The thing is, it's very hard to do this work solidly. Many have repeated this experiment and yet. It still is kind of anecdotal. I'd like to do like a large, you know, citizen science thing sometime and do it. But then I think the problem with that is YouTube would detect it and then change it. Yes, I definitely see. I love that kind of stuff in Twitter. So Jack Dorsey has spoken about doing healthy conversations on Twitter or optimizing for healthy conversations. What that requires within Twitter are most likely citizen experiments of what does healthy conversations actually look like and how do you incentivize those healthy conversations? You're describing what often happens and what is currently happening. What I'd like to argue is it's possible to strive for healthy conversations. Not in a dogmatic way of saying, I know what healthy conversations are, and I will tell you, I think one. Way to do this is to try to look around at social, maybe not. Things that are officially social media, but. Things where people are together online and. See which ones have more healthy conversations. Even if it's hard to be completely. Objective in that measurement, you can kind. Of, at least crudely, you could do. Subjective annotation, like have crowdsourced. One that I've been really interested in. Is GitHub, because it could change. I'm not saying it'll always be, but for the most part, GitHub has had. A relatively quite low poison quotient. And I think there's a few things. About GitHub that are interesting. One thing about it is that people. Have a stake in it. It's not just empty status games, there's actual code, or there's actual stuff being done. And I think as soon as you. Have a real world stake in something. You have a motivation to not screw up that thing. And I think that that's often missing, that there's a, there's no incentive for. The person to really preserve something. If they get a little bit of attention from dumping on somebody's TikTok or something, they don't pay any price for it. But you have to kind of get. Decent with people when you have a shared stake, a little secret. So GitHub does a bit of that. GitHub is wonderful, yes. But I'm tempted to play the Jaron Becca at you, which is that. So GitHub is currently is amazing. But the thing is, if you have a stake, then if it's a social media platform, they can use the fact that you have a stake to manipulate you because you want to preserve the stake. Right. Well, this is why this gets us into the economics. So there's this thing called data dignity. That I've been studying for a long time. I wrote a book about an earlier. Version of it called who owns the future? And the basic idea of it is that, once again, this is a 30 year conversation. It's a fascinating topic. Let me do the fastest version of this I can do. The fastest way I know how to do this is to compare two futures. Future one is then the normative one, the one we're building right now. And future two is going to be data dignity. I'm going to use a particular population. I live on the hill in Berkeley. One of the features about the hill is that as the climate changes, we might burn down and I'll lose our houses or die or something like it's. Dangerous, and it didn't used to be. And so who keeps us alive? Well, the city does. The city does some things. The electric company kind of, sort of, maybe, hopefully better individual people who own property, take care of their property. That's all nice. But there's this other middle layer, which. Is fascinating to me, which is that the groundskeepers who work up and down that hill, many of whom are not. Legally here, many of whom don't speak. English, cooperate with each other to make. Sure trees don't touch, to transfer fire easily from lot to lot. They have this whole little web that's keeping us safe. I didn't know about this at first. I just started talking to them because. They were out there during the pandemic. And so I try to just see, who are these people? Who are these people who are keeping us alive? Now I want to talk about the. Two different fates for those people in your future one and future two. Future one, some weird, like, kindergarten paint job van with all these, like, cameras and where things drives up, observes what. The gardeners and groundskeepers are doing. A few years later, some amazing robots that can shimmy up trees and all this show up. All those people are out of work and there are these robots doing the thing, and the robots are good and. They can scale to more land and they're actually good. But then there are all these people out of work, and these people have lost dignity. They don't know what they're going to do. And then somebody will say, well, they. Go on basic income, whatever. They become wards of the state. My problem with that solution is every time in history that you've had some centralized thing that's doling out the benefits, that things get seized by people because it's too centralized and it gets seized. That's happened to every communist experiment I can find. So I think that turns into a poor future that will be unstable. I don't think people will feel good in it. I think it'll be a political disaster. With a sequence of people seizing this central source of the basic income. And you'll say, oh, no, an algorithm can do it. Then people will seize the algorithm. They'll seize control. Unless the algorithm is decentralized and it's impossible to seize the control. Yeah, but 60 something people own a. Quarter of all the bitcoin. The things that we think are decentralized are not decentralized. So let's go to future two. Future two, the gardeners see that van. With all the cameras and the kindergarten. Paint job, and they say the groundskeepers and they say, hey, the robots are coming. We're going to form a data union. And amazingly, California has a little baby data union law emerging in the books. Yeah, and what they say, they say. We'Re going to form a data union. And we're going to. Not only are we going to sell our data to this place, but we're. Going to make it better than it would have been if they were just grabbing it without our corporation. And we're going to improve it, we're. Going to make the robots more effective, we're going to make them better and we're going to be proud of it. We're going to become a new class of experts that are respected. And then here's the interesting there's two things that are different about that world from future one. One thing, of course, the people have more pride, they have more sense of ownership, of agency. But what the robots do changes. Instead of just this functional. We'll figure out how to keep the neighborhood from burning down. You have this whole creative community that. Wasn'T there before, thinking, well, how can we make these robots better so we can keep on earning money? There'll be waves of creative groundskeeping with spiral pumping pumpkin patches, and waves of cultural things. There'll be new ideas like, wow, I. Wonder if we could do something about climate change mitigation with how we do this. What about fresh water? Can we make the food healthier? What about all of a sudden, there'll. Be this whole creative community on the case? And isn't it nicer to have a. High tech future with more creative classes than one with more dependent classes? Isn't that a better future? But future one and future two have. The same robots and the same algorithms. There's no technological difference, there's only a human difference. Yeah. And that second future, too, that's data dignity. The economy that you're. I mean, the game theory here is on the humans, and then the technology is just the tools that enable. Yeah. You know, I mean, I think you can believe in AI and be in. Future two, I just think it's a little harder. You have to do more contortions. It's possible. So in the case of social media, what does data dignity look like? Is it people getting paid for their data? Yeah, I think what should happen is in the future, there should be massive data unions for people putting content into the system, and those data unions should. Smooth out the results a little bit. So it's not winner take all, but at the same time, and people have. To pay for it. Too. They have to pay for Facebook the way they pay for Netflix, with an. Allowance for the poor. There has to be a way out, too. But the thing is, people do pay for Netflix. It's a going concern. People pay for Xbox and PlayStation. There's enough people to pay for stuff they want. This could happen, too. It's just that this precedent started that moved it in the wrong direction. And then what has to happen? The economy is a measuring device. If it's an honest measuring device, the. Outcomes for people form a normal distribution, a bell curve. And then, so there should be a. Few people who do really well, a lot of people who do okay, and. Then we should have an expanding economy reflecting more and more creativity and expertise flowing through the network. And that expanding economy moves the result. Just a bit forward. So more people are getting money out. Of it, then are putting money into it. So it gradually expands the economy and lifts all boats. And the society has to support the. Lower wing of the bell curve, too. But not universal basic income. It has to be for the, you know, because if it's an honest. If it's an honest economy, there will. Be that lower wing, and we have to support those people. There has to be a safety net. But see, what I believe, I'm not. Going to talk about AI, but I. Will say that I think there'll be. More and more algorithms that are useful. And so I don't think everybody's going. To be supplying data to groundskeeping robots. Nor do I think everybody's going to. Make their living with TikTok videos. I think in both cases, there'll be a rather small contingent that do well. Enough at either of those things. But I think there might be many. Many, many of those niches that start to evolve as there are more and more algorithms, more and more robots. And it's that large number that will. Create the economic potential for a very. Large part of society to become members. Of new creative classes. Do you think it's possible to create a social network that competes with Twitter and Facebook that's large and centralized in this way? Not centralized or large, large. So I got to tell you, how to get from what I'm talking, how. To get from where we are to. Anything kind of in the zone of what I'm talking about is challenging. I know some of the people who. Run like I know Jack Dorsey, and I view Jack as somebody who's actually. I think he's really striving and searching. And finding and trying to find a way to make it better, but is kind of like, it's very hard to. Do it while in flight. And he's under enormous business pressure, too. Um, so Jack Dorsey, to me, is a fascinating study, because I think his mind is in a lot of good places. He's. He's a good human being, but there's a big titanic ship that's already moving in one direction. It's hard to know what to do with that. I think that's the story of Twitter. I think that's the story of Twitter. Um, one of the things that I observe is that if you just want. To look at the human side, meaning, like, how are people being changed? How do they feel? What is the culture? Like? Almost all of the social media platforms. That get big have an initial sort of honeymoon period where they're actually kind. Of sweet and cute. Like, if you look at the early. Years of Twitter, it was really sweet. And cute, but also look at snap TikTok. And then what happens is, as they scale and the algorithms become more influential. Instead of just the early people, when. It gets big enough that it's the algorithm running it, then you start to. See the rise of the paranoid, and then they start to get dark. And we've seen that shift in TikTok. Rather recently, but I feel like that scaling reveals the flaws within the incentives. I feel like I'm torturing you. I'm sorry. It's not torture. No. Because I have hope for the world with humans, and I've hope for a lot of things that humans create, including technology. And I just, I feel it is possible to create social media platforms that incentivize different things than the current. I think the current incentivization is around, like, the dumbest possible thing that was invented, like, 20 years ago, however long. And it just works. And so nobody's changing it. I just think that there could be a lot of innovation for more. See, you kind of push back this idea that we can't know what long term growth or happiness is. If you give control to people to define what their long term happiness and goals are, then that optimization can happen for each of those individual people. Well, I mean, imagine a future where probably a lot of people would love to make their living doing TikTok dance. Videos, but people recognize generally, that's kind of hard to get into. Nonetheless, dance crews have an experience that's very similar to programmers working together on GitHub. So the future is like a cross between TikTok and GitHub, and they get. Together, and they have rights. They're negotiating. They're negotiating for returns. They join different artist societies in order to soften the blow of the randomness. Of who gets the network effect benefit, because nobody can know that. And I think an individual person might. Join a thousand different data unions in the course of their lives, or maybe even 10,000, I don't know. But the point is that we'll have these very hedge distributed portfolios of different. Data unions we're part of, and some of them might just trickle in a little money for nonsense stuff where we're. Contributing to health studies or something. I think people will find their way. They'Ll find their way to the right. GitHub like community in which they find their value in the context of supplying inputs and data and taste and correctives. And all of this into the algorithms and the robots of the future. And that is a way to resist the lizard brain based funding mechanisms. It's an alternate economic system that rewards productivity, creativity, value as perceived by others. It's a genuine market. It's not doled out from a center. There's not some communist person deciding who's valuable, it's actual market. And the money is made by supporting that instead of just grabbing people's attention. In the cheapest possible way. Which is definitely how you get the lizard brain. Yeah. Okay, so we're finally at the agreement, but I just think that. So, yeah, I'll tell you how I think. Fix social media. There's a few things. There's a few things. So, one, I think people should have complete control over their data and transparency of what that data is and how it's being used. If they do hand over the control. Another thing they should be able to delete. Walk away with their data at any moment. Easy, like with a single click of a button, maybe two buttons, I don't know, just easily walk away with their data. The other is control of the algorithm, individualized control of the algorithm for them. So each one has their own algorithm, each person has their own algorithm. They get to be the decider of what they see in this world. And to me, that, I mean, that's, I guess, fundamentally decentralized in terms of the key decisions being made. But if that's made transparent, I feel like people will choose that system over Twitter of today, over Facebook of today, when they have the ability to walk away to control their data and to control the kinds of thing they see. Now, let's walk away from the term AI. You're right. In this case, you have full control of the algorithms that help you if you want to use their help, but you can also say f you to those algorithms and just consume the raw, beautiful waterfall of the Internet. I think that to me, that's not only fixes social media, but I think you'll make a lot more money. So I would like to challenge the idea. I know you're not presenting that, but that the only way to make a ton of money is to operate like Facebook is I think you can make more money by giving people control. Yeah, I mean, I certainly believe that we're definitely in the territory of wholehearted agreement here. I do want to caution against one thing, which is making a future that benefits programmers versus people like this idea. That people are in control of their data. So years ago, I co founded an. Advisory board for the EU with a guy named Giovanni Butarelli, who passed away. It's one of the reasons I wanted to mention it. A remarkable guy who'd been, he was originally a prosecutor who was throwing mafioso in jail in Sicily. So he's like this intense guy who is like, I've dealt with death threats. Mark Zuckerberg doesn't scare me. Whatever. So we worked on this path of. Saying, let's make it all about transparency and consent, and it was one of the feeders that led to this huge. Data privacy and protection framework in Europe called the GDPR. So therefore, we've been able to have. Empirical feedback on how that goes. And the problem is that most people actually get stymied by the complexity of that kind of management. They have trouble, and reasonably so. I don't, I'm like a techie, you. Know, I can go in and I can figure out what's going on, but most people really do, and why. And so there's a problem that it, it differentially benefits those who have a technical mindset and can go in and sort of have a feeling for how this stuff works. I kind of still want to come back to incentives, and so if the incentive for whoever is, if the commercial. Incentive is to help the creative people. Of the future make more money because you get a cut of it, that's. How you grow an economy. Not the programmers. Well, some of them will be programmers. It's not anti programmer. I'm just saying that, um, it's not only programmers, you know? So, uh, I mean, I definitely. So, yeah, yeah, you have to make sure the incentives are right. I mean, I like, control is an interface problem to where you have to create something that's, that's compelling to everybody, to the creatives, to the public. I mean, there's um, I don't know, creative commons, like the licensing, you know, there's a bunch of legal speak, just in general, the whole legal profession. It's nice when it can be simplified in the way that you can truly simply understand. Everybody can simply understand the basics. In that same way, it should be very simple to understand how the data is being used and what data is being used for people. But then you're arguing that in order for that to happen, you have to have the incentives. I mean, a lot of the reason. That money works is actually information hiding and information loss. Like, one of the things about money is a particular dollar you get might have passed through your enemy's hands and you don't know it. But also, I mean, this is what Adam Smith, if you want to give. The most charitable interpretation possible to the invisible hand, is what he was saying. Is that there's this whole complicated thing, and not only do you not need. To know about it, the truth is you'd never be able to follow it if you tried. And just let the economic incentives solve. For this whole thing. And that, in a sense, every transaction. Is like a neuron and a neural net. If he'd had that metaphor, he would. Have used it and let the whole. Thing settle to a solution. And don't worry about it. I think this idea of having incentives that reduce complexity for people can be made to work. And that's an example of an algorithm that could be manipulative or not. Going back to your question before about can you do it in a way that's not manipulative? And I would say a GitHub. Like, if you just have this vision, GitHub plus TikTok combined, is it possible? I think it is. I'm not going to be able to unsee that idea of creatives on TikTok collaborating in the same way people on GitHub collaborate. I like that kind of version. Why not? I like it. I love it. I just like right now when people use, by the way, father of teenage. Daughters, it's all about TikTok, right? So, you know, when people use TikTok, there's a lot of, it's kind of funny. I was going to say cattiness, but I was just using the cat as. This exemplar of overcoming. I contradict myself. But anyway, there's all this cattiness where people are like this person, and I just, what about people getting together in. Kitchen saying, okay, we're gonna work on this move. We're gonna get a bit of, can we get a better musician like, and they do that. But that's the part that's kind of. Off the books right now. You know, that should be, like, right there. That should be the center. That's where the. That's the really best part. Well, that's. That's where the invention of git, period, the versioning, is brilliant. And so some of the. Some of the things you're talking about, technology, algorithms, tools can empower. That's the thing for humans to connect, to, collaborate and so on. Can we. Can we upset more people a little bit? You already. Maybe? We'd have to try. No, no. Can we can ask you to elaborate, because my intuition was that you would be a supporter of something like cryptocurrency and bitcoin, because it is fundamentally emphasizes decentralization. What do you. So, can you elaborate on. Okay, look. Your thoughts on bitcoin? It's kind of funny. I've been advocating some kind of digital. Currency for a long time, and when. Bitcoin came out and the original paper. On blockchain, my heart kind of sank, because I thought, oh, my God, we're. Applying all of this fancy thought and. All these very careful, distributed security measures to recreate the gold standard. Like, it's just so retro, it's so dysfunctional, it's so useless from an economic point of view. So it's always. And then the other thing is, using computational inefficiency at a boundless scale as your form of security is a crime against the atmosphere. Obviously, a lot of people know that now, but we knew that at the start. Like, the thing is, when the first paper came out, I remember a lot. Of people saying, oh, my God, this thing scales. It's a carbon disaster. And I'm just mystified. But that's a different question than when you asked, can you have a cryptographic currency or at least some kind of. Digital currency that's of a benefit and. Absolutely. And there are people who are trying. To be thoughtful about this. If you haven't, you should interview Vitalik Buterin. Sometimes twice. Okay. So, like, there are people in the. Community who are trying to be thoughtful and trying to figure out how to do this better. It has nice properties, though, right? So one of the nice properties is that, like, government centralized, it's hard to control. And then the other one to fix some of the issues that you're referring to, I'm sort of playing devil's advocate here, is, you know, there's lightning network, there's ideas how to. How you build stuff on top of bitcoin, similar with gold, that allow you to have this kind of vibrant economy that operates not on the blockchain, but outside the blockchain, and uses bitcoin for checking the security of those transactions. So bitcoin's not new. It's been around for a while. I've been watching it closely. I've not seen one example of it creating economic growth. There was this obsession with the idea. That government was the problem. That idea that government's the problem. Let's say government earned that wrath, honestly. Because if you look at some of the things that governments have done in. Recent decades, it's not a pretty story. Like after. After a very small number of people in the US, government decided to bomb. And landmine Southeast Asia, it's hard to come back and say, oh, government's this great thing. But then I. The problem is that this resistance to. Government is basically a resistance to politics. It's a way of saying, if I. Can get rich, nobody should bother me. It's a way of not having obligations to others. And that ultimately is a very suspect motivation. But does that mean that the impulse that the government should not overreach its power is flawed? I mean, what I want to ask you to do is to replace the. Word government with politics. Like our politics, is people having to deal with each other. My theory about freedom is that the only authentic form of freedom is perpetual annoyance. All right, so annoyance means you're actually dealing with people because people are annoying. Perpetual means that that annoyance is survivable, so it doesn't destroy us all. So if you have perpetual annoyance, then you have freedom. And that's politics. That's politics. If you don't have perpetual annoyance, something's. Gone very wrong and you suppress those people, it is only temporary. It's going to come back and be horrible. You should seek perpetual annoyance. I'll invite you to a Berkeley city. Council meeting so you can know what. That feels like, what professional feels like. But anyway, so freedom is being. The test of freedom is that you're annoyed by other people. If you're not, you're not free. If you're nothing, you're trapped in some temporary illusion that's going to fall apart. Now, this quest to avoid government is. Really a quest to avoid that political feeling, but you have to have it. You have to deal with it, and it sucks. But that's the human situation, that's the human condition. And this idea that we're going to have, this abstract thing that protects us from having to deal with each other is always an illusion. The idea, and I apologize, I overstretched these. The word government. The idea is there should be some punishment from the people when a group, when a bureaucracy, when a set of people, or a particular leader, like in an authoritarian regime, which more than half the world currently lives under, if you like, if they become. They start stop representing the people. It stops being like a Berkeley meeting and starts being more like. Like a dictatorial kind of situation. And so the point is, it's nice to give people, the populace, in decentralized way, power to resist that kind of like government becoming over autonomous. Yeah, but people see, this idea that. The problem is always the government being powerful is false. The problem can also be criminal gangs. The problem can also be weird cults. The problem can be. Abusive clergy. The problem can be infrastructure that fails. The problem can be poisoned water. The problem can be failed electric grids. The problem can be. A crappy education. System that makes the whole society less. And less able to create value. There are all these other problems that are different from an overbearing government. You have to keep some sense of perspective and not be obsessed with only one kind of problem, because then the others will pop up. But empirically speaking, some problems are bigger than others. So, like, some, like, groups of people, like governments or gangs or companies lead. Are you a us citizen? Yes. Has the government ever really been a problem for you? Well, okay. So, first of all, I grew up in the soviet union. Used to. And actually, yeah, my wife did, too. So I have seen, you know. Sure. And has the government bothered me? I would say that that's a really complicated question, especially because the United States is such. It's a special place, like a lot of other countries. My wife's family were refused nics, and. So we have, like, a very. And her dad was sent to the gulag. For what it's worth, on my father's. Side, all but a few were killed. By a pogrom in a post soviet pogrom in Ukraine. So I would say, because you did a little trick of eloquent trick of language, that you switched to the United States to talk about government. So I believe, unlike my friend Michael Malice, who's an anarchist, I believe government can do a lot of good in the world. That is exactly what you're saying, which is. It's politics. The thing that bitcoin folks and cryptocurrency folks argue is that one of the big ways that government can control the populace is centralized. Bank like, control the money. That was the case in the Soviet Union, too. There's, you know, inflation can really make poor people suffer. And so what they argue is this is one way to go around that power that government has of controlling the monetary system. So that's a way to resist. That's not actually saying government bad. That's saying some of the ways that central banks get into trouble can be resisted through centralized. Preston, so let me ask you, on. Balance today in the real world, in. Terms of actual facts, do you think. Cryptocurrencies are doing more to prop up corrupt, murderous, horrible regimes or to resist those regimes? Where do you think the balance is right now? I know. Exactly. Having talked to a lot of cryptocurrency folks, what they would tell me, right. It's hard. It's. I don't, no, no, I'm asking it. As a real question. There's no way to know the answer. There's no way to know the answer perfectly. However, I gotta say, if you look at people who've been able to decode a blockchains, and they do leak a. Lot of data, they're not as secure as it's widely thought. There are a lot of unknown bitcoin. Whales from pretty early, and they're huge. And if you ask, who are these people? There's evidence that a lot of them are quite not the people you'd want to support. Let's say. I think empirically this idea. That there's some intrinsic way that bad. Governments will be, will be disempowered and. People will be able to resist them. More than new villains or even villainous. Governments will be empowered. There's no basis for that assertion. It just is kind of circumstantial. And I think in general, bitcoin ownership. Is one thing, but bitcoin transactions have. Tended to support criminality more than productivity. Of course, they would argue that was the story of its early days, that now more and more bitcoin is being used for legitimate transactions. But that's a different. I didn't say for legitimate transactions, I. Said for economic growth, for creativity. Like, I think what's happening is people. Are using it a little bit for. Buying, I don't know, maybe somebody's companies. Make it available for this and that they buy a Tesla with it or something. Investing in a startup hard, it might have happened a little bit, but it's. Not an engine of productivity, creativity and economic growth, whereas old fashioned currency still is. And anyway, look, I think something. I'm pro the idea of digital currencies. I am anti the idea of economics wiping out politics as a result, I think they have to exist in some balance to avoid the worst dysfunctions of each. In some ways, there's parallels to our discussion of algorithms and cryptocurrency is you're pro the idea, but it can be used to manipulate. You can be used poorly by aforementioned humans. Well, I think that you can make. Better designs and worse designs. And I think, and you know, the. Thing about cryptocurrency that's so interesting is. How many of us are responsible for the poor designs, because we're all so hooked on that Horatio Alger story on, like, I'm going to be the one. Who gets the viral benefit. You know, way back when all this stuff was starting, I remember it would. Have been in the eighties, somebody had the idea of using viral as a metaphor for network effect. And the whole point was to talk about how bad network effect was, that it always created distortions that ruined the usefulness of economic incentives, that that created dangerous distortions. But then somehow, even after the pandemic. We think of viral as this good thing because we imagine ourselves as the virus, right? We want to be on the beneficiary side of it. But of course, you're not likely to be. There is a sense, because money is involved, people are not reasoning clearly, always, because they want to be. They want to be part of that first viral wave that makes them rich, and that blinds people from their basic morality. I had an interesting conversation. I sort of feel like I should respect some people's privacy, but some of the initial people who started bitcoin, I remember having an argument about, like, it's. Intrinsically a Ponzi scheme. Like, you know, the early people have more than the later people. And the further down the chain you. Get, the more you're subject to gambling like dynamics, where it's more and more random and more and more subject to. Weird network effects and whatnot. Unless you're a very small player, perhaps, and you're just buying something, but even. Then you'll be subject to fluctuations, because. The whole thing is just kind of like that. As it fluctuates, it's going to wave. Around the little people more. And I remember the conversation turned to. Gambling, because gambling is a pretty large. Economic sector, and it's always struck me as being non productive. Like, somebody goes to Las Vegas and they lose money. And so one argument is, well, they got entertainment. They paid for entertainment as they lost money, so that's fine. And Las Vegas does up the losing. Of money in an entertaining way, so why not? It's like going to a show. So that's one argument. The argument that was made to me. Was different from that. It's that, no, what they're doing is. They'Re getting a chance to experience hope, and a lot of people don't get that chance. And so that's really worth it. Even if they're going to lose. They have that moment of hope and. They need to be able to experience that. And it's a very interesting argument. That's so heartbreaking, because I. Well, but I've seen that I have that a little bit of a sense. I've talked to some young people who invest in cryptocurrency, and what I see is this hope. This is the first thing that gave them hope. And that's so heartbreaking to me that you've gotten hope from. So much is invested. It's like hope from somehow becoming rich as opposed to something. To me, I apologize, but money is, in the long term, not going to be a source of that deep meaning. It's good to have enough money, but it should not be the source of hope. And it's heartbreaking to me how many people. It's the source of hope. Yeah. Um, you've just described the psychology of virality, or the psychology of, of trying. To base a civilization on semi random occurrences of network effect peaks. Yeah. And it doesn't really work. I mean, I think we need to. Get away from that. We need to soften those peaks. And except Microsoft, which deserves every penny. But in every other case. Well, you mentioned GitHub. I think what Microsoft did with GitHub was brilliant. I was very. Okay, if I can give a. Not a critical but sure on Microsoft because they recently purchased Bethesda. So Elder Scrolls is in their hands. I'm watching you, Microsoft. Do not screw up. My favorite game. So, yeah, look, I'm not speaking for Microsoft. I have an explicit arrangement with them. Where I don't speak for them. Obviously, that should be very clear. I do not speak for them. I am not saying I like him. I think Satya is amazing. The term data dignity was coined by Satya. It's extraordinary. But Microsoft's this giant thing. It's going to screw up this or that. I don't know. It's interesting. I've had a few occasions in my. Life to see how things work from. The inside of some big thing. And it's always just people kind of. It's. I don't know, there's always, like, coordination problem and there's also. There's always human problems. Oh, there's some good people. There's some bad people. It's always, I hope Microsoft doesn't screw. Up your team, and I hope they bring Clippy back. You should never kill Clippy. Bring Clippy back. Oh, Clippy. But Clippy promotes the myth of AI. Well, that's why you're wrong. How about if we. All right, could we bring back Bob instead of Clippy? Which one was Bob? Oh, Bob was another thing. Bob was this other screen character who. Was supposed to be the voice of AI. Cortana. Cortana. With Cortana do it for you. Cortana is too corporate. I like it. There's a woman in Seattle who's, like, the model for Cortana, did Cortana's voice, and was, there was like, no, the voice is great. We had a vision. We had her as a, she used. To walk around if you were wearing hololens forbid. I don't think that's happening anymore. I think. I don't think you should turn a software into a creature. I think you and I. You and I. Well, get a dog. Get a dog. Or a dog. Yeah. Yeah. A hedgehog. Hedgehog. Yeah. You co authored a paper you mentioned, Lee small, titled the autodidactic universe. Mm hmm. Which describes our universe as one that learns its own physical laws. That's a trippy and beautiful and powerful idea. What would you say are the key ideas in this paper? Okay. Well, I should say that paper reflected. Work from last year and the project. The program has moved quite a lot. So there's a lot of stuff that's. Not published that I'm quite excited about. So I have to kind of keep. My frame in that last year's things. I have to try to be a little careful about that. We can think about it in a few different ways. The core of the paper, the technical. Core of it, is a triple correspondence. One part of it was already established. And then another part is in the process. The part that was established was, of course, understanding different theories of physics as matrix models. The part that was fresher is understanding. Those as a machine learning system so that we could move fluidly between these different ways of describing systems. And the reason to want to do. That is to just have more tools and more options because. Well, theoretical physics. Is really hard, and a lot of programs have kind of run into a state where they feel a little stalled. I guess I can. I want to be delicate about this because I'm not a physicist. I'm the computer scientist collaborating. So I don't mean to diss anybody's. So this is almost like, gives a framework for generating new ideas in physics. As we start to publish more about. Where it's gone, I think you'll start to see there's tools and ways of thinking about theories that, I think open up some new paths that will be of interest. There's the technical core of it, which is this idea of a correspondence to give you more facility. But then there's also the storytelling part of it. And this is something Lee loves stories, and I do. And the idea here is that a typical way of thinking about physics is that there's some kind of starting condition. And then there's some principle by which. The starting condition evolves. And the question is, like, why the starting condition? Like, how. How the starting condition has to get kind of. This has to be fine tuned, and all these things about it have to be kind of perfect. And so we were thinking, well, look, what if we could push the storytelling about where the universe comes from much further back by starting with really simple. Things that evolve, and then through that evolution, explain how things got to be, how they are through very simple principles. Right. And so we've been exploring a variety. Of ways to push the start of. The storytelling further and further back, which. And it's an interesting. It's really kind of interesting because, like, for all of his. Lee is sometimes considered to be. To have a radical quality in the physics world, but he still is like, no, this is going to be the kind of time we're talking about in which evolution happens is the same time. We'Re now, and we're talking about something. That starts and continues. And I'm like, well, what if there's some other kind of time? That's time like. And that sounds like metaphysics, but there's an ambiguity, you know, like, it has to start from something, and it's kind of an interesting. So there's this. A lot of the math can be. Thought of either way, which is kind of interesting. So push it so far back that basically all the things we take for granted in physics start becoming emergent. I really want to emphasize this is. All super baby steps. I don't want to over claim. It's like, it's. I think a lot of the things. We'Re doing, we're approaching some old problems in a pretty fresh way. Informed. There's been a zillion papers about how you can think of the universe as. A big neural net, or how you. Can think of different ideas in physics. As being quite similar to, or even equivalent to some of the ideas in machine learning. And that actually works out crazy. Well, that is actually kind of eerie when you look at it. There's probably two or three dozen papers. That have this quality, and some of. Them are just crazy good. And it's very interesting. What we're trying to do is take. Those kinds of observations and turn them into an actionable framework where you can then start to do things with landscapes or theories that you couldn't do before and that sort of thing. So, in that context, or maybe beyond, how do you explain us humans? How unlikely are we this intelligent civilization? Or is there a lot of others, or are we alone in this universe? Yeah. You seem to appreciate humans very much. I've grown fond of us. Okay, whatever our nice qualities. I like that. I mean, we're kind of weird. We sprout this hair on our heads. And then, I don't know, we're sort of weird animals. That's the feature, not a bug. I think the weirdness. I hope so. I hope so. I. I think if I'm just going to answer you in terms of truth, the first thing I'd say is we're not in a privileged enough position, at least as yet, to really know much about who we are, how we are, what we're really like, in the context of something larger, what that context is, all that stuff. We might learn more in the future. Our descendants might learn more, but we don't really know very much, which you. Can either view as frustrating or charming, like that first year of TikTok or something. But all roads lead back to TikTok. I like it well, lately, but in terms of. There's another level at which I can think about it, where I sometimes think that if you are just quiet and. You do something that gets you in touch with the way reality happens. And for me, it's playing music. Sometimes it seems like you can feel. A bit of how the universe is, and it feels like there's a lot more going on in it, and there is a lot more life and a. Lot more stuff happening and a lot. More stuff flowing through. I don't know. I'm not speaking as a scientist now. This is kind of a more my. Artist side talking, and it's. I feel like I'm suddenly in multiple personalities with you. But Kerouac, Jack Kerouac said that music is the only truth. What do you. It sounds like you might be, at least in part. There's a passage in Kerouac's book, Doctor. Sacks, where somebody tries to just explain the whole situation with reality and people in like, a paragraph, and I couldn't reproduce it for you here, but it's like. Yeah, like there are these bulbous things. That walk around and they make these sounds. You can sort of understand them, but only kind of. And then there's like this. And it's just like this amazing. Like, just really quick. Like if some spirit being or something was going to show up in our. Reality and had knew nothing about it. It's like a little basic intro of, like, okay, here's what's going on here. It's an incredible passage. Yeah, yeah. It's like a one or two sentence summary in Hitchhiker's Guides of the galaxy. Right. Of what? This. Mostly harmless. Mostly harmless? Yeah. Do you think there's truth to that? That music somehow connects to something that words cannot? Yeah. Music is something that just towers above me. I don't. I don't. I don't feel like I have an overview of it. It's just the reverse. I don't. I don't fully understand it, because on one level, it's simple. Like, you can say, oh, it's. It's a thing. People evolved to coordinate our brains on. A pattern level or something like that. There's all these things you can say about music which are, you know, some. Of that's probably true. It's also. There's kind of like this. This is the mystery of meaning. Like, there's a way that just. Instead of just being pure abstraction, music can have, like, this kind of substantiality. To it that is philosophically impossible. I don't know what to do with it. Yeah. The amount of understanding I feel I have when I hear the right song at the right time is not comparable to anything I can read on wikipedia. Anything I can understand, read through in language. There's. The music does connect us to something. There's a thing there. Yeah, there's. There's. There's some kind of a thing in it. I've never, ever. I've read across a lot of explanations. From all kinds of interesting people like that it's some kind of a flow. Language between people or between people and. How they perceive and that kind of thing. And that sort of explanation is fine, but it's not quite it either. Yeah. There's something about music that makes me believe that panpsychism could possibly be true, which is that everything in the universe is conscious. It makes me think, makes me be humble in how much or how little I understand about the functions of our universe that everything might be conscious. Most people interested in theoretical physics eventually land in panpsychism, but I'm not one of them. I still think there's this pragmatic imperative to treat people as special. So I will proudly be a dualist. People and cats. People and cats, yeah. I'm not quite sure where to draw the line or why the line's there. Or anything like that, but I don't. Think I should be required to all the same questions or equally mysterious for no line. So I don't feel disadvantaged by that. So I shall remain a dualist. But if. If you listen to anyone trying to explain where consciousness is in a dualistic sense, either believing in souls or some special thing in the brain or something, you pretty much say, screw this, I'm going to be a panpsychist. Fair enough. Well put. Is there moments in your life that happen that we're defining in the way that you hope others, your daughter? Well, listen, I gotta say, the moments. That defined me were not the good ones. The moments that defined me were often horrible. I've had successes, but if you ask. What defined me, my mother's death. Being. Under the World Trade center and the attack. The things that have had an. Effect on me were the most were sort of real world terrible things, which I don't wish on young people at all. And this is the thing that's hard. About giving advice to young people, that they have to learn their own lessons. And lessons don't come easily. And a world which avoids hard lessons will be a stupid world, and I don't know what to do with it. That's a little bundle of truth that has a bit of a fatalistic quality. To it, but I don't. This is like what I'm saying, that. Freedom equals eternal annoyance. There's a degree to which honest advice is not that pleasant to give. And I don't want young people to have to know about everything. I think you don't want to wish hardship on them. Yeah, I think they deserve to have. A little grace period of naivety. That's pleasant. I mean, I do, if it's possible, if it's. These things are. This is tricky stuff. I mean, if you. If you. Okay, so let me. Let me try a little bit on this advice thing. I think one thing and any serious. Broad advice will have been given a thousand times before for a thousand years. So this, I'm not going to. I'm not going to claim originality, but I think trying to find a way to really pay attention to what you're. Feeling, fundamentally, what your sense of the world is, what your intuition is, if you feel like an intuitive person, what. You'Re to try to escape the constant. Sway of social perception or manipulation, whatever you wish. Not to escape it entirely, that would be horrible. But to find cover from it once in a while, to find a sense. Of being anchored in that, to believe in experience as a real thing. Believing in experience as a real thing is very dualistic. That goes with my philosophy of dualism. I believe there's something magical, and instead of squirting the magic dust on the programs, I think experience is something real. And something apart, something mystical and your. Own personal internal experience that you just have. And then you're saying, yeah, silence the rest of the world enough to hear that, like, whatever that magic dust is. From that experience, find with what? What is there? And I think that's what. That's one thing. Another thing is to recognize that kindness requires genius, that it's actually really hard. That facile kindness is not kindness in. That it'll take you a while to have the skills, to have kind impulse. As to how to be kind, you can have right away. To be effectively kind is hard. To be effectively kind, yes. It takes skill. It takes. It takes hard lessons. You'll never be perfect at it to the degree you get anywhere with it. It's the most rewarding thing ever. Let's see, what else would I say? I would say when you're young, you can be very overwhelmed. By social and interpersonal emotions. You'll have broken hearts and jealousies. You'll feel socially down the ladder instead of up the ladder. It feels horrible when that happens, all. Of these things, and you have to. Remember what a fragile crust all that stuff is. And it's hard because right when it's happening, it's just so intense. And. If I was actually giving this advice to my daughter, she'd already be. Out of the room. So I'm just. This is for some, like, hypothetical teenager that doesn't really exist, that really wants to sit and listen to my wisdom. For your daughter, ten years from now, maybe. Can I ask you a difficult question? Yeah, sure. You talked about losing your mom. Yeah. Do you miss her? Yeah. I mean, I still connect to her through music. She was a. She was a young prodigy piano player in Vienna, and she survived the concentration. Camp and then died in a car accident here in the US. What music makes you think of her? Is there. Is there a song? Well, you know, she was in Vienna, so she had the whole viennese music thing going, which is this, you know, incredible school of absolute skill and romance. Bundled together and wonderful. On the piano especially, I learned to. Play some of the Beethoven sonatas for her, and I played them in this. Exaggerated, drippy way I remember when I was a kid. And exaggerated meaning, too. Full of emotion. Yeah. Like, just like, isn't that the only way to play Beethoven? I mean, I didn't know there's any. That's a reasonable question. I mean, the fashion these days is. To be slightly apollonian with. Even with Beethoven. But one imagines that actual Beethoven playing might have been different. I don't know. I've gotten to play a few instruments. He played and tried to see if. I could feel anything about how it. Might have been for him. I don't know, really. I was always against the clinical precision of classical music. I thought a great piano player should be, like, in pain, emotionally, truly feel the music and make it messy. Maybe play classical music the way. I don't know, blues pianist plays blues. Like, it seems like they actually got happier. And I'm not sure if Beethoven got happier. I think it's a different. I think it's a different kind of. Concept of the place of music. I think the blues, the whole african. American tradition was initially surviving awful, awful. Circumstances, you could say, you know, there was some of that. The concentration camps and all that, too. And it's not that Beethoven's circumstances were. Brilliant, but he kind of also. I don't know, this is hard. It would seem to be. His misery was somewhat self imposed, maybe through. I don't know, it's kind of interesting. I've known some people who loathed Beethoven, like the composer, late composer Pauline Oliveros, wonderful modernist composer. I played in her band for a while and she was like, oh, Beethoven. That'S the worst music ever. It's like all ego. It completely. It turns information. I mean, it turns emotion into your. Enemy, and it's ultimately all about your. Own self importance, which has to be. At the expense of others. Could. But what else could it be? And blah, blah, blah. So she had. I shouldn't say. I don't mean it to be dismissive. But I'm just saying, like, her position. On Beethoven was very negative and very. Unimpressed, which is really interesting for the. Man or the music, I think. I don't know. I mean, she's not here to speak. For herself, so it's a little hard for me to answer that question. But it was interesting because I always thought of Beethoven's like, whoa. You know, this is like, Beethoven is like, really the dude, you know? And she's like, ah, you know, Beethoven Schmeethoven, you know, it's, like, not really happening. Yeah, I still, even though it's cliche, I like playing personally, just for myself. Moonlight sonata. I mean, I just. Moonlight's amazing. You know, I, you know, you're talking about comparing the blues and that sensibility from Europe. It's so different in so many ways. One of the musicians I play with. Is John Baptiste, who has the band on Colbert's show. And he'll sit there playing jazz and. Suddenly go into moonlight. He loves moonlight. And what's kind of interesting is he's. Found a way to do Beethoven. And by the way, he can really do Beethoven. He went through juilliard, and one time he was, one time he was at my house, he's saying, hey, do you have the book of Beethoven's last? To say, yeah, I want to find one I haven't played. Then he sight read through the whole damn thing perfectly, and I'm like, oh, God, I just get out of here. I can't even deal with this. But anyway. Yeah, but anyway, the thing is, he has this way of, with the same Persona and the same philosophy, moving from. The blues into Beethoven. That's really, really fascinating to me. It's like, um, I don't want to say he plays it as if it. Were jazz, but he kind of does. Yeah, it's kind of really. And he talks. He'll sight reason. He talks like Beethoven's talking to him. Like, he's like, oh, yeah, here he's doing this. He's. I can't do John, but, you know, it's like, it's really, it's really interesting. Like, it's very different. Like, for me, I was introduced to Beethoven as, like, almost like, this godlike figure. Figure, and I presume Pauline was, too. That was really kind of a press winner to deal with. And for him, it's just like he's playing James P. Johnson or something. It's like another musician who did something, and they're talking, and it's very cool to be around. It's very kind of freeing to see someone have that relationship. I would love to hear him play Ben ho. That sounds. That sounds amazing. He's great. We talked about Ernest Becker and how much value he puts on our mortality and our denial of our mortality. Do you think about your mortality? Do you think about your own death? You know what's funny is I used. To not be able to. But as you get older, you just know people who die, and there's all these things. It just becomes familiar and. More ordinary. Which is what it is. But are you afraid? Sure, although less so. And it's not like I didn't have. Some kind of insight or revelation to become less afraid. I think I just, like I say, it's kind of familiarity. It's just knowing people who have died. And I really believe in the future. I have this optimism that people or this whole thing of life on earth. This whole thing we're part of, I don't know where to draw that circle. But this thing is going somewhere and. Has some kind of value. And you can't both believe in the future and want to live forever. You have to make room for it. You know, like, you have to. That optimism has to also come with its own, like, humility. You have to make yourself small to believe in the future. And so it actually, in a funny way, comforts me. Wow, that's powerful. And optimism requires you to kind of step down after time. Yeah. I mean, that said, life seems kind of short, but, you know, whatever do you think there? I've tried to find. I can't find the complaint department. You know, I really want to. I want to bring this up, but. The customer service number never answers. And, like, the email bounces one way. Do you think there's meaning to it, to life? Ah, well, see, meaning's a funny word. Like, we say all these things as if we know what they mean, but meaning, we don't know what we mean when we say meaning. Like, we obviously do not. And it's a funny little mystical thing. I think it ultimately connects to that sense of experience that dualists tend to believe in, because there are. Why? Like, if you look up to the stars and you experience that awe inspiring, like, joy at whatever, when you look up to the stars, I don't know why. For me, that kind of makes me feel joyful, maybe a little bit melancholy, just some weird soup of feelings. And ultimately, the question is, like, why are we here in this vast universe? That question, why have you been able, in some way, maybe through music, answer it for yourself. My impulse is to feel like it's not quite the right question to ask. But I feel like going down that. Path is just too tedious for the. Moment, and I don't want to do it. But. The wrong question. Well, just because, you know, I don't know what meaning is, and I think I do know that sense of awe. I grew up in southern New Mexico. And the stars were so vivid. I've had some weird misfortunes, but I've. Had some weird luck also. One of our near neighbors was the. Head of optics research at White Sands. And when he was young, he discovered Pluto. His name was Clyde Tombaugh, and he. Taught me how to make telescopes, grinding mirrors and stuff. And my dad had also made telescopes when he was a kid. But Clyde had, like, backyard telescopes that. Would put to shame a lot of, like, I mean, he really. He did his telescopes, you know? And so I remember he'd let me go and play with him. And just like, looking at a globular. Cluster and you're seeing the actual photons. And with a good telescope, it's really like this object. Like, you can really tell this isn't. Coming through some intervening information structure. This is like the actual photons, and. It'S really a three dimensional object, and. You have even a feeling for the vastness of it. And I don't know. So I definitely, I was very, very. Fortunate to have a connection to this. Guy that way when I was a. Kid, to have had that experience again, the emphasis experience. It's kind of funny. I feel like sometimes I've taken. When she was younger, I took my. Daughter and her friends to a telescope. There are a few around here that. Kids can go and use. And they would look at Jupiter's moons. Or something, I think, like galilean moons. And I don't know if they quite had that because it's like too. It's been just too normalized. And I think maybe when I was. Growing up, screens weren't that common yet. And maybe it's, like, too confusable with a screen. I don't know. You know, somebody brought up in conversation to me somewhere, I don't remember who, but they kind of posited this idea that if humans, early humans, weren't able to see the stars, like, if Earth atmosphere was such that it was cloudy, that we would not develop human civilization. There's something about being able to look up and see a vast universe is like, that's fundamental to the development of human civilization. I thought that was a curious kind of thought. That reminds me of that old Isaac Asimov story where there's this planet where they finally get to see what's in. The sky once in a while, and it turns out they're in the middle. Of a globular cluster and they're all these stars. I forget what happens exactly. God, that's from when I was the. Same age as a kid, I don't. Really remember, but, yeah, I don't know. It might be right. I'm just thinking of all the civilizations. That grew up under clouds. I mean, like, the Vikings needed a special diffracting piece of mica to navigate. Because they could never see the sun. They had this thing called a sunstone that they found from this one cave. Do you know about that? So they were in this, like, they were trying to navigate boats in the north Atlantic without being able to see. The sun because it was cloudy. And so they used. A chunk of mica to diffract it in order to be able to align where the sun. Really was because they couldn't tell by eye and navigate. So I'm just saying there are a. Lot of civilizations that are pretty impressive. That have to deal with a lot of clouds. The Amazonians invented our agriculture, and they. They were probably under clouds a lot. I don't know. I don't know. To me personally, the. The question of the meaning of life becomes most vibrant, most apparent when you look up at the stars, because it makes me feel very small that we're small. But then you ask, it still feels that we're special. And then the natural question is like, well, if we are as special as I think we are, why the heck are we here in this vast universe? That ultimately is the question of. Right. Well, the meaning of life. I mean, look, there's a confusion sometimes. In trying to use. To set up a question or a thought experiment or something that's defined in. Terms of a context to explain something where there is no larger context. And that's a category error if we want to do it in physics, in computer science, it's hard to talk about. The universe as a Turing machine because a Turing machine has an external clock. And an observer and input and output. There's a larger context implied in order for it to be defined at all. And so if you're talking about the universe, you can't talk about it coherently as a Turing machine. Quantum mechanics is like that. Quantum mechanics has an external clock and has some kind of external context, depending on your interpretation. That's either, you know, the observer or whatever. And there's a. They're. They're similar that way. So maybe. Maybe Turing machines and quantum mechanics can. Be better friends or something because they have a similar setup. But the thing is, if you have. Something that's defined I in terms of an outer context, you can't talk about ultimates with it because obviously it's not suited for that. So there's some ideas that are their own context. General relativity is its own context. It's different. That's why it's hard to unify. And I think the same thing is. True when we talk about these types. Of questions, like meaning is in a. Context, and to talk about ultimate meaning is therefore category r. It's not. It's not a. It's not a resolvable way of thinking. It might be a way of thinking that is experientially or aesthetically valuable because it is awesome in the sense of, you know, awe inspiring. Um, but to try to treat it analytically is not sensible. Maybe that's what music and poetry are for. Yeah, maybe. I think so. I think music actually does escape any particular context. That's how it feels to me. But I'm not sure about that. That's, once again, crazy artists talking, not scientists. Well, you did, uh, you do both masterfully. Uh, Jaron, I'm, like I said, I'm a big fan of everything you've done of you as a human being. I appreciate the fun argument we had today that will, I'm sure, continue for 30 years, as it did with Mark Minsky. Honestly, I deeply appreciate that you spend your really valuable time with me today. It was a really great conversation. Thank you so much. Thanks for listening to this conversation with Jaron Lanier. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Jaron Lanier himself. A real friendship ought to introduce each person to unexpected weirdness in the other. Thank you for listening and hope to see you next time.

Utterances:
Speaker A: The following is a conversation with Jaron Lanier, a computer scientist, visual artist, philosopher, writer, futurist, musician, and the founder of the field of virtual reality. To support this podcast, please check out our sponsors in the description. As a side note, you may know that Jaron is a staunch critic of social media platforms. Him and I agree on many aspects of this, except perhaps I am more optimistic about it being possible to build better platforms and better artificial intelligence systems that put long term interests and happiness of human beings. First, let me also say a general comment about these conversations. I try to make sure I prepare well, remove my ego from the picture, and focus on making the other person shine as we try to explore the most beautiful and insightful ideas in their mind. This can be challenging when the ideas that are close to my heart are being criticized. In those cases, I do offer a little pushback, but respectfully and then move on, trying to have the other person come out looking wiser in the exchange. I think there is no such thing as winning in conversations, nor in life. My goal is to learn and to have fun. I ask that you dont see my approach to these conversations as weakness. It is not. It is my attempt at showing respect and love the other person. That said, I also often just do a bad job of talking, but you probably already knew that, so please give.
Speaker B: Me a pass on that as well.
Speaker A: This is the Lex Friedman podcast and here is my conversation with Jaron Lanier.
Speaker B: You're considered the founding father of virtual reality. Do you think we will one day spend most orlando, all of our lives in virtual reality worlds?
Speaker C: I have always found the very most valuable moment in virtual reality to be the moment when you take off the headset and your senses are refreshed and.
Speaker D: You perceive physicality afresh, you know, as if you were a newborn baby, but.
Speaker C: With a little more experience. So you can really notice just how.
Speaker D: Incredibly strange and delicate and peculiar and.
Speaker C: Impossible the real world is.
Speaker B: So the magic is, and perhaps forever will be in the physical world.
Speaker C: Well, that's my take on it.
Speaker D: That's just me. I mean, I think. I don't get to tell everybody else.
Speaker C: How to think or how to experience virtual reality.
Speaker D: And at this point, there have been.
Speaker C: Multiple generations of younger people who've come along and liberated me from having to.
Speaker D: Worry about these things. But I should say also even in what I called it mixed reality back.
Speaker C: In the day, and these days it's.
Speaker D: Called augmented reality, but with something like a HoloLens. Even then, one of my favorite things.
Speaker C: Is to augment a forest, not because I think the forest needs augmentation, but.
Speaker D: When you look at the augmentation next.
Speaker C: To a real tree, the real tree.
Speaker D: Just pops out as being astounding. It's interactive, it's changing slightly all the.
Speaker C: Time if you pay attention, and it's hard to pay attention to that. But when you compare it to virtual reality, all of a sudden you do. And even in practical applications, my favorite early application of virtual reality, which we prototyped going back to the eighties when I was working with doctor Joe Rosen at Stanford Med, near where we are.
Speaker D: Now, we made the first surgical simulator. And to go from the fake anatomy.
Speaker C: Of the simulation, which is incredibly valuable.
Speaker D: For many things, for designing procedures, for training, for all kinds of things, then to go to the real person, boy, it's really something like surgeons really get.
Speaker C: Woken up by that transition. It's very cool.
Speaker D: So I think the transition is actually.
Speaker C: More valuable than the simulation.
Speaker B: That's fascinating. I never really thought about that. It's almost. It's like traveling elsewhere in the physical space can help you appreciate how much you value your home once you return.
Speaker D: Well, that's how I take it. I mean, once again, people have different attitudes towards it.
Speaker C: All are welcome.
Speaker B: What do you think is the difference between the virtual world and the physical meat space world that you are still drawn for you personally, still drawn to the physical world? Like there clearly then, is a distinction. Is there some fundamental distinction or is it the peculiarities of the current set.
Speaker D: Of technology in terms of the kind.
Speaker C: Of virtual reality that we have now? It's made of software, and software is terrible stuff. Software is always the slave of its own history, its own legacy.
Speaker D: It's always infinitely, arbitrarily messy and arbitrary. Working with it brings out a certain.
Speaker C: Kind of nerdy personality in people, or.
Speaker D: At least in me, which I'm not that fond of. And there are all kinds of things about software I don't like, and so that's different from the physical world.
Speaker C: It's not something we understand, as you just pointed out. On the other hand, I'm a little mystified when people ask me, well, do you think the universe is a computer?
Speaker D: And I have to say, well, I mean, what on earth could you possibly.
Speaker C: Mean if you say it isn't a computer?
Speaker D: If it isn't a computer, it wouldn't follow principles consistently and it wouldn't be.
Speaker C: Intelligible, because what else is a computer ultimately? And we have physics, we have technology, so we can do technology, so we can program it.
Speaker D: So I mean, of course it's some kind of computer. But I think trying to understand it.
Speaker C: As a Turing machine is probably a foolish approach.
Speaker B: Right? That's the question. Whether it performs this computer we call the universe performs the kind of computation that can be modeled as a universal Turing machine. Or is it something much more fancy? So fancy, in fact, that it may be beyond our cognitive capabilities to understand.
Speaker D: Turing machines are kind of. I call them teases in a way, because, like, if you have an infinitely.
Speaker C: Smart programmer with an infinite amount of time, an infinite amount of memory and.
Speaker D: An infinite clock speed, then they're universal, but that cannot exist.
Speaker C: So they're not universal in practice, and.
Speaker D: They actually are, in practice, a very.
Speaker C: Particular sort of machine within the constraints.
Speaker D: Within the conservation principles of any reality that's worth being in, probably. And so I think universality of a particular model is probably a deceptive way to think, even though at some sort of limit.
Speaker C: Of course.
Speaker D: Something like that's got to be true at some sort of high enough limit, but it's just not accessible to us.
Speaker C: So what's the point?
Speaker B: Well, to me, the question of, like, whether we're living inside a computer or a simulation is interesting in the following way. There's a technical question is here, how difficult is it to build a machine, not that simulates the universe, but that makes it sufficiently realistic that we wouldn't know the difference, or better yet, sufficiently realistic that we would kind of know the difference, but we would prefer to stay in the virtual world anyway.
Speaker D: I want to give you a few different answers.
Speaker C: I want to give you the one.
Speaker D: That I think has the most practical importance to human beings right now, which is that there's a kind of an.
Speaker C: Assertion sort of built into the way the question's usually asked that I think.
Speaker D: Is false, which is a suggestion that.
Speaker C: People have a fixed level of ability to perceive reality in a given way. And actually people are always learning, evolving, forming themselves. We're fluid, too.
Speaker D: We're also programmable, self programmable, changing, adapting. And so my favorite way to get at this is to talk about the.
Speaker C: History of other media. So, for instance, there was a peer.
Speaker D: Review paper that showed that an early wire recorder playing back an opera singer.
Speaker C: Behind a curtain was indistinguishable from a real opera singer.
Speaker D: And so now, of course, to us.
Speaker C: It would not only be distinguishable, but it would be very blatant because the recording would be horrible.
Speaker D: But to the people at the time.
Speaker C: Without the experience of it, it seemed plausible.
Speaker D: There was an early demonstration of extremely.
Speaker C: Crude video teleconferencing between New York and.
Speaker D: DC in the thirties, I think so that people viewed as being absolutely realistic.
Speaker C: And indistinguishable, which to us would be horrible.
Speaker D: And there are many other examples. Another one of my favorite ones is in the Civil War era, there were.
Speaker C: Itinerant photographers who collected photographs of people.
Speaker D: Who just looked kind of like a few archetypes.
Speaker C: So you could buy a photo of.
Speaker D: Somebody who looked kind of like your loved one to remind you of that person. Because actually photographing them Washington, inconceivable.
Speaker C: And hiring a painter was too expensive, and you didn't have any way for the painter to represent them remotely anyway. How would they even know what they looked like?
Speaker D: So these are all great examples of how in the early days of different.
Speaker C: Media, we perceive the media as being really great. But then we evolved through the experience of the media.
Speaker D: This gets back to what I was saying.
Speaker C: Maybe the greatest gift of photography is that we can see the flaws in a photograph and appreciate reality more. Maybe the greatest gift of audio recording is that we can distinguish that operation.
Speaker D: Singer now from that recording of the.
Speaker C: Opera singer on the horrible wire recorder.
Speaker D: So we shouldn't limit ourselves by some assumption of stasis.
Speaker C: That's incorrect.
Speaker D: So that's the first thing.
Speaker C: That's my first answer, which is, I think, the most important one.
Speaker D: Now, of course, somebody might come back.
Speaker C: And say, oh, but you know, technology can go so far, there must be some point at which it would surpass. That's a different question. I think that's also an interesting question.
Speaker D: But I think the answer I just.
Speaker C: Gave you is actually the more important answer to the more important question.
Speaker A: That's profound.
Speaker B: Yeah. The second question, which you're now making me realize is way different. Is it possible to create worlds in which people would want to stay instead of the real world? Well, like unmask, like, large numbers of people.
Speaker D: What I hope is, you know, as.
Speaker C: I said before, I hope that the experience of virtual worlds helps people appreciate.
Speaker D: This physical world we have and feel tender towards it and keep it from.
Speaker C: Getting too fucked up. That's my hope.
Speaker B: Do you see all technology in that way? So basically, technology helps us appreciate the more sort of technology free aspect of life.
Speaker D: Well, media technology, you can stretch that. Let me say, I could definitely play.
Speaker C: McLuhan and turn this into a general theory.
Speaker D: It's totally doable. The program you just described is totally doable. In fact, I will psychically predict that.
Speaker C: If you did the research, you could find 20 PhD theses that do that already.
Speaker D: I don't know, but they might exist. But I don't know how much value there is in pushing a particular idea that far.
Speaker C: Claiming that reality isn't a computer in some sense seems incoherent to me because we have. We can program it, we have technology.
Speaker D: It has, it seems, to obey physical laws. What more do you want from it.
Speaker C: To be a computer? I mean, it's a computer of some kind. We don't know exactly what kind. We might not know how to think about it. We're working on it.
Speaker B: But sorry to draw, but you're absolutely right. Like, that's my fascination with the AI as well, is it helps in the case of AI, I see as a set of techniques that help us understand ourselves, understand us humans, in the same way, virtual reality, and you're putting it brilliantly. It's a way to help us understand reality, appreciate and open our eyes more richly to reality.
Speaker C: That's certainly how I see it.
Speaker D: And I wish people who become incredibly.
Speaker C: Fascinated, who go down the rabbit hole of the different fascinations with whether we're in a simulation or not.
Speaker D: Orlando, you know, there's a whole world of variations on that. I wish they'd step back and think.
Speaker C: About their own motivations and exactly what they mean.
Speaker D: You know, what? And I think the danger with these things is. So if you say, is the universe.
Speaker C: Some kind of computer? Broadly, it has to be, because it's.
Speaker D: Not coherent to say that it isn't. On the other hand, to say that.
Speaker C: That means, you know, anything about what kind of computer, that's something very different. And the same thing is true for the brain.
Speaker D: The same thing is true for anything where you might use computational metaphors. Like, we have to have a bit.
Speaker C: Of modesty about where we stand. And the problem I have with these framings of computation as these ultimate cosmic questions is that it has a way.
Speaker D: Of getting people to pretend they know.
Speaker C: More than they do.
Speaker B: Can you maybe this is a therapy session. Psychoanalyze me for a second. I really like the Elder Scrolls series. It's a role playing game. Skyrim, for example. Why do I enjoy so deeply just walking around that world? And then there's people and you could talk to and you can just, like it's an escape. But, you know, my life is awesome. I'm truly happy. But I also am happy with the. The music that's playing in the mountains and carrying around a sword and just that. I don't know what that is. It's very pleasant, though, to go there, and I miss it sometimes.
Speaker D: I think it's wonderful to love artistic creations.
Speaker C: It's wonderful to love contact with other people. It's wonderful to love play and ongoing.
Speaker D: Evolving meaning and patterns with other people, I think it's a good thing. You know, I'm not, I'm not, like.
Speaker C: Anti tech, and I'm certainly not anti digital tech.
Speaker D: I'm anti, as everybody knows by now. I think the, you know, manipulative economy.
Speaker C: Of social media is making everybody nuts and all that.
Speaker D: So I'm anti that stuff. But the core of it, of course.
Speaker C: I worked for many, many years on trying to make that stuff happen because.
Speaker D: I think it can be beautiful. Like, I I don't like.
Speaker C: Why not?
Speaker D: And by the way, there's a thing about humans, which is.
Speaker C: We'Re problematic. Any kind of social interaction with other people is gonna have its problems.
Speaker D: People are political and tricky. And, like, I love classical music, but.
Speaker C: When you actually go to a classical music thing and it turns out, oh, actually, this is like a backroom power deal kind of place and a big.
Speaker D: Status ritual as well, and that's kind of not as fun. That's part of the package. And the thing is, it's always going.
Speaker C: To be, there's always going to be a mix of things. I don't think the search for purity is going to get you anywhere.
Speaker D: So I'm not worried about that.
Speaker C: I worry about the really bad cases where we're making ourselves crazy or cruel enough that we might not survive.
Speaker D: And I think the social media criticism rises to that level. But I'm glad you enjoy it.
Speaker C: I think it's great.
Speaker B: And I like that. You basically say that every experience has both beauty and darkness, as in with classical music. I also play classical piano, so I appreciate it very much. But it's interesting. I mean, every, and even the darkness is a man's search for meaning. With Viktor Franco in concentration camps, even there, there's opportunity to discover beauty. And so it's, that's, that's the interesting thing about humans, is the capacity to discover beautiful in the darkest of moments. But there's always the dark parts, too.
Speaker D: Well, I mean, it's.
Speaker C: Our situation is structurally difficult. We are.
Speaker B: Structurally.
Speaker D: No, it is. It's true.
Speaker C: We perceive socially we depend on each.
Speaker D: Other for our sense of place and.
Speaker C: Perception of the world.
Speaker D: I mean, we're dependent on each other, and yet there's also a degree in which we're inevitably, we inevitably let each other down.
Speaker C: We are set up to be competitive as well as supportive. I mean, our fundamental situation is complicated and challenging.
Speaker D: And I wouldn't have it any other way.
Speaker B: Okay, let's talk about one of the most challenging things. One of the things I unfortunately am very afraid of being human. Allegedly, you wrote an essay on death and consciousness in which you write a note. Certainly the fear of death has been one of the greatest driving forces in the history of thought and in the formation of the character of civilization. And yet it is under acknowledged. The great book on the subject, the denial of Death by Ernest Becker, deserves a reconsideration. I'm russian, so I have to ask you about this. What's the role of death in life?
Speaker D: See, you would have enjoyed coming to our house. Cause my wife is russian. And we also have. We have a piano of such spectacular qualities, you would have freaked out. But anyway, we'll let all that go. So the context in which I remember.
Speaker C: That essay, sort of, this was from.
Speaker D: Maybe the nineties or something, and I used to publish in a journal called.
Speaker C: The Journal of Consciousness Studies, because I was interested in these endless debates about.
Speaker D: Consciousness and science, which certainly continue today. And I was interested in how the.
Speaker C: Fear of death and the denial of.
Speaker D: Death played into different philosophical approaches to consciousness. Because I think, on the one hand, this sort of sentimental school of dualism.
Speaker C: Meaning the feeling that there's something apart from the physical brain, some kind of.
Speaker D: Soul or something else, is obviously motivated.
Speaker C: In a sense by a hope that whatever that is will survive death and continue.
Speaker D: And that's the very core aspect of.
Speaker C: A lot of the world religions.
Speaker D: Not all of them, not really, but most of them. The thing I noticed is that the.
Speaker C: Opposite of those, which might be the sort of hardcore, no, the brain's a computer and that's it.
Speaker D: In a sense, we're motivated in the.
Speaker C: Same way with a remarkably similar chain.
Speaker D: Of arguments, which is, no, the brain's a computer, and I'm going to figure it out in my lifetime and upload it.
Speaker C: Upload myself and I'll live forever.
Speaker B: That's interesting. Yeah, that's the implied thought, right?
Speaker D: Yeah. And so it's kind of this, in a funny way, the same thing. It's peculiar to notice that these people who would appear to be opposites in character and cultural references and their ideas.
Speaker C: Actually are remarkably similar.
Speaker D: And to an incredible degree, the sort of hardcore computationalist idea about the brain.
Speaker C: Has turned into medieval Christianity together.
Speaker D: Like, there are the people who are.
Speaker C: Afraid that if you have the wrong.
Speaker D: Thought, you'll piss off the super AI's.
Speaker C: Of the future who will come back.
Speaker D: And zap you and all that stuff. It's like, it's really turned into medieval.
Speaker C: Christianity all over again.
Speaker B: This is so the Ernest Becker's idea that death, the fear of death, is the warm at the core, which is like, that's the core motivator of everything we see humans have created. The question is if that fear of mortality is somehow core is like a prerequisite.
Speaker D: You just moved across this vast cultural chasm that separates me from most of.
Speaker C: My colleagues, in a way, and I can't answer what you just said on the level without this huge deconstruction.
Speaker B: Yes.
Speaker D: Should I do it?
Speaker B: Yes. What's the chasm? Okay, let us travel across this vast.
Speaker D: Okay. I don't believe in AI. I don't think there's any AI. There's just algorithms.
Speaker C: We make them, we control them.
Speaker D: Now, they're tools.
Speaker C: They're not creatures. Now, this is something that rubs a.
Speaker D: Lot of people the wrong way. And don't I know it. When I was young, my main mentor.
Speaker C: Was Marvin Minsky, who's the principal author.
Speaker D: Of the computer as creature rhetoric that we still use.
Speaker C: He was the first person to have the idea at all, but he certainly.
Speaker D: Populated the AI culture with most of its tropes, I would say, because a lot of the stuff people will say.
Speaker C: Oh, did you hear this new idea about AI? And I'm like, yeah, I heard it in 1978.
Speaker D: Sure. Yeah, I remember that. So Marvin was really the person. And Marvin and I used to argue all the time about this stuff because I always rejected it. And of all of his, of all of his. I wasn't formally his student, but I.
Speaker C: Worked for him as a researcher.
Speaker D: But of all of his students and student like people, of his young adoptees, I think I was the one who.
Speaker C: Argued with him about this stuff in particular, and he loved it.
Speaker B: Yeah, I would have loved to hear that conversation.
Speaker D: It was fun.
Speaker B: Did you ever converge to a place?
Speaker D: Oh, no, no.
Speaker C: So the very last time I saw him, he was quite frail.
Speaker D: And I was in Boston, and I.
Speaker C: Was going to the old house in.
Speaker D: Brookline, his amazing house, and one of our mutual friends said, hey, listen, Marvin's so frail. Don't do the argument with him. Don't argue about AI. And so I said, but Marvin loves that. And so I showed up and he's.
Speaker C: Like, he was frail.
Speaker D: He looked up and he said, are you ready to argue?
Speaker B: He's such an amazing person.
Speaker D: Um, it's hard to summarize this because it's decades of stuff. The first thing to say is that nobody can claim absolute knowledge about whether somebody or something else is conscious or not.
Speaker C: This is all a matter of faith.
Speaker D: And, in fact, um, I think the.
Speaker C: Whole idea of faith needs to be updated. So it's not about God, but it's just about stuff in the universe, right? We have faith in each other being conscious.
Speaker D: And then I used to frame this.
Speaker C: As a thing called the circle of empathy in my old papers.
Speaker D: And then it turned into a thing.
Speaker C: For the animal rights movement, too. I noticed Peter Singer using it. I don't know if it was coincident or.
Speaker D: But anyway, there's this idea that you.
Speaker C: Draw a circle around yourself, and the.
Speaker D: Stuff inside is more like, you might.
Speaker C: Be conscious, might be deserving of your empathy, of your consideration.
Speaker D: And the stuff outside the circle isn't. And outside the circle might be a rock or. I don't know.
Speaker B: And that circle is fundamentally based on faith. Well, your faith in what is and what isn't.
Speaker D: The thing about the circle is it.
Speaker C: Can'T be pure faith. It also has. It's also a pragmatic decision.
Speaker D: And this is where things get complicated. If you try to make it too big, you suffer from incompetence. If you say, I don't want to.
Speaker C: Kill a bacteria, I will not brush my teeth. I don't know.
Speaker D: Like, what do you do?
Speaker C: There's a competence question where you do have to draw the line. People who make it too small become cruel.
Speaker D: People are so clannish and political and.
Speaker C: So worried about themselves ending up on.
Speaker D: The bottom of society that they are.
Speaker C: Always ready to gang up on some designated group. And so there's always these people who are being tried.
Speaker D: We're always trying to shove somebody out of the circle.
Speaker B: So aren't you shoving AI outside the circle?
Speaker D: Well, give me a second. All right, so there's a pragmatic consideration here, and the biggest questions are probably.
Speaker C: Fetuses and animals lately, but AI is getting there.
Speaker D: Now with AI, I think, and I've had this discussion so many times, people.
Speaker C: Would say, but aren't you afraid if you exclude AI, you'd be cruel to some consciousness?
Speaker D: And then I would say, well, if you include AI, you make yourself.
Speaker C: You exclude yourself from being able to be a good engineer or designer, and so you're facing incompetence immediately.
Speaker D: So, like, I really think we need.
Speaker C: To subordinate algorithms and be much more skeptical of them.
Speaker B: Your intuition. You speak about this brilliantly with social media, how things can go wrong. Isn't it possible to design systems that show compassion, not to manipulate you, but give you control and make your life better? If you so choose, to, like, grow together with systems and the way we grow with dogs and cats, with pets, with significant others, in that way they grow to become better people. I don't understand why that's fundamentally not possible. You're saying oftentimes you get into trouble by thinking, you know what's good for people.
Speaker D: Well, look, there's this question of what framework we're speaking in. Do you know who Alan Watts was?
Speaker C: So Alan Watts once said, morality is like gravity, that in some absolute cosmic sense, there can't be morality, because at some point it all becomes relative.
Speaker D: And who are we anyway?
Speaker C: Like, morality is relative to us tiny creatures.
Speaker D: But here on earth, we're with each other. This is our frame. And morality is a very real thing, same thing with gravity. At some point you get into interstellar.
Speaker C: Space, and you might not feel much.
Speaker D: Of it, but here we are on earth. And I think in the same sense, I think this identification with a frame that's quite remote cannot be separated from.
Speaker C: A feeling of wanting to feel sort of separate, separate from and superior to other people or something like that. There's an impulse behind it that I.
Speaker D: Really have to reject, and we're just.
Speaker C: Not competent yet to talk about these kinds of absolutes.
Speaker B: Okay, so I agree with you that a lot of technologists sort of lack this basic respect, understanding, and love for humanity. There's a separation there. The thing I'd like to push back against, it's not that you disagree, but I believe you can create technologies and you can create a new kind of technologist, engineer that does build systems that respect humanity. Not just respect, but admire humanity, that have empathy for common humans, have compassion.
Speaker D: I mean, no, no, no. I think. Yeah, I mean, I think musical instruments.
Speaker C: Are a great example of that. Musical instruments are technologies that help people connect in fantastic ways.
Speaker D: And that's a great example.
Speaker C: My invention or design during the pandemic period was this thing called together mode.
Speaker D: Where people see themselves seated sort of in a classroom or a theater instead of in squares, and it allows them to semi consciously perform to each other.
Speaker C: As if they have proper eye contact, as if they're paying attention to each other nonverbally. And weirdly, that turns out to work.
Speaker D: And so it promotes empathy, so far.
Speaker C: As I can tell. I hope, I hope it is of.
Speaker D: Some use to somebody. The AI idea isn't really new. I would say it was born with Adam Smith's invisible hand, with this idea that we build this algorithmic thing, and it gets a bit beyond us, and then we think it must be smarter than us.
Speaker C: And the thing about the invisible hand is, absolutely everybody has some line they.
Speaker D: Draw where they say, no, no, no, we're going to take control of this thing. They might have different lines, they might.
Speaker C: Care about different things, but everybody ultimately.
Speaker D: Became a Keynesian because it just didn't work. It really wasn't that smart. It was sometimes smart, and sometimes it failed. And so if you really, people who really, really, really want to believe in.
Speaker C: The invisible hand is infinitely smart, screw up their economies terribly.
Speaker D: You have to recognize the economy as a subservient tool.
Speaker C: Everybody does when it's to their advantage.
Speaker D: They might not when it's not to their advantage. That's kind of an interesting game that happens. But the thing is, it's just like that with our algorithms. You can have a Chicago economic philosophy about your computer, say, no, no, no, my things come alive. It's smarter than anything.
Speaker B: I think that there is a deep loneliness within all of us. This is what we seek. We seek love from each other. I think AI can help us connect deeper, like this. This is what you criticize social media for. I think there's much better ways of doing social media that doesn't lead to manipulation, but instead leads to deeper connection between humans, leads to you becoming a better human being. And what that requires is some agency on the part of AI to be almost like a therapist, I mean, a companion. It's not telling you what's right. It's not guiding you as if it's an all knowing thing. It's just another companion that you can leave at any time. You have complete transparency, control over. There's a lot of mechanisms that you can have that are counter to how current social media operates that I think is subservient to humans or. No, deeply respects human beings and is empathetic to their experience and all those kinds of things. I think it's possible to create AI systems like that. And I think they, I mean, that's a technical discussion of whether they need to have something that looks like more like AI versus algorithms, something that has identity, something that has a personality, all those kinds of things. AI systems. And you've spoken extensively how AI systems manipulate you within social networks. And that's a, the biggest, the biggest problem isn't necessarily that there's advertisement, that, you know, social networks present you with advertisements that then get you to buy stuff. That's not the biggest problem. The biggest problem is they then manipulate you. You're, they alter, like, your human nature to get you to buy stuff or to get you to do whatever the advertiser wants. Maybe you can correct.
Speaker D: Yeah, I don't see it quite that.
Speaker C: Way, but we can work with that as an approximation.
Speaker B: Sure.
Speaker D: So my, I think the actual thing is even sort of more ridiculous and stupider than that. But that's, that's okay.
Speaker C: Let's.
Speaker B: So my question is, let's not use the word AI, but how do we fix it?
Speaker D: Oh, fixing social media, that diverts us into this whole other field, in my view, which is economics, which I always thought was really boring, but we have.
Speaker C: No choice but to turn it to economists if we want to fix this.
Speaker D: Problem, because it's all about incentives. But I've been around this thing since it started, and I've been in the meetings where the social media companies sell.
Speaker C: Themselves to the people who put the most money into them, which are usually the big advertising holding companies and whatnot.
Speaker D: And there's this idea that I think is kind of a fiction, and maybe it's even been recognized as that by everybody, that the algorithm will get really.
Speaker C: Good at getting people to buy something.
Speaker D: Because I think people have looked at.
Speaker C: Their returns and looked at what happens, and everybody recognizes it's not exactly right.
Speaker D: It's more like a cognitive access blackmail payment at this point, just to be connected.
Speaker C: You're paying the money. It's not so much that the persuasion algorithms.
Speaker D: So Stanford renamed its program, but it used to be called engage.
Speaker C: Persuade. The engage part works. The persuade part is iffy.
Speaker D: But the thing is that once people are engaged, in order for you to.
Speaker C: Exist as a business, in order for.
Speaker D: You to be known at all, you put money into.
Speaker B: That's dark.
Speaker D: Oh, no, that's dark. It doesn't work.
Speaker B: But they have to.
Speaker D: But they're still.
Speaker C: It's a giant cognitive access blackmail scheme at this point.
Speaker D: So because the science behind the persuade part, it's not entirely, it's not entirely a failure, but it's not what there's. We play make believe that it works.
Speaker C: More than it does.
Speaker D: The damage doesn't come honestly, as I've said in my books, I'm not anti advertising. I actually think advertising can be demeaning and annoying and banal and ridiculous and.
Speaker C: Take up a lot of our time with stupid stuff.
Speaker D: Like, there's a lot of ways to criticize that advertising that's accurate, and it can also lie and all kinds of things. However, if I look at the biggest.
Speaker C: Picture, I think advertising, at least as.
Speaker D: It was understood before social media, helped.
Speaker C: Bring people into modernity in a way.
Speaker D: That overall actually did benefit people overall. And you might say, am I contradicting myself? Because I was saying you shouldn't manipulate people. Yeah, I am probably here. I mean, I'm not pretending to have.
Speaker C: This perfect, airtight worldview without some contradictions. I think there's a bit of a contradiction there.
Speaker B: So, you know, well, looking at the long arc of history, advertisement has in some parts benefited society.
Speaker D: Yeah.
Speaker B: Because they funded some efforts that perhaps.
Speaker D: Yeah, I mean, I think, like, there's a, there's a thing where sometimes I think it's actually been of some years now. Let's. Where the damage comes is a different thing, though. Social media, algorithms on social media have.
Speaker C: To work on feedback loops where they.
Speaker D: Present you with stimulus.
Speaker C: They have to see if you respond to the stimulus.
Speaker D: Now, the problem is that the measurement.
Speaker C: Mechanism for telling if you respond in.
Speaker D: The engagement feedback loop is very, very crude. It's things like whether you click more or occasionally if you're staring at the.
Speaker C: Screen more, if there's a forward facing camera that's activated, but typically there isn't. So you have this incredibly crude back channel of information.
Speaker D: And so it's crude enough that it only catches sort of the more dramatic responses from you.
Speaker C: And those are the fight or flight responses.
Speaker D: Those are the things where you get.
Speaker C: Scared or pissed off or aggressive or horny.
Speaker D: These are these ancient, what are sometimes.
Speaker C: Called the lizard brain circuits or whatever.
Speaker D: These fast response, old, old evolutionary business circuits that we have that are helpful.
Speaker C: In survival once in a while, but are not us at our best. They're not who we want to be, they're not how we relate to each other.
Speaker D: They're this old business. But it. So then, just when you're engaged using.
Speaker C: Those intrinsically, totally aside from whatever the.
Speaker D: Topic is, you start to get incrementally just a little bit more paranoid, xenophobic, aggressive, you know, you get a little stupid and like, you become a jerk.
Speaker C: And it happens slowly.
Speaker D: It's not like everybody's instantly transformed, but.
Speaker C: It does kind of happen progressively where.
Speaker D: People who get hooked kind of get.
Speaker C: Drawn more and more into this pattern of being at their worst.
Speaker B: Would you say that people are able to, when they get hooked in this way, look back at themselves from 30 days ago and say, I am less happy with who I am now, or I'm not happy with who I am now versus who I was 30 days ago? Are they able to self reflect when you take yourself outside of the lizard break?
Speaker D: Sometimes. I wrote a book about people suggesting.
Speaker C: People take a break from their social media to see what happens and maybe.
Speaker D: Even actually, the title of the book was just arguments to delete your account.
Speaker B: Ten arguments.
Speaker D: Although I always said, I don't know that you should.
Speaker C: I can give you the arguments. It's up to you.
Speaker D: I'm always very clear about that. But, you know, I get like, I don't have a social media account, obviously, and I, it's not that easy for.
Speaker C: People to reach me. They have to search out an old.
Speaker D: Fashioned email address on a super crappy, antiquated website. It's actually a bit. I don't make it easy. And even with that, I get this.
Speaker C: Huge flood of mail from people who.
Speaker D: Say, oh, I quit my social media. I'm doing so much better. I can't believe how bad it was. But the thing is, what's, for me.
Speaker C: A huge flood of mail would be.
Speaker D: An imperceptible trickle from the perspective of Facebook.
Speaker C: Right?
Speaker D: And so I think it's rare for.
Speaker C: Somebody to look at themselves and say, oh, boy, I sure screwed myself over.
Speaker D: It's a really hard thing to ask of somebody.
Speaker C: None of us find that easy.
Speaker D: Right.
Speaker B: Well, the reason I, it's hard. The reason I ask this is, is it possible to design social media systems that optimize for some longer term metrics of being happy with yourself? Personal growth.
Speaker C: I don't think you should try to engineer personal growth or happiness. I think what you should do is.
Speaker D: Design a system that's just respectful of.
Speaker C: The people and subordinates itself to the.
Speaker D: People and doesn't have perverse incentives, and.
Speaker C: Then at least there's a chance of something decent happening.
Speaker B: You have to recommend stuff. Right? So, but, so you're saying, like, be respectful. What does that actually mean engineering wise? Like people.
Speaker D: Yeah, curation. People have to, people have to be responsible.
Speaker C: Algorithms shouldn't be recommending, algorithms don't understand enough to recommend. Algorithms are crap in this era.
Speaker D: I mean, I'm sorry, they are like, and I'm not saying this as somebody.
Speaker C: As a critic from the outside, I'm.
Speaker D: In the middle of it.
Speaker C: I know what they can do.
Speaker D: I know the math, I know what the corpora are, you know, I know the best ones. Our office is funding GPT-3 and all these things that are, that are, you know, at the, at the edge of what's possible and they do not have yet. I mean, it still is statistical, emergent pseudo semantics.
Speaker C: It doesn't actually have deep representation emerging of anything.
Speaker D: It's just not like, I mean, that.
Speaker C: I'm speaking the truth here and you know it.
Speaker B: Well, let me push back on this. This. There's several truths here. So you're speaking to the way certain companies operate currently. I don't think it's outside the realm of what's technically feasible to do. There's just not incentive like companies are not. Why fix this thing? I am aware that, for example, the YouTube search and discovery has been very helpful to me and there's a huge number of. There's so many videos that it's nice to have a little bit of help.
Speaker C: Have you done.
Speaker B: But I'm still in control.
Speaker C: Let me ask you something. Have you done the experiment of letting YouTube recommend videos to you, either starting.
Speaker D: From a absolutely anonymous, random place where.
Speaker C: It doesn't know who you are or from knowing who you or somebody else is, and then going 15 or 20 hops? Have you ever done that?
Speaker D: And just let it go, top video.
Speaker C: Recommend and then just go 20 hops?
Speaker B: No, I have not.
Speaker D: I've done that many times now. I have.
Speaker C: Because of how large YouTube is and how widely it's used, it's very hard.
Speaker D: To get to enough scale to get a statistically solid result on this.
Speaker C: I've done it with high school kids, with dozens of kids doing it at a time.
Speaker D: Every time I've done an experiment, the.
Speaker C: Majority of times after about 17 or 18 hops, you end up in really weird, paranoid, bizarre territory.
Speaker D: Because ultimately that is the stuff the.
Speaker C: Algorithm rewards the most because of the feedback crudeness I was just talking about. I'm not saying that the video never recommends something cool.
Speaker D: I'm saying that its fundamental core is one that promotes a paranoid style that promotes increasing irritability, that promotes xenophobia, promotes fear, anger, promotes selfishness, promotes separation between people. And I would encourage. The thing is, it's very hard to do this work solidly.
Speaker C: Many have repeated this experiment and yet.
Speaker D: It still is kind of anecdotal. I'd like to do like a large, you know, citizen science thing sometime and do it. But then I think the problem with that is YouTube would detect it and then change it.
Speaker B: Yes, I definitely see. I love that kind of stuff in Twitter. So Jack Dorsey has spoken about doing healthy conversations on Twitter or optimizing for healthy conversations. What that requires within Twitter are most likely citizen experiments of what does healthy conversations actually look like and how do you incentivize those healthy conversations? You're describing what often happens and what is currently happening. What I'd like to argue is it's possible to strive for healthy conversations. Not in a dogmatic way of saying, I know what healthy conversations are, and I will tell you, I think one.
Speaker D: Way to do this is to try to look around at social, maybe not.
Speaker C: Things that are officially social media, but.
Speaker D: Things where people are together online and.
Speaker C: See which ones have more healthy conversations.
Speaker D: Even if it's hard to be completely.
Speaker C: Objective in that measurement, you can kind.
Speaker D: Of, at least crudely, you could do.
Speaker B: Subjective annotation, like have crowdsourced.
Speaker C: One that I've been really interested in.
Speaker D: Is GitHub, because it could change. I'm not saying it'll always be, but for the most part, GitHub has had.
Speaker C: A relatively quite low poison quotient.
Speaker D: And I think there's a few things.
Speaker C: About GitHub that are interesting. One thing about it is that people.
Speaker D: Have a stake in it. It's not just empty status games, there's actual code, or there's actual stuff being done. And I think as soon as you.
Speaker C: Have a real world stake in something.
Speaker D: You have a motivation to not screw up that thing. And I think that that's often missing, that there's a, there's no incentive for.
Speaker C: The person to really preserve something.
Speaker D: If they get a little bit of attention from dumping on somebody's TikTok or something, they don't pay any price for it. But you have to kind of get.
Speaker C: Decent with people when you have a shared stake, a little secret.
Speaker D: So GitHub does a bit of that.
Speaker B: GitHub is wonderful, yes. But I'm tempted to play the Jaron Becca at you, which is that. So GitHub is currently is amazing. But the thing is, if you have a stake, then if it's a social media platform, they can use the fact that you have a stake to manipulate you because you want to preserve the stake.
Speaker D: Right. Well, this is why this gets us into the economics.
Speaker C: So there's this thing called data dignity.
Speaker D: That I've been studying for a long time. I wrote a book about an earlier.
Speaker C: Version of it called who owns the future?
Speaker D: And the basic idea of it is that, once again, this is a 30 year conversation.
Speaker B: It's a fascinating topic.
Speaker D: Let me do the fastest version of this I can do. The fastest way I know how to do this is to compare two futures. Future one is then the normative one, the one we're building right now. And future two is going to be data dignity. I'm going to use a particular population.
Speaker C: I live on the hill in Berkeley.
Speaker D: One of the features about the hill is that as the climate changes, we might burn down and I'll lose our houses or die or something like it's.
Speaker C: Dangerous, and it didn't used to be.
Speaker D: And so who keeps us alive? Well, the city does. The city does some things. The electric company kind of, sort of, maybe, hopefully better individual people who own property, take care of their property.
Speaker C: That's all nice. But there's this other middle layer, which.
Speaker D: Is fascinating to me, which is that the groundskeepers who work up and down that hill, many of whom are not.
Speaker C: Legally here, many of whom don't speak.
Speaker D: English, cooperate with each other to make.
Speaker C: Sure trees don't touch, to transfer fire easily from lot to lot. They have this whole little web that's keeping us safe. I didn't know about this at first.
Speaker D: I just started talking to them because.
Speaker C: They were out there during the pandemic. And so I try to just see, who are these people?
Speaker D: Who are these people who are keeping us alive? Now I want to talk about the.
Speaker C: Two different fates for those people in your future one and future two.
Speaker D: Future one, some weird, like, kindergarten paint job van with all these, like, cameras and where things drives up, observes what.
Speaker C: The gardeners and groundskeepers are doing.
Speaker D: A few years later, some amazing robots that can shimmy up trees and all this show up.
Speaker C: All those people are out of work and there are these robots doing the thing, and the robots are good and.
Speaker D: They can scale to more land and they're actually good. But then there are all these people out of work, and these people have lost dignity. They don't know what they're going to do. And then somebody will say, well, they.
Speaker C: Go on basic income, whatever.
Speaker D: They become wards of the state.
Speaker C: My problem with that solution is every time in history that you've had some centralized thing that's doling out the benefits, that things get seized by people because it's too centralized and it gets seized. That's happened to every communist experiment I can find.
Speaker D: So I think that turns into a poor future that will be unstable. I don't think people will feel good in it.
Speaker C: I think it'll be a political disaster.
Speaker D: With a sequence of people seizing this central source of the basic income. And you'll say, oh, no, an algorithm can do it.
Speaker C: Then people will seize the algorithm. They'll seize control.
Speaker B: Unless the algorithm is decentralized and it's impossible to seize the control.
Speaker D: Yeah, but 60 something people own a.
Speaker C: Quarter of all the bitcoin.
Speaker D: The things that we think are decentralized are not decentralized. So let's go to future two. Future two, the gardeners see that van.
Speaker C: With all the cameras and the kindergarten.
Speaker D: Paint job, and they say the groundskeepers and they say, hey, the robots are coming.
Speaker C: We're going to form a data union. And amazingly, California has a little baby data union law emerging in the books.
Speaker D: Yeah, and what they say, they say.
Speaker C: We'Re going to form a data union.
Speaker D: And we're going to.
Speaker C: Not only are we going to sell our data to this place, but we're.
Speaker D: Going to make it better than it would have been if they were just grabbing it without our corporation. And we're going to improve it, we're.
Speaker C: Going to make the robots more effective, we're going to make them better and we're going to be proud of it.
Speaker D: We're going to become a new class of experts that are respected. And then here's the interesting there's two things that are different about that world from future one. One thing, of course, the people have more pride, they have more sense of ownership, of agency. But what the robots do changes. Instead of just this functional.
Speaker C: We'll figure out how to keep the neighborhood from burning down.
Speaker D: You have this whole creative community that.
Speaker C: Wasn'T there before, thinking, well, how can we make these robots better so we can keep on earning money?
Speaker D: There'll be waves of creative groundskeeping with spiral pumping pumpkin patches, and waves of cultural things. There'll be new ideas like, wow, I.
Speaker C: Wonder if we could do something about climate change mitigation with how we do this. What about fresh water? Can we make the food healthier?
Speaker D: What about all of a sudden, there'll.
Speaker C: Be this whole creative community on the case?
Speaker D: And isn't it nicer to have a.
Speaker C: High tech future with more creative classes than one with more dependent classes? Isn't that a better future?
Speaker D: But future one and future two have.
Speaker C: The same robots and the same algorithms. There's no technological difference, there's only a human difference.
Speaker B: Yeah.
Speaker D: And that second future, too, that's data dignity.
Speaker B: The economy that you're. I mean, the game theory here is on the humans, and then the technology is just the tools that enable.
Speaker C: Yeah.
Speaker D: You know, I mean, I think you can believe in AI and be in.
Speaker C: Future two, I just think it's a little harder.
Speaker D: You have to do more contortions. It's possible.
Speaker B: So in the case of social media, what does data dignity look like? Is it people getting paid for their data?
Speaker D: Yeah, I think what should happen is in the future, there should be massive data unions for people putting content into the system, and those data unions should.
Speaker C: Smooth out the results a little bit.
Speaker D: So it's not winner take all, but at the same time, and people have.
Speaker C: To pay for it.
Speaker D: Too. They have to pay for Facebook the way they pay for Netflix, with an.
Speaker C: Allowance for the poor.
Speaker D: There has to be a way out, too. But the thing is, people do pay for Netflix. It's a going concern. People pay for Xbox and PlayStation. There's enough people to pay for stuff they want. This could happen, too.
Speaker C: It's just that this precedent started that moved it in the wrong direction.
Speaker D: And then what has to happen? The economy is a measuring device. If it's an honest measuring device, the.
Speaker C: Outcomes for people form a normal distribution, a bell curve. And then, so there should be a.
Speaker D: Few people who do really well, a lot of people who do okay, and.
Speaker C: Then we should have an expanding economy reflecting more and more creativity and expertise flowing through the network. And that expanding economy moves the result.
Speaker D: Just a bit forward. So more people are getting money out.
Speaker C: Of it, then are putting money into it. So it gradually expands the economy and lifts all boats.
Speaker D: And the society has to support the.
Speaker C: Lower wing of the bell curve, too.
Speaker D: But not universal basic income. It has to be for the, you know, because if it's an honest.
Speaker C: If it's an honest economy, there will.
Speaker D: Be that lower wing, and we have to support those people. There has to be a safety net. But see, what I believe, I'm not.
Speaker C: Going to talk about AI, but I.
Speaker D: Will say that I think there'll be.
Speaker C: More and more algorithms that are useful.
Speaker D: And so I don't think everybody's going.
Speaker C: To be supplying data to groundskeeping robots.
Speaker D: Nor do I think everybody's going to.
Speaker C: Make their living with TikTok videos.
Speaker D: I think in both cases, there'll be a rather small contingent that do well.
Speaker C: Enough at either of those things.
Speaker D: But I think there might be many.
Speaker C: Many, many of those niches that start to evolve as there are more and more algorithms, more and more robots.
Speaker D: And it's that large number that will.
Speaker C: Create the economic potential for a very.
Speaker D: Large part of society to become members.
Speaker C: Of new creative classes.
Speaker B: Do you think it's possible to create a social network that competes with Twitter and Facebook that's large and centralized in this way? Not centralized or large, large.
Speaker D: So I got to tell you, how to get from what I'm talking, how.
Speaker C: To get from where we are to.
Speaker D: Anything kind of in the zone of what I'm talking about is challenging.
Speaker C: I know some of the people who.
Speaker D: Run like I know Jack Dorsey, and I view Jack as somebody who's actually.
Speaker C: I think he's really striving and searching.
Speaker D: And finding and trying to find a way to make it better, but is kind of like, it's very hard to.
Speaker C: Do it while in flight. And he's under enormous business pressure, too.
Speaker B: Um, so Jack Dorsey, to me, is a fascinating study, because I think his mind is in a lot of good places. He's. He's a good human being, but there's a big titanic ship that's already moving in one direction. It's hard to know what to do with that.
Speaker C: I think that's the story of Twitter.
Speaker D: I think that's the story of Twitter. Um, one of the things that I observe is that if you just want.
Speaker C: To look at the human side, meaning, like, how are people being changed?
Speaker D: How do they feel?
Speaker C: What is the culture?
Speaker D: Like? Almost all of the social media platforms.
Speaker C: That get big have an initial sort of honeymoon period where they're actually kind.
Speaker D: Of sweet and cute. Like, if you look at the early.
Speaker C: Years of Twitter, it was really sweet.
Speaker D: And cute, but also look at snap TikTok. And then what happens is, as they scale and the algorithms become more influential.
Speaker C: Instead of just the early people, when.
Speaker D: It gets big enough that it's the algorithm running it, then you start to.
Speaker C: See the rise of the paranoid, and then they start to get dark. And we've seen that shift in TikTok.
Speaker B: Rather recently, but I feel like that scaling reveals the flaws within the incentives.
Speaker D: I feel like I'm torturing you. I'm sorry.
Speaker B: It's not torture. No. Because I have hope for the world with humans, and I've hope for a lot of things that humans create, including technology. And I just, I feel it is possible to create social media platforms that incentivize different things than the current. I think the current incentivization is around, like, the dumbest possible thing that was invented, like, 20 years ago, however long. And it just works. And so nobody's changing it. I just think that there could be a lot of innovation for more. See, you kind of push back this idea that we can't know what long term growth or happiness is. If you give control to people to define what their long term happiness and goals are, then that optimization can happen for each of those individual people.
Speaker D: Well, I mean, imagine a future where probably a lot of people would love to make their living doing TikTok dance.
Speaker C: Videos, but people recognize generally, that's kind of hard to get into. Nonetheless, dance crews have an experience that's very similar to programmers working together on GitHub. So the future is like a cross between TikTok and GitHub, and they get.
Speaker D: Together, and they have rights.
Speaker C: They're negotiating. They're negotiating for returns. They join different artist societies in order to soften the blow of the randomness.
Speaker D: Of who gets the network effect benefit, because nobody can know that. And I think an individual person might.
Speaker C: Join a thousand different data unions in the course of their lives, or maybe even 10,000, I don't know.
Speaker D: But the point is that we'll have these very hedge distributed portfolios of different.
Speaker C: Data unions we're part of, and some of them might just trickle in a little money for nonsense stuff where we're.
Speaker D: Contributing to health studies or something. I think people will find their way.
Speaker C: They'Ll find their way to the right.
Speaker D: GitHub like community in which they find their value in the context of supplying inputs and data and taste and correctives.
Speaker C: And all of this into the algorithms and the robots of the future.
Speaker B: And that is a way to resist the lizard brain based funding mechanisms.
Speaker D: It's an alternate economic system that rewards productivity, creativity, value as perceived by others. It's a genuine market.
Speaker C: It's not doled out from a center.
Speaker D: There's not some communist person deciding who's valuable, it's actual market. And the money is made by supporting that instead of just grabbing people's attention.
Speaker C: In the cheapest possible way.
Speaker D: Which is definitely how you get the lizard brain.
Speaker B: Yeah. Okay, so we're finally at the agreement, but I just think that. So, yeah, I'll tell you how I think. Fix social media. There's a few things. There's a few things. So, one, I think people should have complete control over their data and transparency of what that data is and how it's being used. If they do hand over the control. Another thing they should be able to delete. Walk away with their data at any moment. Easy, like with a single click of a button, maybe two buttons, I don't know, just easily walk away with their data. The other is control of the algorithm, individualized control of the algorithm for them. So each one has their own algorithm, each person has their own algorithm. They get to be the decider of what they see in this world. And to me, that, I mean, that's, I guess, fundamentally decentralized in terms of the key decisions being made. But if that's made transparent, I feel like people will choose that system over Twitter of today, over Facebook of today, when they have the ability to walk away to control their data and to control the kinds of thing they see. Now, let's walk away from the term AI. You're right. In this case, you have full control of the algorithms that help you if you want to use their help, but you can also say f you to those algorithms and just consume the raw, beautiful waterfall of the Internet. I think that to me, that's not only fixes social media, but I think you'll make a lot more money. So I would like to challenge the idea. I know you're not presenting that, but that the only way to make a ton of money is to operate like Facebook is I think you can make more money by giving people control.
Speaker C: Yeah, I mean, I certainly believe that we're definitely in the territory of wholehearted agreement here.
Speaker D: I do want to caution against one thing, which is making a future that benefits programmers versus people like this idea.
Speaker C: That people are in control of their data.
Speaker D: So years ago, I co founded an.
Speaker C: Advisory board for the EU with a guy named Giovanni Butarelli, who passed away.
Speaker D: It's one of the reasons I wanted to mention it. A remarkable guy who'd been, he was originally a prosecutor who was throwing mafioso in jail in Sicily. So he's like this intense guy who is like, I've dealt with death threats. Mark Zuckerberg doesn't scare me. Whatever. So we worked on this path of.
Speaker C: Saying, let's make it all about transparency and consent, and it was one of the feeders that led to this huge.
Speaker D: Data privacy and protection framework in Europe called the GDPR. So therefore, we've been able to have.
Speaker C: Empirical feedback on how that goes.
Speaker D: And the problem is that most people actually get stymied by the complexity of that kind of management. They have trouble, and reasonably so.
Speaker C: I don't, I'm like a techie, you.
Speaker D: Know, I can go in and I can figure out what's going on, but most people really do, and why. And so there's a problem that it, it differentially benefits those who have a technical mindset and can go in and sort of have a feeling for how this stuff works. I kind of still want to come back to incentives, and so if the incentive for whoever is, if the commercial.
Speaker C: Incentive is to help the creative people.
Speaker D: Of the future make more money because you get a cut of it, that's.
Speaker C: How you grow an economy.
Speaker B: Not the programmers.
Speaker D: Well, some of them will be programmers. It's not anti programmer. I'm just saying that, um, it's not only programmers, you know?
Speaker B: So, uh, I mean, I definitely. So, yeah, yeah, you have to make sure the incentives are right. I mean, I like, control is an interface problem to where you have to create something that's, that's compelling to everybody, to the creatives, to the public. I mean, there's um, I don't know, creative commons, like the licensing, you know, there's a bunch of legal speak, just in general, the whole legal profession. It's nice when it can be simplified in the way that you can truly simply understand. Everybody can simply understand the basics. In that same way, it should be very simple to understand how the data is being used and what data is being used for people. But then you're arguing that in order for that to happen, you have to have the incentives.
Speaker D: I mean, a lot of the reason.
Speaker C: That money works is actually information hiding and information loss.
Speaker D: Like, one of the things about money is a particular dollar you get might have passed through your enemy's hands and you don't know it. But also, I mean, this is what Adam Smith, if you want to give.
Speaker C: The most charitable interpretation possible to the invisible hand, is what he was saying.
Speaker D: Is that there's this whole complicated thing, and not only do you not need.
Speaker C: To know about it, the truth is you'd never be able to follow it if you tried.
Speaker D: And just let the economic incentives solve.
Speaker C: For this whole thing.
Speaker D: And that, in a sense, every transaction.
Speaker C: Is like a neuron and a neural net. If he'd had that metaphor, he would.
Speaker D: Have used it and let the whole.
Speaker C: Thing settle to a solution.
Speaker D: And don't worry about it. I think this idea of having incentives that reduce complexity for people can be made to work.
Speaker C: And that's an example of an algorithm that could be manipulative or not. Going back to your question before about can you do it in a way that's not manipulative?
Speaker D: And I would say a GitHub. Like, if you just have this vision, GitHub plus TikTok combined, is it possible? I think it is.
Speaker B: I'm not going to be able to unsee that idea of creatives on TikTok collaborating in the same way people on GitHub collaborate. I like that kind of version.
Speaker D: Why not?
Speaker B: I like it. I love it.
Speaker D: I just like right now when people use, by the way, father of teenage.
Speaker B: Daughters, it's all about TikTok, right?
Speaker D: So, you know, when people use TikTok, there's a lot of, it's kind of funny.
Speaker C: I was going to say cattiness, but I was just using the cat as.
Speaker D: This exemplar of overcoming.
Speaker C: I contradict myself.
Speaker D: But anyway, there's all this cattiness where people are like this person, and I just, what about people getting together in.
Speaker C: Kitchen saying, okay, we're gonna work on this move.
Speaker D: We're gonna get a bit of, can we get a better musician like, and they do that. But that's the part that's kind of.
Speaker C: Off the books right now. You know, that should be, like, right there. That should be the center.
Speaker D: That's where the. That's the really best part.
Speaker B: Well, that's. That's where the invention of git, period, the versioning, is brilliant. And so some of the. Some of the things you're talking about, technology, algorithms, tools can empower. That's the thing for humans to connect, to, collaborate and so on. Can we. Can we upset more people a little bit? You already.
Speaker D: Maybe?
Speaker C: We'd have to try.
Speaker B: No, no. Can we can ask you to elaborate, because my intuition was that you would be a supporter of something like cryptocurrency and bitcoin, because it is fundamentally emphasizes decentralization. What do you. So, can you elaborate on.
Speaker D: Okay, look.
Speaker B: Your thoughts on bitcoin?
Speaker D: It's kind of funny.
Speaker C: I've been advocating some kind of digital.
Speaker D: Currency for a long time, and when.
Speaker C: Bitcoin came out and the original paper.
Speaker D: On blockchain, my heart kind of sank, because I thought, oh, my God, we're.
Speaker C: Applying all of this fancy thought and.
Speaker D: All these very careful, distributed security measures to recreate the gold standard. Like, it's just so retro, it's so dysfunctional, it's so useless from an economic point of view. So it's always.
Speaker C: And then the other thing is, using computational inefficiency at a boundless scale as your form of security is a crime against the atmosphere.
Speaker D: Obviously, a lot of people know that now, but we knew that at the start. Like, the thing is, when the first paper came out, I remember a lot.
Speaker C: Of people saying, oh, my God, this thing scales. It's a carbon disaster.
Speaker D: And I'm just mystified. But that's a different question than when you asked, can you have a cryptographic currency or at least some kind of.
Speaker C: Digital currency that's of a benefit and.
Speaker D: Absolutely. And there are people who are trying.
Speaker C: To be thoughtful about this. If you haven't, you should interview Vitalik Buterin.
Speaker B: Sometimes twice.
Speaker D: Okay. So, like, there are people in the.
Speaker C: Community who are trying to be thoughtful and trying to figure out how to do this better.
Speaker B: It has nice properties, though, right? So one of the nice properties is that, like, government centralized, it's hard to control. And then the other one to fix some of the issues that you're referring to, I'm sort of playing devil's advocate here, is, you know, there's lightning network, there's ideas how to. How you build stuff on top of bitcoin, similar with gold, that allow you to have this kind of vibrant economy that operates not on the blockchain, but outside the blockchain, and uses bitcoin for checking the security of those transactions.
Speaker D: So bitcoin's not new.
Speaker C: It's been around for a while.
Speaker D: I've been watching it closely. I've not seen one example of it creating economic growth. There was this obsession with the idea.
Speaker C: That government was the problem. That idea that government's the problem.
Speaker D: Let's say government earned that wrath, honestly. Because if you look at some of the things that governments have done in.
Speaker C: Recent decades, it's not a pretty story.
Speaker D: Like after.
Speaker C: After a very small number of people in the US, government decided to bomb.
Speaker D: And landmine Southeast Asia, it's hard to come back and say, oh, government's this great thing. But then I. The problem is that this resistance to.
Speaker C: Government is basically a resistance to politics.
Speaker D: It's a way of saying, if I.
Speaker C: Can get rich, nobody should bother me. It's a way of not having obligations to others. And that ultimately is a very suspect motivation.
Speaker B: But does that mean that the impulse that the government should not overreach its power is flawed?
Speaker D: I mean, what I want to ask you to do is to replace the.
Speaker C: Word government with politics.
Speaker D: Like our politics, is people having to deal with each other. My theory about freedom is that the only authentic form of freedom is perpetual annoyance. All right, so annoyance means you're actually dealing with people because people are annoying.
Speaker C: Perpetual means that that annoyance is survivable, so it doesn't destroy us all. So if you have perpetual annoyance, then you have freedom.
Speaker B: And that's politics.
Speaker C: That's politics.
Speaker D: If you don't have perpetual annoyance, something's.
Speaker C: Gone very wrong and you suppress those people, it is only temporary.
Speaker D: It's going to come back and be horrible.
Speaker C: You should seek perpetual annoyance.
Speaker D: I'll invite you to a Berkeley city.
Speaker C: Council meeting so you can know what.
Speaker D: That feels like, what professional feels like. But anyway, so freedom is being. The test of freedom is that you're annoyed by other people.
Speaker C: If you're not, you're not free. If you're nothing, you're trapped in some temporary illusion that's going to fall apart.
Speaker D: Now, this quest to avoid government is.
Speaker C: Really a quest to avoid that political feeling, but you have to have it.
Speaker D: You have to deal with it, and it sucks.
Speaker C: But that's the human situation, that's the human condition. And this idea that we're going to have, this abstract thing that protects us from having to deal with each other is always an illusion.
Speaker B: The idea, and I apologize, I overstretched these. The word government. The idea is there should be some punishment from the people when a group, when a bureaucracy, when a set of people, or a particular leader, like in an authoritarian regime, which more than half the world currently lives under, if you like, if they become. They start stop representing the people. It stops being like a Berkeley meeting and starts being more like. Like a dictatorial kind of situation. And so the point is, it's nice to give people, the populace, in decentralized way, power to resist that kind of like government becoming over autonomous.
Speaker D: Yeah, but people see, this idea that.
Speaker C: The problem is always the government being powerful is false. The problem can also be criminal gangs. The problem can also be weird cults. The problem can be.
Speaker D: Abusive clergy. The problem can be infrastructure that fails.
Speaker C: The problem can be poisoned water. The problem can be failed electric grids.
Speaker D: The problem can be.
Speaker C: A crappy education.
Speaker D: System that makes the whole society less.
Speaker C: And less able to create value. There are all these other problems that are different from an overbearing government. You have to keep some sense of perspective and not be obsessed with only one kind of problem, because then the others will pop up.
Speaker B: But empirically speaking, some problems are bigger than others. So, like, some, like, groups of people, like governments or gangs or companies lead.
Speaker D: Are you a us citizen?
Speaker B: Yes.
Speaker D: Has the government ever really been a problem for you?
Speaker B: Well, okay. So, first of all, I grew up in the soviet union. Used to.
Speaker D: And actually, yeah, my wife did, too.
Speaker B: So I have seen, you know.
Speaker D: Sure.
Speaker B: And has the government bothered me? I would say that that's a really complicated question, especially because the United States is such. It's a special place, like a lot of other countries.
Speaker D: My wife's family were refused nics, and.
Speaker C: So we have, like, a very.
Speaker D: And her dad was sent to the gulag. For what it's worth, on my father's.
Speaker C: Side, all but a few were killed.
Speaker D: By a pogrom in a post soviet pogrom in Ukraine.
Speaker B: So I would say, because you did a little trick of eloquent trick of language, that you switched to the United States to talk about government. So I believe, unlike my friend Michael Malice, who's an anarchist, I believe government can do a lot of good in the world. That is exactly what you're saying, which is. It's politics. The thing that bitcoin folks and cryptocurrency folks argue is that one of the big ways that government can control the populace is centralized. Bank like, control the money. That was the case in the Soviet Union, too. There's, you know, inflation can really make poor people suffer. And so what they argue is this is one way to go around that power that government has of controlling the monetary system. So that's a way to resist. That's not actually saying government bad. That's saying some of the ways that central banks get into trouble can be resisted through centralized.
Speaker D: Preston, so let me ask you, on.
Speaker C: Balance today in the real world, in.
Speaker D: Terms of actual facts, do you think.
Speaker C: Cryptocurrencies are doing more to prop up corrupt, murderous, horrible regimes or to resist those regimes? Where do you think the balance is right now?
Speaker B: I know. Exactly. Having talked to a lot of cryptocurrency folks, what they would tell me, right. It's hard. It's. I don't, no, no, I'm asking it.
Speaker D: As a real question. There's no way to know the answer.
Speaker B: There's no way to know the answer perfectly.
Speaker D: However, I gotta say, if you look at people who've been able to decode a blockchains, and they do leak a.
Speaker C: Lot of data, they're not as secure as it's widely thought.
Speaker D: There are a lot of unknown bitcoin.
Speaker C: Whales from pretty early, and they're huge.
Speaker D: And if you ask, who are these people?
Speaker C: There's evidence that a lot of them are quite not the people you'd want to support. Let's say.
Speaker D: I think empirically this idea.
Speaker C: That there's some intrinsic way that bad.
Speaker D: Governments will be, will be disempowered and.
Speaker C: People will be able to resist them.
Speaker D: More than new villains or even villainous.
Speaker C: Governments will be empowered. There's no basis for that assertion.
Speaker D: It just is kind of circumstantial. And I think in general, bitcoin ownership.
Speaker C: Is one thing, but bitcoin transactions have.
Speaker D: Tended to support criminality more than productivity.
Speaker B: Of course, they would argue that was the story of its early days, that now more and more bitcoin is being used for legitimate transactions.
Speaker D: But that's a different. I didn't say for legitimate transactions, I.
Speaker C: Said for economic growth, for creativity.
Speaker D: Like, I think what's happening is people.
Speaker C: Are using it a little bit for.
Speaker D: Buying, I don't know, maybe somebody's companies.
Speaker C: Make it available for this and that they buy a Tesla with it or something.
Speaker D: Investing in a startup hard, it might have happened a little bit, but it's.
Speaker C: Not an engine of productivity, creativity and economic growth, whereas old fashioned currency still is.
Speaker D: And anyway, look, I think something. I'm pro the idea of digital currencies. I am anti the idea of economics wiping out politics as a result, I think they have to exist in some balance to avoid the worst dysfunctions of each.
Speaker B: In some ways, there's parallels to our discussion of algorithms and cryptocurrency is you're pro the idea, but it can be used to manipulate. You can be used poorly by aforementioned humans.
Speaker D: Well, I think that you can make.
Speaker C: Better designs and worse designs.
Speaker D: And I think, and you know, the.
Speaker C: Thing about cryptocurrency that's so interesting is.
Speaker D: How many of us are responsible for the poor designs, because we're all so hooked on that Horatio Alger story on, like, I'm going to be the one.
Speaker C: Who gets the viral benefit.
Speaker D: You know, way back when all this stuff was starting, I remember it would.
Speaker C: Have been in the eighties, somebody had the idea of using viral as a metaphor for network effect.
Speaker D: And the whole point was to talk about how bad network effect was, that it always created distortions that ruined the usefulness of economic incentives, that that created dangerous distortions. But then somehow, even after the pandemic.
Speaker C: We think of viral as this good thing because we imagine ourselves as the virus, right?
Speaker D: We want to be on the beneficiary side of it. But of course, you're not likely to be.
Speaker B: There is a sense, because money is involved, people are not reasoning clearly, always, because they want to be. They want to be part of that first viral wave that makes them rich, and that blinds people from their basic morality.
Speaker C: I had an interesting conversation.
Speaker D: I sort of feel like I should respect some people's privacy, but some of the initial people who started bitcoin, I remember having an argument about, like, it's.
Speaker C: Intrinsically a Ponzi scheme. Like, you know, the early people have more than the later people.
Speaker D: And the further down the chain you.
Speaker C: Get, the more you're subject to gambling like dynamics, where it's more and more random and more and more subject to.
Speaker D: Weird network effects and whatnot. Unless you're a very small player, perhaps, and you're just buying something, but even.
Speaker C: Then you'll be subject to fluctuations, because.
Speaker D: The whole thing is just kind of like that. As it fluctuates, it's going to wave.
Speaker C: Around the little people more.
Speaker D: And I remember the conversation turned to.
Speaker C: Gambling, because gambling is a pretty large.
Speaker D: Economic sector, and it's always struck me as being non productive.
Speaker C: Like, somebody goes to Las Vegas and they lose money.
Speaker D: And so one argument is, well, they got entertainment.
Speaker C: They paid for entertainment as they lost money, so that's fine.
Speaker D: And Las Vegas does up the losing.
Speaker C: Of money in an entertaining way, so why not? It's like going to a show.
Speaker D: So that's one argument. The argument that was made to me.
Speaker C: Was different from that.
Speaker D: It's that, no, what they're doing is.
Speaker C: They'Re getting a chance to experience hope, and a lot of people don't get that chance. And so that's really worth it. Even if they're going to lose. They have that moment of hope and.
Speaker D: They need to be able to experience that.
Speaker C: And it's a very interesting argument.
Speaker B: That's so heartbreaking, because I. Well, but I've seen that I have that a little bit of a sense. I've talked to some young people who invest in cryptocurrency, and what I see is this hope. This is the first thing that gave them hope. And that's so heartbreaking to me that you've gotten hope from. So much is invested. It's like hope from somehow becoming rich as opposed to something. To me, I apologize, but money is, in the long term, not going to be a source of that deep meaning. It's good to have enough money, but it should not be the source of hope. And it's heartbreaking to me how many people. It's the source of hope.
Speaker D: Yeah. Um, you've just described the psychology of virality, or the psychology of, of trying.
Speaker C: To base a civilization on semi random occurrences of network effect peaks. Yeah.
Speaker D: And it doesn't really work. I mean, I think we need to.
Speaker C: Get away from that. We need to soften those peaks.
Speaker D: And except Microsoft, which deserves every penny. But in every other case.
Speaker B: Well, you mentioned GitHub. I think what Microsoft did with GitHub was brilliant. I was very. Okay, if I can give a. Not a critical but sure on Microsoft because they recently purchased Bethesda. So Elder Scrolls is in their hands. I'm watching you, Microsoft. Do not screw up. My favorite game.
Speaker D: So, yeah, look, I'm not speaking for Microsoft.
Speaker C: I have an explicit arrangement with them.
Speaker D: Where I don't speak for them. Obviously, that should be very clear. I do not speak for them. I am not saying I like him.
Speaker C: I think Satya is amazing.
Speaker D: The term data dignity was coined by Satya. It's extraordinary. But Microsoft's this giant thing. It's going to screw up this or that. I don't know. It's interesting.
Speaker C: I've had a few occasions in my.
Speaker D: Life to see how things work from.
Speaker C: The inside of some big thing.
Speaker D: And it's always just people kind of. It's. I don't know, there's always, like, coordination problem and there's also.
Speaker B: There's always human problems. Oh, there's some good people. There's some bad people.
Speaker D: It's always, I hope Microsoft doesn't screw.
Speaker B: Up your team, and I hope they bring Clippy back. You should never kill Clippy. Bring Clippy back.
Speaker D: Oh, Clippy.
Speaker C: But Clippy promotes the myth of AI.
Speaker B: Well, that's why you're wrong.
Speaker D: How about if we. All right, could we bring back Bob instead of Clippy?
Speaker B: Which one was Bob?
Speaker D: Oh, Bob was another thing.
Speaker C: Bob was this other screen character who.
Speaker D: Was supposed to be the voice of AI. Cortana.
Speaker C: Cortana. With Cortana do it for you.
Speaker B: Cortana is too corporate. I like it.
Speaker D: There's a woman in Seattle who's, like, the model for Cortana, did Cortana's voice, and was, there was like, no, the voice is great. We had a vision. We had her as a, she used.
Speaker C: To walk around if you were wearing hololens forbid.
Speaker D: I don't think that's happening anymore. I think.
Speaker C: I don't think you should turn a software into a creature.
Speaker B: I think you and I. You and I. Well, get a dog. Get a dog.
Speaker D: Or a dog. Yeah.
Speaker B: Yeah.
Speaker D: A hedgehog.
Speaker B: Hedgehog.
Speaker C: Yeah.
Speaker B: You co authored a paper you mentioned, Lee small, titled the autodidactic universe.
Speaker D: Mm hmm.
Speaker B: Which describes our universe as one that learns its own physical laws. That's a trippy and beautiful and powerful idea. What would you say are the key ideas in this paper?
Speaker D: Okay. Well, I should say that paper reflected.
Speaker C: Work from last year and the project. The program has moved quite a lot.
Speaker D: So there's a lot of stuff that's.
Speaker C: Not published that I'm quite excited about. So I have to kind of keep.
Speaker D: My frame in that last year's things. I have to try to be a little careful about that. We can think about it in a few different ways. The core of the paper, the technical.
Speaker C: Core of it, is a triple correspondence.
Speaker D: One part of it was already established.
Speaker C: And then another part is in the process.
Speaker D: The part that was established was, of course, understanding different theories of physics as matrix models. The part that was fresher is understanding.
Speaker C: Those as a machine learning system so that we could move fluidly between these different ways of describing systems.
Speaker D: And the reason to want to do.
Speaker C: That is to just have more tools and more options because.
Speaker D: Well, theoretical physics.
Speaker C: Is really hard, and a lot of programs have kind of run into a state where they feel a little stalled. I guess I can.
Speaker D: I want to be delicate about this because I'm not a physicist.
Speaker C: I'm the computer scientist collaborating.
Speaker D: So I don't mean to diss anybody's.
Speaker B: So this is almost like, gives a framework for generating new ideas in physics.
Speaker C: As we start to publish more about.
Speaker D: Where it's gone, I think you'll start to see there's tools and ways of thinking about theories that, I think open up some new paths that will be of interest.
Speaker C: There's the technical core of it, which is this idea of a correspondence to give you more facility. But then there's also the storytelling part of it.
Speaker D: And this is something Lee loves stories, and I do. And the idea here is that a typical way of thinking about physics is that there's some kind of starting condition.
Speaker C: And then there's some principle by which.
Speaker D: The starting condition evolves. And the question is, like, why the starting condition?
Speaker C: Like, how.
Speaker D: How the starting condition has to get kind of. This has to be fine tuned, and all these things about it have to be kind of perfect. And so we were thinking, well, look, what if we could push the storytelling about where the universe comes from much further back by starting with really simple.
Speaker C: Things that evolve, and then through that evolution, explain how things got to be, how they are through very simple principles. Right.
Speaker D: And so we've been exploring a variety.
Speaker C: Of ways to push the start of.
Speaker D: The storytelling further and further back, which. And it's an interesting. It's really kind of interesting because, like, for all of his. Lee is sometimes considered to be. To have a radical quality in the physics world, but he still is like, no, this is going to be the kind of time we're talking about in which evolution happens is the same time.
Speaker C: We'Re now, and we're talking about something.
Speaker D: That starts and continues.
Speaker C: And I'm like, well, what if there's some other kind of time? That's time like.
Speaker D: And that sounds like metaphysics, but there's an ambiguity, you know, like, it has to start from something, and it's kind of an interesting. So there's this. A lot of the math can be.
Speaker C: Thought of either way, which is kind of interesting.
Speaker B: So push it so far back that basically all the things we take for granted in physics start becoming emergent.
Speaker D: I really want to emphasize this is.
Speaker C: All super baby steps.
Speaker D: I don't want to over claim. It's like, it's. I think a lot of the things.
Speaker C: We'Re doing, we're approaching some old problems in a pretty fresh way. Informed.
Speaker D: There's been a zillion papers about how you can think of the universe as.
Speaker C: A big neural net, or how you.
Speaker D: Can think of different ideas in physics.
Speaker C: As being quite similar to, or even equivalent to some of the ideas in machine learning.
Speaker D: And that actually works out crazy. Well, that is actually kind of eerie when you look at it. There's probably two or three dozen papers.
Speaker C: That have this quality, and some of.
Speaker D: Them are just crazy good. And it's very interesting. What we're trying to do is take.
Speaker C: Those kinds of observations and turn them into an actionable framework where you can then start to do things with landscapes or theories that you couldn't do before and that sort of thing.
Speaker B: So, in that context, or maybe beyond, how do you explain us humans? How unlikely are we this intelligent civilization? Or is there a lot of others, or are we alone in this universe?
Speaker C: Yeah.
Speaker B: You seem to appreciate humans very much.
Speaker D: I've grown fond of us.
Speaker B: Okay, whatever our nice qualities.
Speaker D: I like that.
Speaker C: I mean, we're kind of weird. We sprout this hair on our heads.
Speaker D: And then, I don't know, we're sort of weird animals.
Speaker B: That's the feature, not a bug. I think the weirdness.
Speaker C: I hope so.
Speaker D: I hope so. I. I think if I'm just going to answer you in terms of truth, the first thing I'd say is we're not in a privileged enough position, at least as yet, to really know much about who we are, how we are, what we're really like, in the context of something larger, what that context is, all that stuff.
Speaker C: We might learn more in the future.
Speaker D: Our descendants might learn more, but we don't really know very much, which you.
Speaker C: Can either view as frustrating or charming, like that first year of TikTok or something.
Speaker B: But all roads lead back to TikTok.
Speaker D: I like it well, lately, but in terms of. There's another level at which I can think about it, where I sometimes think that if you are just quiet and.
Speaker C: You do something that gets you in touch with the way reality happens.
Speaker D: And for me, it's playing music. Sometimes it seems like you can feel.
Speaker C: A bit of how the universe is, and it feels like there's a lot more going on in it, and there is a lot more life and a.
Speaker D: Lot more stuff happening and a lot.
Speaker C: More stuff flowing through.
Speaker D: I don't know.
Speaker C: I'm not speaking as a scientist now.
Speaker D: This is kind of a more my.
Speaker C: Artist side talking, and it's.
Speaker D: I feel like I'm suddenly in multiple personalities with you.
Speaker B: But Kerouac, Jack Kerouac said that music is the only truth. What do you. It sounds like you might be, at least in part.
Speaker C: There's a passage in Kerouac's book, Doctor.
Speaker D: Sacks, where somebody tries to just explain the whole situation with reality and people in like, a paragraph, and I couldn't reproduce it for you here, but it's like. Yeah, like there are these bulbous things.
Speaker C: That walk around and they make these sounds. You can sort of understand them, but only kind of.
Speaker D: And then there's like this. And it's just like this amazing. Like, just really quick. Like if some spirit being or something was going to show up in our.
Speaker C: Reality and had knew nothing about it.
Speaker D: It's like a little basic intro of, like, okay, here's what's going on here. It's an incredible passage. Yeah, yeah.
Speaker B: It's like a one or two sentence summary in Hitchhiker's Guides of the galaxy. Right. Of what? This.
Speaker D: Mostly harmless.
Speaker B: Mostly harmless?
Speaker D: Yeah.
Speaker B: Do you think there's truth to that? That music somehow connects to something that words cannot?
Speaker D: Yeah.
Speaker C: Music is something that just towers above me. I don't. I don't.
Speaker D: I don't feel like I have an overview of it.
Speaker C: It's just the reverse. I don't. I don't fully understand it, because on one level, it's simple.
Speaker D: Like, you can say, oh, it's. It's a thing.
Speaker C: People evolved to coordinate our brains on.
Speaker D: A pattern level or something like that. There's all these things you can say about music which are, you know, some.
Speaker C: Of that's probably true.
Speaker D: It's also. There's kind of like this.
Speaker C: This is the mystery of meaning.
Speaker D: Like, there's a way that just.
Speaker C: Instead of just being pure abstraction, music can have, like, this kind of substantiality.
Speaker D: To it that is philosophically impossible. I don't know what to do with it.
Speaker B: Yeah. The amount of understanding I feel I have when I hear the right song at the right time is not comparable to anything I can read on wikipedia. Anything I can understand, read through in language. There's. The music does connect us to something.
Speaker D: There's a thing there. Yeah, there's. There's.
Speaker C: There's some kind of a thing in it. I've never, ever. I've read across a lot of explanations.
Speaker D: From all kinds of interesting people like that it's some kind of a flow.
Speaker C: Language between people or between people and.
Speaker D: How they perceive and that kind of thing.
Speaker C: And that sort of explanation is fine, but it's not quite it either.
Speaker D: Yeah.
Speaker B: There's something about music that makes me believe that panpsychism could possibly be true, which is that everything in the universe is conscious. It makes me think, makes me be humble in how much or how little I understand about the functions of our universe that everything might be conscious.
Speaker D: Most people interested in theoretical physics eventually land in panpsychism, but I'm not one of them. I still think there's this pragmatic imperative to treat people as special.
Speaker C: So I will proudly be a dualist.
Speaker B: People and cats. People and cats, yeah.
Speaker C: I'm not quite sure where to draw the line or why the line's there.
Speaker D: Or anything like that, but I don't.
Speaker C: Think I should be required to all the same questions or equally mysterious for no line.
Speaker D: So I don't feel disadvantaged by that.
Speaker C: So I shall remain a dualist.
Speaker D: But if. If you listen to anyone trying to explain where consciousness is in a dualistic sense, either believing in souls or some special thing in the brain or something, you pretty much say, screw this, I'm going to be a panpsychist.
Speaker B: Fair enough. Well put. Is there moments in your life that happen that we're defining in the way that you hope others, your daughter?
Speaker D: Well, listen, I gotta say, the moments.
Speaker C: That defined me were not the good ones. The moments that defined me were often horrible.
Speaker D: I've had successes, but if you ask.
Speaker C: What defined me, my mother's death.
Speaker D: Being.
Speaker C: Under the World Trade center and the attack.
Speaker D: The things that have had an.
Speaker C: Effect on me were the most were sort of real world terrible things, which I don't wish on young people at all.
Speaker D: And this is the thing that's hard.
Speaker C: About giving advice to young people, that they have to learn their own lessons.
Speaker D: And lessons don't come easily.
Speaker C: And a world which avoids hard lessons will be a stupid world, and I don't know what to do with it. That's a little bundle of truth that has a bit of a fatalistic quality.
Speaker D: To it, but I don't. This is like what I'm saying, that.
Speaker C: Freedom equals eternal annoyance. There's a degree to which honest advice is not that pleasant to give.
Speaker D: And I don't want young people to have to know about everything.
Speaker B: I think you don't want to wish hardship on them.
Speaker D: Yeah, I think they deserve to have.
Speaker C: A little grace period of naivety.
Speaker D: That's pleasant. I mean, I do, if it's possible, if it's. These things are.
Speaker C: This is tricky stuff.
Speaker D: I mean, if you. If you. Okay, so let me.
Speaker C: Let me try a little bit on this advice thing.
Speaker D: I think one thing and any serious.
Speaker C: Broad advice will have been given a thousand times before for a thousand years.
Speaker D: So this, I'm not going to. I'm not going to claim originality, but I think trying to find a way to really pay attention to what you're.
Speaker C: Feeling, fundamentally, what your sense of the world is, what your intuition is, if you feel like an intuitive person, what.
Speaker D: You'Re to try to escape the constant.
Speaker C: Sway of social perception or manipulation, whatever you wish. Not to escape it entirely, that would be horrible. But to find cover from it once in a while, to find a sense.
Speaker D: Of being anchored in that, to believe in experience as a real thing.
Speaker C: Believing in experience as a real thing is very dualistic. That goes with my philosophy of dualism.
Speaker D: I believe there's something magical, and instead of squirting the magic dust on the programs, I think experience is something real.
Speaker C: And something apart, something mystical and your.
Speaker B: Own personal internal experience that you just have. And then you're saying, yeah, silence the rest of the world enough to hear that, like, whatever that magic dust is.
Speaker D: From that experience, find with what? What is there? And I think that's what. That's one thing.
Speaker C: Another thing is to recognize that kindness requires genius, that it's actually really hard. That facile kindness is not kindness in.
Speaker D: That it'll take you a while to have the skills, to have kind impulse.
Speaker C: As to how to be kind, you can have right away. To be effectively kind is hard.
Speaker B: To be effectively kind, yes.
Speaker D: It takes skill. It takes.
Speaker C: It takes hard lessons. You'll never be perfect at it to the degree you get anywhere with it. It's the most rewarding thing ever. Let's see, what else would I say?
Speaker D: I would say when you're young, you can be very overwhelmed.
Speaker C: By social and interpersonal emotions. You'll have broken hearts and jealousies. You'll feel socially down the ladder instead of up the ladder. It feels horrible when that happens, all.
Speaker D: Of these things, and you have to.
Speaker C: Remember what a fragile crust all that stuff is. And it's hard because right when it's happening, it's just so intense.
Speaker D: And.
Speaker C: If I was actually giving this advice to my daughter, she'd already be.
Speaker D: Out of the room. So I'm just. This is for some, like, hypothetical teenager that doesn't really exist, that really wants to sit and listen to my wisdom.
Speaker B: For your daughter, ten years from now, maybe. Can I ask you a difficult question?
Speaker D: Yeah, sure.
Speaker B: You talked about losing your mom.
Speaker D: Yeah.
Speaker B: Do you miss her?
Speaker D: Yeah.
Speaker C: I mean, I still connect to her through music. She was a.
Speaker D: She was a young prodigy piano player in Vienna, and she survived the concentration.
Speaker C: Camp and then died in a car accident here in the US.
Speaker B: What music makes you think of her? Is there. Is there a song?
Speaker D: Well, you know, she was in Vienna, so she had the whole viennese music thing going, which is this, you know, incredible school of absolute skill and romance.
Speaker C: Bundled together and wonderful. On the piano especially, I learned to.
Speaker D: Play some of the Beethoven sonatas for her, and I played them in this.
Speaker C: Exaggerated, drippy way I remember when I was a kid.
Speaker B: And exaggerated meaning, too. Full of emotion.
Speaker D: Yeah.
Speaker B: Like, just like, isn't that the only way to play Beethoven? I mean, I didn't know there's any.
Speaker C: That's a reasonable question.
Speaker D: I mean, the fashion these days is.
Speaker C: To be slightly apollonian with. Even with Beethoven.
Speaker D: But one imagines that actual Beethoven playing might have been different. I don't know. I've gotten to play a few instruments.
Speaker C: He played and tried to see if.
Speaker D: I could feel anything about how it.
Speaker C: Might have been for him.
Speaker D: I don't know, really.
Speaker B: I was always against the clinical precision of classical music. I thought a great piano player should be, like, in pain, emotionally, truly feel the music and make it messy. Maybe play classical music the way. I don't know, blues pianist plays blues.
Speaker D: Like, it seems like they actually got happier.
Speaker C: And I'm not sure if Beethoven got happier.
Speaker D: I think it's a different. I think it's a different kind of.
Speaker C: Concept of the place of music.
Speaker D: I think the blues, the whole african.
Speaker C: American tradition was initially surviving awful, awful.
Speaker D: Circumstances, you could say, you know, there was some of that.
Speaker C: The concentration camps and all that, too.
Speaker D: And it's not that Beethoven's circumstances were.
Speaker C: Brilliant, but he kind of also. I don't know, this is hard.
Speaker D: It would seem to be.
Speaker C: His misery was somewhat self imposed, maybe through.
Speaker D: I don't know, it's kind of interesting.
Speaker C: I've known some people who loathed Beethoven, like the composer, late composer Pauline Oliveros, wonderful modernist composer.
Speaker D: I played in her band for a while and she was like, oh, Beethoven.
Speaker C: That'S the worst music ever.
Speaker D: It's like all ego. It completely.
Speaker C: It turns information. I mean, it turns emotion into your.
Speaker D: Enemy, and it's ultimately all about your.
Speaker C: Own self importance, which has to be.
Speaker D: At the expense of others. Could. But what else could it be? And blah, blah, blah. So she had.
Speaker C: I shouldn't say.
Speaker D: I don't mean it to be dismissive.
Speaker C: But I'm just saying, like, her position.
Speaker D: On Beethoven was very negative and very.
Speaker C: Unimpressed, which is really interesting for the.
Speaker B: Man or the music, I think.
Speaker D: I don't know. I mean, she's not here to speak.
Speaker C: For herself, so it's a little hard for me to answer that question.
Speaker D: But it was interesting because I always thought of Beethoven's like, whoa. You know, this is like, Beethoven is like, really the dude, you know? And she's like, ah, you know, Beethoven Schmeethoven, you know, it's, like, not really happening.
Speaker B: Yeah, I still, even though it's cliche, I like playing personally, just for myself. Moonlight sonata. I mean, I just.
Speaker C: Moonlight's amazing.
Speaker D: You know, I, you know, you're talking about comparing the blues and that sensibility from Europe. It's so different in so many ways. One of the musicians I play with.
Speaker C: Is John Baptiste, who has the band on Colbert's show.
Speaker D: And he'll sit there playing jazz and.
Speaker C: Suddenly go into moonlight. He loves moonlight.
Speaker D: And what's kind of interesting is he's.
Speaker C: Found a way to do Beethoven.
Speaker D: And by the way, he can really do Beethoven. He went through juilliard, and one time he was, one time he was at my house, he's saying, hey, do you have the book of Beethoven's last? To say, yeah, I want to find one I haven't played. Then he sight read through the whole damn thing perfectly, and I'm like, oh, God, I just get out of here. I can't even deal with this. But anyway. Yeah, but anyway, the thing is, he has this way of, with the same Persona and the same philosophy, moving from.
Speaker C: The blues into Beethoven. That's really, really fascinating to me.
Speaker D: It's like, um, I don't want to say he plays it as if it.
Speaker C: Were jazz, but he kind of does.
Speaker D: Yeah, it's kind of really. And he talks. He'll sight reason.
Speaker C: He talks like Beethoven's talking to him.
Speaker D: Like, he's like, oh, yeah, here he's doing this.
Speaker C: He's.
Speaker D: I can't do John, but, you know, it's like, it's really, it's really interesting.
Speaker C: Like, it's very different.
Speaker D: Like, for me, I was introduced to Beethoven as, like, almost like, this godlike figure. Figure, and I presume Pauline was, too. That was really kind of a press winner to deal with. And for him, it's just like he's playing James P. Johnson or something. It's like another musician who did something, and they're talking, and it's very cool to be around. It's very kind of freeing to see someone have that relationship.
Speaker B: I would love to hear him play Ben ho. That sounds. That sounds amazing.
Speaker C: He's great.
Speaker B: We talked about Ernest Becker and how much value he puts on our mortality and our denial of our mortality. Do you think about your mortality? Do you think about your own death?
Speaker D: You know what's funny is I used.
Speaker C: To not be able to. But as you get older, you just know people who die, and there's all these things.
Speaker D: It just becomes familiar and.
Speaker C: More ordinary.
Speaker D: Which is what it is.
Speaker B: But are you afraid?
Speaker C: Sure, although less so.
Speaker D: And it's not like I didn't have.
Speaker C: Some kind of insight or revelation to become less afraid.
Speaker D: I think I just, like I say, it's kind of familiarity.
Speaker C: It's just knowing people who have died.
Speaker D: And I really believe in the future. I have this optimism that people or this whole thing of life on earth.
Speaker C: This whole thing we're part of, I don't know where to draw that circle.
Speaker D: But this thing is going somewhere and.
Speaker C: Has some kind of value. And you can't both believe in the future and want to live forever. You have to make room for it.
Speaker D: You know, like, you have to.
Speaker C: That optimism has to also come with its own, like, humility. You have to make yourself small to believe in the future. And so it actually, in a funny way, comforts me.
Speaker B: Wow, that's powerful. And optimism requires you to kind of step down after time.
Speaker C: Yeah.
Speaker D: I mean, that said, life seems kind of short, but, you know, whatever do you think there? I've tried to find.
Speaker C: I can't find the complaint department.
Speaker D: You know, I really want to. I want to bring this up, but.
Speaker C: The customer service number never answers.
Speaker B: And, like, the email bounces one way. Do you think there's meaning to it, to life?
Speaker D: Ah, well, see, meaning's a funny word. Like, we say all these things as if we know what they mean, but meaning, we don't know what we mean when we say meaning. Like, we obviously do not. And it's a funny little mystical thing. I think it ultimately connects to that sense of experience that dualists tend to believe in, because there are.
Speaker C: Why?
Speaker B: Like, if you look up to the stars and you experience that awe inspiring, like, joy at whatever, when you look up to the stars, I don't know why. For me, that kind of makes me feel joyful, maybe a little bit melancholy, just some weird soup of feelings. And ultimately, the question is, like, why are we here in this vast universe? That question, why have you been able, in some way, maybe through music, answer it for yourself.
Speaker C: My impulse is to feel like it's not quite the right question to ask.
Speaker D: But I feel like going down that.
Speaker C: Path is just too tedious for the.
Speaker D: Moment, and I don't want to do it. But.
Speaker B: The wrong question.
Speaker D: Well, just because, you know, I don't know what meaning is, and I think I do know that sense of awe.
Speaker C: I grew up in southern New Mexico.
Speaker D: And the stars were so vivid. I've had some weird misfortunes, but I've.
Speaker C: Had some weird luck also.
Speaker D: One of our near neighbors was the.
Speaker C: Head of optics research at White Sands. And when he was young, he discovered Pluto.
Speaker D: His name was Clyde Tombaugh, and he.
Speaker C: Taught me how to make telescopes, grinding mirrors and stuff. And my dad had also made telescopes when he was a kid. But Clyde had, like, backyard telescopes that.
Speaker D: Would put to shame a lot of, like, I mean, he really. He did his telescopes, you know? And so I remember he'd let me go and play with him. And just like, looking at a globular.
Speaker C: Cluster and you're seeing the actual photons. And with a good telescope, it's really like this object.
Speaker D: Like, you can really tell this isn't.
Speaker C: Coming through some intervening information structure. This is like the actual photons, and.
Speaker D: It'S really a three dimensional object, and.
Speaker C: You have even a feeling for the vastness of it.
Speaker D: And I don't know. So I definitely, I was very, very.
Speaker C: Fortunate to have a connection to this.
Speaker D: Guy that way when I was a.
Speaker B: Kid, to have had that experience again, the emphasis experience.
Speaker D: It's kind of funny. I feel like sometimes I've taken. When she was younger, I took my.
Speaker C: Daughter and her friends to a telescope. There are a few around here that.
Speaker D: Kids can go and use.
Speaker C: And they would look at Jupiter's moons.
Speaker D: Or something, I think, like galilean moons. And I don't know if they quite had that because it's like too. It's been just too normalized. And I think maybe when I was.
Speaker C: Growing up, screens weren't that common yet.
Speaker D: And maybe it's, like, too confusable with a screen.
Speaker C: I don't know.
Speaker B: You know, somebody brought up in conversation to me somewhere, I don't remember who, but they kind of posited this idea that if humans, early humans, weren't able to see the stars, like, if Earth atmosphere was such that it was cloudy, that we would not develop human civilization. There's something about being able to look up and see a vast universe is like, that's fundamental to the development of human civilization. I thought that was a curious kind of thought.
Speaker D: That reminds me of that old Isaac Asimov story where there's this planet where they finally get to see what's in.
Speaker C: The sky once in a while, and it turns out they're in the middle.
Speaker D: Of a globular cluster and they're all these stars.
Speaker C: I forget what happens exactly.
Speaker D: God, that's from when I was the.
Speaker C: Same age as a kid, I don't.
Speaker D: Really remember, but, yeah, I don't know.
Speaker C: It might be right.
Speaker D: I'm just thinking of all the civilizations.
Speaker C: That grew up under clouds.
Speaker D: I mean, like, the Vikings needed a special diffracting piece of mica to navigate.
Speaker C: Because they could never see the sun. They had this thing called a sunstone that they found from this one cave.
Speaker D: Do you know about that? So they were in this, like, they were trying to navigate boats in the north Atlantic without being able to see.
Speaker C: The sun because it was cloudy.
Speaker D: And so they used.
Speaker C: A chunk of mica to diffract it in order to be able to align where the sun.
Speaker D: Really was because they couldn't tell by eye and navigate. So I'm just saying there are a.
Speaker C: Lot of civilizations that are pretty impressive.
Speaker D: That have to deal with a lot of clouds. The Amazonians invented our agriculture, and they.
Speaker C: They were probably under clouds a lot. I don't know. I don't know.
Speaker B: To me personally, the. The question of the meaning of life becomes most vibrant, most apparent when you look up at the stars, because it makes me feel very small that we're small. But then you ask, it still feels that we're special. And then the natural question is like, well, if we are as special as I think we are, why the heck are we here in this vast universe? That ultimately is the question of.
Speaker C: Right.
Speaker B: Well, the meaning of life.
Speaker C: I mean, look, there's a confusion sometimes.
Speaker D: In trying to use. To set up a question or a thought experiment or something that's defined in.
Speaker C: Terms of a context to explain something where there is no larger context.
Speaker D: And that's a category error if we want to do it in physics, in computer science, it's hard to talk about.
Speaker C: The universe as a Turing machine because a Turing machine has an external clock.
Speaker D: And an observer and input and output.
Speaker C: There's a larger context implied in order for it to be defined at all.
Speaker D: And so if you're talking about the universe, you can't talk about it coherently as a Turing machine.
Speaker C: Quantum mechanics is like that. Quantum mechanics has an external clock and has some kind of external context, depending on your interpretation.
Speaker D: That's either, you know, the observer or whatever. And there's a. They're.
Speaker C: They're similar that way. So maybe. Maybe Turing machines and quantum mechanics can.
Speaker D: Be better friends or something because they have a similar setup. But the thing is, if you have.
Speaker C: Something that's defined I in terms of an outer context, you can't talk about ultimates with it because obviously it's not suited for that.
Speaker D: So there's some ideas that are their own context.
Speaker C: General relativity is its own context. It's different.
Speaker D: That's why it's hard to unify. And I think the same thing is.
Speaker C: True when we talk about these types.
Speaker D: Of questions, like meaning is in a.
Speaker C: Context, and to talk about ultimate meaning is therefore category r. It's not.
Speaker D: It's not a. It's not a resolvable way of thinking. It might be a way of thinking that is experientially or aesthetically valuable because it is awesome in the sense of, you know, awe inspiring. Um, but to try to treat it analytically is not sensible.
Speaker B: Maybe that's what music and poetry are for.
Speaker D: Yeah, maybe. I think so.
Speaker C: I think music actually does escape any particular context. That's how it feels to me.
Speaker D: But I'm not sure about that. That's, once again, crazy artists talking, not scientists.
Speaker B: Well, you did, uh, you do both masterfully. Uh, Jaron, I'm, like I said, I'm a big fan of everything you've done of you as a human being. I appreciate the fun argument we had today that will, I'm sure, continue for 30 years, as it did with Mark Minsky. Honestly, I deeply appreciate that you spend your really valuable time with me today. It was a really great conversation. Thank you so much.
Speaker A: Thanks for listening to this conversation with Jaron Lanier. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Jaron Lanier himself. A real friendship ought to introduce each person to unexpected weirdness in the other.
Speaker B: Thank you for listening and hope to see you next time.
