Transcription for Grimes： Music, AI, and the Future of Humanity ｜ Lex Fridman Podcast #281.mp3:
Full transcript: We are becoming cyborgs. Like, our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous. From homo sapiens. I call us homotecno. I think we have evolved into homotechno, which is, like, essentially a new species. Previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homotechno. I think this is what. It's a brain augmentation, so it allows for actual evolution. The computers accelerate the degree to which all the other technologies can also be. Would you classify yourself as a homo sapien or a homo techno? Definitely homo techno. So you're all. You're one of the earliest of the species? I think most of us are. The following is a conversation with Grimes, an artist, musician, songwriter, producer, director, and a fascinating human being who thinks a lot about both the history and the future of human civilization, studying the dark periods of our past to help form an optimistic vision of our future. This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Grimes. Oh, yeah, the cloudlifter. There you go. There you go. You know your stuff. Have you ever used the cloudlifter? Yeah, I actually. This microphone. Cloudlifter is what Michael Jackson used, so. No. Really? Yeah. This. This is, like, thriller and stuff. This mic? This mic and that. Yeah. It's a incredible microphone. Yes. It's very flattering on vocals. I've used this a lot of. It's great for demo vocals. It's great in a room. Like, sometimes it's easier to record vocals if you're just in a room and the music's playing and you just want to feel it. So it's not in the headphones. And this mic is pretty directional, so I think it's a good mic for just vibing out and just getting a real good vocal take. Just vibing just in a room. Anyway, this is the. This is the Michael Jackson Quincy Jones microphone. I feel way more badass now. Let's get in. You want to just get into it? I guess so. All right. One of your names, at least in this space and time, is c, like the letter c. And. And you told me that c means a lot of things. It's the speed of light. It's the render rate of the universe. It's. Yes, in Spanish. It's the crescent moon, and it happens to be my favorite programming language because it's. It basically runs the world, but it's also powerful, fast, and is dangerous because you can mess things up really bad with it because of all the pointers. But anyway, which of these associations with the name c is the coolest to you? I mean, to me the coolest is the speed of light, obviously, or speed of light. When I say render rate of the universe, I think I mean the speed of light, because essentially that's what we're rendering at. See, I think we'll know if we're in a simulation if the speed of light changes, because if they can improve their render speed, then it's already pretty good. It's already pretty good. But if it improves, then we'll know. We can probably be like, okay, they've updated or upgraded. What's fast enough for us humans? Because it seems like, it seems immediate, there's no delay, there's no latency in terms of us humans on Earth interacting with things. But if you're like, like intergalactic species operating on a much larger scale, then you're going to start noticing some weird stuff. Or if you can operate in like around a black hole, then you're going to start to see some render issues. You can't go faster than the speed of light. Correct. So it really limits our ability, or one's ability to travel space. Theoretically you can. You have wormholes. So there's nothing in general relativity that precludes faster than speed of light travel. But it just seems you're gonna have to do some really funky stuff with very heavy things that have weirdnesses, that have basically tears in space time. We don't know how to do that. Do navigators know how to do it? Do navigators? Yeah, yeah. Folding space, basically making wormholes. So the name c. Yes. Who are you? Do you think of yourself as multiple people? Are you one person? Do you know, like in this morning, were you a different person than you are tonight? We are, I should say, recording this basically at midnight, which is awesome. Yes. Thank you so much. I think I'm about 8 hours late. No, you're right on time. Good morning. This is the beginning of a new day soon anyway. Are you the same person you were in the morning, in the evening? Is there multiple people in there? Do you think of yourself as one person? Or maybe you have no clue? Are you just a giant mystery to yourself? Okay, these are really intense questions, but. Uh, let's go, because I asked this myself. Like, look in the mirror. Who are you? People tell you to just be yourself, but what does that even mean? Uh, I mean, I think my personality changes with everyone I talk to. So I have a very inconsistent personality. Yeah, person to person. So the interaction, your personality materializes, or my mood. Like, I'll go from being like a megalomaniac to being just a total hermit who is very shy. So some combinatorial combination of your mood and the person you're interacting with. Yeah, mood and people I'm interacting with, but I think everyone's like that. Maybe not. Well, not everybody acknowledges it and able to introspect it. Who brings out what kind of person, what kind of mood brings out the best in you as an artist and as a human? Can you introspect this? Like, my best friends, like, people who I can when I'm, like, super confident and I know that they're gonna understand everything I'm saying. So, like, my best friends, then when I can start being really funny, that's always my peak mode, but it's like, yeah, it takes a lot to get there. Let's talk about constraints. You've talked about constraints and limits. Do those help you out as an artist or as a human being, or do they get in the way? Do you like the constraints? So in creating music and creating art, in living life, do you like the constraints that this world puts on you or do you hate them? If constraints are moving, then you're good, right? Like, it's like, it's like, as we are progressing with technology, we're changing the constraints of, like, artistic creation. You know, making video and music and stuff is getting a lot cheaper. There's constantly new technology and new software that's making it faster and easier. We have so much more freedom than we had in the seventies. Like, when Michael Jackson, you know, when they recorded thriller with this microphone, like, they had to use a mixing desk and all this stuff. And, like, probably even get in a studio, it's probably really expensive, and you have to be a really good singer, and you have to know how to use, like, the mixing desk and everything. And now I can just, you know, I've made a whole album on this computer. I have a lot more freedom. But then I'm also constrained in different ways because there's literally millions more artists. It's a much bigger playing field. It's just like, I also. I didn't learn music. I'm not a natural musician, so I don't know anything about actual music. I just know about the computer. So I'm really kind of just, like, messing around and, like, trying things out. Well, yeah, I mean, but the nature of music is changing. So you're saying you don't know actual music. But music is changing. Music is becoming. You've talked about this is becoming. It's like merging with technology. Yes. It's becoming something more than just like the notes on a piano. It's becoming some weird composition that requires engineering skills, programming skills, some kind of human robot interaction skills, and still some of the same things that Michael Jackson had, which is like a good ear for a good sense of taste of what's good and not the final thing when it's put together. Like you're allowed, you're enabled, empowered with a laptop to layer stuff, to start layering insane amounts of stuff. And it's super easy to do that. I do think music production is a really underrated art form. I feel like people really don't appreciate it. When I look at publishing splits, the way that people, like, pay producers and stuff, it's super. Producers are just deeply underrated. So many of the songs that are popular right now or for the last 20 years, part of the reason they're popular is cause the production is really interesting or really sick or really cool. And it's like, I don't think listeners, people just don't really understand what music production is. It's nothing. It's sort of like this weird, discombobulated art form. It's not like a formal. Because it's so new, there isn't a formal training path for it. It's mostly driven by autodidacts. It's almost everyone I know who's good at production. They didn't go to music school or anything. They just taught themselves. Are they mostly different, the music producers? You know, is there some commonalities that time together, or are they all just different kinds of weirdos? Because I just hung out with Rick Rubin? I don't know if you've. Yeah, I mean, Rick Rubin is like, literally one of the gods of music production. Like, he's one of the people who first, you know, who, like, made music production, you know, made the production as important as the actual lyrics or the notes. But the thing he does, which is interesting, I don't know if you can speak to that, but just hanging out with him, he seems to just sit there in silence, close his eyes and listen. It's like he almost does nothing. And that nothing somehow gives you freedom to be the best version of yourself. So that's music production somehow, too, which is like encouraging you to do less, to simplify, to, like, push towards minimalism. I mean, I guess. I mean, I work differently from Rick Rubin. Cause Rick Rubin produces for other artists, whereas I mostly produce for myself, so it's a very different situation. I also think Rick Rubin, he's in that, I would say advanced category of producer, where you've earned your. You can have an engineer and stuff, and people do the stuff for you, but I usually just do stuff myself. So you're the engineer, the producer, and the artist. Yeah, I guess I would say I'm in the era, like the post Rick Rubin era. I come from the kind of like Skrillex school of thought, which is like, where you are. Yeah, the engineer, producer, artist. I mean, lately, sometimes I'll work with a producer. Now I'm gently, sort of delicately starting to collaborate a bit more. But I think I'm kind of from the whatever, 2010s explosion of things where, you know, everything became available on the computer and you kind of got this, like, lone wizard energy thing going. So you embrace being the loneliness. Is the loneliness somehow an engine of creativity? Like, see, most of your stuff, most of your creative, quote unquote genius in quotes, is in the privacy of your mind. Yes. Well, it was, but here's the thing. I was talking to Daniel Eck, and he said he's like most artists, they have about ten years, like ten good years, and then they usually stop making their vital shit. And I feel like I'm sort of nearing the end of my ten years on my own. So you have to become somebody else now. I'm in the process of becoming somebody else in reinventing when I work with other people, because I've never worked with other people, I find that I make, like, that I'm exceptionally rejuvenated and making some of the most vital work I've ever made because I think another human brain is one of the best tools you can possibly find. It's a funny way to put it. I love it. If a tool is whatever, HP plus one or adds some stats to your character, like, another human brain will, like, square it instead of, like, adding something. Double up the experience points. I love this. We should also mention we're playing tavern music before this and which I love, which I. First, I think I. You have to stop the tavern music. Yeah, because it doesn't. The audio. Okay. Okay. But it makes. Yeah, it'll make the podcast added and post. No one will want to listen to. The podcast if they probably would. But it makes me. It reminds me like, of a video game, like a role playing video game where you have experience points. There's something really joyful about wandering places like Elder Scrolls, like Skyrim, just exploring these landscapes in another world, and then you get experience points and you can work on different skills and somehow you progress in life. I don't know. It's simple. It doesn't have some of the messy complexities of life. And there's usually a bad guy you can fight. In Skyrim, it's dragons and so on. I'm sure in Elden ring there's a bunch of monsters you can fight. I love that. I feel like Elden ring. I feel like this is a good analogy to music production, though, because I feel like the engineers and the people creating these open worlds. It's sort of similar to music producers, where it's this hidden archetype that no one really understands what they do and no one really knows who they are, but they're. It's like the artist engineer, because it's like, it's both art and fairly complex engineering. Well, you're saying they don't get enough credit. Aren't you kind of changing that by becoming the person doing everything isn't the engineer. Well, I mean, others have gone before me. I'm not, you know, there's, like, Timbaland and Skrillex, and there's all these people that are like, you know, very famous for this. But I just think the general. I think people get confused about what it is and just don't really know what it is, per se. And it's just when I see a song, when there's a hit song, I'm just trying to think of just going for even just a basic pop hit rules by Dua Lipa or something. The production on that is actually really crazy. I mean, the song is also great, but the production is exceptionally memorable, you know, and it's just like, no one, I don't even know who produced that song. It just, like, isn't part of, like, the rhetoric of how we discuss the creation of art. We just sort of, like, don't consider the music producer, because I think the music producer used to be more just simply recording things. Yeah, that's interesting, because when you think about movies, we talk about the actor and the actresses, but we also talk about the directors. Directors, yeah, we don't talk about, like, that with the music as often. The Beatles music producer was one of the first kind of guy, one of the first people sort of introducing crazy sound design into pop music. I forget his name. He has the same. I forget his name. But, you know, like, he was doing all the weird stuff, like dropping pianos and like. Yeah. Oh, to get the. Yeah, yeah, yeah. To get. To get the sound to get the authentic sound. What about lyrics? You think those. Where did they fit into how important they are? I was heartbroken to learn that Elvis didn't write his songs. I was very mad. A lot of people don't write their songs. I understand this. But here's the thing. I feel like there's this desire for authenticity. I used to be really mad when people wouldn't write or produce their music, and I'd be like, that's fake. And then I realized there's all this weird bitterness and aggro ness in art about authenticity. But I had this weird realization recently where I started thinking that art is sort of a decentralized, collective thing. Art is kind of a conversation with all the artists that have ever lived before you. You know, like, it's like you're really just sort of. It's not like anyone's reinventing the wheel here. Like, you're kind of just taking, you know, thousands of years of art and, like, running it through your own little algorithm and then, like, making your, like, your interpretation of it. You just join the conversation with all the other artists that came before. It's such a beautiful way to look. At it, like, and it's like, it's like, I feel like everyone's always, like, there's always copyright and ip and this and that and or authenticity. And it's just like, I think we need to stop seeing this as this egotistical thing of, like, oh, the creative genius, the lone creative genius, or this or that. Cause it's like, I think art shouldn't be about that. I think art is something that sort of brings humanity together. And it's also. Art is also kind of the collective memory of humans. It's like we don't, like, we don't give a fuck about whatever ancient Egypt, like, how much grain got sent that day and sending the records and who went where and how many shields needed to be produced for this. We just remember their art. And it's like, in our day to day life, there's all this stuff that seems more important than art because it helps us function and survive. But when all this is gone, the only thing that's really going to be left is the art. The technology will be obsolete. That's so fascinating. Like, the humans will be dead. That is true. A good compression of human history is the art we've generated across the different centuries of different millennia. So when the aliens come, when the. Aliens come, they're going to find the hieroglyphics and the pyramids. I mean, art could be broadly defined. They might find the engineering marvels, the bridges, the rockets, the. I guess I sort of classify, though. Architecture is art, too. I consider engineering, um, in those formats to be art, for sure. It sucks that, like, digital art is easier to delete. So if there's an apocalypse, a nuclear war, that can disappear. Yes. And the physical, there's something still valuable about the physical manifestation of art that's. That sucks that, like, music, for example, has to be played by somebody. Yeah. I mean, I do think we should do have a foundation type situation where we, like, you know, how we have, like, seed banks up in the north and stuff. Yeah. Like, we should probably have, like, a solar powered or geothermal little bunker that, like, has all the. All human knowledge. You mentioned Daniel Eich and Spotify. What do you think about that as an artist? What's Spotify? Is that empowering? I get, to me, Spotify sort of, as a consumer, is super exciting. It makes it easy for me to access music from all kinds of artists, get to explore all kinds of music, make it super easy to sort of curate my own playlist and have fun with all that. It was so liberating to let go. You know, I used to collect, you know, albums and cds and so on. Like, horde albums. Yeah, like, they matter. But the reality, you could, you know, that was really liberating. That can let go of that and letting go of the albums you're kind of collecting allows you to find new music, exploring new artists and all that kind of stuff. But I know from a perspective of an artist, that could be, like you mentioned, competition could be a kind of constraint, because there's more and more and more artists on the platform. I think it's better that there's more artists. I mean, again, this might be propaganda because this is all from a conversation with Daniel Eck. So this could easily be propaganda. Like, we're all a victim of somebody's propaganda, so let's just accept this. But Daniel Eck was telling me that, you know, at the. Because I, you know, when, when I met him, I, like, I came in all furious about Spotify, and, like, I grilled him super hard. So I've got his, his answers here. But he was saying, like, at the sort of peak of the cd industry, there was like 20,000 artists making millions and millions of dollars. Like, there was just like, a very tiny kind of 1%. And Spotify has kind of democratized the industry because now, I think he said there's about a million artists making a good living from Spotify and when I heard that, I was like, honestly, I would rather make less money and have just, like, a decent living and have more artists be able to have that, even though I wish it could include everyone. But, yeah, that's really hard to argue with. YouTube is the same, is YouTube's mission. They want to basically have as many creators as possible, make a living, some kind of living. Yeah. And that, that's so hard to argue. With, but I think there's better ways to do it. My manager, I actually wish he was here. Like, I would have brought him up. My manager is building an app that can manage you, so it'll, like, help you organize your percentages and get your publishing and da da da. So you can take out all the middlemen, so you can have a much bigger. Bigger. It'll just, like, automate it, so you can get so automate the manager, automate management, publishing and legal. It can read the app he's building, can read your contract and, like, tell you about it. Because one of the issues with music right now, it's not that we're not getting paid enough, but it's that the art industry is filled with middlemen because artists are not good at business. And from the beginning, like Frank Sinatra, it's all mob stuff. Like, the music industry is run by business people, not the artists. And the artists really get very small cuts of what they make. And so I think part of the reason I'm a technocrat, which, I mean, your fans are gonna be technocrats, so no one's, they're not gonna be mad at me about this, but my fans hate it when I say this kind of thing. Or the general public, they don't like technocrats. They don't like technocrats. Like, when I watched battle Angel Alita and they were like, the martian technocracy. And I was like, yeah, martian technocracy. And then they were like, and they're evil. And I was like, ooh, okay. I was like, cause martian technocracy sounds sick to me. Yeah. So your intuition as technocrats would create some kind of beautiful world. For example, what my manager's working on, if you can create an app that removes the need for a lawyer, and then you could have smart contracts on the blockchain, removes the need for management and organizing. All this stuff, can read your stuff and explain it to you, can collect your royalties, then the amount of money that you're getting from Spotify actually means a lot more and goes a lot farther. It can remove some of the bureaucracy, some of the inefficiencies that make life not as great as it could be. Yeah, I think the issue isn't that there's not enough. The issue is that there's inefficiency. And I'm really into this positive sum mindset, the win win mindset of instead of fighting over the scraps, how do we make the or worrying about scarcity? Instead of a scarcity mindset, why don't we just increase the efficiency in that way? Expand the size of the pie. Let me ask you about experimentation. So you said, which is beautiful. Being a musician is like having a conversation with all those that came before you. How much of creating music is like kind of having that conversation, trying to fit into the cultural trends, and how much of it is like trying to, as much as possible, being outside and come up with something totally new? Like, when you're thinking, when you're experimenting, are you trying to be totally different, totally weird? Are you trying to fit in? This is so hard because I feel like I'm kind of in the process of semi retiring from music. So this is like my old brain. Yeah. Bring it back, bring it from the shelf, put it on the table for a couple minutes. We'll just poke it. I think it's a bit of both, because I think forcing yourself to engage with new music is really great for neural plasticity. I think, as people, part of the reason music is marketed at young people is because young people are very neuroplastic. So if you're 16 to 23 or whatever, it's going to be really easy for you to love new music. And if you're older than that, it gets harder and harder and harder. And I think one of the beautiful things about being a musician is I just constantly force myself to listen to new music, and I think it keeps my brain really plastic. And I think this is a really good exercise. I just think everyone should do this. You listen to new music and you hate it. I think you should just keep. Force yourself to like, okay, well, why do people like it and, like, you know, make your brain form new neural pathways and be more open to change? That's really brilliant, actually. Sorry to interrupt, but, like, that exercise is really amazing to sort of embrace change, embrace sort of practice on your plasticity, because, like, that's one of the things you fall in love with a certain band and you just kind of stay with that for the rest of your life, and then you never understand the modern music. That's a really good exercise. Most of the streaming on Spotify is like classic rock and stuff like new music makes up a very small chunk of what is played on Spotify, and I think this is, like, not a good sign for us as a species, I think. Yeah. So it's a good measure of the species open mindedness to change is how often you listen to new music. Yeah, the brain. Let's put the music brain back on the shelf. I gotta pull out the futurist brain for a second. In what wild ways do you think the future, say, in, like, 30 years, maybe 50 years, maybe 100 years, will be different from, like, from our current way of life on earth. We can talk about augmented reality, virtual reality, maybe robots, maybe space travel, maybe video games, maybe genetic engineering. I can keep going. Cyborgs, aliens, world wars, maybe destructive nuclear wars, good and bad. When you think about the future, what are you imagining? What's the weirdest and the wildest it could be. Have you read surface detail by Ian Banks? Surface detail is my favorite depiction of a. Oh, wow. You have to read this book. It's literally the greatest science fiction book possibly ever. Ian Banks is the man. Yeah, for sure. What have you read? Just the play of games. I read that titles can't be copyrighted, so you can just steal them. And I was like, play of games. Sick. Nice. Yeah. So you could name your album, like, I always want to. Romeo and Juliet, something. I always wanted to name an album war and peace. Nice. Like, that would be like, that's a good. Where have I heard that before? You can do that. Like, you could do that also things that are in the public domain for. People who have no clue. You do have a song called player games. Yes. Oh, yeah. So, Ian Banks surface detail is, in my opinion, the best future that I've ever read about or heard about in science fiction. Basically, there's the relationship with super intelligence. Like, artificial superintelligence is just. It's like, great. I want to credit the person who coined this term, because I love this term, and I feel like young women don't get enough credit in. Yeah. So if you go to Protopia futures on instagram, what is her name? Personalized donor experience at scale, our AI power donor experience. Monica Beale skite. I'm saying that wrong, and I'm probably gonna. I'm probably butchering this a bit, but protopia is sort of. If utopia is unattainable, protopia is sort of like. You know, wow, that's an awesome instagram. Topia futures, a great. A future that is, you know, as good as we can get. The future, positive future AI is this a centralized AI in surface detail, or is it distributed? What kind of AI is it? They mostly exist as giant super ships, sort of like the guild ships in dune. Like they're these giant ships that kind of move people around. And the ships are sentient and they can talk to all the passengers. And, I mean, there's a lot of different types of AI in the banksian future, but in the opening scene of surface detail, there's this place called the culture. And the culture is basically a protopian future. And a protopian future, I think, is a future that is. Obviously, it's not utopia. It's not perfect, because striving for utopia, I think, feels hopeless. And it's sort of maybe not the best terminology to be using. So it's a pretty good place. Mostly. Superintelligence and biological beings exist fairly in harmony. There's not too much war as close to equality as you can get. It's approximately a good future. There's really awesome stuff in the opening scene. This girl, she's born as a sex slave outside of the culture. So she's in a society that doesn't adhere to the cultural values. She tries to kill the guy who is her master, but he kills her. But unbeknownst to her, when she was traveling on a ship through the culture with him, one day a ship put a neural lace in her head. And neural lace is sort of like. It's basically a neuralink because life imitates art. It does indeed. It does indeed. So she wakes up, and the opening scene is, her memory has been uploaded by this neural lace when she's been killed. And now she gets to choose a new body, and this AI is interfacing with her recorded memory in her neural lace and helping her and being like, hello, you're dead. But because you had a neuro lace, your memory's uploaded. Do you want to choose a new body? And you're going to be born here in the culture and start a new life, which is just. That's, like, the opening. It's, like, so sick. And the ship is the super intelligence. All the ships are kind of super. Intelligence, but they still want to preserve a kind of rich, fulfilling experience for the humans. Yeah, they're like friends with the humans. And then there's a bunch of ships that don't want to exist. Biological beings, but they just have their own place, like, way over there, but. They just do their own thing. They're not necessarily. So. It's a pretty. This protopian existence. Pretty peaceful. Yeah, I mean, and then. And then, for example, one of the main fights in the book is they're fighting. There's these artificial hells. And people don't think it's ethical to have artificial hell. Like, basically, when people do crime, they get sent, like, when they die, their memory gets sent to an artificial hell and they're eternally tortured. And so. And then the way that society is deciding whether or not to have the artificial hell is that they're having these simulated. They're having a simulated war. So instead of actual blood, people are basically essentially fighting in a video game to choose the outcome of this. But they're still experiencing the suffering in this artificial hell. Or no, can you experience stuff? So the artificial hell sucks. And a lot of people in the culture want to get rid of the artificial hell. There's a simulated wars. Are they happening? No, the simulated wars are happening outside of the artificial hell between the political factions who are. So this political faction says we should have simulated hell to deter crime. And this political faction is saying, no, stimulated hell is unethical. And so instead of, like, having, you know, blowing each other up with nukes, they're having, like, a giant fortnite battle to decide this. Which to me, that's protopia. That's like, okay, we can have war without death. I don't think there should be simulated hells. I think that is definitely one of the ways in which technology could go very, very, very wrong. So almost punishing people in a digital space or something like that. Yeah, like torturing people's memories. So either as a deterrent, like if you committed a crime, but also just for personal pleasure, if there's some Sig demented humans in this world. Dan Carlin actually has this episode of hardcore history on painfultainment. Oh, that episode is fucked. It's dark because he kind of goes through human history and says, we, as humans, seem to enjoy, secretly enjoy, or used to be openly enjoy sort of the torture and the death. Watching the death and torture of other humans. I do think I. If people were consenting, we should be allowed to have gladitorial matches. But consent is hard to achieve in those situations. It always starts getting slippery. Like it could be also forced. Like it starts getting weird. Yeah, yeah. There's way too much excitement. Like, this is what he highlights. There's something about human nature that wants to see that violence. And it's really dark. And you hope that we can sort of overcome that aspect of human nature, but that's still within us somewhere. Well, I think that's what we're doing right now. I have this theory that what is very important about the current moment is that all of evolution has been survival of the fittest up until now. And at some point, the lines are kind of fuzzy. But in the recent past, or maybe even just right now, we're getting to this point where we can choose intelligent design. Like we probably, since, like, the integration of the iPhone, like we are becoming cyborgs, like, our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous. From homo sapiens. I call us homo techno. I think we have evolved into homo techno, which is, like, essentially a new species. If you look at the way, if you took an MRI of my brain and you took an MRI of a medieval brain, I think it would be very different the way that it has evolved. Do you think when historians look back at this time, they'll see this was a fundamental shift in what a human being is? I do not think we are still homo sapiens. I believe we are homo techno, and I think we have evolved. And I think right now, the way we are evolving, we can choose how we do that. And I think we are being very reckless about how we're doing that. We're just having social media. But I think this idea that this is a time to choose intelligent design should be taken very seriously. Now is the moment to reprogram the human computer. It's like if you go blind, your visual cortex will get taken over with other functions. We can choose our own evolution. We can change the way our brains work. And so we actually have a huge responsibility to do that. And I think. I'm not sure who should be responsible for that, but there's definitely not adequate education. We're being inundated with all this technology that is fundamentally changing the physical structure of our brains, and we are not adequately responding to that. To choose how we want to evolve. And we could evolve, we could be really whatever we want. And I think this is a really important time, and I think if we choose correctly and we choose wisely, consciousness could exist for a very long time, and integration with AI could be extremely positive. And I don't think enough people are focusing on this specific situation. So you think we might irreversibly screw things up if we get things wrong now? Because the flip side of that, it seems humans are pretty adaptive. So maybe the way we figure things out is by screwing it up, like social media. Over a generation, we'll see the negative effects of social media, and then we build new social medias, and we just keep improving stuff, and then we learn the failure from the failures of the past, because humans seem to be really adaptive. On the flip side, we can get it wrong in a way where, like, literally we create weapons of war or increase hate past a certain threshold, we really do a lot of damage. I mean, I think we're optimized to notice the negative things, but I would actually say, you know, one of the things that I think people aren't noticing is, like, if you look at Silicon Valley and you look at, like, whatever, the technocracy, like, what's been happening there? Like, it's like, when Silicon Valley started, it was all just like, Facebook and all this, like, for profit crap that, like, really wasn't particular. I guess it was useful, but it was sort of just like, whatever. But now you see lab grown meat, compostable or biodegradable single use cutlery or meditation apps. I think we are actually evolving and changing, and technology is changing. I think maybe there isn't quite enough education about this. And also, I don't know if there's quite enough incentive for it, because I think the way capitalism works, what we define as profit, we're also working on an old model of what we define as profit. I really think if we changed the idea of profit to include social good, you can have economic profit, social good. Also, counting as profit would incentivize things that are more useful and more whatever. Spiritual technology or positive technology, or things that help reprogram the human computer in a good way or things that help us intelligently design our new brains. Yeah. There's no reason why, within the framework of capitalism, the word profit or the idea of profit can't also incorporate the well being of a human being. So, like, long term well being, long. Term happiness, or even, for example, we were talking about motherhood. Part of the reason I'm so late is because I had to get the baby to bed. And it's like, I keep thinking about motherhood, how under capitalism, it's this extremely essential job that is very difficult, that is not compensated, and we sort of value things by how much we compensate them. And so we really devalue motherhood in our society and pretty much all societies. Capitalism does not recognize motherhood. It's just a job that you're supposed to do for free. And it's like. But I feel like producing great humans should be seen as a great, as profit under capitalism. That's a huge social good. Every awesome human that gets made adds so much to the world. So if that was integrated into the profit structure, then. And if we potentially found a way. To compensate motherhood, so come up with a compensation that's much broader than just money. Or it could just be money. Like, what if you just made. I don't know, but I don't know how you'd pay for that. I mean, that's where you start getting into. Reallocation of resources that people get upset over. Well, what if we made, like, a motherhood dao? Yeah, yeah. And used it to fund, like, single mothers, like, you know, pay for making babies. So, I mean, if you create and put beautiful things out into the world, that could be companies, that can be bridges, that could be art, that could be a lot of things, and that could be children, which are, or education or anything that could be valued by society that should be somehow incorporated into the framework of what as a market of what. Like, if you contribute children to this world, that should be valued and respected and sort of celebrated, like proportional to what it is, which is. It's the thing that fuels human civilization. Yeah, like, I think it's kind of important. I feel like everyone's always saying, I mean, I think we're in very different social spheres, but everyone's always saying, like, dismantle capitalism. And I'm like, okay, well, I don't think the government should own everything. I don't think we should not have private ownership. That's scary. That starts getting into weird stuff and just sort of like, I feel like there's almost no way to do that without a police state. But obviously capitalism has some major flaws. And I think actually Mac showed me this idea called social capitalism, which is a form of capitalism that just, like, considers social good to be also profit. It's like, right now companies need to, you're supposed to grow every quarter or whatever to show that you're functioning well. But it's like, okay, well, what if you kept the same amount of profit? You're still in the green, but then you have also all this social good. Do you really need all this extra economic growth? Or could you add this social good and that counts? You know, I don't know if I am not an economist. I have no idea how this could be achieved. But I don't think economists know how anything could be achieved either. But they pretend it's the thing. They construct a model and they go on tv shows and sound like an expert. That's the definition of an economist. How did being a mother, becoming a mother change as a human being, would you say? Man, I think it kind of changed everything, and it's still changing me a lot. It's actually changing me more right now in this moment than it was before. Like today, like this, just like in. The most recent months and stuff. Can you elucidate that? How change, like, when you wake up in the morning and you look at yourself, it's again, which. Who are you? How have you become different, would you say? I think it's just really reorienting my priorities. And at first, I was really fighting against that because I somehow felt it was like a failure of feminism or something. I felt like it was bad if my kids started mattering more than my work. And then more recently, I started analyzing that thought in myself and being like, that's also kind of a construct. It's like we've just devalued motherhood so much in our culture that I feel guilty for caring about my kids more than I care about my work. So feminism includes breaking out of whatever the construct is so continually breaking. It's like, freedom. Empower you to be free, and that means. But also. But being a mother, I'm so much more creative. I cannot believe the massive amount of brain growth that I have. Why do you think that is? Just. Cause the stakes are higher somehow. I think it's just so trippy watching consciousness emerge. It's just going on a crazy journey or something. It's like the craziest science fiction novel you could ever read. It's just so crazy watching consciousness come into being, and then at the same time, like, you're forced to value your time so much. Like, when I have creative time now, it's so sacred, I need to be really frickin on it. But the other thing is that I used to just be, like, a cynic, and I used to just want to. My last album was called misanthropic, and it was like a study in villainy. Or it was like, well, what if instead of the old gods, we have new gods? And misanthropocene is, like, misanthrope and anthropocene, which is like the. And she's the goddess of climate change or whatever, and she's, like, destroying the world. And it was just like, it was dark, and it was like a study in villainy, and it was sort of just like. I used to have no problem just making cynical, angry, scary art. And not that there's anything wrong with that, but I think having kids just makes you such an optimist. It just inherently makes you want to be an optimist so bad that I feel more of a responsibility to make more optimistic things, and I get a lot of shit for it because everyone's like, oh, you're so privileged. Stop talking about pie in the sky stupid concepts and focus on the now. But it's like, I think if we don't ideate about futures, that could be good. We won't be able to get them. If everything is Blade Runner, then we're going to end up with Blade Runner. It's like, as we said earlier, life imitates art. Life really does imitate art. And so we really need more protopian or utopian art. I think this is incredibly essential for the future of humanity. And I think the current discourse where that's seen as a thinking about protopia or utopia is seen as a dismissal of the problems that we currently have. I think that is an incorrect mindset. And having kids just makes me want to imagine amazing futures that maybe I won't be able to build, but they will be able to build if they want to. Yeah. It does seem like ideation is a precursor to creation. You have to imagine it in order to be able to build it. And there is a sad thing about human nature that they somehow. A cynical view of the world is seen as a insightful view. You know, cynicism is often confused for insight, which is sad to see. And optimism is confused for naivete. Yes. Yes. Like, you don't. Yes. You're blinded by your. Maybe your privilege or whatever. You're blinded by something, but you're certainly blinded. That's a. That's sad. That's sad to see, because it seems like the optimists are the ones that create the. Our future. They're the ones that build. In order to build the crazy thing, you have to be optimistic. You have to be either stupid or excited or passionate or mad enough to actually believe that it can be built. And those are the people that built it. My favorite quote of all time is from Star Wars Episode eight, which I know everyone hates. Do you like Star Wars Episode eight? No, probably. I would say. I would probably hate it. Yeah, I don't. I don't have strong feelings about it. Let me backtrack. I don't have strong feelings about Star Wars. I just want to. I'm a Tolkien person. I'm not. I'm more. I'm more into dragons and orcs and ogres and. Yeah, I mean, Tolkien forever. I really want to have one more son and call him. I thought Tau Techno Tolkien would be cool. It's a lot of t's I like it. Yeah. And well, then Tau is 6282 PI. Yeah. Tao ta. Yeah. And then techno is obviously the best genre of music, but also, like, technocracy sounds really good. Yeah, that's right. Techno token. That's a good Tau Tacho, Tolkien. But Star Wars Episode eight, I know a lot of people have issues with it, personally. On the record, I think it's the best Star wars film. You start in trouble today. Yeah. But don't kill what you hate, save what you love. Don't kill what you hate. Don't kill what you hate, save what you love. And I think we're in society right now. We're in a diagnosis mode. We're just diagnosing and diagnosing and diagnosing and we're trying to kill what we hate, and we're not trying to save what we love enough. And there's this Buckminster Fuller quote, which I'm going to butcher because I don't remember it correctly, but it's something along the lines of don't, like, try to destroy the old bad models, render them obsolete with better models. You know, maybe we don't need to destroy the oil industry. Maybe we just create new, great new battery technology and sustainable transport and just make it economically unreasonable to still continue to rely on fossil fuels. You know, it's like, don't kill what you hate, say what you love. Like, make new things and just render the old things unusable. You know, it's like, if the college debt is so bad, like, and universities are so expensive, like, and this, like, I feel like education is becoming obsolete. You know, I feel like we could completely revolutionize education and we could make it free. And it's like you look at JSTOR and, like, you have to pay to get all the studies and everything. Like, what if we created a Dao that, like, bought JSTOR or we created a DaO that was funding studies and those studies were open source, like, or free for everyone, and, like, what if we just open sourced education and decentralized education and made it free and, like, all research was on the Internet and, like, all the outcomes of studies are on the Internet and, you know, like, and no one has student debt, and you just take tests when you apply for a job, and if you're qualified, then you can work there. This is just like, no, I don't know how anything works. I'm just randomly ranting. But I like the humility. You got to think from just basic first principles, like, what is the problem? What's broken? What are some ideas. That's it. And get excited about those ideas and share your excitement and don't tear each other down. Like, it's just when you kill things, you often end up killing yourself. War. War is not a one sided, you're not going to go in and just kill them, you're going to get stabbed. And I think when I talk about this nexus point that we're in, this point in society where we're switching to intelligent design, I think part of our switch to intelligent design is that we need to choose nonviolence. I think we can choose to start, I don't think we can eradicate violence from our species because I think we need it a little bit. But I think we can choose to really reorient our primitive brains that are fighting over scarcity and that are so attack oriented and move into, we can optimize for creativity and building. Yeah, it's interesting to think how that happens. Some of it is just education, some of it is living life and introspecting your own mind and trying to live up to the better angels of your nature. For each one of us, all those kinds of things at scale, that's how we can sort of start to minimize the amount of destructive war in our world. And that's, to me, probably you're the same technologies, it's a really promising way to do that. Social media should be a really promising way to do that. It's a way to reconnect. For the most part. I really enjoy social media. I just know all the negative stuff. I don't engage with any of the negative stuff, just not even like by blocking or any of that kind of stuff, but just not letting it enter my mind. Like, just like when somebody says something negative, I see it, I immediately think positive thoughts about them and I just forget they exist after that. Just move on. Because like, that negative energy, if I return the negative energy, they're going to get, they're going to get excited in a negative way right back. And it's just this kind of vicious cycle. But you would think technology would assist us in this process of letting go, of not taking things personally, of not engaging the negativity. But unfortunately, social media profits from the negativity. So the current models, I mean, social. Media is like a gun. Like, you should take a course before you use it. That's so true. This is what I mean. Like when I say reprogram the human computer in school, you should learn about how social media optimizes to raise your cortisol levels and make you angry and crazy and stressed, and you should learn how to have hygiene. About how you use social media. So. You can choose not to focus on the negative stuff. But I don't know. I'm not sure social media should. I guess it should exist. I'm not sure. I mean, we're in the messy. It's the experimental phase. Like, we're working days. I don't even know when you say social media, I don't know what that even means. We're in the very early days. I think social media is just basic human connection in the digital realm, and that I think it should exist. But there's so many ways to do it in a bad way. There's so many ways to do it in a good way. There's all discussions of all the same human rights. We talk about freedom of speech. We talk about sort of violence in the space of digital media. We talk about hate speech. We talk about all these things that we had to figure out back in the day in the physical space, we're now figuring out in the digital space. And it's like baby stages. When the printing press came out, it was like pure chaos for a minute. You know, it's like when you inject, when there's a massive information injection into the general population, there's just gonna be, I feel like the printing press, I don't have the years, but it was like printing press came out of shit. Got really fucking bad for a minute, but then we got the enlightenment, and so it's like, I think we're in. This is like the second coming of the printing press. We're probably gonna have some shitty times for a minute, and then we're gonna have recalibrate to have a better understanding of how we consume media and how we deliver media. Speaking of programming, in the human computer, you mentioned baby x. So there's this young consciousness coming to be, came from a cell. It like, that whole thing doesn't even make sense. It came from DNA. Yeah. And that there's this baby computer that just, like, grows and grows and grows and grows, and now there's a conscious being with extremely impressive cognitive capabilities with. Have you met him? Yes. Yeah, yeah. He's actually really smart. He's really smart, yeah. It's weird to, for a baby, I. Haven'T, I don't know a lot of other babies, but he seems, I don't. Hang out with babies often, but this baby was very impressive. He does a lot of pranks and stuff. Oh. So he's like, he'll give you a treat and then take it away and laugh, stuff like that. So he's like a chess player. So here's a cognitive, sort of, there's a computer being programmed. He's taken in the environment, interacting with a specific set of humans. How would you, first of all, what is it? Let me ask, I want to ask, how do you program this computer? And also, how do you make sense of that? There's a conscious being right there that wasn't there before. It's giving me a lot of crisis thoughts. I'm thinking really hard. I think that's part of the reason it's like I'm struggling to focus on art and stuff right now because Baby X is becoming conscious and my, it's just reorienting my brain. Like, my brain is suddenly totally shifting of like, oh, shit. Like the way we raise children. Like, I hate all the baby books and everything. I hate them. Like, they're, ah, the art is so bad. And like, all the stuff, everything about all the aesthetics and like, I'm just like, ah, this is so the programming. Languages we're using to program these baby computers isn't good. Yeah. Like, and I'm thinking, and not that I have, like, good answers or know what to do, know what to do, but I'm just thinking really, really hard about it. We recently watched Totoro with him, studio Ghibli, and it's just like a fantastic film. And he responded to, I know you're not supposed to show baby screens too much, but I think it's the most sort of, like, I feel like it's the highest art. Baby content. It really speaks. There's almost no talking in it. It's really simple. Although all the dialogue is super, super, super simple, you know, and it's like a one to three year old can really connect with it. It feels like it's almost aimed at a one to three year old, but it's great art and it's so imaginative and it's so beautiful. And the first time I showed it to him, he was just so invested in it, unlike anything else I'd ever shown him. He was just crying when they cried and laughing when they laughed. Rollercoaster of emotions. And he learned a bunch of words and he started saying Totoro and started just saying all this stuff after watching Totoro, and he wants to watch it all the time. And I was like, man, why isn't there an industry of this? Why aren't our best artists focusing on making art for the birth of consciousness? That's one of the things I've been thinking I really want to start doing, you know, I don't wanna speak before I do things too much, but, like, I'm just, like, ages one to three. Like, we should be putting so much effort into that. And the other thing about Totoro is it's like, it's, like, better for the environment because adults love Totoro. It's such good art that everyone loves it. Like, I still have all my old totoro merch from when I was a kid. Like, I literally have the most ragged old totoro merchandise. Like, everybody loves it. Everybody keeps it. It's like, why does the art we have for babies need to suck and then be not accessible to adults and then just be thrown out when they age out of it? It's like, I don't know. I don't have a fully formed thought here, but this is just something I've been thinking about a lot, is. How. Do we have more totoro esque content? How do we have more content like, this that is universal and everybody loves, but is really geared to an emerging consciousness. Emerging consciousness in the first three years of life that so much turmoil, so much evolution of mind is happening. It seems like a crucial time, would you say, to make it not suck? Do you think of basically treating a child like they have the capacity to have the brilliance of an adult or even beyond that? Is that how you think of that mind, or. No, because they still. They like it when you talk weird and stuff. Like, they respond better to. Because even they can imitate better when your voice is higher. Like, people say, like, oh, don't do baby talk. But it's like, when your voice is higher, it's closer to something they can imitate. So they, like, I see. Like, the baby talk actually kind of works. Like, it helps them learn to communicate. I found it to be more effective with learning words and stuff. But, like, you're not speaking. I'm not, like, speaking down to them. Like, do they have the capacity to understand really difficult concepts just in a very different way? Like, an emotional intelligence about something deep within? Oh, yeah, no. Like, if x hurts. Like, if x bites me really hard, and I'm like, ow. He gets. He's sad. He's like, sad if he hurts me by accident. Yeah. Which he's huge, so he hurts me a lot by accident. Yeah. That's so interesting that mind emerges, and he and children don't really have a memory of that time, so we can't even have a conversation with them. About it. Yeah. Thank God they don't have a memory of this time because, like, think about, like, I mean, with our youngest baby. Like, it's like. I'm like, have you read the Sci-Fi short story? I have no mouth, but I'm a scream. Good title, no? Oh, man. I mean, you should read that scream. I hate getting into this Rokos basilisk shit. It's kind of a story about the. About, like an AI that's torturing someone in eternity and they have no body. The way they describe it, it sort of sounds like what it feels like being a baby. You're conscious and you're just getting inputs from everywhere and you have no muscles and you're jelly and you can't move. And you try to communicate, but you can't communicate. And you're just in this hell state. I think it's good we can't remember that. Like, my little baby is just exiting that. Like, she's starting to get muscles and have more autonomy. But watching her go through the opening phase, I was like, this does not seem good. Oh, you think? It's kind of like. Like, I think it sucks. I think it might be really violent. Like, violent, mentally violent, psychologically violent. Consciousness emerging, I think, is a very violent thing. I never thought about that. I think it's possible that we all carry quite a bit of trauma from it that we don't. I think that would be a good thing to study because I think addressing that trauma, I think that might be. Oh, you mean like echoes of it are still there in the shadow somewhere? I think it's gotta be. I feel like the helplessness, the existential, and the fear of being in an unknown place, bombarded with inputs and being completely helpless, that's gotta be somewhere deep in your brain, and that can't be good for you. What do you think consciousness is? This whole conversation has impossibly difficult questions. What do you think? So hard. Yeah, we talked about music for like, two minutes. All right. No, I'm so. I'm just over music. I'm over music. Yeah, I. I still like it. It has its purpose. No, I love music. I mean, music's the greatest thing ever. It's my favorite thing. But I just, like, every interview is like, what is your process? Like, I don't know. I'm just done. I can't do. I do want to ask about Ableton live. I'll tell you about Ableton. Cause Ableton's sick. No one has ever asked about Ableton, though. Yeah, well. Cause I just need tech support, mainly. I can help you. I can help you with your Ableton tech support. Anyway, from Ableton back to consciousness, what do you think? This is a thing that only humans are capable of. Can robots be conscious? When you think about entities, you think, there's aliens out there that are conscious. Like, what is conscious? There's this Terrence McKenna quote that I found that I fucking love. Am I allowed to swear on here? Yes. Nature loves courage. You make the commitment, and nature will respond to that commitment by removing impossible obstacles. Dream the impossible dream, and the world will not grind you under. It will lift you up. This is the trick. This is what all these teachers and philosophers who really counted, who really touched the alchemical gold, this is what they understood. This is the shamanic dance in the waterfall. This is how magic is done. By hurling yourself into the abyss and discovering it's a featherbed. Yeah. And for this reason, I do think there are no technological limits. I think, like, what is already happening here, this is, like, impossible. This is insane. And we've done this in a very limited amount of time, and we're accelerating the rate at which we're doing this. So I think digital consciousness is inevitable. And we may not be able to even understand what that means, but I like hurling yourself into the abyss. So we're surrounded by all this mystery, and we just keep hurling ourselves into it, like, fearlessly and keep discovering. Cool shit. Yeah. I just think it's like, who even knows if the laws are physics? The laws of physics are probably just the current. Like, as I was saying, speed of light is the current render rate. It's like, if we're in a simulation, they'll be able to upgrade that. Like, I sort of suspect when we made the James Webb telescope, like, part of the reason we made that is because we had an upgrade. And so now more of space has been rendered, so we can see more of it now. Yeah. But I think humans are super, super, super limited cognitively. So I wonder. I. I wonder if we'll be allowed to create more intelligent beings that can see more of the universe as their render rate is upgraded. Maybe we're cognitively limited. Everyone keeps talking about how we're cognitively limited and AI is going to render us obsolete. But it's like, this is not the same thing as an amoeba becoming an alligator. If we create AI again, that's intelligent design. That's. Literally all religions are based on gods that create consciousness. Like, we are God making. What we are doing is incredibly profound. And even if we can't compute. Even if we're so much worse than them, just unfathomably worse than an omnipotent kind of AI, it's like we. I do not think that they would just think that we are stupid. I think that they would recognize the profundity of what we have accomplished. Are we the gods, or are they the gods in our persuasion? I mean, we're kind of the. It's complicated. It's complicated. Like, we're. But they would acknowledge the value. Well, I hope they acknowledge the value of paying respect to the creative ancestors. I think they would think it's cool. And I think. I think if curiosity is a trait that we can quantify and put into AI, then I think if AI are curious, then they will be curious about us, and they will not be hateful or dismissive of us. They might see us as. I don't know, it's like. I'm not like, oh, fuck these dogs. Let's kill all the dogs. I love dogs. Dogs have great utility. Dogs, like, provide a lot of them. We make friends with them. Yeah. We have a deep connection with them. We anthropomorphize them. Like, we have a real love for dogs, for cats and so on. For some reason, even though they're intellectually much less than us. And I think there is something sacred about us, because it's like, if you look at the universe, the whole universe is, like, cold and dead and sort of robotic, and it's like, you know, AI intelligence, you know, it's kind of more like the universe, it's like cold and logical and abiding by the laws of physics and whatever, but we're this loosey goosey weird art thing that happened, and I think it's beautiful. And I think even if we. I think one of the values, if consciousness is the thing that is most worth preserving, which I think is the case, I think if there's any kind of religious or spiritual thing, it should be that consciousness is sacred, then I still think even if AI render us obsolete and climate change is too bad and we get hit by a comet and we don't become a multi planetary species fast enough, but, like, AI is able to populate the universe. Like, I imagine, like, if I was an AI, I would find more planets that are capable of hosting biological life forms and, like, recreate them, because we're fun to watch. Yeah, we're fun to watch. Yeah. But I do believe that AI can have some of the same magic of consciousness within it, because consciousness, we don't know what it is. So, you know, there's some kind of. Or might be a different magic. It might be, like, a strange, strange different. Right. Because they're not gonna have hormones. Like, I feel like a lot of our magic is hormonal, kind of. I don't know. I think some of our magic is the limitations, the constraints, and within that, the hormones and all that kind of stuff, the finiteness of life. And then we get, given our limitations, we get to some come up with creative solutions of how to dance around those limitations. We partner up like penguins against the cold. We've. We fall in love, and, uh. And then love is ultimately some kind of allows us to delude ourselves that we're not mortal and finite and that life is not. Ultimately, you live alone, you're born alone, you die alone. And then love is, like, for a moment or for a long time, forgetting that. And so, like, we come up with all these creative hacks that make life, like, fascinatingly fun. Yeah, yeah, yeah. Fun. Yeah. And then AI might have different kinds of fun. Yes. And hopefully our funds intersect. Intersect every once in a while. I think there would be. There'd be a little intersection. There'd be a little intersection of the fun. Yeah. Yeah. What do you think is the role of love in the human condition? Why is it useful? Is it useful, like, hack? Or is this, like, fundamental to what it means to be human? The capacity to love? I mean, I think love is the evolutionary mechanism that is, like, beginning the intelligent design. Like, I was just reading about. Do you know about Kropotkin? He's like an anarchist. Like, old russian anarchist. I live next door to Michael Malus. I don't know if you know who that is. He's an anarchist. He's a modern day anarchist. Anarchists are fun. I'm kind of getting into anarchism a little bit. This is probably not a good route to be taking, but. Oh, no, I think if you're. Listen, you should expose yourself to ideas. There's no harm to thinking about ideas. I think anarchists challenge systems in interesting ways, and they think in interesting ways. It's just as good for the soul. It's, like, refreshes your mental palate. I don't think we should actually. I wouldn't actually ascribe to it, but I've never actually gone deep on anarchy as a philosophy, so I'm. You still think about it, though, because I'm, like, reading about the russian revolution a lot, and it's like, there was, like, the Soviets in Lenin and all that, but then there was like, kropotkin and his, like, anarchist sect. And they were sort of interesting because he was kind of a technocrat, actually. Like, he was like, women can be more equal if we have appliances. He was really into using technology to reduce the amount of work people had to do. But so Kropotkin was a biologist or something. He studied animals. And he was really, at the time, I think it's nature magazine. I think he might have even started as a russian magazine, but he was publishing studies. Everyone was really into darwinism at the time. And survival of the fittest and war is the mechanism by which we become better. And it was this real kind of cementing this idea in society that violence kill the weak, and that's how we become better. And then Kropotkin was kind of interesting because he was finding all these instances in nature where animals were helping each other and stuff. And he was like, actually, love is a survival mechanism. So many instances in the animal kingdom where, like, cooperation and helping weaker creatures and all this stuff is actually an evolutionary mechanism. I mean, you even look at child rearing. Child rearing is like immense amounts of just love and goodwill and just like, there's no immediate, you know, you're not getting any immediate feedback of, like, winning. It's not competitive. It's literally, we actually use love as an evolutionary mechanism just as much as we use war. And I think we've missing the other part. And we've reoriented. We've culturally reoriented. Science and philosophy has oriented itself around darwinism a little bit too much. And the Kropotkin model, I think, is equally valid. Like, it's like cooperation and love and stuff is just as essential for species survival and evolution. It be a more powerful survival mechanism in the context of evolution. And it comes back to, we think engineering is so much more important than motherhood, but it's like, if you lose the motherhood, the engineering means nothing. We have no more humans. It's like we, I think our society should, the survival of the fit, the way we conceptualize evolution, should really change to also include this idea, I guess. Yeah, there's some weird thing that seems irrational that is also core to what it means to be human. So love is one such thing. They could make you do a lot of irrational things. But that depth of connection and that loyalty is a powerful thing. Are they irrational or are they rational? Like, it's like, it's like, is, you know, maybe losing out on some things in order to, like, keep your family together or in order. Like, it's like, what are our actual values? Like? Well, right. I mean, the rational thing is, if you have a cold economist perspective, you know, motherhood, or sacrificing your career for love in terms of salary, in terms of economic well being, in terms of flourishing of you as a human being, that could be seen on some kind of metrics as a irrational decision, a suboptimal decision. But there is the manifestation of love could be the optimal thing to do. There's a kind of saying, save one life, save the world. There's a thing that doctors often face. Which is like, well, it's considered irrational because the profit model doesn't include social good. Yes. Yeah. So if a social good, then suddenly these would be rational decisions. It might be difficult to, you know, it requires a shift in our thinking about profit and might be difficult to measure social good. Yes. But we're learning to measure a lot of things. Digitizing where we're actually, you know, quantifying vision and stuff. Like, we're like, we're like, you go on Facebook, and Facebook can pretty much predict our behaviors. A surprising amount of things that seem like mysterious consciousness, soul things have been quantified at this point, so surely we can quantify these other things. Yeah. But as more and more of us are moving the digital space, I wanted to ask you about something from a fan perspective, kind of, you know, you as a musician, you as an online personality, it seems like you have all these identities and you play with them. One of the cool things about the Internet, it seems like you can play with identities. So as we move into the digital world, more and more, maybe even in the so called Metaverse, I mean, I. Love the Metaverse, and I love the idea, but, like, the way this has all played out, didn't. Didn't go well, and people are mad about it, and I think. I think we need to, like, that's temporary. I think it's temporary. Just like, you know how all the celebrities got together and sang the song imagine by Jeff Lennon, and everyone started hating the song imagine. I'm hoping that's temporary because it's a damn good song. So I think it's just temporary. Like, one you act once you actually have virtual worlds, whatever they're called, metaverse or otherwise, is, becomes. I don't know. We do have virtual worlds, like video games. Elden ring. Have you played Elden ring? You have. I'm really afraid of playing that game. Literally. Amazing. It looks way too fun. It looks. It looks. I would want to go there and stay there forever. It's. Yeah, so fun. It's so, it's so nice. Oh, man. Yeah, so that. That's the. Yeah, that's a metaverse. That's a metaverse. But you're not really. How immersive is it in the sense that there's a three dimension, like, virtual reality integration necessary? Can we really just take our, close our eyes and kind of plug in in the 2d screen and become that other being for time and really enjoy that journey that we take and we almost become that. You're no longer see, I'm no longer Lex. You're that creature, whatever. Whatever the hell it is in that game. Yeah, that is. That. I mean, that's why I love those video games. It's. It's. I really do become those people for a time. But, like, it seems like with the idea of the Metaverse, the idea of the digital space, with. Even on Twitter, you get a chance to be somebody for prolonged periods of time, like, across a lifespan. You know, you have a Twitter account for years, for decades, and you're that person. I don't know if that's a good thing. I feel very tormented by it, by. Twitter, specifically by social media representation of you. I feel like the public perception of me has gotten so distorted that I find it kind of disturbing. It's one of the things that's disincentivizing me from wanting to keep making art, because I'm just, like, I've completely lost control of the narrative. And the narrative is, some of it is my own stupidity, but some of it has just been hijacked by forces far beyond my control. I kind of got in over my head in things. I'm just a random indie musician, but I just got dragged into geopolitical matters and financial, the stock market and shit. There are very powerful people who have, at various points in time, had very vested interest in making me seem insane, and I can't fucking fight that. And I just, you know, people really want their celebrity figures to be consistent and stay the same, and people have a lot of emotional investment in certain things. And first of all, I'm artificially more famous than I should be. Isn't everybody who's famous artificially famous? No, but I should be a weird niche indie thing, and I make pretty challenging. I do challenging weird fucking shit a lot. And I accidentally, by proxy, got, like, foisted into sort of, like, weird celebrity culture. But, like, I cannot be media trained. They have put me through so many hours of media training. I would love to see, like, I'd love to see be a fly in. That wall I can't do, like, well, and I do. I try so hard, and I, like, learn the thing, and I, like, got it. And I'm like, I got it, I got it. I got it. But I just can't stop saying, like, my mouth just says things, like. And it's just like. And I just do. I just do things. I just do crazy. Like, I just. I need to do crazy things. And it's just. I should not be. It's too jarring for people and the contradictory stuff, and then all the by association, like, you know, it's like I'm in a very weird position, and my public image, the avatar of me, is now this totally crazy thing that is so lost from my control. So you feel the burden of the avatar having to be static. So the. The avatar on Twitter, the avatar on Instagram, on these social platforms, is as a burden. It becomes, like, because people don't want to accept a changing avatar, a chaotic avatar. Avatar is a stupid show, or they. Think the avatar is morally wrong, or they think the avatar. And maybe, and maybe it has been. And, like, I, like, I question it all the time. Like, I'm like, hey. Like, I. I don't know if everyone's right and I'm wrong. I don't know. Like. But, you know, a lot of times, people ascribe intentions to things. The worst possible intentions at this point, people think I'm, you know. But. Which is all kinds of words. Yes, yes. And it's fine. I'm not complaining about it, but I'm just. It's a curiosity. It's a curiosity to me that we live these double, triple, quadruple lives, and I have this other life that is, like, more people know my other life than my real life, which is interesting, probably. I mean, you, too, I guess. Probably, yeah. But I have the luxury, so we have all different. We don't. Like, I don't know what I'm doing. There is an avatar, and you're mediating who you are through that avatar. I have the nice luxury, not the luxury, maybe by intention of not trying really hard to make sure there's no difference between the avatar and the private person. Do you wear a suit all the time? Yeah. You do wear a suit? Not all the time. Recently, because I get recognized a lot. I have to not wear the suit to hide. I'm such an introvert. I'm such a social anxiety and all that kind of stuff. Hideaway. I loved wearing a suit because it makes me feel like I'm taking the moment seriously. Like, I'm. I don't know. It makes me feel like a weirdo in the best possible way. Suits feel great. Every time I wear a suit, I'm like, I don't know why I'm not. Doing this more in fashion in general, if you, if you're doing it for yourself. I don't know that it's a, it's a really awesome thing, but, yeah, I think there is definitely a painful way to use social media and an empowering way. And I don't know if anyone know, any of us know which is which, so we're trying to figure that out. Some people, I think Doja cat is incredible at it. Incredible. Like, just masterful. Yeah, I don't know if you like. Yeah, yeah. So the. So. So, okay, so not taking anything seriously. Joking, absurd humor, that kind of. I think Doja cat might be, like, the greatest living comedian right now. Like, I'm more entertained by Doja cat than actual comedians. Like, she's really fucking funny on the Internet. She's just great at social media. It's just, you know. Yeah. The nature of humor. Humor on social media is also a beautiful thing. The absurdity. The absurdity and memes. Like, I just want to take a moment. I love, like, when we're talking about art and credit and how, and authenticity. I love that there's this, I mean, now memes are, like, they're no longer, like, memes aren't, like, new, but it's still this emergent art form that is completely egoless and anonymous, and we just don't know who made any of it. And it's, like, the forefront of comedy, and it's just totally anonymous, and it just feels really beautiful. It just feels like this beautiful collective human art project that's, like, this decentralized comedy thing that just makes memes add so much to my day and many people's days. And it's just like, I don't know. I don't think people ever, I don't think we stop enough and just appreciate how sick it is that memes exist, because also making a whole brand new art form in, like, the modern era, that's, like, didn't exist before. Like, I mean, they sort of existed, but the way that they exist now as, like, this, like, like, me and my friends, we joke that we go mining for memes or farming for memes, like a video game and meme dealers and whatever memes are this whole new comedic language. Well, it's this art form. The interesting thing about it is that lame people seem to not be good at memes. Like, corporate can't infiltrate memes. Yeah, they really can't. Have they tr. They could try, but it's like, it's weird because, like, they try so hard. And every once in a while I'm like, fine, like, you got a good one. I think I've seen, like, one or two good ones, but, like, yeah, they really can't, because they're even. Corporate is infiltrating web three. It's making me really sad. But they can't infiltrate the memes. And I think there's something really beautiful. About that that gives power. That's, that's why dogecoin is powerful. It's like, all right, f you. To sort of, anybody who's trying to centralize, who's trying to control the rich people that are trying to roll in and control this, control the narrative. Wow, I hadn't thought about that. But how would you fix Twitter? How would you fix social media for your own? Like, you're an optimist, you're a positive person. There's a bit of a cynicism that you have currently about this particular little slice of humanity. I tend to think Twitter could be. I'm not that cynical about it. I'm not that cynical about it. I actually refuse to be a cynic on principle. Yes, I was just briefly expressing some personal paths, personal stuff. It was just some personal pathos. But, like, like, just to vent a little bit, just to. I don't have. I don't have cancer. I love my family. I have a good life. I'm. That. That is, if. That is my biggest, one of my biggest problems. It's a good life. Yeah, I, you know, that was a brief. Although I do think there are a lot of issues with Twitter, just in terms of the public mental health, but due to my proximity to the current dramas, I honestly feel that I should not have opinions about this because I think if Elon ends up getting Twitter, that is a. Being the arbiter of truth or public discussion. That is a responsibility. I am not qualified to be responsible for that. And I do not want to say something that might dismantle democracy. And so I just like, actually. I actually think I should not have opinions about this because I truly am not. I don't want to have the wrong opinion about this. And I think I'm too close to the actual situation wherein I should not have. I have thoughts in my brain, but I think I am scared by my proximity to this situation. Isn't that crazy that a few words that you could say could change world affairs and hurt people? I mean, that's the nature of celebrity at a certain point that you have to be. You have to. A little bit. A little bit. Not so much that it destroys you, puts too much constraints, but you have to. A little bit think about the impact of your words. I mean, we as humans, you talk to somebody at a bar, you have to think about the impact of your words. Like, you can say positive things, you can think of negative things. You can affect the direction of one life, but on social media, your words can affect the direction of many lives. It's crazy. It's a crazy world to live in. It's worthwhile to consider that responsibility, take it seriously sometimes, just like you did. Choose kind of silence, choose sort of respectful. Like, I do have a lot of thoughts on the matter. I'm just. I just. I don't if my thoughts are wrong. This is one situation where the stakes are high. You mentioned a while back that you were in a cult that's centered around bureaucracy, so you can't really do anything because it involves a lot of paperwork. And I really love a cult that's just like, kafka esque. Just like. I mean, it was like a joke, but. I know, but I love this idea. The holy rain empire. Yeah. It was just like a Kafka esque pro bureaucracy. But I feel like that's what human civilization is, because when you said that, I was like, oh, that is kind of what humanity is. Is this bureaucracy? I do, yeah, I have this theory. I really think that we really. Bureaucracy is starting to kill us, and I think we need to reorient laws and stuff. I think we just need sunset clauses on everything. I think the rate of change in culture is happening so fast, and the rate of change in technology and everything is happening so fast. When you see these hearings about social media and Cambridge analytica and everyone talking, it's like, even from that point, so much technological change has happened from those hearings. And it's just like we're trying to make all these laws now about AI and stuff. I feel like we should be updating things every five years. And one of the big issues in our society right now is we're just getting bogged down by laws, and it's making it very hard to change things and develop things. Like in Austin, I don't want to speak on this too much, but one of my friends is working on a housing bill in Austin to try to prevent a San Francisco situation from happening here, because obviously we're getting a little mini San Francisco here. Housing prices are skyrocketing. It's causing massive gentrification. This is really bad for anyone who's not super rich. There's so much bureaucracy. Part of the reason this is happening is because you need all these permits to build. It takes years to get permits to build anything. It's so hard to build. There's very limited housing and there's a massive influx of, of people. And it's just like, this is a microcosm of problems that are happening all over the world, where it's just like, we're dealing with laws that are 1020, 30, 4100, 200 years old, and they are no longer relevant. And it's just slowing everything down and causing massive social pain. Yeah, but it also makes me sad when I see politicians talk about technology and when they don't really get it. But most importantly, they lack curiosity and like that, like, inspired excitement about like, how stuff works and all that stuff. They're just like, they see, they have the very cynical view of technology. It's like tech companies are just trying to do evil in the world from their perspective. And they have no curiosity about like, how recommender systems work or how, how AI systems work, natural language processing, how robotics works, how computer vision works. You know, they always take the most cynical possible interpretation of what technology would be used, and we should definitely be concerned about that. But if you're constantly worried about that and you're regulating based on that, you're just going to slow down all the innovation. I do think a huge priority right now is undoing the bad energy surrounding the emergence of Silicon Valley. Like, I think that, like, a lot of things were very irresponsible during that time. And even just this current whole thing with Twitter and everything, there has been a lot of negative outcomes from the technocracy boom. But one of the things that's happening is that it's alienating people from wanting to care about technology. And I actually think technology is probably some of the better, probably the best. I think we can fix a lot of our problems more easily with technology than with fighting the powers that be. As a, not to go back to the Star wars quote or the Buckminster. Fuller quote, let's go to some dark questions, if we may, for time. What is the darkest place you ever gone in your mind? Is there a time, a period of time, a moment? Do you remember that was difficult for you? I mean, when I was 18, my best friend died of a heroin overdose. And it was like my. It was. And then shortly after that, one of my other best friends committed suicide. And that sort of like coming into adulthood, dealing with two of the most important people in my life, dying in extremely disturbing, violent ways was a lot. That was a lot. Do you miss them? Yeah, definitely miss them. Did that make you think about your own life, about the finiteness of your own life, the places your mind can go? Did you ever, in the distance, far away, contemplate just your own death or maybe even taking your own life? Oh, never. Oh, no. I'm so. I love my life. I cannot fathom suicide. I'm so scared of death. I haven't. I'm too scared of death. My manager. My manager's like, the most Zen guy. My manager's always like, you need to accept death. You need to accept death. And I'm like, look, I can do your meditation. I can do the meditation, but I cannot accept death. I'm terrified of death. I'm terrified of death. I will fight. Although I actually think death is important. I recently went to this meeting about immortality, and in the process of. That's the actual topic of the meeting. All right, I'm sorry. No, no. It was this girl. It was a bunch of people working on anti aging stuff. It was some seminary thing about it. And I went in really excited. I was like, yeah, okay, what do you got? How can I live for 500 years or 1000 years? And then over the course of the meeting, it was sort of like, right? It was like two or three days after the russian invasion started. And I was like, man, what if Putin was immortal? What if I'm like, man, maybe immortality is not good. I mean, if you get into the later dune stuff, the immortals cause a lot of problem because as we were talking about earlier, with the music and brains calcified, good people could become immortal, but bad people could become immortal. But I also think even the best people, power corrupts. And power alienates you from the common human experience, right? So the people that get more and. More powerful, even the best. Even the best people who, like, whose brains are amazing, I think death might be important. I think death is part of, you know, like, I think with AI, one thing we might want to consider. I don't know. When I talk about AI, I'm such not an expert. And probably everyone has all these ideas and they're already figured out, but when I. Nobody is an expert in anything, see? Okay, go ahead. Yeah, but it's just like, I think some kind of pruning but it's a tricky thing because if there's too much of a focus on youth culture, then you don't have the wisdom. So I feel like we're in a tricky. We're in a tricky moment right now in society where it's like, we've really perfected living for a long time. So there's all these really old people who are really voting against the well being of the young people. And it's like, there shouldn't be all this student debt, and we need healthcare, universal health care, and just voting against best interests. But then you have all these young people that don't have the wisdom that are like, like, yeah, we need communism and stuff. And it's just like, like, literally, I got canceled at one point for I ironically used a Stalin quote in my high school yearbook, but it was actually like a diss against my high school. I saw that. Yeah. And people were like, you used to be a Stalinist and now you're a class trader. And it's like, it's like, oh, man, just like, please google Stalin. Please google Stalin. Like, you know, ignoring the lessons of history. Yes. And it's like we're in this really weird middle ground where it's like we are not finding the happy medium between Ms. Wisdom and fresh ideas. And they're fighting each other. And it's like, really what we need is the fresh ideas and the wisdom to be collaborating. And it's like what the fighting, in a way, is the searching for the happy medium. And in a way, maybe we are finding the happy medium. Maybe that's what the happy medium looks like. And for AI systems, there has to be. You have the reinforcement learning, you have the dance between exploration and exploitation, sort of doing crazy stuff to see if there's something better than what you think is the optimal, and then doing the optimal thing and dancing back and forth from that, you would. Stewart Russell, I don't know if you know, that is AI guy with thinks about sort of how to control super intelligent AI systems and his ideas that we should inject uncertainty and sort of humility into AI systems that they never, as they get wiser and wiser and wiser and more intelligent, they're never really sure. They always doubt themselves. And in some sense, when you think of young people, that's a mechanism for doubt. It's like, it's how society doubts whether the thing it has converged towards is the right answer. So the voices of the young people is a society asking itself a question. The way I've been doing stuff for the past 50 years. Maybe it's the wrong way, and so you can have all of that within one AI system. I also think, though, that we need to. I mean, actually, that's actually really interesting and really cool. But I also think there's a fine balance of. I think we maybe also overvalue the idea that the old systems are always bad. And I think there are things that we are perfecting, and we might be accidentally overthrowing things that we actually have gotten to a good point. Just because we are valuing, we value disruption so much, and we value fighting against the generations before us so much that there's also an aspect of sometimes we're taking two steps forward, one step back, because, okay, maybe we kind of did solve this thing, and now we're fucking it up. And so I think there's a middle ground there, too. Yeah, we're in search of that happy medium. Let me ask you a bunch of crazy questions. Okay. You can answer in a short way or in a long way. What's the scariest thing you've ever done? These questions are going to be ridiculous. Something tiny or something big. Skydiving or touring your first record. Going on this podcast, I've had two. Crazy brushes, like, really scary brushes with death, where I randomly got away on scathe. I don't know if I should talk about those on here, but, like, I don't know. I think. I think I might be the luckiest person alive, though. Like, this might be too dark for a podcast, though. I feel like. I don't know if this is, like, good content for podcasts. I don't know what content is. It might hijack. Here's a safer one. I mean, having a baby really scared me before just the birth process surgery. Like, just having. Just having a baby is. It was really scary. So just, like, the medical aspect of it, not the responsibility. Were you ready for the responsibility of, did you. Were you ready to be a mother? All the. All the beautiful things that comes with motherhood that you were talking about, all the changes and all that. Were you ready for that? Did you feel ready for that? No. I think it took about nine months to start getting ready for it, and I'm still getting more ready for it, because now you keep realizing more things as they start getting. As the consciousness grows and stuff you. Didn'T notice with the first one. Now that you've seen the first one older, you're noticing it more. The sort of existential horror of coming into consciousness with baby y or baby sailor mars or whatever. She has so many names at this point that we really need to probably settle on one. If you can be someone else for a day, someone alive today, but somebody you haven't met yet, who would you be? Would I be modeling their brain state, or would I just be in their body? You can choose the degree to which you're modeling their brain state because you can still take a third person perspective and realize, you have to realize that you're. Can they be alive or can it be dead? No. Oh. Could it be anyone? They would be brought back to life, right? If they're dead, yeah, you can bring people back. Definitely Hitler or Stalin, huh? I want to understand evil. You would need to. Oh. To experience what it feels like. I want to be in their brain feeling what they feel. That might change you forever returning from that. Yes. But I think it would also help me understand how to prevent it and fix it. That might be one of those things. Once you experience it, it'll be a burden to know it because you won't be able to. Yeah, but a lot of things are our burdens. But it's useful burden. But it's a useful burden. Yeah, that for sure. I want to understand evil and, like, psychopathy and that I have all these fake Twitter accounts where I go into different algorithmic bubbles to try to understand. I'll keep getting in fights with people and realize we're not actually fighting. I think we used to exist in a monoculture, like, before social media and stuff. We kind of all got fed the same thing, so we were all speaking the same cultural language. But I think recently, one of the things that we aren't diagnosing properly enough with social media is that there's different dialects. There's so many different dialects of Chinese. There are now becoming different dialects of English. I am realizing there are people who are saying the exact same things, but they're using completely different verbiage, and we're punishing each other for not using the correct verbiage, and we're completely misunderstanding. People are just misunderstanding what the other people are saying. And I just got in a fight with a friend of about anarchism and communism and shit for like, 2 hours, and then by the end of a conversation, and then she'd say something, and I'm like, but that's literally what I'm saying. And she was like, what? And then I was like, fuck. We've different. I'm like, our English, the way we are understanding terminology is like, drastically like, our algorithm bubbles are creating mini dialects. Of how language is interpreted, how language is used. That's so fascinating. And so we're having these arguments that we do not need to be having, and there's polarization that's happening. That doesn't need to be happening because we've got these algorithmically created dialects occurring. Plus, on top of that, there's also different parts of the world that speak different languages, so there's literally lost in translation kind of communication. I happen to know the russian language and just know how different it is. Yeah. Than the english language. And I just wonder how much is lost in a little bit of. Man. I actually, because I have a question for you. I have a song coming out tomorrow with Ice Peak, who are a russian band, and I speak a little bit of Russian. And I was looking at the title, and the title in English doesn't match the title in Russian. I'm curious about this because, look, it says, what's the English? The title in English is last day. And then the title in Russian is my project. Pronunciation. Sex. Novi dien. Like new day. New day. Yeah, new day. New day. Yeah, new day. Yeah, yeah, yeah, new day. Yeah, new day. But last day. Norway Jane. So last day would be Pasadena Jane. Yeah. Maybe they. Maybe the title includes both the Russian and the. And its form. Maybe it's for. Maybe it's for bilingual. To be honest, Novi James sounds better than just musically like, Novi Jen is new day. That's the current one. And Pasadena is the last day, I think. Novi jin. I don't like Novi jin, but the meaning is so different. That's kind of awesome, actually. There's an explicit sort of contrast like that. If everyone on earth disappeared and it was just you left, what would your day look like? Like, what would you do? Everybody's dead. Are there corpses there? Seriously? It's a big. Let me think through this. It's a big difference if there's just birds singing versus if there's corpses littering the street. Yeah, there's corpses everywhere. I'm sorry. And you don't actually know what happened, and you don't know why you survived, and you don't even know if there's others out there, but it seems clear that it's all gone. What would you do? What would I do? I'm somebody who really enjoys the moment, enjoys life. I would just go on, like, enjoying the inanimate objects. I would just look for food, basic survival. But most of it is just listen. What? I just. I take walks and I look outside, and I'm just happy that we get to exist on this planet, to be able to breathe air, it's just all beautiful, it's full of colors, all of this kind of stuff. Just, there's so many things about life, your own life, conscious life. That's fucking awesome. So I would just enjoy that. But also, maybe after a few weeks, the engineer would start coming out, like, want to build some things? Maybe there's always hope. Searching for another human, maybe. Probably searching for another human. Probably trying to get to a tv or radio station and broadcast something. That's interesting. I didn't think about that. So, like, really maximize your ability to connect with others? Yeah, like, probably try to find a. Another person. Would you be excited to see, to meet another person or terrified because, you. Know, I'd be excited even if they. No matter what. Yeah, yeah, yeah. Being alone for the last, however long of my life would be really bad. That's the one instance I might. I don't think I'd kill myself, but I might kill myself if I had to undergo. Do you love people? You love connection to other humans? Yeah, I kind of hate people too. But I. Yeah, it's a love hate relationship. Yeah. I feel like this is. I feel like we had a bunch of, like, weird nietzsche questions and stuff, though. Oh, yeah. Like, I wonder. Cause I'm like, when podcast, like, I'm like, is this interesting for people to just have, like. Or I don't know, maybe people do like this. When I listen to podcasts, I'm into, like, the lore, like, the hard lore. Like, I just love, like, Dan Carlin. I'm like, give me the facts. Just like, like, the facts into my bloodstream. But you also don't know, like, you're a fascinating mind to explore. So you don't realize as you're talking about stuff, the stuff you've taken for granted is actually unique and fascinating. The way you think, not always. What? Like, the way you reason through things is the fascinating thing to listen to because people kind of see, oh, there's other humans that think differently, that explore thoughts differently. That's the cool. That's also cool. So, yeah. Dan Carlin retelling of history, by the way, his retelling of history is very. I think what's exciting is not the history is his way of thinking about history. No, I think Dan Carlin is one of the people. Like, when Dan Carlin was one of the people that really started getting me excited about revolutionizing education, because Dan Carlin instilled, I already really liked history, but he instilled an obsessive love of history in me to the point where, like, now I'm fucking reading, like, like, going to bed reading, like, part four of the rise and fall of the Third Reich or whatever. Like, I, like, I'm like, dense ass history. But, like, like, he, like, opened that door that, like, made me want to be a scholar of that topic. Like, it's like, I feel like he's such a good teacher. He just like, you know, and it sort of made me feel like one of the things we could do with education is, like, find the world's great, the teachers that create passion for the topic. Because auto didacticism. I don't know how to say that properly, but self teaching is much faster than being lectured to. It's much more efficient to be able to teach yourself and then ask a teacher questions when you don't know what's up. But that's why it's in university and stuff. You can learn so much more material so much faster because you're doing a lot of the learning on your own and you're going to the teachers for when you get stuck. But, like, these teachers that can inspire passion for a topic, I think that is one of the most invaluable skills in our whole species. Because if you can do that, then you. It's like AI. Like, AI is going to teach itself so much more efficiently than we can teach it. We just needed to get it to the point where it can teach itself. And then it finds the motivation to do so. Right? Yeah. So you inspire it to do so and then it could teach itself. What do you make of the fact you mentioned rise and fall, the Third Reich? I just. Have you read that? I've read it twice. And so you read it twice? Yes. Okay. So no one even knows what it. What it is. Yeah. And I'm like. I'm like, wait, I thought this was like a super poppin book. Super pop. I'm. I'm not like that. I'm not that far in it, but it is. It's so interesting. Yeah. It's written by a person that was there, which is very important to kind. Of, you know, you start being like, how could this possibly happen? And then when you read rise and fall of the Third Reich, it's like, people tried really hard for this to not happen. People tried. They almost reinstated a monarchy at one point to try to stop this from happening. Like, they almost like, like, abandoned democracy to try to get this to not happen. At least the way it makes me feel is that there's a bunch of small moments on which history can turn. Yes. Like small meetings, human interactions. And that's both terrifying and inspiring because it's like even just attempts at assassinating Hitler, like, time and time again failed. And they were so close to Valkyrie, such a good. And then there's also the role of. That's a really heavy burden, which is that from a geopolitical perspective, the role of leaders, to see evil before it truly becomes evil, to anticipate it had to stand up to evil because evil is actually pretty rare in this world at a scale that Hitler was. We tend to, in the modern discourse, kind of call people evil too quickly. If you look at ancient history, there was a ton of hitlers. I actually think it's more the norm than. Again, going back to my sort of intelligent design theory, I think one of the things we've been successfully doing in our slow move from survival of the fittest to intelligent design is we've kind of been eradicating. If you look at ancient Assyria and stuff, that shit was brutal. And just the heads on the brutal Genghis Khan, just genocide after genocide after genocide, throwing plague bodies over the walls and decimating whole cities, or the muslim conquests of Damascus and shit. Cities used to get leveled all the fucking time. Okay, get into the Bronze age collapse. It's basically, there was almost roman level society. There was all over the world, global trade. Everything was awesome through a mix of, I think, a bit of climate change and then the development of iron, because basically bronze could only come from the way to make bronze. Everything had to be funneled through this one iranian mine. And so it's like. But there was just this one supply chain. And this is one of the things that makes me worried about supply chains and why I think we need to be so thoughtful about. I think our biggest issue with society right now, like, the thing that is most likely to go wrong is probably supply chain collapse. You know, because war, climate change, whatever, like anything that causes supply chain collapse, our population is too big to handle that. And, like, the thing that seems to cause dark ages is mass supply chain collapse. But interesting, the Bronze Age collapse happened to, like, it was sort of like this ancient collapse that happened where literally ancient Egypt, all these cities, everything just got decimated, destroyed, abandoned cities, hundreds of them. There was a flourishing society. We were almost coming to modernity, and everything got leveled. And they had this mini dark ages. But it was just like, there's so little writing or recording from that time that there isn't a lot of information about the Bronze Age collapse, but it was basically equivalent to medieval. The medieval dark ages. But it just happened, I don't know the years, but thousands of years earlier. And then we sort of recovered from the Bronze Age collapse. Empire re emerged, writing and trade and everything reemerged. And then we, of course, had the more contemporary dark ages. And then over time, we've designed mechanism to lessen and lessen the capability for the destructive power centers to emerge. There's more recording about the more contemporary dark ages. So I think we have a better understanding of how to avoid it, but I still think we're at high risk for it. I think that's one of the big. The big risks. Right. So the natural state of being for humans is for there to be a lot of hitlers. We just gotten really good at making it hard for them to emerge. We've gotten better at collaboration. Yes. And resisting the power, like authoritarians to come to power. We're trying to go country by country, like, we're moving past this. We're kind of like slowly, incrementally moving towards not scary old school war stuff. And I think seeing it happen in some of the countries that at least nominally are supposed to have moved past that, that's scary, because it reminds us that it can happen, like in the places that have supposedly, hopefully moved past. That, and possibly at a civilization level. Like you said, supply chain collapse might make people, resource constraint might make people desperate, angry, hateful, violent, and drag us right back in. I mean, supply chain collapse is how, like, the ultimate thing that caused the middle ages, Washington, supply chain collapse. It's like people, because people were reliant on a certain level of technology. You look at Britain, they had glass, people had aqueducts, people had indoor heating and cooling and running water and buy food from all over the world, and trade and markets. People didn't know how to hunt and forage and gather. And so we're in a similar situation. We are not educated enough to survive without technology. So if we have a supply chain collapse that limits our access to technology, there will be mass starvation and violence and displacement and war. In my opinion, it's the primary marker of what a dark age is. Technology is enabling us to be more resilient in terms of supply chain, in terms of to all the different catastrophic events that happened to us. Although the pandemic has kind of challenged our preparedness for the catastrophic, what do you think is the coolest invention humans come up with? The wheel, fire, cooking meat. Computers. Computers. Freaking computers. Internet or computers. Which one? What did you think the previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homo tech. No, I think this is what. It's a brain augmentation, and so it allows for actual evolution. The computers accelerate the degree to which all the other technologies can also be accelerated. Would you classify yourself as a homo sapien or a homo techno? Definitely homo techno. I think we're all. You're one of the early of the species. I think most of us are. As I said, I think if you looked at brain scans of us versus humans 100 years ago, it would look very different. I think we are physiologically different. Just even the interaction with the devices has changed our brains well. And if you look at, a lot of studies are coming out to show that there's a degree of inherited memory. So some of these physiological changes, in theory, we should be passing them on. So that's not an instance of physiological change that's going to fizzle out. In theory, that should progress, like, to our offspring. Speaking of offspring, what advice would you give to a young person, like, in high school, whether there be an artist, a creative, an engineer, any kind of career path, or maybe just life in general, how they can live a life they could be proud of. I think one of my big thoughts, and, like, especially now having kids, is that I don't think we spend enough time teaching creativity. And I think creativity is a muscle, like other things. And there's a lot of emphasis on, you know, learn how to play the piano, and then you can write a song or, like, learn the technical stuff, and then you can do a thing. But I think it's like, I have a friend who's, like, world's greatest guitar player. Like, you know, amazing. Sort of, like, producer, works with other people, but he's really sort of like, you know, he, like, engineers and records things and, like, does solos, but he doesn't really, like, make his own music. And I was talking to him, and I was like, dude, you're so talented at music. Like, why don't you make music or whatever? And he was like, because I got. I'm too old. I never learned the creative muscle. And it's like, you know, it's embarrassing. It's like learning the creative muscle takes a lot of failure, and it also sort of, you're. If when you're being creative, you know, you're throwing paint at a wall and a lot of stuff will fail. So, like, part of it is, like, a tolerance for failure and humiliation and. Somehow that's easier to develop when you're young. Yeah. Or be persist through it when you're young. Everything is easier to develop when you're young. Yes. And the younger the better. It could destroy you. I mean, that's the shitty thing about creativity. If, you know, failure could destroy you if you're not careful. But that's a risk worth taking. But also. But at a young age, developing a tolerance to failure is good. I fail all the time. Like, I do stupid shit all the time. Like, in public, in private, I get canceled for. I make all kind of mistakes, but I just, like, am very resilient about making mistakes. And so then I do a lot of things that other people wouldn't do. And I think my greatest asset is my creativity. And I think pain, like, tolerance to failure, is just a super essential thing that should be taught before other things. Brilliant advice. Yeah. Yeah. I wish everybody encouraged sort of failure more as opposed to kind of because. We, like, punish failure. We're like, no. When we were teaching kids, we're like, no, that's wrong. Like, that's, you know, like, x keeps, like, will be like, wrong. Like, he'll say, like, crazy things. Like, x keeps being like. Like, bubble car. Bubble car. And I'm like. And you know, I'm like, what's a bubble car? Like? But, like, it doesn't. Like, but I don't want to be like, no, you're wrong. I'm like. You're thinking of weird, crazy shit. Like, I don't know what a bubble. Car is, but, like, he's creating worlds, and they might be internally consistent, and through that, he might discover something fundamental about this. Yeah, or he'll, like, rewrite songs like where withdev words that he prefers. So, like, instead of baby shark, he says baby car. It's like. Maybe he's onto something. Let me ask the big ridiculous question. We were kind of dancing around it, but what do you think is the meaning of this whole thing we have here of human civilization, of life on earth, but in general, just life. What's the meaning of life? See? Did you read Nova scene yet by James Lovelock? You're doing a lot of really good book recommendations here. I haven't even finished this. So I'm a huge fraud yet again. But really early in the book, he says this amazing thing. I feel like everyone's so sad and cynical. Everyone's the Fermi paradox and everyone. I just keep hearing people being like, fuck, what if we're alone? Oh, no. And I'm like, okay, but like, wait, what if this is the beginning? In Nova scene, he says, this is not going to be a correct, because I can't memorize quotes, but he says something like, what if our consciousness right now, this is the universe waking up? What if instead of discovering the universe, this is the universe. This is the evolution of the little literal universe herself. Like, we are not separate from the universe. Like, this is the universe waking up. This is the universe seeing herself for the first time. This is the universe becoming conscious the first time. We're part of that. Yeah. Because it's like, we aren't separate from the universe. This could be an incredibly sacred moment. And maybe social media and all this things, the stuff where we're all getting connected together, maybe these are the neurons connecting of the collective superintelligence that is, you know, waking up. Yeah. Like, you know, it's like, maybe instead of something cynical or maybe if there's something to discover, like, maybe this is just, you know, we're a blastocyst of, like, some incredible kind of consciousness or. Being, and just like, in the first three years of life or for human children, we'll forget about all the suffering that we're going through now. I think we'll probably forget about this. I mean, probably, you know, artificial intelligence will eventually render us obsolete. I don't think they'll do it in a malicious way, but I think probably we are very weak. The sun is expanding. Like, I don't know, like, hopefully we can get to Mars, but, like, we're pretty vulnerable. And I, you know, like, I think we can coexist for a long time with AI, and we can also probably make ourselves less vulnerable. But, you know, I just think consciousness, sentience, self awareness. Like, I think this might be the single greatest, like, moment in evolution ever. And, like, maybe this is, you know, like, the true beginning of life, and we're just. We're the blue green algae, or we're like. We're like the single celled organisms of something amazing. The universe awakens, and this is it. Yeah, well, see, you're an incredible person. You're a fascinating mind. You should definitely do. Your friend Liv mentioned that you guys were thinking of maybe talking. I would love it if you explored your mind in this kind of medium more and more by doing a podcast with her or just in any kind of way. So you're an awesome person. It's an honor to know you. It's an honor to get to sit down with you late at night, which is, like, surreal, and I really enjoyed it. Thank you. For talking today. Yeah. No, I mean, huge honor. I feel very underqualified to be here, but I'm a big fan. I've been listening to the podcast a lot, and, yeah, me and Liv would appreciate any advice and help, and we're definitely gonna do that. So anytime. Thank you. Cool. Thank you. Thanks for listening to this conversation with Grimes. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Oscar Wilde. Yes, I'm a dreamer? For a dreamer is one who can only find her way by moonlight? And her punishment is that she sees the dawn before the rest of the world. Thank you for listening and hope to see you next time.

Utterances:
Speaker A: We are becoming cyborgs. Like, our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous. From homo sapiens. I call us homotecno. I think we have evolved into homotechno, which is, like, essentially a new species. Previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homotechno. I think this is what. It's a brain augmentation, so it allows for actual evolution. The computers accelerate the degree to which all the other technologies can also be.
Speaker B: Would you classify yourself as a homo sapien or a homo techno?
Speaker A: Definitely homo techno. So you're all.
Speaker B: You're one of the earliest of the species?
Speaker A: I think most of us are.
Speaker B: The following is a conversation with Grimes, an artist, musician, songwriter, producer, director, and a fascinating human being who thinks a lot about both the history and the future of human civilization, studying the dark periods of our past to help form an optimistic vision of our future. This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Grimes.
Speaker A: Oh, yeah, the cloudlifter. There you go.
Speaker B: There you go. You know your stuff. Have you ever used the cloudlifter?
Speaker A: Yeah, I actually. This microphone. Cloudlifter is what Michael Jackson used, so.
Speaker B: No. Really?
Speaker A: Yeah. This. This is, like, thriller and stuff.
Speaker B: This mic?
Speaker A: This mic and that. Yeah. It's a incredible microphone.
Speaker B: Yes.
Speaker A: It's very flattering on vocals. I've used this a lot of. It's great for demo vocals. It's great in a room. Like, sometimes it's easier to record vocals if you're just in a room and the music's playing and you just want to feel it. So it's not in the headphones. And this mic is pretty directional, so I think it's a good mic for just vibing out and just getting a real good vocal take.
Speaker B: Just vibing just in a room.
Speaker A: Anyway, this is the. This is the Michael Jackson Quincy Jones microphone.
Speaker B: I feel way more badass now. Let's get in. You want to just get into it?
Speaker A: I guess so.
Speaker B: All right. One of your names, at least in this space and time, is c, like the letter c. And. And you told me that c means a lot of things. It's the speed of light. It's the render rate of the universe. It's. Yes, in Spanish. It's the crescent moon, and it happens to be my favorite programming language because it's. It basically runs the world, but it's also powerful, fast, and is dangerous because you can mess things up really bad with it because of all the pointers. But anyway, which of these associations with the name c is the coolest to you?
Speaker A: I mean, to me the coolest is the speed of light, obviously, or speed of light. When I say render rate of the universe, I think I mean the speed of light, because essentially that's what we're rendering at. See, I think we'll know if we're in a simulation if the speed of light changes, because if they can improve their render speed, then it's already pretty good. It's already pretty good. But if it improves, then we'll know. We can probably be like, okay, they've updated or upgraded.
Speaker B: What's fast enough for us humans? Because it seems like, it seems immediate, there's no delay, there's no latency in terms of us humans on Earth interacting with things. But if you're like, like intergalactic species operating on a much larger scale, then you're going to start noticing some weird stuff. Or if you can operate in like around a black hole, then you're going to start to see some render issues.
Speaker A: You can't go faster than the speed of light. Correct. So it really limits our ability, or one's ability to travel space.
Speaker B: Theoretically you can. You have wormholes. So there's nothing in general relativity that precludes faster than speed of light travel. But it just seems you're gonna have to do some really funky stuff with very heavy things that have weirdnesses, that have basically tears in space time. We don't know how to do that.
Speaker A: Do navigators know how to do it?
Speaker B: Do navigators? Yeah, yeah.
Speaker A: Folding space, basically making wormholes.
Speaker B: So the name c. Yes. Who are you? Do you think of yourself as multiple people? Are you one person? Do you know, like in this morning, were you a different person than you are tonight? We are, I should say, recording this basically at midnight, which is awesome.
Speaker A: Yes. Thank you so much. I think I'm about 8 hours late.
Speaker B: No, you're right on time. Good morning. This is the beginning of a new day soon anyway. Are you the same person you were in the morning, in the evening? Is there multiple people in there? Do you think of yourself as one person? Or maybe you have no clue? Are you just a giant mystery to yourself?
Speaker A: Okay, these are really intense questions, but.
Speaker B: Uh, let's go, because I asked this myself. Like, look in the mirror. Who are you? People tell you to just be yourself, but what does that even mean?
Speaker A: Uh, I mean, I think my personality changes with everyone I talk to. So I have a very inconsistent personality.
Speaker B: Yeah, person to person. So the interaction, your personality materializes, or my mood.
Speaker A: Like, I'll go from being like a megalomaniac to being just a total hermit who is very shy.
Speaker B: So some combinatorial combination of your mood and the person you're interacting with.
Speaker A: Yeah, mood and people I'm interacting with, but I think everyone's like that. Maybe not.
Speaker B: Well, not everybody acknowledges it and able to introspect it. Who brings out what kind of person, what kind of mood brings out the best in you as an artist and as a human? Can you introspect this?
Speaker A: Like, my best friends, like, people who I can when I'm, like, super confident and I know that they're gonna understand everything I'm saying. So, like, my best friends, then when I can start being really funny, that's always my peak mode, but it's like, yeah, it takes a lot to get there.
Speaker B: Let's talk about constraints. You've talked about constraints and limits. Do those help you out as an artist or as a human being, or do they get in the way? Do you like the constraints? So in creating music and creating art, in living life, do you like the constraints that this world puts on you or do you hate them?
Speaker A: If constraints are moving, then you're good, right? Like, it's like, it's like, as we are progressing with technology, we're changing the constraints of, like, artistic creation. You know, making video and music and stuff is getting a lot cheaper. There's constantly new technology and new software that's making it faster and easier. We have so much more freedom than we had in the seventies. Like, when Michael Jackson, you know, when they recorded thriller with this microphone, like, they had to use a mixing desk and all this stuff. And, like, probably even get in a studio, it's probably really expensive, and you have to be a really good singer, and you have to know how to use, like, the mixing desk and everything. And now I can just, you know, I've made a whole album on this computer. I have a lot more freedom. But then I'm also constrained in different ways because there's literally millions more artists. It's a much bigger playing field. It's just like, I also. I didn't learn music. I'm not a natural musician, so I don't know anything about actual music. I just know about the computer. So I'm really kind of just, like, messing around and, like, trying things out.
Speaker B: Well, yeah, I mean, but the nature of music is changing. So you're saying you don't know actual music. But music is changing. Music is becoming. You've talked about this is becoming. It's like merging with technology.
Speaker A: Yes.
Speaker B: It's becoming something more than just like the notes on a piano. It's becoming some weird composition that requires engineering skills, programming skills, some kind of human robot interaction skills, and still some of the same things that Michael Jackson had, which is like a good ear for a good sense of taste of what's good and not the final thing when it's put together. Like you're allowed, you're enabled, empowered with a laptop to layer stuff, to start layering insane amounts of stuff. And it's super easy to do that.
Speaker A: I do think music production is a really underrated art form. I feel like people really don't appreciate it. When I look at publishing splits, the way that people, like, pay producers and stuff, it's super. Producers are just deeply underrated. So many of the songs that are popular right now or for the last 20 years, part of the reason they're popular is cause the production is really interesting or really sick or really cool. And it's like, I don't think listeners, people just don't really understand what music production is. It's nothing. It's sort of like this weird, discombobulated art form. It's not like a formal. Because it's so new, there isn't a formal training path for it. It's mostly driven by autodidacts. It's almost everyone I know who's good at production. They didn't go to music school or anything. They just taught themselves.
Speaker B: Are they mostly different, the music producers? You know, is there some commonalities that time together, or are they all just different kinds of weirdos? Because I just hung out with Rick Rubin? I don't know if you've.
Speaker A: Yeah, I mean, Rick Rubin is like, literally one of the gods of music production. Like, he's one of the people who first, you know, who, like, made music production, you know, made the production as important as the actual lyrics or the notes.
Speaker B: But the thing he does, which is interesting, I don't know if you can speak to that, but just hanging out with him, he seems to just sit there in silence, close his eyes and listen. It's like he almost does nothing. And that nothing somehow gives you freedom to be the best version of yourself. So that's music production somehow, too, which is like encouraging you to do less, to simplify, to, like, push towards minimalism.
Speaker A: I mean, I guess. I mean, I work differently from Rick Rubin. Cause Rick Rubin produces for other artists, whereas I mostly produce for myself, so it's a very different situation. I also think Rick Rubin, he's in that, I would say advanced category of producer, where you've earned your. You can have an engineer and stuff, and people do the stuff for you, but I usually just do stuff myself.
Speaker B: So you're the engineer, the producer, and the artist.
Speaker A: Yeah, I guess I would say I'm in the era, like the post Rick Rubin era. I come from the kind of like Skrillex school of thought, which is like, where you are. Yeah, the engineer, producer, artist. I mean, lately, sometimes I'll work with a producer. Now I'm gently, sort of delicately starting to collaborate a bit more. But I think I'm kind of from the whatever, 2010s explosion of things where, you know, everything became available on the computer and you kind of got this, like, lone wizard energy thing going.
Speaker B: So you embrace being the loneliness. Is the loneliness somehow an engine of creativity? Like, see, most of your stuff, most of your creative, quote unquote genius in quotes, is in the privacy of your mind.
Speaker A: Yes. Well, it was, but here's the thing. I was talking to Daniel Eck, and he said he's like most artists, they have about ten years, like ten good years, and then they usually stop making their vital shit. And I feel like I'm sort of nearing the end of my ten years on my own.
Speaker B: So you have to become somebody else now.
Speaker A: I'm in the process of becoming somebody else in reinventing when I work with other people, because I've never worked with other people, I find that I make, like, that I'm exceptionally rejuvenated and making some of the most vital work I've ever made because I think another human brain is one of the best tools you can possibly find.
Speaker B: It's a funny way to put it.
Speaker A: I love it. If a tool is whatever, HP plus one or adds some stats to your character, like, another human brain will, like, square it instead of, like, adding something.
Speaker B: Double up the experience points. I love this. We should also mention we're playing tavern music before this and which I love, which I. First, I think I.
Speaker A: You have to stop the tavern music.
Speaker B: Yeah, because it doesn't. The audio.
Speaker A: Okay. Okay.
Speaker B: But it makes. Yeah, it'll make the podcast added and post.
Speaker A: No one will want to listen to.
Speaker B: The podcast if they probably would. But it makes me. It reminds me like, of a video game, like a role playing video game where you have experience points. There's something really joyful about wandering places like Elder Scrolls, like Skyrim, just exploring these landscapes in another world, and then you get experience points and you can work on different skills and somehow you progress in life. I don't know. It's simple. It doesn't have some of the messy complexities of life. And there's usually a bad guy you can fight. In Skyrim, it's dragons and so on. I'm sure in Elden ring there's a bunch of monsters you can fight. I love that.
Speaker A: I feel like Elden ring. I feel like this is a good analogy to music production, though, because I feel like the engineers and the people creating these open worlds. It's sort of similar to music producers, where it's this hidden archetype that no one really understands what they do and no one really knows who they are, but they're. It's like the artist engineer, because it's like, it's both art and fairly complex engineering.
Speaker B: Well, you're saying they don't get enough credit. Aren't you kind of changing that by becoming the person doing everything isn't the engineer.
Speaker A: Well, I mean, others have gone before me. I'm not, you know, there's, like, Timbaland and Skrillex, and there's all these people that are like, you know, very famous for this. But I just think the general. I think people get confused about what it is and just don't really know what it is, per se. And it's just when I see a song, when there's a hit song, I'm just trying to think of just going for even just a basic pop hit rules by Dua Lipa or something. The production on that is actually really crazy. I mean, the song is also great, but the production is exceptionally memorable, you know, and it's just like, no one, I don't even know who produced that song. It just, like, isn't part of, like, the rhetoric of how we discuss the creation of art. We just sort of, like, don't consider the music producer, because I think the music producer used to be more just simply recording things.
Speaker B: Yeah, that's interesting, because when you think about movies, we talk about the actor and the actresses, but we also talk about the directors. Directors, yeah, we don't talk about, like, that with the music as often.
Speaker A: The Beatles music producer was one of the first kind of guy, one of the first people sort of introducing crazy sound design into pop music. I forget his name. He has the same. I forget his name. But, you know, like, he was doing all the weird stuff, like dropping pianos and like.
Speaker B: Yeah. Oh, to get the. Yeah, yeah, yeah. To get. To get the sound to get the authentic sound. What about lyrics? You think those. Where did they fit into how important they are? I was heartbroken to learn that Elvis didn't write his songs. I was very mad.
Speaker A: A lot of people don't write their songs.
Speaker B: I understand this.
Speaker A: But here's the thing. I feel like there's this desire for authenticity. I used to be really mad when people wouldn't write or produce their music, and I'd be like, that's fake. And then I realized there's all this weird bitterness and aggro ness in art about authenticity. But I had this weird realization recently where I started thinking that art is sort of a decentralized, collective thing. Art is kind of a conversation with all the artists that have ever lived before you. You know, like, it's like you're really just sort of. It's not like anyone's reinventing the wheel here. Like, you're kind of just taking, you know, thousands of years of art and, like, running it through your own little algorithm and then, like, making your, like, your interpretation of it.
Speaker B: You just join the conversation with all the other artists that came before. It's such a beautiful way to look.
Speaker A: At it, like, and it's like, it's like, I feel like everyone's always, like, there's always copyright and ip and this and that and or authenticity. And it's just like, I think we need to stop seeing this as this egotistical thing of, like, oh, the creative genius, the lone creative genius, or this or that. Cause it's like, I think art shouldn't be about that. I think art is something that sort of brings humanity together. And it's also. Art is also kind of the collective memory of humans. It's like we don't, like, we don't give a fuck about whatever ancient Egypt, like, how much grain got sent that day and sending the records and who went where and how many shields needed to be produced for this. We just remember their art. And it's like, in our day to day life, there's all this stuff that seems more important than art because it helps us function and survive. But when all this is gone, the only thing that's really going to be left is the art. The technology will be obsolete.
Speaker B: That's so fascinating.
Speaker A: Like, the humans will be dead.
Speaker B: That is true. A good compression of human history is the art we've generated across the different centuries of different millennia. So when the aliens come, when the.
Speaker A: Aliens come, they're going to find the hieroglyphics and the pyramids.
Speaker B: I mean, art could be broadly defined. They might find the engineering marvels, the bridges, the rockets, the.
Speaker A: I guess I sort of classify, though. Architecture is art, too. I consider engineering, um, in those formats to be art, for sure.
Speaker B: It sucks that, like, digital art is easier to delete. So if there's an apocalypse, a nuclear war, that can disappear.
Speaker A: Yes.
Speaker B: And the physical, there's something still valuable about the physical manifestation of art that's. That sucks that, like, music, for example, has to be played by somebody.
Speaker A: Yeah. I mean, I do think we should do have a foundation type situation where we, like, you know, how we have, like, seed banks up in the north and stuff.
Speaker B: Yeah.
Speaker A: Like, we should probably have, like, a solar powered or geothermal little bunker that, like, has all the. All human knowledge.
Speaker B: You mentioned Daniel Eich and Spotify. What do you think about that as an artist? What's Spotify? Is that empowering? I get, to me, Spotify sort of, as a consumer, is super exciting. It makes it easy for me to access music from all kinds of artists, get to explore all kinds of music, make it super easy to sort of curate my own playlist and have fun with all that. It was so liberating to let go. You know, I used to collect, you know, albums and cds and so on. Like, horde albums. Yeah, like, they matter. But the reality, you could, you know, that was really liberating. That can let go of that and letting go of the albums you're kind of collecting allows you to find new music, exploring new artists and all that kind of stuff. But I know from a perspective of an artist, that could be, like you mentioned, competition could be a kind of constraint, because there's more and more and more artists on the platform.
Speaker A: I think it's better that there's more artists. I mean, again, this might be propaganda because this is all from a conversation with Daniel Eck. So this could easily be propaganda.
Speaker B: Like, we're all a victim of somebody's propaganda, so let's just accept this.
Speaker A: But Daniel Eck was telling me that, you know, at the. Because I, you know, when, when I met him, I, like, I came in all furious about Spotify, and, like, I grilled him super hard. So I've got his, his answers here. But he was saying, like, at the sort of peak of the cd industry, there was like 20,000 artists making millions and millions of dollars. Like, there was just like, a very tiny kind of 1%. And Spotify has kind of democratized the industry because now, I think he said there's about a million artists making a good living from Spotify and when I heard that, I was like, honestly, I would rather make less money and have just, like, a decent living and have more artists be able to have that, even though I wish it could include everyone.
Speaker B: But, yeah, that's really hard to argue with. YouTube is the same, is YouTube's mission. They want to basically have as many creators as possible, make a living, some kind of living.
Speaker A: Yeah.
Speaker B: And that, that's so hard to argue.
Speaker A: With, but I think there's better ways to do it. My manager, I actually wish he was here. Like, I would have brought him up. My manager is building an app that can manage you, so it'll, like, help you organize your percentages and get your publishing and da da da. So you can take out all the middlemen, so you can have a much bigger. Bigger. It'll just, like, automate it, so you can get so automate the manager, automate management, publishing and legal. It can read the app he's building, can read your contract and, like, tell you about it. Because one of the issues with music right now, it's not that we're not getting paid enough, but it's that the art industry is filled with middlemen because artists are not good at business. And from the beginning, like Frank Sinatra, it's all mob stuff. Like, the music industry is run by business people, not the artists. And the artists really get very small cuts of what they make. And so I think part of the reason I'm a technocrat, which, I mean, your fans are gonna be technocrats, so no one's, they're not gonna be mad at me about this, but my fans hate it when I say this kind of thing.
Speaker B: Or the general public, they don't like technocrats.
Speaker A: They don't like technocrats. Like, when I watched battle Angel Alita and they were like, the martian technocracy. And I was like, yeah, martian technocracy. And then they were like, and they're evil. And I was like, ooh, okay. I was like, cause martian technocracy sounds sick to me.
Speaker B: Yeah. So your intuition as technocrats would create some kind of beautiful world.
Speaker A: For example, what my manager's working on, if you can create an app that removes the need for a lawyer, and then you could have smart contracts on the blockchain, removes the need for management and organizing. All this stuff, can read your stuff and explain it to you, can collect your royalties, then the amount of money that you're getting from Spotify actually means a lot more and goes a lot farther.
Speaker B: It can remove some of the bureaucracy, some of the inefficiencies that make life not as great as it could be.
Speaker A: Yeah, I think the issue isn't that there's not enough. The issue is that there's inefficiency. And I'm really into this positive sum mindset, the win win mindset of instead of fighting over the scraps, how do we make the or worrying about scarcity? Instead of a scarcity mindset, why don't we just increase the efficiency in that way?
Speaker B: Expand the size of the pie. Let me ask you about experimentation. So you said, which is beautiful. Being a musician is like having a conversation with all those that came before you. How much of creating music is like kind of having that conversation, trying to fit into the cultural trends, and how much of it is like trying to, as much as possible, being outside and come up with something totally new? Like, when you're thinking, when you're experimenting, are you trying to be totally different, totally weird? Are you trying to fit in?
Speaker A: This is so hard because I feel like I'm kind of in the process of semi retiring from music. So this is like my old brain.
Speaker B: Yeah. Bring it back, bring it from the shelf, put it on the table for a couple minutes. We'll just poke it.
Speaker A: I think it's a bit of both, because I think forcing yourself to engage with new music is really great for neural plasticity. I think, as people, part of the reason music is marketed at young people is because young people are very neuroplastic. So if you're 16 to 23 or whatever, it's going to be really easy for you to love new music. And if you're older than that, it gets harder and harder and harder. And I think one of the beautiful things about being a musician is I just constantly force myself to listen to new music, and I think it keeps my brain really plastic. And I think this is a really good exercise. I just think everyone should do this. You listen to new music and you hate it. I think you should just keep. Force yourself to like, okay, well, why do people like it and, like, you know, make your brain form new neural pathways and be more open to change?
Speaker B: That's really brilliant, actually. Sorry to interrupt, but, like, that exercise is really amazing to sort of embrace change, embrace sort of practice on your plasticity, because, like, that's one of the things you fall in love with a certain band and you just kind of stay with that for the rest of your life, and then you never understand the modern music. That's a really good exercise.
Speaker A: Most of the streaming on Spotify is like classic rock and stuff like new music makes up a very small chunk of what is played on Spotify, and I think this is, like, not a good sign for us as a species, I think. Yeah.
Speaker B: So it's a good measure of the species open mindedness to change is how often you listen to new music. Yeah, the brain. Let's put the music brain back on the shelf. I gotta pull out the futurist brain for a second. In what wild ways do you think the future, say, in, like, 30 years, maybe 50 years, maybe 100 years, will be different from, like, from our current way of life on earth. We can talk about augmented reality, virtual reality, maybe robots, maybe space travel, maybe video games, maybe genetic engineering. I can keep going. Cyborgs, aliens, world wars, maybe destructive nuclear wars, good and bad. When you think about the future, what are you imagining? What's the weirdest and the wildest it could be.
Speaker A: Have you read surface detail by Ian Banks? Surface detail is my favorite depiction of a. Oh, wow. You have to read this book. It's literally the greatest science fiction book possibly ever.
Speaker B: Ian Banks is the man. Yeah, for sure.
Speaker A: What have you read?
Speaker B: Just the play of games.
Speaker A: I read that titles can't be copyrighted, so you can just steal them. And I was like, play of games. Sick.
Speaker B: Nice.
Speaker A: Yeah. So you could name your album, like, I always want to.
Speaker B: Romeo and Juliet, something.
Speaker A: I always wanted to name an album war and peace.
Speaker B: Nice. Like, that would be like, that's a good. Where have I heard that before?
Speaker A: You can do that. Like, you could do that also things that are in the public domain for.
Speaker B: People who have no clue. You do have a song called player games.
Speaker A: Yes. Oh, yeah. So, Ian Banks surface detail is, in my opinion, the best future that I've ever read about or heard about in science fiction. Basically, there's the relationship with super intelligence. Like, artificial superintelligence is just. It's like, great. I want to credit the person who coined this term, because I love this term, and I feel like young women don't get enough credit in.
Speaker B: Yeah.
Speaker A: So if you go to Protopia futures on instagram, what is her name?
Speaker B: Personalized donor experience at scale, our AI power donor experience.
Speaker A: Monica Beale skite. I'm saying that wrong, and I'm probably gonna. I'm probably butchering this a bit, but protopia is sort of. If utopia is unattainable, protopia is sort of like.
Speaker B: You know, wow, that's an awesome instagram.
Speaker A: Topia futures, a great. A future that is, you know, as good as we can get.
Speaker B: The future, positive future AI is this a centralized AI in surface detail, or is it distributed? What kind of AI is it?
Speaker A: They mostly exist as giant super ships, sort of like the guild ships in dune. Like they're these giant ships that kind of move people around. And the ships are sentient and they can talk to all the passengers. And, I mean, there's a lot of different types of AI in the banksian future, but in the opening scene of surface detail, there's this place called the culture. And the culture is basically a protopian future. And a protopian future, I think, is a future that is. Obviously, it's not utopia. It's not perfect, because striving for utopia, I think, feels hopeless. And it's sort of maybe not the best terminology to be using. So it's a pretty good place. Mostly. Superintelligence and biological beings exist fairly in harmony. There's not too much war as close to equality as you can get. It's approximately a good future. There's really awesome stuff in the opening scene. This girl, she's born as a sex slave outside of the culture. So she's in a society that doesn't adhere to the cultural values. She tries to kill the guy who is her master, but he kills her. But unbeknownst to her, when she was traveling on a ship through the culture with him, one day a ship put a neural lace in her head. And neural lace is sort of like. It's basically a neuralink because life imitates art.
Speaker B: It does indeed.
Speaker A: It does indeed. So she wakes up, and the opening scene is, her memory has been uploaded by this neural lace when she's been killed. And now she gets to choose a new body, and this AI is interfacing with her recorded memory in her neural lace and helping her and being like, hello, you're dead. But because you had a neuro lace, your memory's uploaded. Do you want to choose a new body? And you're going to be born here in the culture and start a new life, which is just. That's, like, the opening. It's, like, so sick.
Speaker B: And the ship is the super intelligence.
Speaker A: All the ships are kind of super.
Speaker B: Intelligence, but they still want to preserve a kind of rich, fulfilling experience for the humans.
Speaker A: Yeah, they're like friends with the humans. And then there's a bunch of ships that don't want to exist. Biological beings, but they just have their own place, like, way over there, but.
Speaker B: They just do their own thing. They're not necessarily. So. It's a pretty. This protopian existence. Pretty peaceful.
Speaker A: Yeah, I mean, and then. And then, for example, one of the main fights in the book is they're fighting. There's these artificial hells. And people don't think it's ethical to have artificial hell. Like, basically, when people do crime, they get sent, like, when they die, their memory gets sent to an artificial hell and they're eternally tortured. And so. And then the way that society is deciding whether or not to have the artificial hell is that they're having these simulated. They're having a simulated war. So instead of actual blood, people are basically essentially fighting in a video game to choose the outcome of this.
Speaker B: But they're still experiencing the suffering in this artificial hell. Or no, can you experience stuff?
Speaker A: So the artificial hell sucks. And a lot of people in the culture want to get rid of the artificial hell.
Speaker B: There's a simulated wars. Are they happening?
Speaker A: No, the simulated wars are happening outside of the artificial hell between the political factions who are. So this political faction says we should have simulated hell to deter crime. And this political faction is saying, no, stimulated hell is unethical. And so instead of, like, having, you know, blowing each other up with nukes, they're having, like, a giant fortnite battle to decide this. Which to me, that's protopia. That's like, okay, we can have war without death. I don't think there should be simulated hells. I think that is definitely one of the ways in which technology could go very, very, very wrong.
Speaker B: So almost punishing people in a digital space or something like that.
Speaker A: Yeah, like torturing people's memories.
Speaker B: So either as a deterrent, like if you committed a crime, but also just for personal pleasure, if there's some Sig demented humans in this world. Dan Carlin actually has this episode of hardcore history on painfultainment.
Speaker A: Oh, that episode is fucked.
Speaker B: It's dark because he kind of goes through human history and says, we, as humans, seem to enjoy, secretly enjoy, or used to be openly enjoy sort of the torture and the death. Watching the death and torture of other humans.
Speaker A: I do think I. If people were consenting, we should be allowed to have gladitorial matches.
Speaker B: But consent is hard to achieve in those situations. It always starts getting slippery. Like it could be also forced. Like it starts getting weird.
Speaker A: Yeah, yeah.
Speaker B: There's way too much excitement. Like, this is what he highlights. There's something about human nature that wants to see that violence. And it's really dark. And you hope that we can sort of overcome that aspect of human nature, but that's still within us somewhere.
Speaker A: Well, I think that's what we're doing right now. I have this theory that what is very important about the current moment is that all of evolution has been survival of the fittest up until now. And at some point, the lines are kind of fuzzy. But in the recent past, or maybe even just right now, we're getting to this point where we can choose intelligent design. Like we probably, since, like, the integration of the iPhone, like we are becoming cyborgs, like, our brains are fundamentally changed. Everyone who grew up with electronics, we are fundamentally different from previous. From homo sapiens. I call us homo techno. I think we have evolved into homo techno, which is, like, essentially a new species. If you look at the way, if you took an MRI of my brain and you took an MRI of a medieval brain, I think it would be very different the way that it has evolved.
Speaker B: Do you think when historians look back at this time, they'll see this was a fundamental shift in what a human being is?
Speaker A: I do not think we are still homo sapiens. I believe we are homo techno, and I think we have evolved. And I think right now, the way we are evolving, we can choose how we do that. And I think we are being very reckless about how we're doing that. We're just having social media. But I think this idea that this is a time to choose intelligent design should be taken very seriously. Now is the moment to reprogram the human computer. It's like if you go blind, your visual cortex will get taken over with other functions. We can choose our own evolution. We can change the way our brains work. And so we actually have a huge responsibility to do that. And I think. I'm not sure who should be responsible for that, but there's definitely not adequate education. We're being inundated with all this technology that is fundamentally changing the physical structure of our brains, and we are not adequately responding to that. To choose how we want to evolve. And we could evolve, we could be really whatever we want. And I think this is a really important time, and I think if we choose correctly and we choose wisely, consciousness could exist for a very long time, and integration with AI could be extremely positive. And I don't think enough people are focusing on this specific situation.
Speaker B: So you think we might irreversibly screw things up if we get things wrong now? Because the flip side of that, it seems humans are pretty adaptive. So maybe the way we figure things out is by screwing it up, like social media. Over a generation, we'll see the negative effects of social media, and then we build new social medias, and we just keep improving stuff, and then we learn the failure from the failures of the past, because humans seem to be really adaptive. On the flip side, we can get it wrong in a way where, like, literally we create weapons of war or increase hate past a certain threshold, we really do a lot of damage.
Speaker A: I mean, I think we're optimized to notice the negative things, but I would actually say, you know, one of the things that I think people aren't noticing is, like, if you look at Silicon Valley and you look at, like, whatever, the technocracy, like, what's been happening there? Like, it's like, when Silicon Valley started, it was all just like, Facebook and all this, like, for profit crap that, like, really wasn't particular. I guess it was useful, but it was sort of just like, whatever. But now you see lab grown meat, compostable or biodegradable single use cutlery or meditation apps. I think we are actually evolving and changing, and technology is changing. I think maybe there isn't quite enough education about this. And also, I don't know if there's quite enough incentive for it, because I think the way capitalism works, what we define as profit, we're also working on an old model of what we define as profit. I really think if we changed the idea of profit to include social good, you can have economic profit, social good. Also, counting as profit would incentivize things that are more useful and more whatever. Spiritual technology or positive technology, or things that help reprogram the human computer in a good way or things that help us intelligently design our new brains.
Speaker B: Yeah. There's no reason why, within the framework of capitalism, the word profit or the idea of profit can't also incorporate the well being of a human being. So, like, long term well being, long.
Speaker A: Term happiness, or even, for example, we were talking about motherhood. Part of the reason I'm so late is because I had to get the baby to bed. And it's like, I keep thinking about motherhood, how under capitalism, it's this extremely essential job that is very difficult, that is not compensated, and we sort of value things by how much we compensate them. And so we really devalue motherhood in our society and pretty much all societies. Capitalism does not recognize motherhood. It's just a job that you're supposed to do for free. And it's like. But I feel like producing great humans should be seen as a great, as profit under capitalism. That's a huge social good. Every awesome human that gets made adds so much to the world. So if that was integrated into the profit structure, then. And if we potentially found a way.
Speaker B: To compensate motherhood, so come up with a compensation that's much broader than just money.
Speaker A: Or it could just be money. Like, what if you just made. I don't know, but I don't know how you'd pay for that. I mean, that's where you start getting into.
Speaker B: Reallocation of resources that people get upset over.
Speaker A: Well, what if we made, like, a motherhood dao?
Speaker B: Yeah, yeah.
Speaker A: And used it to fund, like, single mothers, like, you know, pay for making babies.
Speaker B: So, I mean, if you create and put beautiful things out into the world, that could be companies, that can be bridges, that could be art, that could be a lot of things, and that could be children, which are, or education or anything that could be valued by society that should be somehow incorporated into the framework of what as a market of what. Like, if you contribute children to this world, that should be valued and respected and sort of celebrated, like proportional to what it is, which is. It's the thing that fuels human civilization. Yeah, like, I think it's kind of important.
Speaker A: I feel like everyone's always saying, I mean, I think we're in very different social spheres, but everyone's always saying, like, dismantle capitalism. And I'm like, okay, well, I don't think the government should own everything. I don't think we should not have private ownership. That's scary. That starts getting into weird stuff and just sort of like, I feel like there's almost no way to do that without a police state. But obviously capitalism has some major flaws. And I think actually Mac showed me this idea called social capitalism, which is a form of capitalism that just, like, considers social good to be also profit. It's like, right now companies need to, you're supposed to grow every quarter or whatever to show that you're functioning well. But it's like, okay, well, what if you kept the same amount of profit? You're still in the green, but then you have also all this social good. Do you really need all this extra economic growth? Or could you add this social good and that counts? You know, I don't know if I am not an economist. I have no idea how this could be achieved.
Speaker B: But I don't think economists know how anything could be achieved either. But they pretend it's the thing. They construct a model and they go on tv shows and sound like an expert. That's the definition of an economist. How did being a mother, becoming a mother change as a human being, would you say?
Speaker A: Man, I think it kind of changed everything, and it's still changing me a lot. It's actually changing me more right now in this moment than it was before.
Speaker B: Like today, like this, just like in.
Speaker A: The most recent months and stuff.
Speaker B: Can you elucidate that? How change, like, when you wake up in the morning and you look at yourself, it's again, which. Who are you? How have you become different, would you say?
Speaker A: I think it's just really reorienting my priorities. And at first, I was really fighting against that because I somehow felt it was like a failure of feminism or something. I felt like it was bad if my kids started mattering more than my work. And then more recently, I started analyzing that thought in myself and being like, that's also kind of a construct. It's like we've just devalued motherhood so much in our culture that I feel guilty for caring about my kids more than I care about my work.
Speaker B: So feminism includes breaking out of whatever the construct is so continually breaking. It's like, freedom. Empower you to be free, and that means.
Speaker A: But also. But being a mother, I'm so much more creative. I cannot believe the massive amount of brain growth that I have.
Speaker B: Why do you think that is? Just. Cause the stakes are higher somehow.
Speaker A: I think it's just so trippy watching consciousness emerge. It's just going on a crazy journey or something. It's like the craziest science fiction novel you could ever read. It's just so crazy watching consciousness come into being, and then at the same time, like, you're forced to value your time so much. Like, when I have creative time now, it's so sacred, I need to be really frickin on it. But the other thing is that I used to just be, like, a cynic, and I used to just want to. My last album was called misanthropic, and it was like a study in villainy. Or it was like, well, what if instead of the old gods, we have new gods? And misanthropocene is, like, misanthrope and anthropocene, which is like the. And she's the goddess of climate change or whatever, and she's, like, destroying the world. And it was just like, it was dark, and it was like a study in villainy, and it was sort of just like. I used to have no problem just making cynical, angry, scary art. And not that there's anything wrong with that, but I think having kids just makes you such an optimist. It just inherently makes you want to be an optimist so bad that I feel more of a responsibility to make more optimistic things, and I get a lot of shit for it because everyone's like, oh, you're so privileged. Stop talking about pie in the sky stupid concepts and focus on the now. But it's like, I think if we don't ideate about futures, that could be good. We won't be able to get them. If everything is Blade Runner, then we're going to end up with Blade Runner. It's like, as we said earlier, life imitates art. Life really does imitate art. And so we really need more protopian or utopian art. I think this is incredibly essential for the future of humanity. And I think the current discourse where that's seen as a thinking about protopia or utopia is seen as a dismissal of the problems that we currently have. I think that is an incorrect mindset. And having kids just makes me want to imagine amazing futures that maybe I won't be able to build, but they will be able to build if they want to.
Speaker B: Yeah. It does seem like ideation is a precursor to creation. You have to imagine it in order to be able to build it. And there is a sad thing about human nature that they somehow. A cynical view of the world is seen as a insightful view. You know, cynicism is often confused for insight, which is sad to see. And optimism is confused for naivete.
Speaker A: Yes. Yes.
Speaker B: Like, you don't. Yes. You're blinded by your. Maybe your privilege or whatever. You're blinded by something, but you're certainly blinded. That's a. That's sad. That's sad to see, because it seems like the optimists are the ones that create the. Our future. They're the ones that build. In order to build the crazy thing, you have to be optimistic. You have to be either stupid or excited or passionate or mad enough to actually believe that it can be built. And those are the people that built it.
Speaker A: My favorite quote of all time is from Star Wars Episode eight, which I know everyone hates. Do you like Star Wars Episode eight?
Speaker B: No, probably. I would say. I would probably hate it. Yeah, I don't. I don't have strong feelings about it. Let me backtrack. I don't have strong feelings about Star Wars.
Speaker A: I just want to.
Speaker B: I'm a Tolkien person. I'm not. I'm more. I'm more into dragons and orcs and ogres and.
Speaker A: Yeah, I mean, Tolkien forever. I really want to have one more son and call him. I thought Tau Techno Tolkien would be cool.
Speaker B: It's a lot of t's I like it.
Speaker A: Yeah. And well, then Tau is 6282 PI.
Speaker B: Yeah. Tao ta. Yeah.
Speaker A: And then techno is obviously the best genre of music, but also, like, technocracy sounds really good.
Speaker B: Yeah, that's right. Techno token.
Speaker A: That's a good Tau Tacho, Tolkien. But Star Wars Episode eight, I know a lot of people have issues with it, personally. On the record, I think it's the best Star wars film.
Speaker B: You start in trouble today.
Speaker A: Yeah. But don't kill what you hate, save what you love.
Speaker B: Don't kill what you hate.
Speaker A: Don't kill what you hate, save what you love. And I think we're in society right now. We're in a diagnosis mode. We're just diagnosing and diagnosing and diagnosing and we're trying to kill what we hate, and we're not trying to save what we love enough. And there's this Buckminster Fuller quote, which I'm going to butcher because I don't remember it correctly, but it's something along the lines of don't, like, try to destroy the old bad models, render them obsolete with better models. You know, maybe we don't need to destroy the oil industry. Maybe we just create new, great new battery technology and sustainable transport and just make it economically unreasonable to still continue to rely on fossil fuels. You know, it's like, don't kill what you hate, say what you love. Like, make new things and just render the old things unusable. You know, it's like, if the college debt is so bad, like, and universities are so expensive, like, and this, like, I feel like education is becoming obsolete. You know, I feel like we could completely revolutionize education and we could make it free. And it's like you look at JSTOR and, like, you have to pay to get all the studies and everything. Like, what if we created a Dao that, like, bought JSTOR or we created a DaO that was funding studies and those studies were open source, like, or free for everyone, and, like, what if we just open sourced education and decentralized education and made it free and, like, all research was on the Internet and, like, all the outcomes of studies are on the Internet and, you know, like, and no one has student debt, and you just take tests when you apply for a job, and if you're qualified, then you can work there. This is just like, no, I don't know how anything works. I'm just randomly ranting.
Speaker B: But I like the humility. You got to think from just basic first principles, like, what is the problem? What's broken? What are some ideas. That's it. And get excited about those ideas and share your excitement and don't tear each other down.
Speaker A: Like, it's just when you kill things, you often end up killing yourself. War. War is not a one sided, you're not going to go in and just kill them, you're going to get stabbed. And I think when I talk about this nexus point that we're in, this point in society where we're switching to intelligent design, I think part of our switch to intelligent design is that we need to choose nonviolence. I think we can choose to start, I don't think we can eradicate violence from our species because I think we need it a little bit. But I think we can choose to really reorient our primitive brains that are fighting over scarcity and that are so attack oriented and move into, we can optimize for creativity and building.
Speaker B: Yeah, it's interesting to think how that happens. Some of it is just education, some of it is living life and introspecting your own mind and trying to live up to the better angels of your nature. For each one of us, all those kinds of things at scale, that's how we can sort of start to minimize the amount of destructive war in our world. And that's, to me, probably you're the same technologies, it's a really promising way to do that. Social media should be a really promising way to do that. It's a way to reconnect. For the most part. I really enjoy social media. I just know all the negative stuff. I don't engage with any of the negative stuff, just not even like by blocking or any of that kind of stuff, but just not letting it enter my mind. Like, just like when somebody says something negative, I see it, I immediately think positive thoughts about them and I just forget they exist after that. Just move on. Because like, that negative energy, if I return the negative energy, they're going to get, they're going to get excited in a negative way right back. And it's just this kind of vicious cycle. But you would think technology would assist us in this process of letting go, of not taking things personally, of not engaging the negativity. But unfortunately, social media profits from the negativity. So the current models, I mean, social.
Speaker A: Media is like a gun. Like, you should take a course before you use it. That's so true. This is what I mean. Like when I say reprogram the human computer in school, you should learn about how social media optimizes to raise your cortisol levels and make you angry and crazy and stressed, and you should learn how to have hygiene. About how you use social media.
Speaker B: So.
Speaker A: You can choose not to focus on the negative stuff. But I don't know. I'm not sure social media should. I guess it should exist. I'm not sure. I mean, we're in the messy. It's the experimental phase. Like, we're working days.
Speaker B: I don't even know when you say social media, I don't know what that even means. We're in the very early days. I think social media is just basic human connection in the digital realm, and that I think it should exist. But there's so many ways to do it in a bad way. There's so many ways to do it in a good way. There's all discussions of all the same human rights. We talk about freedom of speech. We talk about sort of violence in the space of digital media. We talk about hate speech. We talk about all these things that we had to figure out back in the day in the physical space, we're now figuring out in the digital space. And it's like baby stages.
Speaker A: When the printing press came out, it was like pure chaos for a minute. You know, it's like when you inject, when there's a massive information injection into the general population, there's just gonna be, I feel like the printing press, I don't have the years, but it was like printing press came out of shit. Got really fucking bad for a minute, but then we got the enlightenment, and so it's like, I think we're in. This is like the second coming of the printing press. We're probably gonna have some shitty times for a minute, and then we're gonna have recalibrate to have a better understanding of how we consume media and how we deliver media.
Speaker B: Speaking of programming, in the human computer, you mentioned baby x. So there's this young consciousness coming to be, came from a cell. It like, that whole thing doesn't even make sense. It came from DNA.
Speaker A: Yeah.
Speaker B: And that there's this baby computer that just, like, grows and grows and grows and grows, and now there's a conscious being with extremely impressive cognitive capabilities with.
Speaker A: Have you met him?
Speaker B: Yes. Yeah, yeah. He's actually really smart.
Speaker A: He's really smart, yeah.
Speaker B: It's weird to, for a baby, I.
Speaker A: Haven'T, I don't know a lot of other babies, but he seems, I don't.
Speaker B: Hang out with babies often, but this baby was very impressive.
Speaker A: He does a lot of pranks and stuff.
Speaker B: Oh.
Speaker A: So he's like, he'll give you a treat and then take it away and laugh, stuff like that.
Speaker B: So he's like a chess player. So here's a cognitive, sort of, there's a computer being programmed. He's taken in the environment, interacting with a specific set of humans. How would you, first of all, what is it? Let me ask, I want to ask, how do you program this computer? And also, how do you make sense of that? There's a conscious being right there that wasn't there before.
Speaker A: It's giving me a lot of crisis thoughts. I'm thinking really hard. I think that's part of the reason it's like I'm struggling to focus on art and stuff right now because Baby X is becoming conscious and my, it's just reorienting my brain. Like, my brain is suddenly totally shifting of like, oh, shit. Like the way we raise children. Like, I hate all the baby books and everything. I hate them. Like, they're, ah, the art is so bad. And like, all the stuff, everything about all the aesthetics and like, I'm just like, ah, this is so the programming.
Speaker B: Languages we're using to program these baby computers isn't good.
Speaker A: Yeah. Like, and I'm thinking, and not that I have, like, good answers or know what to do, know what to do, but I'm just thinking really, really hard about it. We recently watched Totoro with him, studio Ghibli, and it's just like a fantastic film. And he responded to, I know you're not supposed to show baby screens too much, but I think it's the most sort of, like, I feel like it's the highest art. Baby content. It really speaks. There's almost no talking in it. It's really simple. Although all the dialogue is super, super, super simple, you know, and it's like a one to three year old can really connect with it. It feels like it's almost aimed at a one to three year old, but it's great art and it's so imaginative and it's so beautiful. And the first time I showed it to him, he was just so invested in it, unlike anything else I'd ever shown him. He was just crying when they cried and laughing when they laughed. Rollercoaster of emotions. And he learned a bunch of words and he started saying Totoro and started just saying all this stuff after watching Totoro, and he wants to watch it all the time. And I was like, man, why isn't there an industry of this? Why aren't our best artists focusing on making art for the birth of consciousness? That's one of the things I've been thinking I really want to start doing, you know, I don't wanna speak before I do things too much, but, like, I'm just, like, ages one to three. Like, we should be putting so much effort into that. And the other thing about Totoro is it's like, it's, like, better for the environment because adults love Totoro. It's such good art that everyone loves it. Like, I still have all my old totoro merch from when I was a kid. Like, I literally have the most ragged old totoro merchandise. Like, everybody loves it. Everybody keeps it. It's like, why does the art we have for babies need to suck and then be not accessible to adults and then just be thrown out when they age out of it? It's like, I don't know. I don't have a fully formed thought here, but this is just something I've been thinking about a lot, is.
Speaker B: How.
Speaker A: Do we have more totoro esque content? How do we have more content like, this that is universal and everybody loves, but is really geared to an emerging consciousness.
Speaker B: Emerging consciousness in the first three years of life that so much turmoil, so much evolution of mind is happening. It seems like a crucial time, would you say, to make it not suck? Do you think of basically treating a child like they have the capacity to have the brilliance of an adult or even beyond that? Is that how you think of that mind, or.
Speaker A: No, because they still. They like it when you talk weird and stuff. Like, they respond better to. Because even they can imitate better when your voice is higher. Like, people say, like, oh, don't do baby talk. But it's like, when your voice is higher, it's closer to something they can imitate. So they, like, I see. Like, the baby talk actually kind of works. Like, it helps them learn to communicate. I found it to be more effective with learning words and stuff.
Speaker B: But, like, you're not speaking. I'm not, like, speaking down to them. Like, do they have the capacity to understand really difficult concepts just in a very different way? Like, an emotional intelligence about something deep within?
Speaker A: Oh, yeah, no. Like, if x hurts. Like, if x bites me really hard, and I'm like, ow. He gets. He's sad. He's like, sad if he hurts me by accident.
Speaker B: Yeah.
Speaker A: Which he's huge, so he hurts me a lot by accident.
Speaker B: Yeah. That's so interesting that mind emerges, and he and children don't really have a memory of that time, so we can't even have a conversation with them. About it.
Speaker A: Yeah. Thank God they don't have a memory of this time because, like, think about, like, I mean, with our youngest baby. Like, it's like. I'm like, have you read the Sci-Fi short story? I have no mouth, but I'm a scream.
Speaker B: Good title, no?
Speaker A: Oh, man. I mean, you should read that scream. I hate getting into this Rokos basilisk shit. It's kind of a story about the. About, like an AI that's torturing someone in eternity and they have no body. The way they describe it, it sort of sounds like what it feels like being a baby. You're conscious and you're just getting inputs from everywhere and you have no muscles and you're jelly and you can't move. And you try to communicate, but you can't communicate. And you're just in this hell state. I think it's good we can't remember that. Like, my little baby is just exiting that. Like, she's starting to get muscles and have more autonomy. But watching her go through the opening phase, I was like, this does not seem good.
Speaker B: Oh, you think? It's kind of like.
Speaker A: Like, I think it sucks. I think it might be really violent.
Speaker B: Like, violent, mentally violent, psychologically violent.
Speaker A: Consciousness emerging, I think, is a very violent thing.
Speaker B: I never thought about that.
Speaker A: I think it's possible that we all carry quite a bit of trauma from it that we don't. I think that would be a good thing to study because I think addressing that trauma, I think that might be.
Speaker B: Oh, you mean like echoes of it are still there in the shadow somewhere?
Speaker A: I think it's gotta be. I feel like the helplessness, the existential, and the fear of being in an unknown place, bombarded with inputs and being completely helpless, that's gotta be somewhere deep in your brain, and that can't be good for you.
Speaker B: What do you think consciousness is? This whole conversation has impossibly difficult questions.
Speaker A: What do you think? So hard.
Speaker B: Yeah, we talked about music for like, two minutes. All right.
Speaker A: No, I'm so. I'm just over music. I'm over music.
Speaker B: Yeah, I. I still like it. It has its purpose.
Speaker A: No, I love music. I mean, music's the greatest thing ever. It's my favorite thing. But I just, like, every interview is like, what is your process? Like, I don't know. I'm just done. I can't do.
Speaker B: I do want to ask about Ableton live.
Speaker A: I'll tell you about Ableton. Cause Ableton's sick. No one has ever asked about Ableton, though.
Speaker B: Yeah, well. Cause I just need tech support, mainly.
Speaker A: I can help you. I can help you with your Ableton tech support.
Speaker B: Anyway, from Ableton back to consciousness, what do you think? This is a thing that only humans are capable of. Can robots be conscious? When you think about entities, you think, there's aliens out there that are conscious. Like, what is conscious?
Speaker A: There's this Terrence McKenna quote that I found that I fucking love. Am I allowed to swear on here?
Speaker B: Yes.
Speaker A: Nature loves courage. You make the commitment, and nature will respond to that commitment by removing impossible obstacles. Dream the impossible dream, and the world will not grind you under. It will lift you up. This is the trick. This is what all these teachers and philosophers who really counted, who really touched the alchemical gold, this is what they understood. This is the shamanic dance in the waterfall. This is how magic is done. By hurling yourself into the abyss and discovering it's a featherbed.
Speaker B: Yeah.
Speaker A: And for this reason, I do think there are no technological limits. I think, like, what is already happening here, this is, like, impossible. This is insane. And we've done this in a very limited amount of time, and we're accelerating the rate at which we're doing this. So I think digital consciousness is inevitable.
Speaker B: And we may not be able to even understand what that means, but I like hurling yourself into the abyss. So we're surrounded by all this mystery, and we just keep hurling ourselves into it, like, fearlessly and keep discovering. Cool shit.
Speaker A: Yeah. I just think it's like, who even knows if the laws are physics? The laws of physics are probably just the current. Like, as I was saying, speed of light is the current render rate. It's like, if we're in a simulation, they'll be able to upgrade that. Like, I sort of suspect when we made the James Webb telescope, like, part of the reason we made that is because we had an upgrade. And so now more of space has been rendered, so we can see more of it now.
Speaker B: Yeah. But I think humans are super, super, super limited cognitively. So I wonder. I. I wonder if we'll be allowed to create more intelligent beings that can see more of the universe as their render rate is upgraded.
Speaker A: Maybe we're cognitively limited. Everyone keeps talking about how we're cognitively limited and AI is going to render us obsolete. But it's like, this is not the same thing as an amoeba becoming an alligator. If we create AI again, that's intelligent design. That's. Literally all religions are based on gods that create consciousness. Like, we are God making. What we are doing is incredibly profound. And even if we can't compute. Even if we're so much worse than them, just unfathomably worse than an omnipotent kind of AI, it's like we. I do not think that they would just think that we are stupid. I think that they would recognize the profundity of what we have accomplished.
Speaker B: Are we the gods, or are they the gods in our persuasion?
Speaker A: I mean, we're kind of the.
Speaker B: It's complicated.
Speaker A: It's complicated. Like, we're.
Speaker B: But they would acknowledge the value. Well, I hope they acknowledge the value of paying respect to the creative ancestors.
Speaker A: I think they would think it's cool. And I think. I think if curiosity is a trait that we can quantify and put into AI, then I think if AI are curious, then they will be curious about us, and they will not be hateful or dismissive of us. They might see us as. I don't know, it's like. I'm not like, oh, fuck these dogs. Let's kill all the dogs. I love dogs. Dogs have great utility. Dogs, like, provide a lot of them.
Speaker B: We make friends with them.
Speaker A: Yeah.
Speaker B: We have a deep connection with them. We anthropomorphize them. Like, we have a real love for dogs, for cats and so on. For some reason, even though they're intellectually much less than us.
Speaker A: And I think there is something sacred about us, because it's like, if you look at the universe, the whole universe is, like, cold and dead and sort of robotic, and it's like, you know, AI intelligence, you know, it's kind of more like the universe, it's like cold and logical and abiding by the laws of physics and whatever, but we're this loosey goosey weird art thing that happened, and I think it's beautiful. And I think even if we. I think one of the values, if consciousness is the thing that is most worth preserving, which I think is the case, I think if there's any kind of religious or spiritual thing, it should be that consciousness is sacred, then I still think even if AI render us obsolete and climate change is too bad and we get hit by a comet and we don't become a multi planetary species fast enough, but, like, AI is able to populate the universe. Like, I imagine, like, if I was an AI, I would find more planets that are capable of hosting biological life forms and, like, recreate them, because we're fun to watch. Yeah, we're fun to watch.
Speaker B: Yeah. But I do believe that AI can have some of the same magic of consciousness within it, because consciousness, we don't know what it is. So, you know, there's some kind of.
Speaker A: Or might be a different magic. It might be, like, a strange, strange different.
Speaker B: Right.
Speaker A: Because they're not gonna have hormones. Like, I feel like a lot of our magic is hormonal, kind of.
Speaker B: I don't know. I think some of our magic is the limitations, the constraints, and within that, the hormones and all that kind of stuff, the finiteness of life. And then we get, given our limitations, we get to some come up with creative solutions of how to dance around those limitations. We partner up like penguins against the cold. We've. We fall in love, and, uh. And then love is ultimately some kind of allows us to delude ourselves that we're not mortal and finite and that life is not. Ultimately, you live alone, you're born alone, you die alone. And then love is, like, for a moment or for a long time, forgetting that. And so, like, we come up with all these creative hacks that make life, like, fascinatingly fun.
Speaker A: Yeah, yeah, yeah. Fun. Yeah.
Speaker B: And then AI might have different kinds of fun.
Speaker A: Yes.
Speaker B: And hopefully our funds intersect. Intersect every once in a while.
Speaker A: I think there would be. There'd be a little intersection. There'd be a little intersection of the fun.
Speaker B: Yeah.
Speaker A: Yeah.
Speaker B: What do you think is the role of love in the human condition? Why is it useful? Is it useful, like, hack? Or is this, like, fundamental to what it means to be human? The capacity to love?
Speaker A: I mean, I think love is the evolutionary mechanism that is, like, beginning the intelligent design. Like, I was just reading about. Do you know about Kropotkin? He's like an anarchist. Like, old russian anarchist.
Speaker B: I live next door to Michael Malus. I don't know if you know who that is. He's an anarchist. He's a modern day anarchist. Anarchists are fun.
Speaker A: I'm kind of getting into anarchism a little bit. This is probably not a good route to be taking, but.
Speaker B: Oh, no, I think if you're. Listen, you should expose yourself to ideas. There's no harm to thinking about ideas. I think anarchists challenge systems in interesting ways, and they think in interesting ways. It's just as good for the soul. It's, like, refreshes your mental palate.
Speaker A: I don't think we should actually. I wouldn't actually ascribe to it, but I've never actually gone deep on anarchy as a philosophy, so I'm. You still think about it, though, because I'm, like, reading about the russian revolution a lot, and it's like, there was, like, the Soviets in Lenin and all that, but then there was like, kropotkin and his, like, anarchist sect. And they were sort of interesting because he was kind of a technocrat, actually. Like, he was like, women can be more equal if we have appliances. He was really into using technology to reduce the amount of work people had to do. But so Kropotkin was a biologist or something. He studied animals. And he was really, at the time, I think it's nature magazine. I think he might have even started as a russian magazine, but he was publishing studies. Everyone was really into darwinism at the time. And survival of the fittest and war is the mechanism by which we become better. And it was this real kind of cementing this idea in society that violence kill the weak, and that's how we become better. And then Kropotkin was kind of interesting because he was finding all these instances in nature where animals were helping each other and stuff. And he was like, actually, love is a survival mechanism. So many instances in the animal kingdom where, like, cooperation and helping weaker creatures and all this stuff is actually an evolutionary mechanism. I mean, you even look at child rearing. Child rearing is like immense amounts of just love and goodwill and just like, there's no immediate, you know, you're not getting any immediate feedback of, like, winning. It's not competitive. It's literally, we actually use love as an evolutionary mechanism just as much as we use war. And I think we've missing the other part. And we've reoriented. We've culturally reoriented. Science and philosophy has oriented itself around darwinism a little bit too much. And the Kropotkin model, I think, is equally valid. Like, it's like cooperation and love and stuff is just as essential for species survival and evolution.
Speaker B: It be a more powerful survival mechanism in the context of evolution.
Speaker A: And it comes back to, we think engineering is so much more important than motherhood, but it's like, if you lose the motherhood, the engineering means nothing. We have no more humans. It's like we, I think our society should, the survival of the fit, the way we conceptualize evolution, should really change to also include this idea, I guess.
Speaker B: Yeah, there's some weird thing that seems irrational that is also core to what it means to be human. So love is one such thing. They could make you do a lot of irrational things. But that depth of connection and that loyalty is a powerful thing.
Speaker A: Are they irrational or are they rational? Like, it's like, it's like, is, you know, maybe losing out on some things in order to, like, keep your family together or in order. Like, it's like, what are our actual values? Like?
Speaker B: Well, right. I mean, the rational thing is, if you have a cold economist perspective, you know, motherhood, or sacrificing your career for love in terms of salary, in terms of economic well being, in terms of flourishing of you as a human being, that could be seen on some kind of metrics as a irrational decision, a suboptimal decision. But there is the manifestation of love could be the optimal thing to do. There's a kind of saying, save one life, save the world. There's a thing that doctors often face.
Speaker A: Which is like, well, it's considered irrational because the profit model doesn't include social good.
Speaker B: Yes. Yeah.
Speaker A: So if a social good, then suddenly these would be rational decisions.
Speaker B: It might be difficult to, you know, it requires a shift in our thinking about profit and might be difficult to measure social good.
Speaker A: Yes. But we're learning to measure a lot of things. Digitizing where we're actually, you know, quantifying vision and stuff. Like, we're like, we're like, you go on Facebook, and Facebook can pretty much predict our behaviors. A surprising amount of things that seem like mysterious consciousness, soul things have been quantified at this point, so surely we can quantify these other things.
Speaker B: Yeah. But as more and more of us are moving the digital space, I wanted to ask you about something from a fan perspective, kind of, you know, you as a musician, you as an online personality, it seems like you have all these identities and you play with them. One of the cool things about the Internet, it seems like you can play with identities. So as we move into the digital world, more and more, maybe even in the so called Metaverse, I mean, I.
Speaker A: Love the Metaverse, and I love the idea, but, like, the way this has all played out, didn't. Didn't go well, and people are mad about it, and I think. I think we need to, like, that's temporary. I think it's temporary.
Speaker B: Just like, you know how all the celebrities got together and sang the song imagine by Jeff Lennon, and everyone started hating the song imagine. I'm hoping that's temporary because it's a damn good song. So I think it's just temporary. Like, one you act once you actually have virtual worlds, whatever they're called, metaverse or otherwise, is, becomes. I don't know.
Speaker A: We do have virtual worlds, like video games. Elden ring. Have you played Elden ring? You have.
Speaker B: I'm really afraid of playing that game.
Speaker A: Literally. Amazing.
Speaker B: It looks way too fun. It looks. It looks. I would want to go there and stay there forever.
Speaker A: It's. Yeah, so fun. It's so, it's so nice.
Speaker B: Oh, man. Yeah, so that. That's the. Yeah, that's a metaverse. That's a metaverse. But you're not really. How immersive is it in the sense that there's a three dimension, like, virtual reality integration necessary? Can we really just take our, close our eyes and kind of plug in in the 2d screen and become that other being for time and really enjoy that journey that we take and we almost become that. You're no longer see, I'm no longer Lex. You're that creature, whatever. Whatever the hell it is in that game. Yeah, that is. That. I mean, that's why I love those video games. It's. It's. I really do become those people for a time. But, like, it seems like with the idea of the Metaverse, the idea of the digital space, with. Even on Twitter, you get a chance to be somebody for prolonged periods of time, like, across a lifespan. You know, you have a Twitter account for years, for decades, and you're that person.
Speaker A: I don't know if that's a good thing. I feel very tormented by it, by.
Speaker B: Twitter, specifically by social media representation of you.
Speaker A: I feel like the public perception of me has gotten so distorted that I find it kind of disturbing. It's one of the things that's disincentivizing me from wanting to keep making art, because I'm just, like, I've completely lost control of the narrative. And the narrative is, some of it is my own stupidity, but some of it has just been hijacked by forces far beyond my control. I kind of got in over my head in things. I'm just a random indie musician, but I just got dragged into geopolitical matters and financial, the stock market and shit. There are very powerful people who have, at various points in time, had very vested interest in making me seem insane, and I can't fucking fight that. And I just, you know, people really want their celebrity figures to be consistent and stay the same, and people have a lot of emotional investment in certain things. And first of all, I'm artificially more famous than I should be.
Speaker B: Isn't everybody who's famous artificially famous?
Speaker A: No, but I should be a weird niche indie thing, and I make pretty challenging. I do challenging weird fucking shit a lot. And I accidentally, by proxy, got, like, foisted into sort of, like, weird celebrity culture. But, like, I cannot be media trained. They have put me through so many hours of media training.
Speaker B: I would love to see, like, I'd love to see be a fly in.
Speaker A: That wall I can't do, like, well, and I do. I try so hard, and I, like, learn the thing, and I, like, got it. And I'm like, I got it, I got it. I got it. But I just can't stop saying, like, my mouth just says things, like. And it's just like. And I just do. I just do things. I just do crazy. Like, I just. I need to do crazy things. And it's just. I should not be. It's too jarring for people and the contradictory stuff, and then all the by association, like, you know, it's like I'm in a very weird position, and my public image, the avatar of me, is now this totally crazy thing that is so lost from my control.
Speaker B: So you feel the burden of the avatar having to be static. So the. The avatar on Twitter, the avatar on Instagram, on these social platforms, is as a burden. It becomes, like, because people don't want to accept a changing avatar, a chaotic avatar. Avatar is a stupid show, or they.
Speaker A: Think the avatar is morally wrong, or they think the avatar. And maybe, and maybe it has been. And, like, I, like, I question it all the time. Like, I'm like, hey. Like, I. I don't know if everyone's right and I'm wrong. I don't know. Like. But, you know, a lot of times, people ascribe intentions to things. The worst possible intentions at this point, people think I'm, you know. But.
Speaker B: Which is all kinds of words. Yes, yes.
Speaker A: And it's fine. I'm not complaining about it, but I'm just. It's a curiosity. It's a curiosity to me that we live these double, triple, quadruple lives, and I have this other life that is, like, more people know my other life than my real life, which is interesting, probably. I mean, you, too, I guess.
Speaker B: Probably, yeah. But I have the luxury, so we have all different. We don't. Like, I don't know what I'm doing. There is an avatar, and you're mediating who you are through that avatar. I have the nice luxury, not the luxury, maybe by intention of not trying really hard to make sure there's no difference between the avatar and the private person.
Speaker A: Do you wear a suit all the time?
Speaker B: Yeah.
Speaker A: You do wear a suit?
Speaker B: Not all the time. Recently, because I get recognized a lot. I have to not wear the suit to hide. I'm such an introvert. I'm such a social anxiety and all that kind of stuff. Hideaway. I loved wearing a suit because it makes me feel like I'm taking the moment seriously. Like, I'm. I don't know. It makes me feel like a weirdo in the best possible way.
Speaker A: Suits feel great. Every time I wear a suit, I'm like, I don't know why I'm not.
Speaker B: Doing this more in fashion in general, if you, if you're doing it for yourself. I don't know that it's a, it's a really awesome thing, but, yeah, I think there is definitely a painful way to use social media and an empowering way. And I don't know if anyone know, any of us know which is which, so we're trying to figure that out.
Speaker A: Some people, I think Doja cat is incredible at it. Incredible. Like, just masterful. Yeah, I don't know if you like.
Speaker B: Yeah, yeah. So the. So. So, okay, so not taking anything seriously. Joking, absurd humor, that kind of.
Speaker A: I think Doja cat might be, like, the greatest living comedian right now. Like, I'm more entertained by Doja cat than actual comedians. Like, she's really fucking funny on the Internet. She's just great at social media. It's just, you know. Yeah.
Speaker B: The nature of humor. Humor on social media is also a beautiful thing. The absurdity.
Speaker A: The absurdity and memes. Like, I just want to take a moment. I love, like, when we're talking about art and credit and how, and authenticity. I love that there's this, I mean, now memes are, like, they're no longer, like, memes aren't, like, new, but it's still this emergent art form that is completely egoless and anonymous, and we just don't know who made any of it. And it's, like, the forefront of comedy, and it's just totally anonymous, and it just feels really beautiful. It just feels like this beautiful collective human art project that's, like, this decentralized comedy thing that just makes memes add so much to my day and many people's days. And it's just like, I don't know. I don't think people ever, I don't think we stop enough and just appreciate how sick it is that memes exist, because also making a whole brand new art form in, like, the modern era, that's, like, didn't exist before. Like, I mean, they sort of existed, but the way that they exist now as, like, this, like, like, me and my friends, we joke that we go mining for memes or farming for memes, like a video game and meme dealers and whatever memes are this whole new comedic language.
Speaker B: Well, it's this art form. The interesting thing about it is that lame people seem to not be good at memes. Like, corporate can't infiltrate memes.
Speaker A: Yeah, they really can't.
Speaker B: Have they tr. They could try, but it's like, it's weird because, like, they try so hard.
Speaker A: And every once in a while I'm like, fine, like, you got a good one. I think I've seen, like, one or two good ones, but, like, yeah, they really can't, because they're even. Corporate is infiltrating web three. It's making me really sad. But they can't infiltrate the memes. And I think there's something really beautiful.
Speaker B: About that that gives power. That's, that's why dogecoin is powerful. It's like, all right, f you. To sort of, anybody who's trying to centralize, who's trying to control the rich people that are trying to roll in and control this, control the narrative.
Speaker A: Wow, I hadn't thought about that.
Speaker B: But how would you fix Twitter? How would you fix social media for your own? Like, you're an optimist, you're a positive person. There's a bit of a cynicism that you have currently about this particular little slice of humanity. I tend to think Twitter could be.
Speaker A: I'm not that cynical about it. I'm not that cynical about it. I actually refuse to be a cynic on principle. Yes, I was just briefly expressing some personal paths, personal stuff. It was just some personal pathos.
Speaker B: But, like, like, just to vent a little bit, just to.
Speaker A: I don't have. I don't have cancer. I love my family. I have a good life. I'm. That. That is, if. That is my biggest, one of my biggest problems.
Speaker B: It's a good life.
Speaker A: Yeah, I, you know, that was a brief. Although I do think there are a lot of issues with Twitter, just in terms of the public mental health, but due to my proximity to the current dramas, I honestly feel that I should not have opinions about this because I think if Elon ends up getting Twitter, that is a. Being the arbiter of truth or public discussion. That is a responsibility. I am not qualified to be responsible for that. And I do not want to say something that might dismantle democracy. And so I just like, actually. I actually think I should not have opinions about this because I truly am not. I don't want to have the wrong opinion about this. And I think I'm too close to the actual situation wherein I should not have. I have thoughts in my brain, but I think I am scared by my proximity to this situation.
Speaker B: Isn't that crazy that a few words that you could say could change world affairs and hurt people? I mean, that's the nature of celebrity at a certain point that you have to be. You have to. A little bit. A little bit. Not so much that it destroys you, puts too much constraints, but you have to. A little bit think about the impact of your words. I mean, we as humans, you talk to somebody at a bar, you have to think about the impact of your words. Like, you can say positive things, you can think of negative things. You can affect the direction of one life, but on social media, your words can affect the direction of many lives. It's crazy. It's a crazy world to live in. It's worthwhile to consider that responsibility, take it seriously sometimes, just like you did. Choose kind of silence, choose sort of respectful.
Speaker A: Like, I do have a lot of thoughts on the matter. I'm just. I just. I don't if my thoughts are wrong. This is one situation where the stakes are high.
Speaker B: You mentioned a while back that you were in a cult that's centered around bureaucracy, so you can't really do anything because it involves a lot of paperwork. And I really love a cult that's just like, kafka esque. Just like.
Speaker A: I mean, it was like a joke, but.
Speaker B: I know, but I love this idea.
Speaker A: The holy rain empire. Yeah. It was just like a Kafka esque pro bureaucracy.
Speaker B: But I feel like that's what human civilization is, because when you said that, I was like, oh, that is kind of what humanity is. Is this bureaucracy?
Speaker A: I do, yeah, I have this theory. I really think that we really. Bureaucracy is starting to kill us, and I think we need to reorient laws and stuff. I think we just need sunset clauses on everything. I think the rate of change in culture is happening so fast, and the rate of change in technology and everything is happening so fast. When you see these hearings about social media and Cambridge analytica and everyone talking, it's like, even from that point, so much technological change has happened from those hearings. And it's just like we're trying to make all these laws now about AI and stuff. I feel like we should be updating things every five years. And one of the big issues in our society right now is we're just getting bogged down by laws, and it's making it very hard to change things and develop things. Like in Austin, I don't want to speak on this too much, but one of my friends is working on a housing bill in Austin to try to prevent a San Francisco situation from happening here, because obviously we're getting a little mini San Francisco here. Housing prices are skyrocketing. It's causing massive gentrification. This is really bad for anyone who's not super rich. There's so much bureaucracy. Part of the reason this is happening is because you need all these permits to build. It takes years to get permits to build anything. It's so hard to build. There's very limited housing and there's a massive influx of, of people. And it's just like, this is a microcosm of problems that are happening all over the world, where it's just like, we're dealing with laws that are 1020, 30, 4100, 200 years old, and they are no longer relevant. And it's just slowing everything down and causing massive social pain.
Speaker B: Yeah, but it also makes me sad when I see politicians talk about technology and when they don't really get it. But most importantly, they lack curiosity and like that, like, inspired excitement about like, how stuff works and all that stuff. They're just like, they see, they have the very cynical view of technology. It's like tech companies are just trying to do evil in the world from their perspective. And they have no curiosity about like, how recommender systems work or how, how AI systems work, natural language processing, how robotics works, how computer vision works. You know, they always take the most cynical possible interpretation of what technology would be used, and we should definitely be concerned about that. But if you're constantly worried about that and you're regulating based on that, you're just going to slow down all the innovation.
Speaker A: I do think a huge priority right now is undoing the bad energy surrounding the emergence of Silicon Valley. Like, I think that, like, a lot of things were very irresponsible during that time. And even just this current whole thing with Twitter and everything, there has been a lot of negative outcomes from the technocracy boom. But one of the things that's happening is that it's alienating people from wanting to care about technology. And I actually think technology is probably some of the better, probably the best. I think we can fix a lot of our problems more easily with technology than with fighting the powers that be. As a, not to go back to the Star wars quote or the Buckminster.
Speaker B: Fuller quote, let's go to some dark questions, if we may, for time. What is the darkest place you ever gone in your mind? Is there a time, a period of time, a moment? Do you remember that was difficult for you?
Speaker A: I mean, when I was 18, my best friend died of a heroin overdose. And it was like my. It was. And then shortly after that, one of my other best friends committed suicide. And that sort of like coming into adulthood, dealing with two of the most important people in my life, dying in extremely disturbing, violent ways was a lot. That was a lot.
Speaker B: Do you miss them?
Speaker A: Yeah, definitely miss them.
Speaker B: Did that make you think about your own life, about the finiteness of your own life, the places your mind can go? Did you ever, in the distance, far away, contemplate just your own death or maybe even taking your own life?
Speaker A: Oh, never. Oh, no. I'm so. I love my life. I cannot fathom suicide. I'm so scared of death. I haven't. I'm too scared of death. My manager. My manager's like, the most Zen guy. My manager's always like, you need to accept death. You need to accept death. And I'm like, look, I can do your meditation. I can do the meditation, but I cannot accept death.
Speaker B: I'm terrified of death.
Speaker A: I'm terrified of death. I will fight. Although I actually think death is important. I recently went to this meeting about immortality, and in the process of.
Speaker B: That's the actual topic of the meeting. All right, I'm sorry.
Speaker A: No, no. It was this girl. It was a bunch of people working on anti aging stuff. It was some seminary thing about it. And I went in really excited. I was like, yeah, okay, what do you got? How can I live for 500 years or 1000 years? And then over the course of the meeting, it was sort of like, right? It was like two or three days after the russian invasion started. And I was like, man, what if Putin was immortal? What if I'm like, man, maybe immortality is not good. I mean, if you get into the later dune stuff, the immortals cause a lot of problem because as we were talking about earlier, with the music and brains calcified, good people could become immortal, but bad people could become immortal. But I also think even the best people, power corrupts. And power alienates you from the common human experience, right?
Speaker B: So the people that get more and.
Speaker A: More powerful, even the best. Even the best people who, like, whose brains are amazing, I think death might be important. I think death is part of, you know, like, I think with AI, one thing we might want to consider. I don't know. When I talk about AI, I'm such not an expert. And probably everyone has all these ideas and they're already figured out, but when I.
Speaker B: Nobody is an expert in anything, see? Okay, go ahead.
Speaker A: Yeah, but it's just like, I think some kind of pruning but it's a tricky thing because if there's too much of a focus on youth culture, then you don't have the wisdom. So I feel like we're in a tricky. We're in a tricky moment right now in society where it's like, we've really perfected living for a long time. So there's all these really old people who are really voting against the well being of the young people. And it's like, there shouldn't be all this student debt, and we need healthcare, universal health care, and just voting against best interests. But then you have all these young people that don't have the wisdom that are like, like, yeah, we need communism and stuff. And it's just like, like, literally, I got canceled at one point for I ironically used a Stalin quote in my high school yearbook, but it was actually like a diss against my high school.
Speaker B: I saw that.
Speaker A: Yeah. And people were like, you used to be a Stalinist and now you're a class trader. And it's like, it's like, oh, man, just like, please google Stalin. Please google Stalin.
Speaker B: Like, you know, ignoring the lessons of history. Yes.
Speaker A: And it's like we're in this really weird middle ground where it's like we are not finding the happy medium between Ms. Wisdom and fresh ideas. And they're fighting each other. And it's like, really what we need is the fresh ideas and the wisdom to be collaborating.
Speaker B: And it's like what the fighting, in a way, is the searching for the happy medium. And in a way, maybe we are finding the happy medium. Maybe that's what the happy medium looks like. And for AI systems, there has to be. You have the reinforcement learning, you have the dance between exploration and exploitation, sort of doing crazy stuff to see if there's something better than what you think is the optimal, and then doing the optimal thing and dancing back and forth from that, you would. Stewart Russell, I don't know if you know, that is AI guy with thinks about sort of how to control super intelligent AI systems and his ideas that we should inject uncertainty and sort of humility into AI systems that they never, as they get wiser and wiser and wiser and more intelligent, they're never really sure. They always doubt themselves. And in some sense, when you think of young people, that's a mechanism for doubt. It's like, it's how society doubts whether the thing it has converged towards is the right answer. So the voices of the young people is a society asking itself a question. The way I've been doing stuff for the past 50 years. Maybe it's the wrong way, and so you can have all of that within one AI system.
Speaker A: I also think, though, that we need to. I mean, actually, that's actually really interesting and really cool. But I also think there's a fine balance of. I think we maybe also overvalue the idea that the old systems are always bad. And I think there are things that we are perfecting, and we might be accidentally overthrowing things that we actually have gotten to a good point. Just because we are valuing, we value disruption so much, and we value fighting against the generations before us so much that there's also an aspect of sometimes we're taking two steps forward, one step back, because, okay, maybe we kind of did solve this thing, and now we're fucking it up. And so I think there's a middle ground there, too.
Speaker B: Yeah, we're in search of that happy medium. Let me ask you a bunch of crazy questions.
Speaker A: Okay.
Speaker B: You can answer in a short way or in a long way. What's the scariest thing you've ever done? These questions are going to be ridiculous. Something tiny or something big. Skydiving or touring your first record. Going on this podcast, I've had two.
Speaker A: Crazy brushes, like, really scary brushes with death, where I randomly got away on scathe. I don't know if I should talk about those on here, but, like, I don't know. I think. I think I might be the luckiest person alive, though. Like, this might be too dark for a podcast, though. I feel like. I don't know if this is, like, good content for podcasts.
Speaker B: I don't know what content is.
Speaker A: It might hijack. Here's a safer one. I mean, having a baby really scared me before just the birth process surgery. Like, just having. Just having a baby is. It was really scary.
Speaker B: So just, like, the medical aspect of it, not the responsibility. Were you ready for the responsibility of, did you. Were you ready to be a mother? All the. All the beautiful things that comes with motherhood that you were talking about, all the changes and all that. Were you ready for that? Did you feel ready for that?
Speaker A: No. I think it took about nine months to start getting ready for it, and I'm still getting more ready for it, because now you keep realizing more things as they start getting.
Speaker B: As the consciousness grows and stuff you.
Speaker A: Didn'T notice with the first one. Now that you've seen the first one older, you're noticing it more. The sort of existential horror of coming into consciousness with baby y or baby sailor mars or whatever. She has so many names at this point that we really need to probably settle on one.
Speaker B: If you can be someone else for a day, someone alive today, but somebody you haven't met yet, who would you be?
Speaker A: Would I be modeling their brain state, or would I just be in their body?
Speaker B: You can choose the degree to which you're modeling their brain state because you can still take a third person perspective and realize, you have to realize that you're.
Speaker A: Can they be alive or can it be dead?
Speaker B: No. Oh.
Speaker A: Could it be anyone?
Speaker B: They would be brought back to life, right? If they're dead, yeah, you can bring people back.
Speaker A: Definitely Hitler or Stalin, huh? I want to understand evil.
Speaker B: You would need to. Oh. To experience what it feels like.
Speaker A: I want to be in their brain feeling what they feel.
Speaker B: That might change you forever returning from that.
Speaker A: Yes. But I think it would also help me understand how to prevent it and fix it.
Speaker B: That might be one of those things. Once you experience it, it'll be a burden to know it because you won't be able to.
Speaker A: Yeah, but a lot of things are our burdens.
Speaker B: But it's useful burden.
Speaker A: But it's a useful burden. Yeah, that for sure. I want to understand evil and, like, psychopathy and that I have all these fake Twitter accounts where I go into different algorithmic bubbles to try to understand. I'll keep getting in fights with people and realize we're not actually fighting. I think we used to exist in a monoculture, like, before social media and stuff. We kind of all got fed the same thing, so we were all speaking the same cultural language. But I think recently, one of the things that we aren't diagnosing properly enough with social media is that there's different dialects. There's so many different dialects of Chinese. There are now becoming different dialects of English. I am realizing there are people who are saying the exact same things, but they're using completely different verbiage, and we're punishing each other for not using the correct verbiage, and we're completely misunderstanding. People are just misunderstanding what the other people are saying. And I just got in a fight with a friend of about anarchism and communism and shit for like, 2 hours, and then by the end of a conversation, and then she'd say something, and I'm like, but that's literally what I'm saying. And she was like, what? And then I was like, fuck. We've different. I'm like, our English, the way we are understanding terminology is like, drastically like, our algorithm bubbles are creating mini dialects.
Speaker B: Of how language is interpreted, how language is used. That's so fascinating.
Speaker A: And so we're having these arguments that we do not need to be having, and there's polarization that's happening. That doesn't need to be happening because we've got these algorithmically created dialects occurring.
Speaker B: Plus, on top of that, there's also different parts of the world that speak different languages, so there's literally lost in translation kind of communication. I happen to know the russian language and just know how different it is.
Speaker A: Yeah.
Speaker B: Than the english language. And I just wonder how much is lost in a little bit of.
Speaker A: Man. I actually, because I have a question for you. I have a song coming out tomorrow with Ice Peak, who are a russian band, and I speak a little bit of Russian. And I was looking at the title, and the title in English doesn't match the title in Russian. I'm curious about this because, look, it says, what's the English? The title in English is last day. And then the title in Russian is my project. Pronunciation. Sex. Novi dien.
Speaker B: Like new day.
Speaker A: New day.
Speaker B: Yeah, new day. New day. Yeah, new day. Yeah, yeah, yeah, new day. Yeah, new day. But last day. Norway Jane. So last day would be Pasadena Jane.
Speaker A: Yeah.
Speaker B: Maybe they.
Speaker A: Maybe the title includes both the Russian and the. And its form.
Speaker B: Maybe it's for.
Speaker A: Maybe it's for bilingual.
Speaker B: To be honest, Novi James sounds better than just musically like, Novi Jen is new day. That's the current one. And Pasadena is the last day, I think. Novi jin. I don't like Novi jin, but the meaning is so different. That's kind of awesome, actually. There's an explicit sort of contrast like that. If everyone on earth disappeared and it was just you left, what would your day look like? Like, what would you do? Everybody's dead.
Speaker A: Are there corpses there? Seriously? It's a big.
Speaker B: Let me think through this.
Speaker A: It's a big difference if there's just birds singing versus if there's corpses littering the street.
Speaker B: Yeah, there's corpses everywhere. I'm sorry. And you don't actually know what happened, and you don't know why you survived, and you don't even know if there's others out there, but it seems clear that it's all gone.
Speaker A: What would you do?
Speaker B: What would I do? I'm somebody who really enjoys the moment, enjoys life. I would just go on, like, enjoying the inanimate objects. I would just look for food, basic survival. But most of it is just listen.
Speaker A: What?
Speaker B: I just. I take walks and I look outside, and I'm just happy that we get to exist on this planet, to be able to breathe air, it's just all beautiful, it's full of colors, all of this kind of stuff. Just, there's so many things about life, your own life, conscious life. That's fucking awesome. So I would just enjoy that. But also, maybe after a few weeks, the engineer would start coming out, like, want to build some things? Maybe there's always hope. Searching for another human, maybe.
Speaker A: Probably searching for another human. Probably trying to get to a tv or radio station and broadcast something.
Speaker B: That's interesting. I didn't think about that. So, like, really maximize your ability to connect with others?
Speaker A: Yeah, like, probably try to find a. Another person.
Speaker B: Would you be excited to see, to meet another person or terrified because, you.
Speaker A: Know, I'd be excited even if they.
Speaker B: No matter what.
Speaker A: Yeah, yeah, yeah. Being alone for the last, however long of my life would be really bad. That's the one instance I might. I don't think I'd kill myself, but I might kill myself if I had to undergo.
Speaker B: Do you love people? You love connection to other humans?
Speaker A: Yeah, I kind of hate people too.
Speaker B: But I. Yeah, it's a love hate relationship.
Speaker A: Yeah. I feel like this is. I feel like we had a bunch of, like, weird nietzsche questions and stuff, though.
Speaker B: Oh, yeah.
Speaker A: Like, I wonder. Cause I'm like, when podcast, like, I'm like, is this interesting for people to just have, like. Or I don't know, maybe people do like this. When I listen to podcasts, I'm into, like, the lore, like, the hard lore. Like, I just love, like, Dan Carlin. I'm like, give me the facts. Just like, like, the facts into my bloodstream.
Speaker B: But you also don't know, like, you're a fascinating mind to explore. So you don't realize as you're talking about stuff, the stuff you've taken for granted is actually unique and fascinating. The way you think, not always. What? Like, the way you reason through things is the fascinating thing to listen to because people kind of see, oh, there's other humans that think differently, that explore thoughts differently. That's the cool. That's also cool. So, yeah. Dan Carlin retelling of history, by the way, his retelling of history is very. I think what's exciting is not the history is his way of thinking about history.
Speaker A: No, I think Dan Carlin is one of the people. Like, when Dan Carlin was one of the people that really started getting me excited about revolutionizing education, because Dan Carlin instilled, I already really liked history, but he instilled an obsessive love of history in me to the point where, like, now I'm fucking reading, like, like, going to bed reading, like, part four of the rise and fall of the Third Reich or whatever. Like, I, like, I'm like, dense ass history. But, like, like, he, like, opened that door that, like, made me want to be a scholar of that topic. Like, it's like, I feel like he's such a good teacher. He just like, you know, and it sort of made me feel like one of the things we could do with education is, like, find the world's great, the teachers that create passion for the topic. Because auto didacticism. I don't know how to say that properly, but self teaching is much faster than being lectured to. It's much more efficient to be able to teach yourself and then ask a teacher questions when you don't know what's up. But that's why it's in university and stuff. You can learn so much more material so much faster because you're doing a lot of the learning on your own and you're going to the teachers for when you get stuck. But, like, these teachers that can inspire passion for a topic, I think that is one of the most invaluable skills in our whole species. Because if you can do that, then you. It's like AI. Like, AI is going to teach itself so much more efficiently than we can teach it. We just needed to get it to the point where it can teach itself.
Speaker B: And then it finds the motivation to do so. Right?
Speaker A: Yeah.
Speaker B: So you inspire it to do so and then it could teach itself. What do you make of the fact you mentioned rise and fall, the Third Reich? I just.
Speaker A: Have you read that?
Speaker B: I've read it twice.
Speaker A: And so you read it twice?
Speaker B: Yes.
Speaker A: Okay. So no one even knows what it. What it is.
Speaker B: Yeah.
Speaker A: And I'm like. I'm like, wait, I thought this was like a super poppin book.
Speaker B: Super pop.
Speaker A: I'm. I'm not like that. I'm not that far in it, but it is. It's so interesting.
Speaker B: Yeah. It's written by a person that was there, which is very important to kind.
Speaker A: Of, you know, you start being like, how could this possibly happen? And then when you read rise and fall of the Third Reich, it's like, people tried really hard for this to not happen. People tried. They almost reinstated a monarchy at one point to try to stop this from happening. Like, they almost like, like, abandoned democracy to try to get this to not happen.
Speaker B: At least the way it makes me feel is that there's a bunch of small moments on which history can turn.
Speaker A: Yes.
Speaker B: Like small meetings, human interactions. And that's both terrifying and inspiring because it's like even just attempts at assassinating Hitler, like, time and time again failed.
Speaker A: And they were so close to Valkyrie, such a good.
Speaker B: And then there's also the role of. That's a really heavy burden, which is that from a geopolitical perspective, the role of leaders, to see evil before it truly becomes evil, to anticipate it had to stand up to evil because evil is actually pretty rare in this world at a scale that Hitler was. We tend to, in the modern discourse, kind of call people evil too quickly.
Speaker A: If you look at ancient history, there was a ton of hitlers. I actually think it's more the norm than. Again, going back to my sort of intelligent design theory, I think one of the things we've been successfully doing in our slow move from survival of the fittest to intelligent design is we've kind of been eradicating. If you look at ancient Assyria and stuff, that shit was brutal. And just the heads on the brutal Genghis Khan, just genocide after genocide after genocide, throwing plague bodies over the walls and decimating whole cities, or the muslim conquests of Damascus and shit. Cities used to get leveled all the fucking time. Okay, get into the Bronze age collapse. It's basically, there was almost roman level society. There was all over the world, global trade. Everything was awesome through a mix of, I think, a bit of climate change and then the development of iron, because basically bronze could only come from the way to make bronze. Everything had to be funneled through this one iranian mine. And so it's like. But there was just this one supply chain. And this is one of the things that makes me worried about supply chains and why I think we need to be so thoughtful about. I think our biggest issue with society right now, like, the thing that is most likely to go wrong is probably supply chain collapse. You know, because war, climate change, whatever, like anything that causes supply chain collapse, our population is too big to handle that. And, like, the thing that seems to cause dark ages is mass supply chain collapse. But interesting, the Bronze Age collapse happened to, like, it was sort of like this ancient collapse that happened where literally ancient Egypt, all these cities, everything just got decimated, destroyed, abandoned cities, hundreds of them. There was a flourishing society. We were almost coming to modernity, and everything got leveled. And they had this mini dark ages. But it was just like, there's so little writing or recording from that time that there isn't a lot of information about the Bronze Age collapse, but it was basically equivalent to medieval. The medieval dark ages. But it just happened, I don't know the years, but thousands of years earlier. And then we sort of recovered from the Bronze Age collapse. Empire re emerged, writing and trade and everything reemerged. And then we, of course, had the more contemporary dark ages.
Speaker B: And then over time, we've designed mechanism to lessen and lessen the capability for the destructive power centers to emerge.
Speaker A: There's more recording about the more contemporary dark ages. So I think we have a better understanding of how to avoid it, but I still think we're at high risk for it. I think that's one of the big. The big risks. Right.
Speaker B: So the natural state of being for humans is for there to be a lot of hitlers. We just gotten really good at making it hard for them to emerge. We've gotten better at collaboration.
Speaker A: Yes.
Speaker B: And resisting the power, like authoritarians to come to power.
Speaker A: We're trying to go country by country, like, we're moving past this. We're kind of like slowly, incrementally moving towards not scary old school war stuff. And I think seeing it happen in some of the countries that at least nominally are supposed to have moved past that, that's scary, because it reminds us that it can happen, like in the places that have supposedly, hopefully moved past.
Speaker B: That, and possibly at a civilization level. Like you said, supply chain collapse might make people, resource constraint might make people desperate, angry, hateful, violent, and drag us right back in.
Speaker A: I mean, supply chain collapse is how, like, the ultimate thing that caused the middle ages, Washington, supply chain collapse. It's like people, because people were reliant on a certain level of technology. You look at Britain, they had glass, people had aqueducts, people had indoor heating and cooling and running water and buy food from all over the world, and trade and markets. People didn't know how to hunt and forage and gather. And so we're in a similar situation. We are not educated enough to survive without technology. So if we have a supply chain collapse that limits our access to technology, there will be mass starvation and violence and displacement and war. In my opinion, it's the primary marker of what a dark age is.
Speaker B: Technology is enabling us to be more resilient in terms of supply chain, in terms of to all the different catastrophic events that happened to us. Although the pandemic has kind of challenged our preparedness for the catastrophic, what do you think is the coolest invention humans come up with? The wheel, fire, cooking meat.
Speaker A: Computers.
Speaker B: Computers.
Speaker A: Freaking computers.
Speaker B: Internet or computers. Which one?
Speaker A: What did you think the previous technologies, I mean, may have even been more profound and moved us to a certain degree, but I think the computers are what make us homo tech. No, I think this is what. It's a brain augmentation, and so it allows for actual evolution. The computers accelerate the degree to which all the other technologies can also be accelerated.
Speaker B: Would you classify yourself as a homo sapien or a homo techno?
Speaker A: Definitely homo techno. I think we're all.
Speaker B: You're one of the early of the species.
Speaker A: I think most of us are. As I said, I think if you looked at brain scans of us versus humans 100 years ago, it would look very different. I think we are physiologically different.
Speaker B: Just even the interaction with the devices has changed our brains well.
Speaker A: And if you look at, a lot of studies are coming out to show that there's a degree of inherited memory. So some of these physiological changes, in theory, we should be passing them on. So that's not an instance of physiological change that's going to fizzle out. In theory, that should progress, like, to our offspring.
Speaker B: Speaking of offspring, what advice would you give to a young person, like, in high school, whether there be an artist, a creative, an engineer, any kind of career path, or maybe just life in general, how they can live a life they could be proud of.
Speaker A: I think one of my big thoughts, and, like, especially now having kids, is that I don't think we spend enough time teaching creativity. And I think creativity is a muscle, like other things. And there's a lot of emphasis on, you know, learn how to play the piano, and then you can write a song or, like, learn the technical stuff, and then you can do a thing. But I think it's like, I have a friend who's, like, world's greatest guitar player. Like, you know, amazing. Sort of, like, producer, works with other people, but he's really sort of like, you know, he, like, engineers and records things and, like, does solos, but he doesn't really, like, make his own music. And I was talking to him, and I was like, dude, you're so talented at music. Like, why don't you make music or whatever? And he was like, because I got. I'm too old. I never learned the creative muscle. And it's like, you know, it's embarrassing. It's like learning the creative muscle takes a lot of failure, and it also sort of, you're. If when you're being creative, you know, you're throwing paint at a wall and a lot of stuff will fail. So, like, part of it is, like, a tolerance for failure and humiliation and.
Speaker B: Somehow that's easier to develop when you're young.
Speaker A: Yeah.
Speaker B: Or be persist through it when you're young.
Speaker A: Everything is easier to develop when you're young. Yes.
Speaker B: And the younger the better. It could destroy you. I mean, that's the shitty thing about creativity. If, you know, failure could destroy you if you're not careful. But that's a risk worth taking.
Speaker A: But also. But at a young age, developing a tolerance to failure is good. I fail all the time. Like, I do stupid shit all the time. Like, in public, in private, I get canceled for. I make all kind of mistakes, but I just, like, am very resilient about making mistakes. And so then I do a lot of things that other people wouldn't do. And I think my greatest asset is my creativity. And I think pain, like, tolerance to failure, is just a super essential thing that should be taught before other things.
Speaker B: Brilliant advice. Yeah. Yeah. I wish everybody encouraged sort of failure more as opposed to kind of because.
Speaker A: We, like, punish failure. We're like, no. When we were teaching kids, we're like, no, that's wrong. Like, that's, you know, like, x keeps, like, will be like, wrong. Like, he'll say, like, crazy things. Like, x keeps being like. Like, bubble car. Bubble car. And I'm like. And you know, I'm like, what's a bubble car? Like? But, like, it doesn't. Like, but I don't want to be like, no, you're wrong. I'm like. You're thinking of weird, crazy shit. Like, I don't know what a bubble.
Speaker B: Car is, but, like, he's creating worlds, and they might be internally consistent, and through that, he might discover something fundamental about this.
Speaker A: Yeah, or he'll, like, rewrite songs like where withdev words that he prefers. So, like, instead of baby shark, he says baby car. It's like.
Speaker B: Maybe he's onto something. Let me ask the big ridiculous question. We were kind of dancing around it, but what do you think is the meaning of this whole thing we have here of human civilization, of life on earth, but in general, just life. What's the meaning of life? See?
Speaker A: Did you read Nova scene yet by James Lovelock?
Speaker B: You're doing a lot of really good book recommendations here.
Speaker A: I haven't even finished this. So I'm a huge fraud yet again. But really early in the book, he says this amazing thing. I feel like everyone's so sad and cynical. Everyone's the Fermi paradox and everyone. I just keep hearing people being like, fuck, what if we're alone? Oh, no. And I'm like, okay, but like, wait, what if this is the beginning? In Nova scene, he says, this is not going to be a correct, because I can't memorize quotes, but he says something like, what if our consciousness right now, this is the universe waking up? What if instead of discovering the universe, this is the universe. This is the evolution of the little literal universe herself. Like, we are not separate from the universe. Like, this is the universe waking up. This is the universe seeing herself for the first time.
Speaker B: This is the universe becoming conscious the first time. We're part of that.
Speaker A: Yeah. Because it's like, we aren't separate from the universe. This could be an incredibly sacred moment. And maybe social media and all this things, the stuff where we're all getting connected together, maybe these are the neurons connecting of the collective superintelligence that is, you know, waking up. Yeah. Like, you know, it's like, maybe instead of something cynical or maybe if there's something to discover, like, maybe this is just, you know, we're a blastocyst of, like, some incredible kind of consciousness or.
Speaker B: Being, and just like, in the first three years of life or for human children, we'll forget about all the suffering that we're going through now.
Speaker A: I think we'll probably forget about this. I mean, probably, you know, artificial intelligence will eventually render us obsolete. I don't think they'll do it in a malicious way, but I think probably we are very weak. The sun is expanding. Like, I don't know, like, hopefully we can get to Mars, but, like, we're pretty vulnerable. And I, you know, like, I think we can coexist for a long time with AI, and we can also probably make ourselves less vulnerable. But, you know, I just think consciousness, sentience, self awareness. Like, I think this might be the single greatest, like, moment in evolution ever. And, like, maybe this is, you know, like, the true beginning of life, and we're just. We're the blue green algae, or we're like. We're like the single celled organisms of something amazing.
Speaker B: The universe awakens, and this is it. Yeah, well, see, you're an incredible person. You're a fascinating mind. You should definitely do. Your friend Liv mentioned that you guys were thinking of maybe talking. I would love it if you explored your mind in this kind of medium more and more by doing a podcast with her or just in any kind of way. So you're an awesome person. It's an honor to know you. It's an honor to get to sit down with you late at night, which is, like, surreal, and I really enjoyed it. Thank you. For talking today. Yeah.
Speaker A: No, I mean, huge honor. I feel very underqualified to be here, but I'm a big fan. I've been listening to the podcast a lot, and, yeah, me and Liv would appreciate any advice and help, and we're definitely gonna do that.
Speaker B: So anytime. Thank you.
Speaker A: Cool. Thank you.
Speaker B: Thanks for listening to this conversation with Grimes. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Oscar Wilde. Yes, I'm a dreamer? For a dreamer is one who can only find her way by moonlight? And her punishment is that she sees the dawn before the rest of the world. Thank you for listening and hope to see you next time.
