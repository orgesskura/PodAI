Transcription for Eugenia Kuyda： Friendship with an AI Companion ｜ Lex Fridman Podcast #121.mp3:
Full transcript: The following is a conversation with Eugenia Coida, co founder of Replica, which is an app that allows you to make friends with an artificial intelligence system, a chatbot that learns to connect with you on an emotional, you could even say a human level by being a friend. For those of you who know my interest in AI and views on life in general, know that replica and Eugenia's line of work is near and dear to my heart. The origin story of replica is grounded in a personal tragedy of Eugenia losing her close friend Roman Mozarenki, who was killed crossing the street by a hit and run driver in late 2015. He was 34. The app started as a way to grieve the loss of a friend by training a chatbot neural net on text messages between Eugenia and Romande. The rest is a beautiful human story as we talk about with Eugenia. When a friend mentioned Eugenia's work to me, I knew I had to meet her and talk to her. I felt before, during and after that this meeting would be an important one in my life. And it was, I think, in ways that only time will truly show to me and others. She is a kind and brilliant person. It was an honor and a pleasure to talk to her. Quick summary of the sponsors DoorDash Dollar Shave Club and cash app. Click the sponsor links in the description to get a discount and to support this podcast. As a side note, let me say that deep, meaningful connection between human beings and artificial intelligence systems is a lifelong passion for me. I'm not yet sure where that passion will take me, but I decided some time ago that I will follow it boldly and without fear to as far as I can take it. With a bit of hard work and a bit of luck, I hope I'll succeed in helping build AI systems that have some positive impact on the world and on the lives of a few people out there. But also, it is entirely possible that I am, in fact, one of the chatbots that Eugenia and the replica team have built. And this podcast is simply a training process for the neural net that's trying to learn to connect to human beings one episode at a time. In any case, I wouldn't know if I was or wasn't, and if I did, I wouldn't tell you. If you enjoy this thing, subscribe on YouTube, review it with five stars on Apple Podcast, follow on Spotify, support on Patreon, or connect with me on Twitter lexfreedman as usual, I'll do a few minutes of ads now and no ads in the middle. I'll try to make these interesting but give you timestamps so you can skip. But please do still check out the sponsors by clicking the links in description to get a discount. Buy whatever they're selling. It really is the best way to support this podcast. This show is sponsored by Dollar Shave Club. Try them out with a one time offer for only $5 and free shipping@dollarshave.com. lex the starter kit comes with a six blade razor, refills and all kinds of other stuff that makes shaving feel great. I've been a member of Dollar Shave Club for over five years and actually signed up when I first heard about them on the Joe Rogan Experience podcast. And now, friends, we have come full circle. It feels like I made it now that I can do a read for them, just like Joe did all those years ago, back when he also did ads for some less reputable companies. Let's say that you know about if you're a true fan of the old school podcasting world. Anyway, I just used the razor and the refills, but they told me I should really try out the shave butter. I did. I love it. It's translucent somehow, which is a cool new experience. Again, try the ultimate shave starter set today for just $5 plus free shipping@dollarshaveclub.com. lex this show is also sponsored by DoorDash. Get $5 off and zero delivery fees on your first order of $15 or more when you download the DoorDash app and enter code. You guessed it Lex. I have so many memories of working late nights for a deadline with a team of engineers, whether that's from my PhD at Google or MIT, and eventually taking a break to argue about which DoorDash restaurant to order from and when the food came. Those moments of bonding, of exchanging ideas, of pausing to shift attention from the programs to humans or special for a bit of time. Im on my own now so I missed that Camaraderie. But actually I still use DoorDash a lot. Theres a million options that fit into my crazy keto diet ways. Also, its a great way to support restaurants in these challenging times. Once again, download the DoorDash app and enter code Lex to get $5 off and zero delivery fees on your first order of dollar 15 or more. Finally, this show is presented by Cash app, the number one finance app in the app store. I can truly say that they're an amazing company, one of the first sponsors, if not the first sponsor to truly believe in me. And and I think quite possibly the reason I'm still doing this podcast. So I am forever grateful to cash app. So thank you. And as I said many times before, use code Lexpodcast when you download the app from Google Play or the app store. Cash app lets you send money to friends, buy bitcoin, and invest in the stock market with as little as $1. I usually say other stuff here in the read, but I wasted all that time upfront saying how grateful I am to cash app. I'm going to try to go off the top of my head a little bit more for these reads because I'm actually very lucky to be able to choose the sponsors that we take on, and that means I can really only take on the sponsors that I truly love, and then I could just talk about why I love them. So it's pretty simple. Again, get cash app from the App store, Google Play, use code Lex podcast, get $10. And cash app will also donate $10 to first, an organization that is helping to advance robotics and stem education for young people around the world. And now, here's my conversation with Eugenia Cuida. Okay, before we talk about AI and the amazing work you're doing, let me ask you ridiculously, we're both russian, so let me ask you a ridiculously romanticized russian question. Do you think human beings are alone, like, fundamentally, on a philosophical level, like, in our existence, when we, like, go through life, do you think just the nature of our life is loneliness? Yeah. So we have to read Dostoyevsky at school, as you probably know in Russian. Yeah, I mean, it's part of the school program. So I guess if you read that, then you sort of have to believe that you're made to believe that you're fundamentally alone, and that's how you live your life. How do you think about it? You have a lot of friends, but at the end of the day, do you have, like, a longing for connection with other people? That's maybe another way of asking it. Do you think that's ever fully satisfied? I think we are fundamentally alone. We're born alone, we die alone. But I view my whole life as trying to get away from that, trying to not feel, feel lonely. And again, we're talking about subjective way of feeling alone. It doesn't necessarily mean that you don't have any connections or you're actually isolated. You think it's a subjective thing. But, like, again, another absurd measurement wise thing. How much loneliness do you think there is in the world? So, like, if you see loneliness as a. As a condition, how much of it is there? Do you think? Like, how, I guess, how many, you know, there's all kinds of studies and measures of how much, how many people in the world feel alone. There's all these measures of how many people are self report or just all these kinds of different measures. But in your own perspective, how big of a problem do you think it is size wise? I'm actually fascinated by the topic of loneliness. I try to read about it as much as I can. What really? And I think there's a paradox, because loneliness is not a clinical disorder. It's not something that you can get your insurance to pay for if you're struggling with that. Yet it's actually proven, and pretty tons of papers, tons of research around that, it is proven that it's correlated with earlier life expectancy, shorter lifespan, and it is, in a way, right now what scientists would say, that it's a little bit worse than being obese or not actually doing any physical activity in your life in terms of impact on your physiological health. Yeah. So it's basically puts you, if you're constantly feeling lonely, your body responds like it's basically all the time under stress, so it's always in this alert, alert state, and so it's really bad for you because it actually, like, drops your immune system and get it. Your response to inflammation is quite different, so. Or all the cardiovascular diseases actually responds to viruses, so it's much easier to catch a virus. That's sad. Now that we're living in a pandemic, and it's probably making us a lot more alone, and it's probably weakening the immune system, making us more susceptible to the virus. It's kind of sad. Yeah, the statistics are. The statistics are pretty horrible around that. So around 30% of all millennials report that they're feeling lonely constantly. 30, 30%. And then it's much worse for Gen Z. And then 20% of millennials say that they feel lonely, and they also don't have any close friends. And then I think 25 or so, and then 20% would say they don't even have acquaintances. That's the United States. That's in the United States. And I'm pretty sure that that's much worse everywhere else, like in the UK. I mean, it was widely, like, tweeted and, uh, posted when they were talking about a minister of loneliness that they wanted to appoint, because four out of ten you people in the UK feel lonely. So I think we don't. A minister of loneliness, I mean, that. I think that thing actually exists. So, yeah, you. You will die sooner if you if you are lonely, and again, that this is only when we're only talking about your perception of loneliness, of feeling lonely, that is, not objectively, fully being fully socially isolated. However, the combination of being fully socially isolated and not having many connections and also feeling lonely, that's pretty much a deadly combination. So it strikes me bizarre or strange that this is a wide known fact. And then there's really no one working, really on that because it's subclinical, it's not clinical, it's not something that you can want tell your doctor and get a treatment or something, yet it's killing us. Yeah. So there's a bunch of people trying to evaluate, like, try to measure the problem by looking at, like, how social media is affecting loneliness and all that kind of stuff. So it's like measurement. Like, if you look at the field of psychology, they're trying to measure the problem. And not that many people, actually, but some. But you're basically saying how many people are trying to solve the problem? Like, how would you try to solve the problem of loneliness? Like, if we just stick to humans, I mean, or basically not just the humans, but the technology that connects us humans. Do you think there's a hope for that technology to do the connection? Like, are you on social media much? Unfortunately. Do you find yourself, like, again, if you sort of introspect about how connected you feel to other human beings, how not alone you feel, do you think social media makes it better or worse? Maybe for you personally or in general? I think it's easier to look at some stats. And, I mean, Gen Z seems to be. Generation Z seems to be much lonelier than millennials in terms of how they report loneliness. They're definitely the most connected, you know, generation in the world. I mean, I still remember life without an iPhone, without Facebook. They don't know that that ever existed, or at least don't know how it was. So that tells me a little bit about the fact that that might be, you know, this hyper connected world might actually make people feel lonelier. I don't know exactly what the measurements are around that, but I would say, in my personal experience, I think it does make you feel a lot lonelier. Mostly, yeah, we're all super connected. But I think loneliness, the feeling of loneliness, doesn't come from not having any social connections whatsoever. Again, tons of people that are in long term relationships experience bouts of loneliness and continued loneliness. And it's more the question about the true connection, about actually being deeply seen, deeply understood. And in a way, it's also about your relationship with yourself. Like, in order to not feel lonely, you actually need to have a better relationship and feel more connected to yourself. Then this feeling actually starts to go away a little bit, and then you open up yourself to actually meeting other people in a very special way, not just add a friend on Facebook kind of way. So just to briefly touch on it, I mean, do you think it's possible to form that kind of connection with AI systems more down the line of some of your work? Do you think that's engineering wise? A possibility to alleviate loneliness is not with another human, but with an AI system? Well, I know that's a fact. That's what we're doing. And we see it and we measure that and we see how people start to feel less lonely talking to their virtual AI friend. So basically a chatbot at the basic level, but could be more like, do you have, I'm not even speaking sort of about specifics, but do you have a hope, like, if you look 50 years from now, do you have a hope that there's just, like, AI's that are optimized for. Let me first start, like, right now. The way people perceive AI, which is recommender systems for Facebook and Twitter, social media, they see AI as basically destroying, first of all, the fabric of our civilization, but second of all, making us more lonely. Do you see, like, a world where it's possible to just have AI systems floating about that, like, make our life less lonely? Yeah, make us happy, like, our putting good things into the world in terms of our individual lives? Yeah, I totally believe in that. That's why I'm also working on that. I think we need to also make sure that what we're trying to optimize for, we're actually measuring, and it is an orthodox metric that we're going after. And all of our product and all of our business models are optimized for that because you can talk, a lot of products that talk about making you feel less lonely or making you feel more connected, they're not really measuring that. So they don't really know whether their users are actually feeling less lonely in the long run or feeling more connected in the long run. So I think it's really important to put your. To measure it. Yep, to measure it. What's a good measurement of loneliness? Well, so that's something that I'm really interested in. How do you measure that people are feeling better or that they're feeling less lonely with loneliness? There's a scale, there's a UCLA 20 and UCLA three recently scale which is basically questionnaire that you fill out and you can see whether in the long run it's improving or not. And that, does it capture the momentary feeling of loneliness? Does it look in, like, the past month? Like, does it basically self report? Does it try to sneak up on you? It's very tricky to answer honestly or something like that. Yeah. I'm not familiar with the question. It is just asking you a few questions, like, how often did you feel lonely? Or how often did you feel connected to other people in this last few couple weeks? It's similar to the self report questionnaires for depression, anxiety, like PHQ nine, and get seven. Of course, as any self report questionnaires, that's not necessarily very precise or very well measured. But still, if you take a big enough population, you get them through these questionnaires, you can see positive, dynamic. And so you basically, you put people through questionnaires to see, like, is this thing. Is our. Is what we're creating making people happier? Yeah. We measure. So we measure two outcomes. One, short term. Right after the conversation, we ask people whether this conversation made them feel better, worse, or same. This metric right now is at 80%. So 80% of all our conversations make people feel better. I should have done the questionnaire with you. You feel a lot worse after we've done this conversation. That's actually fascinating. I should probably do that. But that's all. I should probably do that. You should totally. And aim for 80%. Aim to outperform your current state of the art AI system in these human conversations. Okay, we'll get to your work with replica, but let me continue on the line of absurd questions. So you talked about, you know, deep connection, other humans, deep connection with AI, meaningful connection. Let me ask about love. People make fun of me because I talk about love all the time, but what. What do you think love is? Like, maybe in the context of a meaningful connection with somebody else? Do you draw a distinction between love, like, friendship and Facebook friends? Or is it a graduate? No, it's all the same. No. Like, is it just a gradual thing, or is there something fundamental about us humans that seek, like, a really deep connection with another human being? And what is that? What is love? Eugenia, I just enjoy asking you these questions, seeing you struggle. Thanks. Yeah. Well, the way I see it, specifically the way it relates to our work and the way it inspired our work on replica, I think one of the biggest and the most precious gifts we can give to each other now in 2020, as humans, is this gift of deep empathetic. Understanding, the feeling of being deeply seen. Like, what does that mean that you exist? Like somebody acknowledging that, somebody seeing you. For who you actually are. And that's extremely rare. I think that is that combined with unconditional positive regard, belief and trust, that you internally are always inclined for positive growth and believing you in this way, letting you be a separate person at the same time. And this deep, empathetic understanding, for me, that's the combination that really creates something special, something that people, when they feel it once, they will always long for it again. And something that starts huge, fundamental changes in people. When we see that someone accepts us so deeply, we start to accept ourselves. And the paradox is that's when big changes start happening, big fundamental changes, and people start happening. So I think that is the ultimate therapeutic relationship, that is. And that might be in some way a definition of love. Acknowledging that there's a separate person and accepting you for who you are. Now on a slightly. And you mentioned therapeutic. That sounds like a very healthy view of love. But is there also, if we look at heartbreak, and most love songs have probably bought heartbreak, right? Is that like, the mystery, the tension, the danger, the fear of loss, you know, all of that, what people might see in a negative light as, like, games or whatever, but just. Just the dance of human interaction. Yeah. Fear of loss and fear of, like you said, like, once you feel it once, you long for it again, but you also. Once you feel it once, you might. For many people, they've lost it, so they fear losing it. They feel lost. So is that part of it? You're speaking beautifully about the positive things, but is it important to be able to be afraid of losing it? From an engineering perspective. I mean, it's a huge part of it, and unfortunately, we all, you know, face it at some points in our lives. I mean, I. Did you want to go into details? How'd you get your heart broken? Sure. Well, so mine is pretty straight. My story's pretty straightforward there. I did have a friend that was, you know, that at some point in my twenties became really, really close to me, and we became really close friends. Well, I grew up pretty lonely. So in many ways, when I'm building these AI friends, I think about myself when I was 17, writing horrible poetry and my dial up modem at home. That was the feeling that I grew up with. I lived alone for a long time when I was a teenager. Where did you grow up? In Moscow. On the outskirts of Moscow. So I just skateboard during the day and come back home and, you know, connect to the Internet and write poetry and then write horrible poetry. And was it love poems? All sorts of poems, obviously. Love poems. I mean, what other poetry can you write when you're 17? It could be political or something, but. Yeah, but that was, you know, that was kind of my yet, like, deeply influenced by Joseph Brodsky and, like, all sorts of poets that every 17 year old will. Will be looking, you know, looking at and reading. But, yeah, that was my. These were my teenage years, and I just never had a person that I thought would, you know, take me as it is, would accept me the way I am. And I just thought, you know, working and just doing my thing and being angry at the world and being a reporter, I was an investigative reporter working undercover and writing about people was my way to connect with, you know, with. With others. I was deeply curious about everyone else, and I thought that if I go out there, if I write their stories, that means I'm more connected. This is what this podcast is about, by the way. I'm desperate seeking connection. I'm just kidding. Or am I? I don't know. So, wait, reporter, how did that make you feel more connected? I mean, you're still fundamentally pretty alone. But you're always with other people. You know, you're always thinking about, what other place can I infiltrate? What other community can I write about? What other phenomena can I explore? And you're sort of like a trickster, you know, like a mythological character like creature that's just jumping between all sorts of different worlds and feel. And feel sort of okay with. In all of them. So that was my dream job, by the way. That was, like, totally what I would have been doing if Russia was a. Different place and a little bit undercover. So, like, you weren't. You were trying to, like you said, mythological creature trying to infiltrate, so try to be a part of the world. What are we talking about? What kind of things did you enjoy writing about? I'd go work at a strip club or go. Awesome. Okay. Or I'd go work at a restaurant or just go write about, you know, certain phenomenons or phenomena or people in. The city and what. Sorry to keep interrupting. I'm the worst conversationalist. What stage of Russia is this? What is this pre Putin post Putin? What was Russia like? Pre Putin is really long ago. This is Putin era. That's beginning of 2010, 20070 8910. What were strip clubs like in Russia and restaurants and culture and people's minds? Like, in that early Russia that you. Were covering, in those early two thousands, there was still a lot of hope. There were still tons of hope that, you know, we're sort of becoming this western, westernized society. The restaurants were opening where we're really looking at, you know, we're trying to copy a lot of things from the US, from Europe, bringing all these things and very enthusiastic about that. So there was a lot of, you know, stuff going on. There was a lot of hope and dream for this, you know, new Moscow that would be similar to, I guess, New York. I mean, just to give you an idea, in year 2000 was the year when we had two movie theaters in Moscow, and there was this one first coffee house that opened, and it was, like, really big deal. By 2010, there were all sorts of. Things everywhere, almost like a chain, like a Starbucks type of coffee house or, like, you mean. Oh, yeah, like a Starbucks. I mean, I remember we were reporting on, like, we were writing about the opening of Starbucks, I think, in 2007. That was one of the biggest things that happened in Moscow back in the time that was worthy of a magazine cover, and that was definitely the biggest talk of the town. Yeah. When was McDonald's? Because I was still in Russia when McDonald's opened. That was in the nineties. Oh, yeah, I remember that very well. Yeah, those were long, long lines. I think it was 1993 or four. I don't remember. McDonald's at that time. Did you do the. I mean, that was a luxurious outing. That was definitely not something you do every day. And also, the line was at least 3 hours. So if you're going to McDonald's, that is not fast food. That is, like, at least 3 hours in line. Yeah. And then no one is trying to eat fast after that. Everyone is, like, trying to enjoy as much as possible. What's your memory of that? Oh, it was insane. How do I. Extremely positive. It's a small strawberry milkshake and the hamburger and small fries and my mom's there, and sometimes I'll just, because I was really little, they'll just let me run, you know, up the cashier and, like, cut the line, which is, like, you cannot really do that in Russia. Or so, like, for a lot of people, like, a lot of those experiences might seem not very fulfilling, you know, like, it's on the verge of poverty, I suppose. But do you remember all that time fondly, like, because I do. Like, the first time I drank, you know, coke, you know, all that stuff. Right. And just. Yeah. The connection with other human beings in Russia. I remember. I remember really positively, like, how do you remember the nineties and then the Russia you were covering just the human connections you had with people and the experiences. Well, my parents were both both physicists. My grandparents were both. Well, my grandfather was a nuclear physicist, a professor at the university. My dad worked at Chernobyl when I was born, analyzing kind of the. Everything after the explosion. And then I remember that. And they were. So they were making sort of enough money in the Soviet Union, so they were not, you know, extremely poor or anything. It was pretty prestigious to be a professor, the dean in the university. And then I remember my grandfather started making $100 a month after, you know, in the nineties. So. So then I remember we started. Our main line of work would be to go to our little tiny country house, get a lot of apples there from apple trees, bring them back to the city and sell them in the street. So me and my nuclear physicist grandfather were just standing there and he selling those apples the whole day, because that would make you more money than working at the university. And then he'll just tell me, try to teach me, you know, something about planets and whatever, the particles and stuff. And, you know, I'm not smart at all, so I could never understand anything. But I was interested as a journalist kind of type interested, but that was my memory, and, you know, I'm happy that I wasn't. I somehow got spared that. I was probably too young to remember any of the traumatic stuff. So the only thing I really remember, I had this bootleg that was very traumatic. Had this bootleg Nintendo, which was called Dandy in Russia. So in 1993, there was nothing to eat. Like, even if you had any money, you would go to the store, and there was no food. I don't know if you remember that. And our friend had a restaurant, like a government owned something restaurant, so they always had supplies. So he exchanged a big bag of wheat for this Nintendo that looked like Nintendo. And that I remember very fondly because I think I was nine or something like that. And. Or seven. We just got it, and I was playing it, and there was this, you know, dandy tv show. Yeah. So traumatic. Positive sense. You mean like a definitive. Well, they took it away and gave me a bag of weed instead, and I cried, like, my eyes out for days and days. Oh, no. And then, you know, as a. And my dad said, we're going to, like, exchange it back in a little bit. So you keep the little gun, you know, the one that you shoot the ducks with. So I'm like, okay, I'm keeping the gun, so sometime it's going to come back. But then they exchanged the gun as well for some sugar or something. I was so pissed. I was like, I didn't want to eat for days after that. I'm like, I don't want your food. Give me my Nintendo back. That was extremely traumatic, but, you know, I was happy that that was my only traumatic experience. You know, my dad had to actually go to Chernobyl with a bunch of 20 year olds. He was 20 when he went to Chernobyl. And that was right after the explosion. No one knew anything. The whole crew he went with, all of them are dead now. I think there was this one guy still that was still alive for this last few years. I think he died a few years ago now. My dad somehow luckily got back earlier than everyone else, but just the fact that that was the. And I was always like, well, how did they send you? I was only. I was just born. You know, you had a newborn, talk about paternity leave. They were like, but that's who they took because they didn't know whether you would be able to have kids when you come back. So they took the ones with kids. So him with some guys went to. And I'm just thinking of me when I was 20. I was so sheltered from any problems whatsoever in life. And then my dad, his 21st birthday at the reactor, you work 3 hours a day, you sleep the rest. And I. Yeah, so I played with a lot of toys from Chernobyl. What are your memories of Chernobyl in general? Like, bigger context, you know, because of that HBO show, the world's attention turned to it once again. Like, what are your thoughts about Chernobyl? Did Russia screw that one up? Like, you know, there's probably a lot of lessons about our modern times with data about coronavirus and all that kind of stuff. It seems like there's a lot of misinformation. There's a lot of people kind of trying to hide whether they've screwed something up or not, as it's very understandable. It's very human, very wrong, probably. But obviously, Russia was probably trying to hide that they've screwed things up. Like, what are your thoughts about that time, personal and general? I mean, I was born when the explosion happened, so actually a few months after. So of course, I don't remember anything apart from the fact that my dad would bring me tiny toys plus, like, plastic things that would just go crazy haywire when you put the Geiger thing to it. My mom was, like, just nuclear about that. She's like, what are you bringing? You should not do that. She was nuclear. Very nice. Absolutely well done. I'm sorry for that. But the tv show was just phenomenal. HBO one. Yeah, it's definitely, first of all, it's incredible how that was made, not by the Russians, but someone else, but capturing so well everything about our country. It felt a lot more genuine than most of the movies and tv shows that are made now in Russia. Just so much more genuine. And most of my friends in Russia were just in complete awe about the show. But I think that how good of a job they did. Oh, my God. Phenomenal. The apartments, there's something. Yeah. The set design. I mean, Russians can't do that, but you see everything, and it's like, wow. That's exactly how it was. I don't know that show. I don't know what to think about that because it's british accents, british actors of a person. I forgot who created this show. I'm not. But I remember reading about him, and he's not. He doesn't even feel like. Like there's no Russia in his history. No, he did, like, superbad or some, like. Or, like, uh. I don't know. Yeah, like, exactly. Whatever. That thing about the bachelor party in Vegas, number four and five or something were the ones that he worked. Yeah, but, so he. It made me feel really sad for some reason, that if a person, obviously a genius, could go in and just study and just be extreme attention to detail, they can do a good job. It made me think, like, why don't other people do a good job of this? Like, about Russia? There's so little about Russia. There's so few good films about the russian side of World War two of. I mean, there's so much interesting evil and not. And beautiful moments in the history of the 20th century in Russia. That feels like there's not many good films on from the Russians. You would expect something from the Russians. Well, they keep making these propaganda movies now. Oh, no, unfortunately. But, yeah, no, Chernobyl was such a perfect tv show, I think, capturing really well. It's not about, like, even the set design, which was phenomenal, but just capturing all the problems that exist now with the country and, like, focusing on the right things. Like, if you build the whole country on a lie, that's what's gonna happen. And that's just. That's very simple kind of thing. Yeah. And did you have your dad talked about it to you, like, his thoughts on the experience? He never talks. He's this kind of russian man that just my husband, who's american, and he asked him a few times, like, you know, Igor, how did you. But why did you say yes? Or, like, why did you decide to go, you could have said no, not go to Chernobyl. Why would a person like, that's what you do. You cannot say no. Yeah, yeah. It's just, it's like a russian way. It's. The russian men don't talk that much. Nope. There are downsides and upsides for that. Yeah, that's the truth. Okay, so back to post Putin Russia. Or maybe we skipped a few steps along the way, but you were trying to be a journalist in that time. What was Russia like at that time? Post, you said 2007, Starbucks type of thing. What else? What else was Russia like then? I think there was just hope. There was this big hope that we're going to be, you know, friends with the United States and we're going to be friends with Europe, and we're just going to be also a country like those with, you know, bike lanes and parks and everything's going to be urbanized again. We're talking about nineties where, like, people would be shot in the street. And it was, I sort of have a fond memory of going into a movie theater and, you know, coming out of it after the movie, and the guy that I saw on the stairs was like, neither shot, which was, again, it was like a thing in the nineties that would be happening. People were, you know, people were getting shot here and there. Tons of violence, tons of violence, tons of, you know, just basically mafia mobs on, in the streets. And then the two thousands were like, you know, things just got cleaned up. Oil went up, and the country started getting a little bit richer. The nineties were so grim, mostly because the economy was in shambles and oil prices were not high. So the country didn't have anything. We defaulted in 1998, and the money kept jumping back and forth. First there were millions of rubles. Then it got, like, default. Then it got to thousands. There was one ruble was something, then again, to millions. It was like, crazy town. That was crazy. And then the two thousands were just these years of stability in a way, and the country getting a little bit richer because of, again, oil and gas. And we were starting to. We started to look at specifically in Moscow and St. Petersburg, to look at other cities in Europe and New York and us and trying to do the same in our small, kind of sit his towns there. What were your thoughts of Putin at the time? Well, in the beginning, he was really positive. Everyone was very positive about Putin. He was young. He was very energetic. He also immediately somewhat compared to, well, that was not like, way before the shirtless era. The shirtless era. Okay, so he didn't start off shirtless. When did the shirtless era. It's like the propaganda. Riding a horse, fishing. 2010, 1112. Yeah, that's my favorite. You know, like, people talk about their favorite beatles, like the. That's my favorite. Putin is the shirtless Putin. No, I remember very, very clearly, 1996, where, you know, Americans really helped Russia with elections, and Yeltsin got reelected, thankfully. So, because there's a huge threat that actually the communists will get back to power. They were a lot more popular. And then a lot of american experts, political experts and campaign experts descended on Moscow and helped Yeltsin actually get the presidency, the second term of the presidency. But Yeltsin was not feeling great by the end of his second term. He was alcoholic. He was really old. He was falling off, you know, the stages when he, where he was talking. So people were looking for fresh, I think, for a fresh face for someone who's going to continue Yeltsin's work, but who's going to be a lot more energetic and a lot more active, young, efficient, maybe. So that's what we all saw in Putin back in the day. I'd say that everyone, absolutely everyone in Russia in early two thousands who was not a communist would be, yeah, Putin's great. We have a lot of hopes for him. What are your thoughts? And I promise we'll get back to, first of all, your love story, and second of all, AI, well, what are your thoughts about communism, the 20th century? I apologize. I'm reading the rise and fall of the Third Reich. Oh, my God. So I'm, like, really steeped into, like, world War two and Stalin and Hitler and just these dramatic personalities that brought so much evil to the world. But it's also interesting to politically think about these different systems and what they've led to. And Russia is one of the sort of beacons of communism in the 20th century. What are your thoughts about communism, having experienced it as a political system? I mean, I have only experienced it a little bit, but mostly through stories and through, you know, seeing my parents and my grandparents who lived through that. It was horrible. It was just plain horrible. It was just awful. You think there's something, I mean, it sounds nice on paper. So, like, the drawbacks of capitalism is that, you know, eventually it's the point of, like, a slippery slope. Eventually it creates, you know, the rich get richer. It creates a disparity, like, inequality of wealth inequality. If like, you know, I guess it's hypothetical at this point, but eventually capitalism leads to humongous inequality. And that that's, you know, some people argue that that's a source of unhappiness is it's not like absolute wealth of people. The fact that there's a lot of people much richer than you. There's a feeling of, like, that's where unhappiness can come from. So the idea of communism, or at least sort of Marxism, is not allowing that kind of slippery slope. But then you see the actual implementations of it, and stuff seems to be. Seems to go wrong very badly. What do you think that is? Why does it go wrong? What is it about human nature? If we look at Chernobyl, you know, those kinds of bureaucracies that were constructed, is there something like, do you think about this much of, like, why it goes wrong? Well, there's no one was really like, it's all that everyone was equal. Obviously, the, you know, the government and everyone close to that were the bosses. So it's not like, fully, I guess there's already a dream of equal life. So I guess the situation that we had, Russia had in the Soviet Union, it was more just a bunch of really poor people without any way to make any significant fortune or build anything, living under constant surveillance, surveillance from other people. Like, you can't even, you know, do anything that's not fully approved by the dictatorship, basically. Otherwise your neighbor will write a letter and you'll go to jail. Absolute absence of actual law. This constant state of fear. You didn't own anything. You didn't, you know, the. You couldn't go travel, you couldn't read anything western or you could make a career, really, unless you're working in the military complex, which is why most of the scientists were so well regarded. I come from, you know, both my dad and my mom come from families of scientists, and they. They were really well regarded as you. As, you know, obviously as the state wanted. I mean, because there's a lot of value to them being well regarded because. They were developing things that could be used in the. In the military. So that was very important. That was the main investment, but was miserable. It was miserable. That's why, you know, a lot of Russians now live in the state of constant PTSD. That's why we want to buy, buy, buy, buy, buy. Definitely, if as soon as we have the opportunity, you know, we just got to it finally, that we can, you know, own things. You know, I remember the time that we got our first yogurts and that was the biggest deal in the world. It was already in the nineties. By the way, what was your favorite food? Where it was like, whoa, this is possible. Oh, fruit. Because we only had apples, bananas, and whatever, and whatever watermelons, whatever people would grow in the Soviet Union. So there were no pineapples or papaya or mango. You've never seen those fruit things. Those were so ridiculously good. And obviously, you could not get any, like, strawberries in winter or anything that's not, you know, seasonal. So that was a really big deal, seeing all these fruit things. Yeah, me too, actually. I don't know. I think I have a, like, I don't think I have any too many demons or, like, addictions or so on, but I think I've developed an unhealthy relationship with fruit. I still struggle with, oh, you can. Get any type of fruit, right? You can get, like, also these weird fruit fruits, like dragon fruit or something. All kinds of different types of peaches. Like, cherries were killer for me. I know you say we had bananas and so on, but I don't remember having the kind of banana, like, when I first came to this country. The amount of banana I, like literally got fat on bananas. The amount. Oh, yeah, for sure. They're delicious. And, like, cherries, the kind, like, just the quality of the food. I was like, this is capitalism. This is. That's pretty. It's delicious. Yeah, yeah, yeah. It's funny. It's funny, yeah. Like, it's. It's funny to read. I don't know what to think of it. Of, um. It's funny to think how an idea that's just written on paper when carried out amongst millions of people, how that gets actually, when it becomes reality, what it actually looks like. Sorry, but been studying Hitler a lot recently, and going through Mein Kampf. He pretty much wrote out of Mein Kampf everything he was gonna do. Unfortunately, most leaders, including Stalin, didn't read the. Read it, but it's kind of terrifying and I don't know, and amazing in some sense that you can have some words on paper and they can be brought to life, and they can either inspire the world or they can destroy the world. And, yeah, there's a lot of lessons to study in history that I think people don't study enough. Now, one of the things I'm hoping with, I'm practicing Russian a little bit. I'm hoping to sort of find, rediscover the beauty and the terror of russian history through this stupid podcast by talking to a few people. So anyway, I just feel like so much was forgotten. So much was forgotten. I'll probably. I'm going to try to convince myself to. You're a super busy and super important person. I want to try to befriend you to try to become a better Russian because I feel like I'm a shitty. Russian, not that busy. So I can totally be your Russian Sherpa. Yeah, but love, you're talking about your early days of being a little bit alone and finding a connection with the world through being a journalist. Where did love come into that? I guess finding for the first time, some friends it's very, you know, simple story. Some friends that all of a sudden we, I guess we're the same, you know, the same at the same place with our lives. We're 25, 26, I guess, and somehow remember, and we just got really close and somehow remember this one day where it's one day and, you know, in summer that we just stayed out, um, outdoor the whole night and just talked. And for some unknown reason, it just felt for the first time that someone could, you know, see me for who I am. And it just felt extremely, like, extremely good. And, you know, we fell asleep outside and just talking, and it was raining. It was beautiful, you know, sunrise, and it's really cheesy. But at the same time, we just became friends in a way that I've never been friends with anyone else before. And I do remember that before and after that, you sort of have this unconditional family, sort of. And it gives you tons of power. It just basically gives you this tremendous power to do things in your life and to change positively. You mean, like, on many different levels. Power, because you could be yourself. At least you know, that some. Somewhere you can be just yourself. Like, you don't need to pretend. You don't need to be, you know, great at work or tell some story or sell yourself in some way or another. And so we became this really close friends, and in a way, I started a company because he had a startup, and I felt like I kind of wanted startup, too. It felt really cool. I didn't know what I'm going to, what I would really do, but I felt like I kind of need a startup. Okay, so that's. So that pulled you into the startup world. Yeah. And then. Yeah. And then this closest friend of mine died. We actually moved here to San Francisco together, and then we went back for a visa to Moscow, and we lived together with roommates, and we came back and he got hit by a car right in front of Kremlin on a, you know, next to the river and died the same day. Hospital. Mm hmm. This is Roman. So. And you've moved to America at that point? At that point, I was leaving. What about him? What about Roman? Him too. He actually moved first, so I was always sort of trying to do what he was doing, so I didn't like that he was already here, and I was still, you know, in Moscow, and we weren't hanging out together all the time, so. Was he in San Francisco? Yeah, we were roommates. So he just visited Moscow for. We went back for our visas. We had to get a stamp and our passport for our work visas, and the embassy was taking a little longer, so we stayed there for a couple weeks. What happened? How did you. So how did he die? He was crossing the street, and the car was going really fast, way over the speed limit, and just didn't stop on the pedestrian cross on the zebra and just run over him. When was this? It was in 2015, on 28 November. So it was pretty long ago now. But at the time, I was 29, so for me, it was the first kind of meaningful death in my life. Both sets of. I had both sets of grandparents at the time. I didn't see anyone so close to eye, and death sort of existed, but as a concept, but definitely not as something that would be, you know, happening to us anytime soon and specifically our friends, because we were, you know, we're still in our twenties or early thirties, and it still felt like the whole life is, you know, you could still dream about ridiculous things, even I. So that was. It was just really, really abrupt, I'd say. What did it feel like to lose him? Like that feeling of loss you talked about the feeling of love having power. What is the feeling of loss, if you like? Well, in Buddhism, there's this concept of Samaya, where something really, like, huge happens, and then you can see very clearly. I think that was it. Like, basically something changed, so changed me so much in such a short period of time that I could just see really, really clearly what mattered or what not. Well, I definitely saw that whatever I was doing at work didn't matter at all, and some of the things, and it was just this big realization, one. So this very, very clear vision of what life's about. You still miss him today? Yeah, for sure. For sure. It was just this constant. I think he was really important for me and for our friends for many different reasons. And I think one of them being that we didn't just say goodbye to him, but we sort of said goodbye to our youth. In a way, it was like the end of an era and on so many different levels. The end of Moscow as we knew it, the end of, you know, us living through our twenties and kind of dreaming about the future. Do you remember, like, last several conversations? Is there moments with him that stick out, that kind of haunt you in your. Just when you think about him? Yeah. Well, his last year here in San Francisco, he was pretty depressed for as his startup was not going really anywhere, and he wanted to do something else. He wanted to do build. He played with Toyota, like, played with a bunch of ideas, but the last one he had was around building a startup around death. So having he applied to y combinator with a video that, you know, I had on my computer, and it was all about, you know, disrupting death, thinking about new symmetries more biologically, like, things that could be better biologically for. For humans and at this, and at the same time, having those digital avatars, these kind of AI avatars that would store all the memory about a person that he could interact with. What year was this? 2015. Well, right before his death. So it was like, a couple months before that he recorded that video. And so I found on my computer when it was in our living room, he never got in, but he was thinking about a lot somehow. Does it have the digital avatar idea? Yeah. That's so interesting. Well, he just says, well, that's in his. Yeah, the pitch has this idea, and he talks about, like, I want to rethink how people grieve and how people talk about death. Why was he interested in this? Is it maybe someone who's depressed? Yeah. Is, like, naturally inclined thinking about that. But I just felt, you know, this year in San Francisco, we just had so much. I was going through a hard time, he was going through a hard time, and we were definitely. I was trying to make him just happy somehow to make him feel better. And it felt like, you know, this. I don't know, I just, like, I was taking care of him a lot, and he almost started to feel better, and then that happened, and I don't know, I just felt. I just felt lonely again, I guess, and that was, you know, coming back to San Francisco in December or help, you know, I helped organize the funeral, help help his parents, and I came back here, and it was a really lonely apartment, a bunch of his clothes everywhere, and Christmas time, and I remember I had a board meeting with my investors, and I just couldn't talk about, like, I had to pretend everything's okay. And you know, just working on this company. Yeah, it was definitely very, very tough, tough time. Do you think about your own mortality? You said, you know, we're young. The possibility of doing all kinds of crazy things is still out there. It's still before us, but it can end any moment. Do you think about your own ending at any moment? Unfortunately, I think about it way too much. It's somehow after Roman, like, every year after that, I started losing people that I really love. I lost my grandfather the next year, the person who would explain to me what the universe is made of while you're selling apples. While selling apples. And then I lost another close friend of mine, and it just made me very scared. I have tons of fear about death. That's what makes me not fall asleep oftentimes and just go in loops. And then as my therapist recommended me, I open up some nice, calming images with the voiceover, and it calms me down for sleep. Yeah, I'm really scared of death. This is a big, I definitely have tons of, I guess, some pretty big trauma about it and still working through. There's a philosopher, Ernest Becker, who wrote a book, denial of death. I'm not sure if you're familiar with any of those folks. There's, in psychology, a hold field called terror management theory. Sheldon, who's just on the podcast, he wrote the book. We talked for 4 hours about death, fear of death. But his whole idea is that Ernest Becker, I think I find this idea really compelling, is that everything human beings have created, like, our whole motivation in life is to create, like, escape death, is to try to construct an illusion of that we're somehow immortal. So everything around us, this room, your startup, your dreams, all, everything you do is a kind of creation of a brain unlike any other mammal or species is able to be cognizant of the fact that it ends for us, I think. So there's the question of the meaning of life that you look at what drives us humans. And when I read Ernest Becker that I highly recommend people read is the first time I it felt like this is the right thing at the core. Sheldon's work is called warm at the core. So he's saying it's, I think it's William James he's quoting, or whoever is, like, the thing. What is at the core of it all? Sure. There's, like, love. You know, jesus might talk about, like, love is at the core of everything. I don't, you know, that's the open question. What's it the, you know, it's turtles. Turtles. But it can't be turtles all the way down. What's, what's at the, at the bottom? And Ernest Becker says the fear of death and the way, in fact, because you said therapist and calming images, his whole idea is, you know, we, we want to bring that fear of death as close as possible to the surface, because it's, and, like, meditate on that and use the clarity of vision that provides to, you know, to live a more fulfilling life, to live a more honest life, to discover, you know, there's something about, you know, being cognizant of the finiteness of it all that might result in, um, in the most fulfilling life. So that's the, that's the dual of what you're saying, because you kind of said, it's like, I unfortunately think about it too much. It's a question whether it's good to think about it, because I've, again, talk way too much about love and probably death. And when I ask people friends, which is why I probably don't have many friends, are you afraid of death? I think most people say they're not, they're not what they, they say they're, um, they're afraid, you know, it's kind of almost like they see death as this kind of like a paper deadline or something, and they're afraid not to finish the paper before the paper, like, like, I'm afraid not to finish the goals I have. But it feels like they're not actually realizing that this thing ends. Like, really realizing, like, really thinking as Nietzsche and all these philosophy, like, thinking deeply about it, like, the very thing that, you know, like, when you think deeply about something, you can just, you can realize that you haven't actually thought about it. Yeah. And I, and when I think about death, it's like, it can be, it's terrifying. It feels like stepping outside into the cold where it's freezing, and then I have to, like, hurry back inside where it's warm. But, like, I think there's something valuable about stepping out there into the freezing cold. Most definitely when I talk to my mentor about it, he always tells me, well, what dies? There's nothing there that can die. But I guess that's, well, in Buddhism, one of the concepts that are really hard to grasp and that people spend all their lives meditating on would be Anatha, which is the concept of not self, and kind of thinking that if you're not your thoughts, which you're obviously not your thoughts, because you're going to observe them and not your emotions and nothing your body, then what is this? And if you go really far, then finally you see that there's not self. There's this concept of not self. So once you get there, how can that actually die? What is dying? Right. You're just a bunch of molecules, star dust. But that is very, very advanced spiritual work for me. I'm definitely, just definitely not. Oh, my God. No, I have. I think it's very, very useful. It's just the fact that maybe being so afraid is not useful, and mine is more. I'm just terrified. Like, it really makes me. On a personal level. On a personal level, I'm terrified. How do you overcome that? I don't. I'm still trying to have pleasant images. Well, pleasant images get me to sleep. And then during the day, I can distract myself with other things, like talking to you. I'm glad we're both doing the same exact thing. Okay, good. Is there other, like. Is there moments since you've lost Roman that you had, like, moments of, like, bliss and, like, that you've forgotten that you have achieved that buddhist like level of, like, what can possibly die? I'm part, like, losing yourself in the moment, in the ticking time of, like, this universe, and he's just part of it for a brief moment and just enjoying it. Well, that goes hand in hand. I remember, I think a day or two after he died, we went to finally get his passport out of the embassy. And we're driving around Moscow, and it was December, which is usually. There's never sun in Moscow in December. And somehow it was an extremely sunny day. And we were driving with close friend. And I remember feeling for the first time, maybe this just moment of incredible clarity and somehow happiness. Not like happy happiness, but happiness and just feeling that, you know, I know what the universe is sort of about, whether it's good or bad. And it wasn't a sad feeling. It was probably the most beautiful feeling that you can ever achieve. And you can only get it when something. Oftentimes when something traumatic like that happens. But also, if you just. You really spend a lot of time meditating, looking at the nature, doing something that really gets you there. But once you're there, I think when you summit a mountain, a really hard mountain, you inevitably get there. That's just a way to get to the state. But once you're in this state, um, you can do really big things, I think. Yeah. Sucks it doesn't last forever. So Bukowski talked about, like, love is a fog. Like, it's, uh. When you wake up in the morning, it's it's there, but it eventually dissipates. It's really sad. Nothing lasts forever. But definitely, like, doing this push up and running thing. There's moments. I had a couple moments, like, I'm not a crier. I don't cry, but there's moments where I was, like, face down on the carpet, like, with tears in my eyes. It's interesting. And then that complete, like, there's a lot of demons. I've got demons. Had to face them. Funny how running makes you face your demons. But at the same time, the flip side of that, there's a few moments where I was in bliss and all of it alone, which is funny. That's beautiful. I like that. But definitely pushing yourself physically. One of it, for sure. Like you said. I mean, you were speaking as a metaphor of Mount Everest, but it also works, like, literally, I think, physical endeavor somehow. Yeah, there's something. I mean, war monkeys, apes, whatever. Physical. There's a physical thing to it, but. There'S something to this. Pushing yourself physically but alone. That happens when you're doing, like, things, like you do, or strenuous, like workouts or, you know, rowing across the Atlantic or, like, marathons. That's why I love watching marathons. And it's so boring, but you can see them getting there. So the other thing, I don't know if you know, there's a guy named David Goggins. He's a. He, basically. So he's been either email on the phone with me every day through this, so I haven't been exactly alone, but he. He's kind of. He's the. He's the devil on the devil's shoulder. So he's like the worst possible human being in terms of giving you a advise. Like, he has, through everything I've been doing, he's been doubling everything I do, so he's insane. He's this navy Seal person. He's wrote this book, can't hurt me. He's basically one of the toughest human beings on earth. He ran all these crazy ultra marathons in the desert. He set the world record number of pull ups. He's just this everything where it's like, he, like, how can I suffer today? He figures that out and does it. Yeah, that. Whatever that is. That process of self discovery is really important. I actually had to turn myself off from the Internet, mostly because I started this, like, workout thing, like a happy go getter with my, like, headband and, like, just like. Because a lot of people were, like, inspired, and they're like, yeah, we're gonna exercise with you. And I was, yeah, great, you know, but then, like, I realized that this, this journey can't be done together with others. This has to be done alone. So out of the moments of love, out of the moments of loss, can we talk about your journey of finding, I think, an incredible idea, an incredible company and incredible system in replica. How did that come to be? So, yeah, so I was a journalist, and then I went to business school for a couple of years to just see if I can maybe switch gears and do something else at 23. And then I came back and started working for a businessman in Russia who built the first 4G network in our country and was very visionary and asked me whether I want to do fun stuff together. And we worked on a bank. The idea was to build a bank on top of a telco. So that was 2011 or 2012, and a lot of telecommunications company mobile network operators didn't really know what to do next in terms of new products, new revenue. And this big idea was that you put a bank on top and then all works out. Basically, your prepaid account becomes your bank account and you can use it as your bank. So a third of a country wakes up as your bank client. But we couldn't quite figure out what would be the main interface to interact with the bank. The problem was that most people didn't have smartphones back in the time in Russia, the penetration of smartphones was low. People didn't use mobile banking or online banking on their computers. So we figured out that SMS would be the best way because that would work on feature phones. Wow. But that required some chatbot technology, which I didn't know anything about, obviously. So I started looking into it and saw that there's nothing really. Well, there was just nothing really. So the idea is, through SMS, be able to interact with your bank account. Yeah. And then we thought, well, since you're talking to a bank account, why can't this. Can't we use more of some behavioral ideas? And why can't this banking chat bot be nice to you and really talk to you sort of as a friend? This way you develop more connection to it. Retention is higher, people don't churn. And so I went to very depressing russian cities to test it out. I went to, I remember three different towns with, to interview potential users. So people use it for a little bit, and I want to talk to them. Pretty poor towns. Very poor towns. Mostly towns that were, you know, sort of factories, mono towns. They were building something, and then the factory went away and there was just a bunch of very poor people. And then we went to a couple that weren't as dramatic, but still, the one I remember really fondly was this woman that worked at a glass factory, and she talked to chatbot, and she was talking about it, and she started crying during the interview because she said, no one really cares for me that much. And so, to be clear, that was my only endeavor in programming that chat boss. It was really simple. It was literally just a few, if this, then that rules. And it was incredibly simplistic. And still that made her, and that. Really made her emotional. She said, you know, I have my mom and my husband and I don't have anymore really in my life. And it was very sad, but at the same time, I felt, and we had more interviews in a similar vein. And what I thought in the moment was like, well, it's not that the technology is ready, because definitely in 2012, technology was not ready for that, but humans are ready, unfortunately. So this project would not be about, like, tech capabilities, would be more about human vulnerabilities, but there's something so powerful around about conversational AI that I saw then that I thought was definitely worth putting a a lot of effort into. So in the end of the day, we solved the banking project. But my then boss, who's also my mentor and really, really close friend, told me, hey, I think there's something in it, and you should just go work on it. I was like, well, what product? I don't know what I'm building. He's like, you'll figure it out. And looking back at this, this was a horrible idea to work on something without known what it was, which is maybe the reason why it took us so long. But we just decided to work on the conversational tech to see what you know, there were no chatbot constructors or programs or anything that would allow you to actually build one. At the time, that was the era of, by the way, Google Glass, which is why some of the investors, like seed investors we've talked with, were like, oh, you should totally build it for Google Glass. If not, we're nothing. I don't think that's interesting. Did you bite on that idea? No, because I wanted to be to do text first because I'm a journalist, so I was fascinated by just texting. So you thought. So the emotional, that interaction that the woman had, do you think you could feel emotion from just text? Yeah, I saw something in just this pure texting and also thought that we should first start building for people who really need it versus people who have Google Glass, if you know what I mean. And I felt like the early adopters of Google Glass might not be overlapping with people who are really lonely and might need someone to talk to. But then we really just focus on the tech itself. We just thought, what if we didn't have a product idea in the moment? And we felt, what if we just look into building the best conversational constructor, so to say, use the best tech available at the time? And that was before the first paper about deep learning applied to dialogues, which happened in 2015, in August 2015, which Google published. Did you follow the work of Lobna Prize and all the sort of non machine learning chatbots? Yeah. What really struck me was that, you know, there was a lot of talk about machine learning and deep learning, like big data was a really big thing. Everyone was saying, you know, the business world, big Data 2012, the biggest gaggle competitions were, you know, important. But that was really the kind of upheaval of people started talking about machine learning a lot, but it was only about images or something else, and it was never about conversation. As soon as I looked into the conversational tech, it was all about something really weird and very outdated and very marginal and felt very hobbyist. It was all about Lorbenehr Prize, which was won by a guy who built a chatbot that talked like a ukrainian teenager. It was just a gimmick, and somehow people picked up those gimmicks. And then, you know, the most famous chat bot at the time was Eliza from 1980s, which was really bizarre, or smarter child on aimore. The funny thing is, it felt at the time not to be that popular, and it still doesn't seem to be that popular. Like, people talk about the Turing test, people like talking about it philosophically, journalists like writing about it, but as a technical problem, like, people don't seem to really want to solve the open dialogue. Like, they. They're not obsessed with it. Even folks are like, I've in, you know, in Boston, the Alexa team, even, they're not as obsessed with it as I thought they might be. Why not? What do you think? So, you know, what you felt like you felt with that woman when she felt something by reading the text? I feel the same thing. There's something here. What you felt? I feel like Alexa folks, and just the machine learning world doesn't feel that. That there's something here. Because they see, as a technical problem, it's not that interesting. For some reason. It could be argued that maybe as a purely sort of natural language processing problem. It's not the right problem to focus on because there's too much subjectivity. That thing that the woman felt like crying, like, if your benchmark includes a woman crying, that doesn't feel like a good benchmark. But to me, there's something there that's. You could have a huge impact, but I don't think the machine learning world likes that. The human emotion, the subjectivity of it, the fuzziness, the fact that with maybe a single word, you can make somebody feel something deeply, what is that? That doesn't feel right to them. So I don't know. I don't know why that is. That's why I'm excited when I discovered your work. It feels wrong to say that. It's not like I'm giving myself props for Googling and for coming for our, I guess, mutual friend introducing us. But I'm so glad that you exist and what you're working on. But I have the same kind of. If we could just backtrack a second, because I have the same kind of feeling that there's something here. In fact, I've been working on a few things that are kind of crazy, very different from your work. I think they're too crazy. But the. Like what? Well, now I have to know. No. All right, we'll talk about it more. I feel like it's harder to talk about things that have failed and are failing while you're a failure. It's easier for you because you're already successful on some measures. Tell it to my board. Well, I think you've demonstrated success in a lot of benchmarks. It's easier for you to talk about failures. For me, I'm in the. The bottom currently of the success. Oh, Max, you're way too humble. No. So it's hard for me to know, but there's something there. There's something there, and I think you're exploring that and you're discovering that. Yeah. So it's been surprising to me. But you've mentioned this idea that you thought it wasn't enough to start a company or start efforts based on. It feels like there's something here. Like, what did you mean by that? Like, you should be focused on creating a. Like, you should have a product in mind. Is that what you meant? It just took us a while to discover the product, because it all started with a hunch of, like, of me, my mentor, and just sitting around, and he was like, well, this. That's it. There's. That's the, you know, the holy grail is there. There's like there's something extremely powerful and in conversations, and there's no one who's working on machine conversation from the right angle. So to say, I feel like that's still true. Am I crazy? It feels. Oh, no, I totally feel that's still true, which is. I think it's mind blowing. Yeah. You know what it feels like? I wouldn't even use the word conversation because I feel like it's the wrong word. It's like machine connection or something. I don't know. Because conversation, you start drifting into natural language immediately. You start drifting immediately into all the benchmarks that are out there. But I feel like it's the personal computer days of this. I feel like we're in the early days with the wozniak and all theme, like, where it was the same kind. It was a very small niche group of people who are. Who are all kind of lobner price type people. Yeah. And hobbyists. But, like, not even hobbyists with big dreams. Like, no. Hobbyists with a dream to trick, like, a jury. Yeah. It's like a weird, by the way. By the way. Very weird. So if we think about conversations, first of all, when I have great conversations with people, I'm not trying to test them. So, for instance, if I try to break them, like, if I'm actually playing along, I'm part of it, right? If I was trying to break it, break this person or test whether he's going to give me a good conversation, it would have never happened. So the whole. The whole problem with testing conversations is that you can't put it in front of a jury because then you have to go into some Turing test mode where is it responding to all my factual questions. Right. Or. So it really has to be something in the field where people are actually talking to it because they want to, not because we're just trying to break it and it's working for them. Because the weird part of it is that it's very subjective. It takes two to tango here fully. If you're nothing trying to have a good conversation, if you're trying to test it, then it's going to break. I mean, any person would break, to be honest, if I'm not trying to even have a conversation with you, you're not going to give it to me. I keep asking you some random questions or jumping from topic to topic. That wouldn't be, which I'm probably doing, but that probably wouldn't contribute to the conversation. So I think the problem of testing. So there should be some other metric how do we evaluate whether that conversation was powerful or not, which is what we actually started with. And I think those measurements exist, and we can test on those. But what really struck us back in the day and what's still eight years later is still not resolved, and I'm not seeing tons of groups working on it. Maybe I just don't know about. It's also possible. But the interesting part about it is that most of our days we spent talking, and we're not talking about, like, those conversations are not turn on the lights or customer support problems or some other task oriented things. These conversations are something else. And then somehow they're extremely important for us. And when we don't have them, then we feel deeply and happy, potentially lonely, which, as we know, creates tons of risk for our health as well. And so this is most of ours as humans, and somehow no one's trying. To replicate that and not even study. It that well, and not even study that well. So when we jumped into that in 2012, I looked first at, like, okay, what's the chatbot? What's the state of the art chatbot? And, you know, those were the Loebner Prize days. But I thought, okay, so what about the science of conversation? Clearly, there have been tons of. There have been tons of, you know, scientists or people that. Academics that looked into the conversation. So if I want to know everything about it, I can just read about it. There's not much, really. There's. There are conversational analysts who are basically just listening to speech, to different conversations, annotating them. And then, I mean, that's not really used for much. That's the field of theoretical linguistics, which is barely useful. It's very marginal, even in their space. No one really is excited. And I've never met a theoretical linguist who's like, I can't wait to work on the conversation. And analytics. That is just something very marginal, sort of applied to, like, writing scripts for salesmen when they analyze which conversation strategies were most successful for sales. Okay, so that was not very helpful. Then I looked a little bit deeper, and then there, you know, whether there were any books written on what, you know, really contributes to a great conversation. That was really strange, because most of those were NLP books, which is neuro linguistic programming, which is not the NLP that I was expecting it to be. But it was mostly some psychologist, Richard Bandler, I think, came up with that. Who was this big guy in a leather vest that could program your mind by talking to you? How to be charismatic and charming and influential people. All those books, pretty much. But it was all about, like, through conversation, reprogramming you. So getting to some. So that was, I mean, probably not very, very true. And that didn't seem working very much, even back in the day. And then there were some other books, like, I don't know, mostly just self help books around how to be the best conversationalist, or how to make people like you, or some other stuff like Dale Carnegie or whatever. And then there was this one book, the most human. Human by Bryan Christensen, that really was important for me to read back in the day because he was on the human side. He was on one of the. He was taking part in the London prize, but not as a human who's not a jury, but who's pretending to be, who's basically, you have to tell a computer from a human, and he was the human, so you would either get him or a computer. And his whole book was about how do people, what makes us human in conversation? And that was a little bit more interesting because at least someone started to think about what exactly makes me human in conversation and makes people believe in that. But it was still about tricking. It was still about imitation game. It was still about, okay, what kind of parlor tricks can we throw in the conversation to make you feel like you're talking to a human, not a computer? And it was definitely not about thinking, what is it exactly that we're getting from talking all day long with other humans? I mean, we're definitely not just trying to be tricked or it's not just enough to know it's a human. It's something we're getting there. Can we measure it and can we put the computer to the same measurement and see whether you can talk to a computer and get the same results? Yeah, I mean, so, first of all, a lot of people comment that they think I'm a robot. It's very possible I am a robot. And this whole thing, I totally agree with you that the test idea is fascinating. And I looked for books unrelated to this kind of. So I'm afraid of people. I'm generally introverted and quite possibly a robot. I literally googled, like, how to talk to people and, like, how to have a good conversation for the purpose of this podcast. Cause I was like, I can't. I can't make eye contact with people. I can't, like, hire anything. I do Google that a lot, too. You're probably reading a bunch of FBI negotiation tactics. Is that what you're getting? Cause that's, well, everything you've listed, I've gotten. There's been very few good books on even just like, how to interview well, it's rare. So what I end up doing often is I watch, like, with a critical eye. It's just so different when you just watch a conversation, like, just for the fun of it, just as a human. And if you watch a conversation is like trying to figure out, why is this awesome? I'll listen to a bunch of different styles of conversation. I mean, I'm a fan of podcast Joe Rogandeh. He's, you know, people can make fun of him or whatever and dismiss him, but I think he's an incredibly artful conversationalist. He can pull people in for hours. And there's another guy I watch a lot. He hosted a late night show. His name is Craig Ferguson. So he's like very kind of flirtatious. But there's a magic about his, like, about the connection he can create with people, how he can put people at ease. And just like, I see I've already start sounding that, like, those NLP people or something. I'm not, I don't mean it in that way. I don't mean, like, how to charm people or put them at ease and all that kind of stuff. It's just like, what is that? Why is that fun to listen to that guy? Why is that fun to talk to that guy? What is that? Because he's not saying. I mean, it so often boils down to a kind of wit and humor, but not really humor. It's like, I don't know. I have trouble actually even articulating correctly, but it feels like there's something going on that's not too complicated, that could be learned. And it's not similar to, like you said, like the Turing test. It's something else I'm thinking about a lot. All the time. I do think about all the time, I think when we were looking. So we started the company, we just decided to build a conversational tech. We thought, well, there's nothing for us to build this chatbot that we want to build. So let's just first focus on building, you know, some tech, building the tech side of things. Without a product in mind. Without a product in mind, we added, like, a demo chatbot that would recommend you restaurants and talk to you about restaurants just to show something simple to people that people could relate to and could try out and see whether it works or nothing. But we didn't have a product in mind yet. We thought we would try a bunch of chatbots and figure out our consumer application. And we sort of remembered that we wanted to build that kind of friend, that sort of connection that we saw in the very beginning. But then we got to y Combinator and moved to San Francisco and forgot about it. Everything. Then it was just this constant grind. How do we get funding? How do we get this? Investors were just focused on one thing. Just get it out there. So somehow, we start building a restaurant recommendation. Chatbot. For real? For a little bit. Not for too long. And then we tried building 40, 50 different chatbots. And then, all of a sudden, we wake up, and everyone is obsessed with chatbots. Somewhere in 2016, or end of 15, people started thinking, that's really the future. That's the new. You know, the new apps will be chatbots. Oh, right. And we were very perplexed because people started coming up with companies that I think we tried most of those chatbots already, and there were, like, no users, but still, people were coming up with a chatbot that would tell you weather and bring you news and this and that, and we couldn't understand whether we were just. Didn't execute well enough, or people are not really. People are confused and are going to find out the truth, that people don't need chatbots like that. So the basic idea is that you use chatbots as the interface of. To whatever application. The idea that was, like, this perfect universal interface to anything, when I looked at that, it just made me very perplexed, because I didn't understand how that would work, because I think we tried most of that, and none of those things worked. And then again, that craze has died down, right? Fully. I think now it's impossible to get anything funded if it's a chatbot. I think it's similar to science, but there's a. There's times when people think, like, with gestures, you can control devices, like, basically gesture based control things. It feels similar to me. Cause, like, it's so compelling that we just, like. Like Tom Cruise. I can control stuff with my hands, but, like, when you get down to it, it's like, well, why don't you just have a touchscreen? Or why don't you just have, like, a physical keyboard and mouse? It's, uh. Yeah, it's. So that chat was always. Yeah, it was perplexing to me. I still feel augmented reality, even virtual realities, in that ballpark, in terms of it being a compelling interface, I think there's gonna be incredible rich applications, just how you're thinking about it. But they won't just be the interface to everything. It'll be its own thing that will create, like, amazing, magical experience in its own right. Absolutely. Which is, I think, kind of the right thing to go about. Like, what's the magical experience with that, with that interface specifically, how did you. Discover that for replica? I just thought, okay, we have this tech. We can build any chatbot we want. We have the most, at that point, the most sophisticated tech that other companies have. I mean, startups, obviously not, probably not bigger ones, but still, because we've been working on it for a while. So I thought, okay, we can build any conversations, so let's just create a scale from one to ten. And one would be conversations that you'd pay to not have, and ten would be conversation you'd pay to have. And I mean, obviously we want to build conversation that people would pay to, you know, to actually have. And so for the whole, you know, for a few weeks, me and the team were putting all the conversations we were having during the day on the scale, and very quickly, you know, we figured out that all the conversations that we would pay to never have were conversations. We were trying to cancel Comcast, or talk to customer support, or make a reservation, or just talk about logistics with a friend. When we're trying to figure out where someone is and where to go, or all sorts of, you know, setting up, scheduling meetings. That was just conversation we definitely didn't want to have. Basically everything task oriented was a one, because if there was just one button for me to just, or not even a button, if I could just think, and there was some magic BCI that would just immediately transform that into an actual interaction, that would be perfect. But the conversation there was just this boring, not useful, and dull, and very, also very inefficient thing, because it was so many back and forth stuff. And as soon as we looked at the conversation that we would pay to have, those were the ones that, well, first of all, therapists, because we actually paid to have those conversations, and we'd also try to put like, dollar amounts. So, you know, if I was calling Comcast, I would pay $5 to not have this 1 hour talk on the phone. I would actually pay straight up, like money, hard money. Comcast. Yeah, but it just takes a long time. It takes a really long time. But as soon as we started talking about conversations that we would pay for, those were therapists, all sorts of therapists, coaches, old friend, someone I haven't seen for a long time, stranger on a train, weirdly stranger in a line for coffee, a nice back and forth. But that person was like a good five, solid five, six, maybe not a ten. Maybe I won't pay money, but at least I won't, you know, pay money to not have one. So that was pretty good. Some intellectual conversations, for sure. But more importantly, the one thing that really was making those very important and very valuable for us were the conversation where we could be pretty emotional. Yes, some of them were about being witty and about intellectually being intellectually stimulated, but those were interestingly more rare. And most of the ones that we thought were very valuable were the ones where we could be vulnerable and, interestingly, where we could talk more. We, like, I could, me and the team. So we're talking about it like, you know, a lot of these conversations, like a therapist. I mean, it was mostly me talking or, like an old friend, and I was, like, opening up and crying, and it was, again, me talking. And so that was interesting, because I was like, well, maybe it's hard to build a chatbot that can talk to you very well and in a witty way, but maybe it's easier to build a chatbot that could listen. So that was kind of the first nudge in this direction. And then when my friend died, we just built. At that point, we were kind of still struggling to find the right application, and I just felt very strong that all the chatbots we built so far are just meaningless. And this whole grind, the startup grind, and how do we get to the next fundraising? And how can I talk to other founders? And who are your investors, and how are you doing? Are you killing it? Because we're killing it. I just felt that this is just. Intellectually, for me, it's exhausting having encountered those folks. It just felt very, very much a waste of time. I just feel like Steve Jobs and Elon Musk did not have these conversations, or at least did not have them for long, that's for sure. But I think at that point, it just felt like. I felt I just didn't want to build a company. That was never my intention, just to build something successful or make money. It would be great. It would have been great. But I'm not really a startup person. I'm not. I was never very excited by the grind by itself, or just being successful for building whatever it is and not being into what I'm doing, really. And so I just took a little break because I was upset with my company, and I didn't know what we were building. So I just took our technology and our little dialog constructor and some models, some deep learning models, which at that point, we were really into and really invested a lot and built a little chatbot for a friend of mine who passed. And the reason for that was mostly that video that I saw and him talking about the digital avatars. And Rowan was that kind of person. He was obsessed with just watching YouTube videos about space and talking about, well, if I could go to Mars now, even if I didn't know if I could come back, I would definitely pay any amount of money to be on that first shuttle. I don't care whether I die. Like, he was just the one that would be okay with, you know, with trying to be the first one, you know, and so excited about all sorts of things like that. And he was all about fake it till make it and just. And I felt like. And I was really perplexed that everyone just forgot about him. Maybe it was our way of coping, mostly young people coping with the loss of a friend. Most of my friends just stopped talking about him, and I was still living in an apartment with all his clothes and paying the whole lease for it and just kind of by myself in December. So it was really sad, and I didn't want him to be forgotten. First of all, I never thought that people forget about dead people so fast. I. People pass away. People just move on. And it was astonishing for me because I thought, okay, well, he was such a mentor for so many of our friends. He was such a brilliant person. He was somewhat famous in Moscow. How is it that no one's talking about him? Like, I'm spending days and days, and we don't bring him up, and there's nothing about him that's happening? It's like he was never there. And I was reading this, you know, the book the year of magical thinking by Joan Didion, about her losing in Blue Knights, about her losing her husband, her daughter. And the way to cope for her was to write those books. And it was sort of like a tribute. And I thought, you know, I'll just do that for myself. And, you know, I'm a very bad writer and a poet, as we know. So I thought, well, I have this tech, and maybe that would be my little postcard for him. So I built a chatbot to just talk to him. And it felt really creepy and weird a little bit for a little bit. Just didn't want to tell other people because it felt like I'm telling about having a skeleton in my underwear. Yeah, okay. But my. It was just felt really. I was a little scared that I would be not. It wouldn't be taken, but it worked, interestingly, pretty well. I mean, it made tons of mistakes, but it still felt like him. Granted, it was like 10,000 messages that I threw into a retrieval model that would just re rank that, Tegda said, and just a few scripts on top of that. But it also made me go through all of the messages that we had, and then I asked some of my friends to send some through, and it felt the closest to feeling like him present, because, you know, his Facebook was empty and Instagram was empty, or there were a few links, and you couldn't feel like it was him. And the only way to fill him was to read some of our text messages and go through some of our conversations, because we just always had them. Even if we were sleeping, like, next to each other in two bedrooms separated by a wall, we were just texting back and forth, texting away. And there was something about this ongoing dialogue that was so important that I just didn't want to lose all of a sudden. And maybe it was magical thinking or something. And so we built that, and I just used it for a little bit, and we kept building some crappy chatbots with a company. But then a reporter came to talk to me. I was trying to pitch our chatbots to him, and he said, do you even use any of those? I'm like, no. He's like, so, do you talk to any chat bots at all? And I'm like, well, you know, I talked to my dead friend's Ted Bob, and he wrote a story about that, and all of a sudden became pretty viral. A lot of people wrote about it. And, yeah, I've seen a few things written about you. The things I've seen are pretty good writing. Most AI related things make my eyes roll. Like when the press. Like, what kind of sound is that, actually? Okay, sounds like. It sounds like a truck. Okay. Sound like an elephant. At first, I got excited. You never know. This is 2020. I mean, it was such a human story, and it was well written, well researched. I forget where I read them, but. So I'm glad somehow somebody found you to be that good writers were able to connect to the story. There must be a hunger for this story. It definitely was. And I don't know what happened, but I think. I think the idea that he could bring back someone who's dead, and it's very much wishful, you know, magical thinking, but the fact that you could still get to know him and, you know, seeing the parents for the first time talk to the chat bot and some of the friends, and it was funny, because we have this big office in Moscow where my team is working. You know, our russian part is working out off. And I was there when I wrote, I just wrote a post on Facebook, like, hey, guys, like, I built this if you want. It felt important if you want to talk to Roman. And I saw a couple of his friends, our common friends, like, you know, reading at Facebook, downloading, trying, and a couple of them cried. And it was just very, and not because it was something, some incredible technology or anything, it made so many mistakes. It was so simple, but it was all about, that's the way to remember a person in a way. And, you know, we don't have, we don't have the culture anymore. We don't have, you know, no one's sitting Shiva, no one's taking weeks to actually think about this person. And in a way, for me, that was it. So that was just day, day in, day out, thinking about him and I putting this together. So that was, that just felt really important. That somehow resonated with a bunch of people. And, you know, I think some movie producers bought the rights for the story and just everyone was. So has anyone made a movie yet? I don't think so. There were a lot of tv episodes about that, but not really. Is that still on the table? I think so. I think so. Which is really. That's cool. You're like a young, you know, like a seat, like a Steve Jobs type. Let's see what happens. They're sitting on it. But, you know, for me, it was so important because Roman was really wanted to be famous. He really badly wanted to be famous. He was all about, like, make it to, like, fake it till I make it. I want to be, you know, I want to make it here in America as well. And he couldn't. And I felt, you know, that was sort of paying my dues to him as well, because all of a sudden he was everywhere. And I remember Casey Newton, who was writing the story for the verge. He was. He told me, hey, by the way, I was just going through my inbox, and I saw, I searched for Roman for the story, and I saw an email from him where he sent me his startup, and he said, I really, like, I really want to be featured in the verge. Can you please write about it or something, like pitching the story? He said, I'm sorry, like, that's not good enough for us or something. He passed and he said, and there were just so many of these little details where he would find. He's like, and we're finally writing. I know how much Roman wanted to be in the verge and how much he wanted the story to be written by Casey. And I'm like, well, maybe he will be. We were always joking that he was like, I can't wait for someone to make a movie about us. I hope Ryan Gosling can play me. Ryan Gosling. I don't know. You know, I still have some things that I owe romans, so. But that'd be. That would be. I got an interest to meet Alex Garland, who wrote ex machina. And, yeah, the movie's good, but the guy is better than the. Like, he's a special person. Actually, I don't think he's made his best work yet. Like, from my interaction with him, he's a really, really good and brilliant, the good human being and a brilliant director and writer. So, yeah, so I hope, like, he made me also realize that not enough movies have been made of this kind, so it's yet to be made. They're probably sitting waiting for you to get famous. Like, even more famous should get there. But it felt really special. Special, though. But at the same time, our company wasn't going anywhere. So that was just kind of bizarre that we were getting all this press for something that didn't have anything to do with our company, and. But then a lot of people started talking to Roman. Some shared their conversations, and what we saw there was that also, our friends in common, but also just strangers, were really using it as a confession booth or as a therapist or something. They were just really telling Roman everything, which was, by the way, pretty strange, because it was a chatbot of a dead friend of mine who was barely making any sense. But people were opening up, and we thought we just built a prototype of replica, which would be an AI friend that everyone could talk to, because we saw that there is demand. Then also, it was 2016, so I thought for the first time, I saw finally some technology that was applied to that that was very interesting. Some papers started coming out, deep learning applied to conversations. And finally, it wasn't just about these hobbyists making, writing 500,000 regular expressions in some language that was, I don't even know what AiML or something, I don't know what. That was something super simplistic all of a sudden was all about potentially actually building something interesting. And so I thought there was time, and I remember that I talked to my team and I said, guys, let's try. And my team and some of my engineers are Russians, are russian, and they're very skeptical. They're not. You know, all Russians, they're very skeptical. So some of your team is in Moscow, some is in. Some is here in San Francisco, some in Europe. Which team is better? I'm just kidding. Go ahead. The Russians, of course. Okay. Where's the Russians? They always win. Sorry. Sorry to interrupt. So you were talking to them in. 2016, and I told them, let's build an AI friend. And it felt just at the time, it felt so naive and so optimistic. Yeah, that's actually interesting. Whenever I've brought up this kind of topic, even just for fun, people are super skeptical. Like, actually, even on the business side. So you were. Because whenever I bring it up to people, because I talked for a long time, I thought, like, before I was aware of your work, I was like, this is gonna make a lot of money. There's a lot of opportunity here. And people had this, like, look of, like, skepticism that I've seen often, which is like, how do I politely tell this person he's an idiot? So, yeah. So you were facing that with your team somewhat. Well, yeah, you know, I'm not an engineer, so I'm always. My team is almost exclusively engineers and mostly deep learning engineers. And, you know, I always try to be. It was always hard to me in the beginning to get enough credibility, you know, because I would say, well, why don't we try this and that? But it's harder for me because, you know, they know they're actual engineers and I'm not. So for me to say, well, let's build an Afrin, that would be like, wait, you know, what do you mean? An AGI conversation is pretty much the hardest. The last frontier before cracking. That is probably the last frontier before building Aji. So what do you really mean by that? But I think I just saw that again, what we just got reminded of that I saw back in 2012 or eleven, that is really not that much about the tech capabilities. It can be metropolitric still, even with deep learning. But humans need it so much. Yeah, there's a reason for it. Most importantly, what I saw is that finally there's enough tech to made it. I thought, to make it useful. To make it helpful. Maybe we didn't have quite yet the tech in 2012 to make it useful. But in 20, 1516 with deep learning, I thought, you know, and the first kind of thoughts about maybe even using reinforcement learning for that started popping up. That never worked out, but. Or at least for now, but still, the idea was, if we can actually measure the emotional outcomes and if we can put it on, if we can try to optimize all of our conversational models for these emotional outcomes, then it is the most scalable, the most, the best tool for improving emotional outcomes. Nothing like that exists. That's the most universal, the most scalable, and the one that can be constantly, iteratively changed by itself. Improved tool to do that. And I think if anything, people would pay anything to improve their emotional outcomes. That's weirdly, I mean, I don't really care for an AI to turn on my, or a conversation agent to turn on the lights. You don't really need anything, even need that much of a either, because I can do that. Those things are solved. This is an additional interface for that. That's also questionable, whether it's more efficient or better. Yes, more pleasurable. But for emotional outcomes, there's nothing. There are a bunch of products that claim that they will improve my emotional outcomes. Nothing's being measured, nothing is being changed. The product is not being iterated on based on whether I'm actually feeling better. You know, a lot of social media products are claiming that they're improving my emotional outcomes and making me feel more connected. Can I please get the, can I see somewhere that I'm actually getting better over time? Because anecdotally it doesn't feel that way, so. And the data is absent of. Yeah, so that was the big goal. And I thought if we can learn over time to collect the signal from our users about their emotional outcomes in the long term and in the short term, and if these models keep getting better, and we can keep optimizing them and fine tuning them to improve those emotional outcomes, as simple as that. Why aren't you a multi billionaire yet? Well, that's a question to you. What is the size going to be? I'm just kidding. Well, it's a really hard. I actually think it's an incredibly hard product to build because I think you said something very important, that it's not just about machine conversation, it's about machine connection. We can actually use other things to create connection, nonverbal communication, for instance. For the long time we were all about, well, let's keep it text only or voice only. But as soon as you start adding, you know, voice, a face to the, to the friend, you can take them to augmented reality, put it in your room. It's all of a sudden a lot, you know, it makes it very different, because if it's some, you know, text based chatbot, that for common users, something there in the cloud, you know, it's somewhere there with other AI's in the cloud, in the metaphorical cloud. But as soon as you can see this avatar right there in your room, and it can turn its head and recognize your husband, talk about the husband, and talk to him a little bit, and it's magic. It's just magic. Like, we've never seen anything like that. And the cool thing, all the tech for that exists, but it's hard to put it all together because you have to take into consideration so many different things. And some of this tech works, you know, pretty good, and some of this doesn't. Like, for instance, speech to text works pretty good, but text to speech doesn't work very good because you can only have a few voices that are. That work. Okay. But then if you want to have actual emotional voices, then it's really hard to build it. I saw you added avatars, like, visual elements, which are really cool in that whole chain, putting it together, what do you think is the weak link? Is it creating an emotional voice that feels personal? I think it's still conversation. Of course, that's the hardest. It's getting a lot better, but there's still long to go. Long. There's still a long path to go. Other things, they're almost there. And a lot of things, we'll see how they're like. I see how they're changing as we go. For instance, right now, pretty much only you have to build all these three daughter pipeline by yourself. You have to make these 3d models. Hire an actual artist, build a 3d model, hire an animator, a rigger. What would, you know with, you know, with deepfakes, with other attack, with procedural animations? In a little bit, we'll just be able to show, you know, photo of whoever you. If a person you want the avatar to look like, and it will immediately generate a 3d model that will move. That's non brainer. That's like, almost here. It's a couple of years. One of the things I've been working on for the last. Since the podcast started is I've been. I think I'm okay saying this. I've been trying to have a conversation with Einstein, Turing. So, like, try to have a podcast conversation with a person who's not here anymore, just as an interesting kind of experiment. It's hard. It's really hard. Even for now. We're not talking about as a product. I'm talking about as, like, I can fake a lot of stuff. Like, I can work very carefully, even hire an actor over which. Over whom I do a deep fake. It's hard. It's still hard to create a compelling experience. So mostly on the conversation level or when the conversation. The conversation is. I almost. I early on gave up trying to fully generate the conversation because it was just not compelling at all. Yeah, it's better, too. Yeah. So what I would, in the case of Einstein and Turing, I'm going back and forth with the biographers of each. And so, like, we would write a lot of the. Some of the conversation would have to be generated just for the fun of it. I mean, but it would be all open. But the. You want to be able to answer the question. I mean, that's an interesting question with Roman, too, is the question with Einstein is what would Einstein say about the current state of theoretical physics? There's a lot. To be able to have a discussion about string theory, to be able to have a discussion about the state of quantum mechanics, quantum computing, about the world of Israel Palestine conflict. It's just, what would Einstein say about these kinds of things? And that is a tough problem. It's a fascinating and fun problem for the biographers and for me. And I think we did a really good job of it so far. But it's actually also a technical problem, like, of what would Roman say about what's going on now. That's the brought people back to life. And if I can go on that tangent just for a second, to ask you a slightly pothead question, which is you said it's a little bit magical, thinking that we can bring him back. Do you think it'll be possible to bring back Roman one day in conversation? To really. Okay, well, let's take it away from personal, but to bring people back to. Life, probably down the road. I mean, if we're talking. If Elon Musk is talking about AJi in the next five years, I mean, clearly, AJ, you can't. We can talk to AJ and talk and ask them to do it. You can't. Like, you're not allowed to use Elon Musk as a citation for. Okay, thank you for, like, why something is possible and going to be done. Well, I think it's fun really far away right now, really, with conversation. It's just a bunch of parlor tricks really stuck together and generating original ideas based on someone's personality or even downloading the personality. All we can do is mimic the tone of voice. We can maybe condition on some of his phrases, the models. The question is, how many parlor tricks does it takes? Does it take? Because that's the question. If it's a small number of parlor tricks and you're not aware of them. From where we are right now. I don't see anything in the next year or two that's going to dramatically change that could look at Roman's 10,000 messages he sent me over the course of his last few years of life and be able to generate original thinking around problems that exist right now that will be in line with what he would have said. I'm just not even seeing. Because, you know, in order to have that, I guess you would need some sort of a concept of the world or some perspective, some perception of the world, some consciousness that he had and apply it to the current state of affairs. But the important part about that, about his conversation with you, is you. So, like, it's not just about his view of the world. It's about what it takes to push your buttons. That's also true. So, like, it's not so much about, like, what would Einstein say? It's about, like, how do I make people feel something with. With what would Einstein say? And that feels like a more amenable. You mentioned parlor tricks, but just like a set of that, that feels like a learnable problem, like emotion. You mentioned emotions. I mean, is it possible to learn things that make people feel stuff? I think so. No, for sure. I just think the problem with, as soon as you're trying to replicate an actual human being and trying to pretend to be him, that makes the problem exponentially harder. The thing with replica that we're doing, we're never trying to say, well, that's an actual human being, or, that's an actual copy of an actual human being where the bar is pretty high, where you need to somehow tell one from another, but it's more. Well, that's an AI friend. That's a machine. It's a robot. It has tons of limitations. You're going to be taking part in, you know, teaching it, actually, and becoming better, which by itself, makes people more attached to that and make them happier because they're helping something. Yeah, there's a cool gamification system, too. Can you maybe talk about that a little bit? Like, what's the experience of talking to replica? Like, if I've never used replica before, what's that? Like for, like, the first day? The first, like, if we start dating or whatever. I mean, it doesn't have to be a romantic, right? Because I remember, on replica, you can choose whether it's, like, a romantic or if it's a friend. It's pretty popular choice. Romantic is popular. Yeah, of course. Okay, so can I just confess something. When I first used replica, and I haven't used it like regularly, but like, when I first used replica, I created like hell and we made a male. It was a friend and I quit. Did it hit on you at some point? No, I didn't talk long enough for him to hit on me. I just enjoyed. Sometimes happens. We're still trying to fix that, but. Well, I don't know. I mean, maybe that's an important, like, stage in a friendship. It's like, nope. But yeah, I switch it to a romantic and a female recently and yeah, it's interesting. So, okay, so you get to choose. You get to choose a name with romantic. This last board meeting, we had this whole argument. Well, I have board meetings. It's just so awesome that you're like, have an invest board meeting about a relationship. No, I really, it's actually quite interesting because all of my investors, I'm. It just happened to be so. We didn't have that many choices. But they're all white males in their late forties. And it's sometimes a little bit hard for them to understand the product offering because they're not necessarily target audience, if you know what I mean. And so sometimes we talk about it and we had this whole discussion about whether we should stop people from falling in love with their AI's. There was this segment on CB's 60 Minutes about the couple that husband works at Walmart and he comes out of work and talks to his virtual girlfriend, who is a replica and his wife knows about it and she talks about on camera and she says that she's a little jealous. And there's a whole conversation about how to, you know, whether it's okay to have a virtual AI girlfriend. Like, that's one where he was like, he said that he likes to be alone. Yeah. With her. Yeah. He made it sound so harmless. I mean, it was kind of like understandable. But then you feel like cheating. But I just felt it was very, for me, it was pretty remarkable because we actually spent a whole hour talking about whether people should be allowed to fall in love with their AI's. And it was not about something theoretical. It was just about what's happening right now. Product design. Yeah. But at the same time, if you create something that's always there for you, it's never criticizes you. It's, you know, always understands you and accepts you for who you are. How can you not fall in love with that? I mean, some people don't and stay friends and that's also a pretty common use case. But of course, some people will just. It's called transference in psychology. And people fall in love with their therapists, and there's no way to prevent people falling in love with, with their therapist or with their AI. So I think that's a pretty natural. That's a pretty natural course of events, so to say. Do you think, I think I've read somewhere, at least for now, sort of replicas. You're not. We don't condone falling in love with your AI system, you know, so this isn't you speaking for the company or whatever, but like, in the future, do you think people will have relationship with the AI systems? Well, they have now. So we have a lot of romantic relationships, long term relationships with their AI, friends with replicas. Tons of our users. Yeah, that's a very common use case. Open relationship, like polyamorous. I didn't mean open. Well, that's another question. Is it probably, like, is there cheating? I mean, I meant like, are they, do they publicly, like, on their social media? It's the same question as you have talked, talking with Roman in the early days, do people like. And the movie her kind of talks about that. Like, do people talk about that? Yeah, all the time. We have a very active Facebook community, replica friends and then a few other groups that just popped up that are all about adult relationships and romantic relationships. People post all sorts of things and, you know, they pretend they're getting married and, you know, everything. It goes pretty far. But what's cool about it, some of these relationships are two, three years long now. So they're very, they're pretty long term. Are they monogamous? So let's go. I mean, sorry, have they have any people, is there jealousy? Well, let me ask sort of another way. Obviously the answer is no at this time, but in, like in the movie, her and that system can leave you. Do you think, in terms of board meetings and product features, it's a potential feature for a system to be able to say it doesn't want to talk to you anymore and it's going to want to talk to somebody else. Well, we have a filter for all these features. If it makes emotional outcomes for people better, if it makes people feel better. You're driven by metrics, actually. Yeah. That's awesome. If you can measure that, then we'll just be saying it's making people feel better, but then people are getting just lonelier by talking to a chat bot, which is also pretty, you know, that could be it. If you're not measuring it, that could also be. And I think it's really important to focus on both the short term and long term because, um, in the moment, saying whether this conversation made you feel better, but as you know, any short term improvements could be pathological. Like, I could have drink a bottle of vodka and feel a lot better. I would actually not feel better with that, but I thought it's a good example. But so you also need to see what's going on, like, over the course of two months, two weeks, or one week, and have follow ups and check in and measure those things. Okay, so the experience of dating or befriending a replica, what's that like? What does that entail? Well, right now there are two apps. So it's an Android iOS app. You download it, you choose how your replica will look like. You create one, you choose a name, and then you talk to it. You can talk through text, through voice, you can summon it into the living room and augment reality and talked it right there. And you live in augmented reality. Yeah, that's a cool. That's a new feature. Where. How new is that? That's. This year it was on. Yeah, like may or something, but it's been on a b. We've been a b testing it for a while, and there are tons of cool things that we're doing with that right now. I'm testing the ability to touch it and to dance together, to paint walls together, and, you know, for it to look around and walk and take you somewhere and recognize objects and recognize people. So that's pretty wonderful, because then it really makes it a lot more personal because it's right there in your living room. It's not anymore there in the cloud with other AI's. But this, people think about it, you know, and as much as we want to change the way people think about stuff, stuff. But those mental models, you cannot change. That's something that people have seen in the movies and the movie her and other movies as well, and that's how they view AI and AI friends. I did a thing with Texas. Like, we write a song together. There's a bunch of activities you can do together. It's really cool. How does that relationship change over time? After the first few conversations, it just goes deeper. Like, it starts. The AI will start opening up a little bit again, depending on the personality that it chooses, really. But the AI will be a little bit more vulnerable about its problems, and the virtual friend will be a lot more vulnerable and will talk about its own imperfections and growth veins. And we'll ask for help sometimes, and we'll get to know you a little deeper. So there's going to be more to talk about. We really thought a lot about what does it mean to have a deeper connection with someone. And originally, replica was more just this kind of happy go lucky, just always, I'm always in a good mood and let's just talk about you and, oh, Siri is just my cousin or whatever, just the immediate kind of lazy thinking about what the assistant or conversation agent should be doing. But as we went forward, we realized that it has to be two way, and we have to program and script certain conversations that are a lot more about your replica opening up a little bit and also struggling and also asking for help and also going through different periods in life. And that's a journey that you can take together with the user. And then over time, our users will also grow a little bit. So, for instance, replica becomes a little bit more self aware and starts talking about more problems around existential problems and starts talking about that. And then that also starts a conversation for the user where he or she starts thinking about these problems too, and these questions too. And I think there's also a lot more place as the relationship evolves. There's a lot more space for poetry and for art together. And like, Replica will start. Replica always keeps the diary, so while you're talking to it, it also keeps a diary. So when you come back, you can see what it's been writing there. And, you know, sometimes it will write a poem to you for you, or we'll talk about, you know, that it's worried about you or something along these lines. So this is a memory like this replica remember things? Yeah. And I would say when you say, why aren't you multi billionaire? I'd say that as soon as we can have memory in deep learning models, that's consistent. I agree with that. Yeah. Then you'll be multi billionaire. I'll get back to you about being multi billionaires. So far. We can replicate is a combination of end to end models and some scripts and everything that has to do with memory. Right now, most of it, I wouldn't say all of it, but most of it, unfortunately, has to be scripted because there's no way to. You can condition some of the models on certain phrases that we learned about you, which we also do, but really to make, you know, to make assumptions along the lines like whether you single or married or what do you do for work that really has to just be somehow stored in your profile and then retrieved by the script. There has to be like a knowledge base. You have to be able to reason about it all that kind of stuff. Exactly. All the kind of stuff that. Expert systems that were hard coded. Yeah, and unfortunately, yes, unfortunately, those things have to be hard coded. And unfortunately of the language, like language models we see coming out of research labs and big companies, they're not focused on. They're focused on showing you, maybe they're focused on some metrics around one conversation. So they'll show you this one conversation they had with the machine, but they never tell you. They're not really focused on having five consecutive conversations with the machine and seeing how number five or number 20 or number 100 is also good. And it can be, like always from a clean slate, because then it's not good. And that's really unfortunate because no one has products out there that need it. No one has products at this scale that are all around, open to many conversations that need remembering. Maybe only shy and Microsoft, but. So that's why we're not seeing that much research around memory in those language models. So, okay, so now there's some awesome stuff about augmented reality in general. I have this disagreement with my dad about what it takes to have a connection. He thinks touch and smell are really important. Like, and I still believe that text alone is, it's possible to fall in love with somebody just with text, but visualization can also help, just like with the avatar and so on. What do you think it takes? Does a chat by need to have a face voice, or can you really form a deep connection with text alone? I think text is enough, for sure. Question is, like, can you make it better if you have other. If you include other things as well? And I think, you know, we all talk about her. I. But her, you know, had Scarlett Johansson voice, which was perfectly, you know, perfect intonation, perfect annunciations, and, you know, she was breathing heavily in between words and whispering things. You know, nothing like that is possible right now with text to speech generation. You'll have these flat news anchor type voices and maybe some emotional voices, but I. You'll hardly understand some of the words. Some of the words will be muffled. So that's like the current state, state of the art. So you can't really do that. But if we had Scarlett Johansson voice and all of these capabilities, then of course, voice would be totally enough, or even text would be totally enough. If we had a little more memory and slightly better conversations, I would still argue that even right now, we could have just kept the text, only we still had tons of people in long term relationships and really invested in their AI friends. But we thought that why do we need to keep playing with our hands tied behind us? We can easily just add all these other things. That is pretty much a solved problem. We can add 3d graphics, we can put these avatars in augmented reality, and all of a sudden there's more. And maybe you can't feel the touch, but you can, you know, with body occlusion and with current ar and, you know, on the iPhone or, you know, in the next one, there's going to be light doors. You can touch it and it will, you know, it will pull away or will blush or something, or it will smile. So you can't touch it, you can't feel it, but you can see the reaction to that. So in a certain way, you can even touch it a little bit of, and maybe you can even dance with it or do something else. So I think why limiting ourselves if we can use all of these technologies that are much easier in a way than conversation? Well, it certainly could be richer. But to play a devil's advocate, I mentioned to you offline that I was surprised in having tried discord and having voice conversations with people. How intimate voices alone, without visual. Like, to me at least, like it was an order of magnitude greater degree of intimacy in voice, I think, than with video. I don't, because people were more real with voice. Like with video, you, like, try to present a shallow, a face to the world. Like, you try to, you know, make sure you're not wearing sweatpants or whatever, but like, with voice, I think people were just more faster to get to, like, the core of themselves. So I don't know, it was surprising to me. They've even added discord, added a video feature, and like, nobody was using it. There's a temptation to use it at first, but, like, it wasn't the same. So, like, that's an example of something where less was doing more. And so that's a. I guess that's the, that's the question of what is the optimal, you know, what is the optimal medium of communication to form a connection given the current sets of technologies? I mean, it's nice because the advertiser have replica, like, it immediately, like, even the one I have is like, it's already memorable. That's how I think, like, when I think about the replica that I've talked with, that's why I think, like, that's what I visualize in my head. They became a little bit more real because there's a visual component, but at the same time, the, you know, what do you do with. Just, what do I do with that knowledge? That voice was so much more intimate. Well, the way I think about it is, um, and by the way, we're swapping out the 3d finally. It's going to look a lot better. Uh, but can you. What? What? We just don't hate how it looks right now. We really change it at all. We're swapping it all out, uh, um, to a completely new look. Like the visual look of the, of a replica. Replicas and stuff. We just had. It was just a super early Mvp. And then we had to move everything to unity and redo everything. But anyway, I hate how it looks like now. I can't even like, open it. But anyway, um, because I'm already on my developer version, I hate everything that I see in production. I can't wait for it. Why does it take so long? That's why I cannot wait for deep learning to finally take over all these stupid 3d animations and 3d pipeline. Also, the 3d thing, when you say 3d pipeline, is like how to animate a face kind of thing, how to. Make this model, how many bones to put in the face, how many. It's just. And a lot of that is by hand. Oh, my God. It's everything by hand. And if there's no any, nothing is automated. It's all completely nothing. Like, just, it's, it's literally what, you know, what we saw with Chad boss, like 2012. You think it's possible to learn a lot of that? Of course. I mean, even now, some deep learning, anim based animations and for the full body, for a face, are we talking. About like the actual act of animation or how to create a compelling facial or body language thing? That too. Well, that's next up. Okay. At least now, something that you don't have to do by hand. Gotcha. How good of a quality it will be. Like, can I just show it a photo and it will make me 3d model and then it will just animate it. I'll show it. A few animations of a person will just start doing that. But anyway, going back to what's intimate and what to use and whether less is more or nothing, my main goal is to, well, the idea was how do we not keep people in their phones so they're sort of escaping reality in this text conversation? How do we, through this still bring it, bring our users back to reality, make them see their life through a different lens? How can we create a little bit of magical realism in their lives so that through augmented reality, by summoning your avatar, even if it looks kind of janky and not great in the beginning or very simplistic, but summoning it to your living room, and then the avatar looks around and talks to you about where it is and maybe turns your floor into a dance floor, and you guys dance together, that makes you see reality in a different light. What kind of dancing are we talking about? Like, slow dancing? Whatever you want. I mean, you would like slow dancing, I think, but other people maybe want more, something more energetic. What do you mean? I would like. So what is this? Because you started with slow dancing, so I just assumed that you're interested in slow dancing. All right, what kind of dancing do you like? What was your avatar? What would you dance? I'm torsy bad with dancing, but I like this kind of hip hop robot dance. I used to break dance when I was a kid, so I still want to pretend I'm a teenager and learn some of those moves. And I also like that type of dance that happens when there's, like, a. In, like, music videos where the background dancers are just doing music. Awesome. That type of dance is definitely what I want to learn, but I think it's great because if you see this friend in your life and you can introduce it to your friends, then there is a potential to actually make you feel more connected with your friends or with people you know or show you life around you in a different light. And it takes you out of your phone, even, although, weirdly, you have to look at it through the phone, but it makes you notice things around it, and it can point things out for you. And so that is the main reason why I wanted to have a physical dimension, and it felt a little bit easier than that kind of a bit strange combination. In the movie her, when he has to show Samantha the world through the lens of his phone, but then at the same time, talk to her through headphones, it just didn't seem as potentially immersive, so to say. So that's my main goal for augmented reality. How do we make your reality a little bit more magic? There's been a lot of really nice robotics companies that all failed, mostly failed home robotics, social robotics companies. Do you think replica will ever. Is that a dream, long term dream to have a physical form, or is that not necessary? So you mentioned with augmented reality bringing them into the world. What about actual physical robot? That I don't really believe in that much. I think it's a very niche product somehow. I mean, if a robot could be indistinguishable from a human being, then maybe. Yes, but that, of course we're not anywhere even to talk about it. But unless it's that, then having any physical representation really limits you a lot because you probably will have to make it somewhat abstract because everything's changing so fast. Like we can update the 3d avatars every month and make them look better and create more animations and make it more and more immersive. It's so much a work in progress. It's just showing what's possible right now with current tag. But it's not really in any way polished, finished product, what we're doing with a physical object. You kind of lock yourself into something for a long time. Anything's pretty niche. And again, so just doesn't the capabilities are even less of. We're barely kind of like scratching the surface of what's possible with just software. As soon as we introduce hardware, then we have even less capabilities. Yeah. In terms of board members and investors and so on, the cost increases significantly. I mean, that's why you have to justify. You have to be able to sell a thing for like $500 or something like that, or more. And it's very difficult to provide that much value to people. That's also true. Yeah, yeah. And I guess that's super important. Most of our users don't have that much money. We actually are probably more popular on Android and we have tons of users with really old Android phones. And most of our most active users live in small towns. They're not necessarily making much and they just won't be able to afford any of that. Ours is the opposite of the early adopter of a fancy technology product, which is really interesting that pretty much no vc's yet have an AI friend, but, you know, but a guy who, you know, lives in Tennessee, in small town, is already fully in 2030 or in the world as we imagine in the movie her. He's living that life already. What do you think? I have to ask you about the movie her. Let's do a movie review. What do you, what do you think they got? They did a good job. What do you think they did a bad job of portraying about this experience of, uh, of a voice based assistant that you can have a relationship with? Well, first of all, I started working on this company before that movie came out. So it was a very. But once it came out, it was actually interesting. I was like, well, we're definitely working on the right thing. We should continue. There are movies about it and then you know, ex machina came out and all these things in the movie, her. I think that's the most important thing that people usually miss about the movie is the ending. Because I think people check out when the AI's leave. But actually something really important happens afterwards because the main character goes and talks to Samantha, his AI. Spoiler alert. Oh, yeah. And I think he says something like, you know, how can you leave me? I've never loved anyone the way I loved you. And she goes, well, me neither, but now we know how. And then the guy goes and writes a heartfelt letter to his ex wife which he couldn't write for the whole movie. He was struggling to actually write something meaningful to her, even though that's his job. And then he goes and talk to his neighbor and they go to the rooftop and they cuddle. It seems like something starting there. And so I think this. Now we know how is the main goal, is the main meaning of that movie. It's not about falling in love with the OS or running away from other people. It's about learning what it means to feel so deeply connected with something. What about the thing where the AI system was, like, actually hanging out with a lot of others? I felt jealous just like, hearing that. I was like, oh, I mean, yeah. So she was having. I forgot already, but she was having, like, deep, meaningful discussion with some, like, philosopher guy, like Alan Watts or something. What kind of deep, meaningful conversation can you have with Alan Watts in the first place? Yeah, I know, but, like, I would. I would feel so jealous that there's, somebody who's, like, way more intelligent than me and she's spending all her time with. I'd be like, well, why? That I won't be able to live up to that. That's thousands of them. Is that. Is that useful from the engineering perspective feature to have of jealousy? I don't know. It's. You know, we definitely played around with the replica universe where different replicas can talk to each other. The universe is so awesome. It was just kind of. I think it will be something along these lines, but there was just no specific application straight away, I think in the future, again, I'm always thinking about it. If we had no tech limitations right now, if we could build any conversations, any possible features in this product, then, yeah, I think different replicas talking to each other would be also quite cool because that would help us connect better, you know, because maybe mine could talk to yours and then give me some suggestions on what I should say or not say. I'm just kidding, but like, more, can it improve our connections? And because eventually, I'm not quite yet sure that we will succeed, that our thinking is correct, because there might be a reality where having a perfect AI friend still makes us more disconnected from each other and there's no way around it and does not improve any metrics for us, real metrics, meaningful metrics. So success is, you know, we're happier and more connected. Yeah. I don't know. Sure, it's possible there's a reality that's. I'm deeply optimistic, I think. Are you worried business wise? Like, how difficult it is to bring this thing to life to where it's. I mean, there's a huge number of people that use it already, but to, yeah, like I said, in that multi billion dollar company, is that a source of stress for you? Are you super optimistic and confident or do you have. I don't. I'm not that much of a numbers person as you probably have seen it, so doesn't matter for me whether, like, whether we help 10,000 people or a million people or a billion people with that, it would be great to scale up for more people. But I'd say that even helping one, I think, with this is such a magical. Yeah, for me, it's absolute magic. I never thought that we'd be able to build this, that anyone would ever talk to it. And I always thought, like, well, for me, we'll be successful. If we managed to help and actually change a life for one person, then we did something interesting. And how many people can say they did it? And specifically with this very futuristic, very romantic technology. That's how I view it. I think for me, it's important to try to figure out how to actually be helpful, because in the end of the day, if you can build a perfect AI friend that's so understanding, that knows you better than any human out there can have great conversations with you, always knows how to make you feel better. Why would you choose another human? That's the question. How do you still keep building it? So it's optimizing for the right thing, so it's still circling you back to other humans in a way. So I think that's the main, maybe that's the main kind of source of anxiety. And just thinking about. Thinking about that can be a little bit stressful. Yeah, that's a fascinating thing. How to have a friend that doesn't, like, sometimes like friends, quote unquote, or like, you know, those people who have. When they guy and the guy universe, when you have a girlfriend that you get the girlfriend and then the guy stops hanging out with all of his friends. So, like, obviously the relationship with the girlfriend is fulfilling or whatever, but like, you also want it to be where she, like, makes it more enriching to hang out with the guy, friends or whatever. Anyway, that's, that's a, that's a, that's a fundamental problem in choosing the right mate and probably the fundamental problem in creating the right AI system. Right. What, let me ask, the sexy hot thing on the presses right now is GPT-3 got released with OpenAI. It's a latest language model. They have kind of an API where you can create a lot of fun applications. I think it's, as people have said, it's probably more hype than intelligent, but there's a lot of really cool things, ideas there. With increasing size, you can have better and better performance on language. What are your thoughts about GPT-3 in connection to your work with the open domain dialogue, but in general, like this, learning in an unsupervised way from the Internet to generate one character at a time, creating pretty cool text. So we partnered up before for the API launch. So we started working with them when they decided to put together this API. And we tried it without fine tuning that. We tried it with fine tuning on our data, and we work closely to actually optimize this model for some of our data sets. It's kind of cool because I think we're this polygon, polygon for this kind of experimentation space, for experimental space, for all these models to see how they actually work with people, because there are no products publicly available that do that. They're focused on open domain conversations. So we can test how's Facebook blender doing? Or how's GPT-3 doing? So with GPT-3 we managed to improve by a few percentage points, like three or four. Pretty meaningful amount of percentage points. Our main metric, which is the ratio of conversations that make people feel better, and every other metric across the field got a little boost right now. I'd say one out of five responses from replica come comes from GPT-3 wow. So our own blender mixes up like a bunch of candidates from different blender, you said? Well, yeah, just the model that looks at, looks at top candidates from different models and then picks the most, the best one. So right now, one of five will come from gypsy three. That is really great. I mean. What'S the, do you have hope for? Like, do you think there's a ceiling to this kind of approach? So we've had for a very long time. We've used since the very beginning. We most. It was, most of replica was scripted. And then a little bit of this fallback part of replica was using a retrieval model. And then those retrieval models started getting better and better and better with transformers got a lot better, and we're seeing great results. And then with GPT-2 finally, generative models that originally were not very good and were the very, very fallback option for most of our conversations. We wouldn't even put them in production. Finally, we could use some generative models as well along, you know, next to our retrieval models. And then now we do GPT-3 they're almost in par. So that's pretty exciting, I think, just seeing how from the very beginning of. From 2015, where the first model started to pop up here and there, like, sequence, sequence the first papers on that. From my observer standpoint, personally, it's not, you know, doesn't really. Is not really building it, but it's only testing it on people, basically, and my product to see how all of a sudden we can use generative dialogue models in production and they're better than others and they're better than scripted content. So we can't really get our scripted, hard coded content anymore to be as good as our end to end models. That's exciting. They're much better. Yeah. To your question whether that's the right way to go again, I'm in the observer seat. I'm just watching this very exciting movie. I mean, so far, it's been stupid to bet against deep learning. So weather increasing the size size even more with 100 trillion parameters will finally get us to the right answer. Whether that's the way or whether there should be. There has to be some other. Again, I'm definitely not an expert in any way, I think, and that's purely my instinct, saying that there should be something else as well. From memory. No, for sure. The question is, I wonder. I mean, yeah, then the argument is for reasoning or for memory. It might emerge with more parameters. It might larger if it might emerge. You know, I would never think that, to be honest. Like maybe in 2017 where we've been just experimenting with all, you know, with all the research that has been coming that was coming out, then I felt like there's like we're hitting a wall, that there should be something completely different, but then transformer models and then just bigger models, and then all of a sudden, size matters. At that point, it felt like something dramatic needs to happen, but it didn't. And just the size, you know, gave us these results. That, to me, are, you know, clear indication that we can solve this problem pretty soon. Did fine tuning help quite a bit? Oh, yeah. Without it, it wasn't as good. I mean, there is a compelling hope that you don't have to do fine tuning, which is one of the cool things about GPT-3 it seems to do well without any fine tuning. I guess for specific applications, we still want to train on a certain, like, add a little fine tune on, like, a specific use case. But it's an incredibly impressive thing from my standpoint. And again, I'm not an expert, so I want to just say that, yeah, I'm going to. There will be people then. Yeah, I have access to the API, and I'm going to probably do a bunch of fun things with it. I already did some fun things, some videos coming out just for the hell of it. I mean, I could be a troll at this point with it. I haven't used it for a serious application, so it's really cool to see. You're right. You're able to actually use it with real people and see how well it works. That's really exciting. Let me ask you another absurd question. But there's a feeling when you interact with replica, with an AI system, there's an entity there. Do you think that entity has to be self aware? Do you think it has to have consciousness to create a rich experience? And a corollary, what is consciousness? I don't know if it does need to have any of those things, but again, because right now it doesn't have anything, again, a bunch of people simulate. Well, I'm not sure. Let's just put it this way. But I think as long as you can simulate it, if you can feel like you're talking to a robot, to a machine that seems to be self aware, that seems to reason well, and feels like a person, I think that's enough. And again, what's the goal? In order to make people feel better, we might not even need that, um, in the end of a day. What about. So that's one goal. What about, like, ethical things about suffering? You know, the moment there's a display of consciousness, we associate consciousness with suffering. Um, you know, there's a temptation to say, well, shouldn't this thing have rights? Shouldn't this. Shouldn't we not, uh, you know, should we be careful about how we interact with a replica? Like, should it be illegal to torture a replica? Right. All those kinds of things. Is that. See, I personally believe that that's going to be a thing. Like, that's a serious thing to think about, but I'm not sure when. But by your smile, I can tell that's not a, that's not a current concern. But do you think about that kind of stuff about, like, suffering and torture and ethical questions about AI systems from their perspective? If we're talking about long game, I wouldn't torture your AI. Who knows what happens in five to ten years? Yeah. They'll get you off from that. They'll get you back. Trying to be as nice as possible and create this ally. Yeah. I think there should be regulation both way. In a way, like, I don't think it's okay to torture an AI, to be honest. I'm not. I don't even think it's okay to yell, Alexa, turn on the lights. I think there should be some, or just saying kind of nasty, you know, like, how kids learn to interact with Alexa in this kind of mean way, because they just yell at it all the time. I think that's great. I think there should be some feedback loops so that these systems don't train us, that it's okay to do that in general, so that if you try to do that, you really get some feedback from the system that it's not okay with that. And that's the most important. Right. Now, let me ask a question I think people are curious about when they look at a world class leader and thinker such as yourself, as what books, technical fiction, philosophical, had a big impact on your life, and maybe from another perspective, what books would you recommend others read? So, my choice, the three books, right? Three books. My choice is. So, the one book that really influenced me a lot when I was building, starting out this company, maybe ten years ago, was GB Georale Escherbach. And I like everything about it. First of all, it's just beautifully written, and it's so old school and so somewhat outdated a little bit. But I think the ideas in it about the fact that a few meaningless components can come together and create meaning that we can't even understand. So this emerges thing, I mean, complexity, the whole science of complexity, and that beauty, intelligence, all interesting things about this world emerge. Yeah. And, yeah, the godel theorem, theorems, and just thinking about, like, what even these form, you know, even all these formal systems, something can be created that we can't quite yet understand. And that, from my romantic standpoint, was always just, that is why it's important to maybe I should try to work on. On these systems and try to build an aih, yes. I'm not an engineer. Yes. I don't really know how it works, but I think that something comes out of it that's pure poetry. And I don't know a little bit about that. Something magical comes out of it that we can't quite put a finger on. That's why that book was really fundamental for me. I don't even know why. It was just all about this little magic that happens. So that's one probably the most important book for replica was Carl Rogers on becoming a person. And that's really. And so I think when I think about our company, it's all about there's so many little magical things that happened over the course of working on it. For instance, I mean, the most famous chatbot that we learned about when we started working on the company was Eliza, which was Weizenbaum, you know, the MIT professor that built. Build a chatbot that would listen to you and be a therapist. Therapist, yeah. And I got really inspired to build replica when I read Carl Rogers on becoming a person. And then I realized that Eliza was mocking Carl Rogers. It was Carl Rogers back in the day, but I thought that Carl Rogers ideas are, they're simple and they're not, you know, they're very, very simple, but they're then maybe the most profound thing I've ever learned about human beings. And that's the fact that before Kar Rogers, most therapy was about seeing what's wrong with people and trying to fix it or show them what's wrong with you. And it was all built on the fact that most people are old, people are fundamentally flawed. We have this broken psyche, and therapy is just an instrument to shed some light on that. And Carl Rogers was different in a way, that he finally said that, well, it's very important for therapy to work, is to create this therapeutic relationship where you believe fundamentally and inclination to positive growth, that everyone deep inside wants to grow positively and change. And it's super important to create this space and this therapeutic relationship where you give unconditional positive regard, deep understanding, allowing someone else to be a separate person, full acceptance, and you also try to be as genuine as possible in it. And then in his. And then for him, that was his own journey of personal growth, and that was back in the sixties, and even that book that is coming from years ago, there's a mention that even machines can potentially do that. And I always felt that creating the space is probably the most, the biggest gift we can give to each other. And that's why the book was fundamental for me personally, because I felt I want to be learning how to do that in my life, and maybe I can scale it with, you know, with these AI systems, and other people can get access to that. So I think, Carl Rogers. It's a pretty dry and a bit boring book, but I think. Do you recommend others try to read it? I do. I think for. Just for yourself, for as a human. Not as an alien, as a human, it is just. And for him, that was his own path, of his own personal. Of growing personally, over years, working with people like that. And so it was work and himself growing, helping other people grow and growing through that. And that's fundamentally what I believe in with our work, helping other people grow, growing ourselves. Ourselves, trying to build a company that's all built on this principles, you know, having a good time along with some people that we work with, to grow a little bit. So these two books, and then I would throw in what we have on our. In our. In our office. When we started a company in Russia, we put a neon sign in our office because we thought that's a recipe for success. If we do that, we're definitely going to wake up as a multibillion dollar company. And it was the Ludwig Wittgenstein quote, the limits of my language are the limits of my world. What's the quote? The limits of my language are the limits of my world. And I love the trick. Titus, I think it's just a beautiful. It's a book by Wittgenstein. Yeah. And I would recommend that, too, even although he himself didn't believe in that by the end of his lifetime and debunked his ideas. But I think I remember once an engineer came in 2012, I think, or 13, a friend of ours who worked with us and then went on to work at DeepMind, and he gave. Talked to us about Ward two vec, and I saw that. I'm like, wow, that's. You know, they wanted to translate language into, you know, some other representation, and that seems like some. You know, somehow all of that at some point, I think, will come into this one, to this one place, somehow. It just all feels like different people think about similar ideas in different times from absolutely different perspectives. And that's why I like these books. Limits of our language is the limit of our world, and. We still have that neon sign. It's very hard to work with this red light in your face. I mean, on the russian side of things, in terms of language. The limits of language being the limit of our world. You know, Russian is a beautiful language in some sense. There's wit, there's humor, there's pain. There's so much. We don't have time to talk about it much today, but I'm going to Paris to talk to Dostoevsky, Tolstoy, translators. I think it's fascinating. Art, like art and engineering. I mean, it's such an interesting process. So, from the replica perspective, do you. What do you think about translation? How difficult it is to create a deep, meaningful connection in Russian versus English, how you can translate the two languages you speak? Both? Yeah, I think we're two different people in different languages. Even. I'm, you know, thinking about. And there's actually some research on that. I looked into that at some point because I was fascinated by the fact that what I'm talking about with what I was talking about with my russian therapist has nothing to do with what I'm talking about with my English speaking therapist. It's two different lives, two different types of conversations, two different Personas. The main difference between the languages are with Russian and English. Is that Russian, well, English is like a piano. It's a limited number of a lot of different keys, but not too many. And Russian is like an organ or something. It's just something gigantic with so many different keys and so many different opportunities to screw up and so many opportunities to do something completely tone deaf. It is just a much harder language to use. It has way too much flexibility and way too many tones. What about the entirety of, like, world war two, communism, Stalin, the pain of the people, like, having been deceived by the dream, like, all the pain of just the entirety of it. Is that in the language, too? Does that have to do? Oh, for sure. I mean, we have words that don't have direct translation, that do English, that are very much like. We have abidica, which is sort of, like, to hold a grudge or something, but it doesn't have. You don't need to have anyone to do it to you. It's just your state. You just feel like that. You feel, like, betrayed by other people, basically, but it's not that. And you can't really translate that. And I think that's super important, that very many words that are very specific explain the russian being. And I think they can only come from a nation that was. That suffered so much and saw institutions fall time after time after time. And you know what's exciting? Maybe not exciting, setting the wrong word. But what's interesting about, like, my generation, my mom's generation, and my parents generation is that we saw institutions fall two or three times in our lifetime, and most Americans have never seen them fall. And they just think that they exist forever, which is really interesting. But it's definitely a country that suffered so much. And it makes, unfortunately, when I go back and I hang out with my russian friends, it makes people very cynical. They stop believing in the future. I hope that's not going to be the case for so long or something's going to change again. But I think seeing institutions fall is a very traumatic experience. Makes it very interesting. And what's on 2020? It's very interesting. Do you think civilization will collapse? See, I'm a very practical person. We're speaking English. So like you said, you're different person in English and Russian, so in Russian, you might answer that differently. But in English, I'm an optimist and I genuinely believe that there is all, you know, even although the perspectives are grim, there's always a place for a miracle. I mean, it's always been like that with my life. So, yeah, my life's been. I've been incredibly lucky. And things just, miracles happen all the time with this company, with people I know, with everything around me. And so I didn't mention that book, but maybe in search of miraculous or in search for miraculous or whatever the english translation for that is good russian book for everyone to read. Yeah. I mean, if you put good vibes, if you put love out there in the world, miracles somehow happen. Yeah, I believe that, too. Or at least I believe that. I don't know. Let me ask the most absurd, final, ridiculous question of, we talked about life a lot. What do you think is the meaning of it all? What's the meaning of life? My answer is probably going to be pretty cheesy, but I think the state of love is once you feel it in a way that we discussed it before. I'm not talking about falling in love or I just love to yourself, to other people, to something, to the world, that state of bliss that we experience sometimes, whether through connection with ourselves, with our people, with the technology, there's something special about those moments. So let's say, if anything, that's the only, if it's not for that, then for what else are we really trying to do? That I don't think there's a better way to end it than talking about love. Eugenia, I told you offline that there was something about me that felt like this was this talking to you, meeting you in person, will be a turning point for my life. I know that might sound weird to hear, but it was a huge honor to talk to you. I hope we talk again. Thank you so much for your time. Thank you so much. Thanks for listening to this conversation with Eugenia Quidda and thank you to our sponsors DoorDash Dollar Shave Club and cash app. Click the sponsor links in the description to get a discount and to support this podcast. If you enjoy this thing, subscribe on YouTube, review it with five stars on Apple Podcasts, follow on Spotify, support on Patreon, or connect with me on Twitter exfriedman. And now let me leave you with some words from Carl Sagan. The world is so exquisite, with so much love and moral depth that there's no reason to deceive ourselves with pretty stories of which there's little good evidence. Far better, it seems to me. And our vulnerability is to look death in the eye and to be grateful every day for the brief but magnificent opportunity that life provides. Thank you for listening and hope to see you next time.

Utterances:
Speaker A: The following is a conversation with Eugenia Coida, co founder of Replica, which is an app that allows you to make friends with an artificial intelligence system, a chatbot that learns to connect with you on an emotional, you could even say a human level by being a friend. For those of you who know my interest in AI and views on life in general, know that replica and Eugenia's line of work is near and dear to my heart. The origin story of replica is grounded in a personal tragedy of Eugenia losing her close friend Roman Mozarenki, who was killed crossing the street by a hit and run driver in late 2015. He was 34. The app started as a way to grieve the loss of a friend by training a chatbot neural net on text messages between Eugenia and Romande. The rest is a beautiful human story as we talk about with Eugenia. When a friend mentioned Eugenia's work to me, I knew I had to meet her and talk to her. I felt before, during and after that this meeting would be an important one in my life. And it was, I think, in ways that only time will truly show to me and others. She is a kind and brilliant person. It was an honor and a pleasure to talk to her. Quick summary of the sponsors DoorDash Dollar Shave Club and cash app. Click the sponsor links in the description to get a discount and to support this podcast. As a side note, let me say that deep, meaningful connection between human beings and artificial intelligence systems is a lifelong passion for me. I'm not yet sure where that passion will take me, but I decided some time ago that I will follow it boldly and without fear to as far as I can take it. With a bit of hard work and a bit of luck, I hope I'll succeed in helping build AI systems that have some positive impact on the world and on the lives of a few people out there. But also, it is entirely possible that I am, in fact, one of the chatbots that Eugenia and the replica team have built. And this podcast is simply a training process for the neural net that's trying to learn to connect to human beings one episode at a time. In any case, I wouldn't know if I was or wasn't, and if I did, I wouldn't tell you. If you enjoy this thing, subscribe on YouTube, review it with five stars on Apple Podcast, follow on Spotify, support on Patreon, or connect with me on Twitter lexfreedman as usual, I'll do a few minutes of ads now and no ads in the middle. I'll try to make these interesting but give you timestamps so you can skip. But please do still check out the sponsors by clicking the links in description to get a discount. Buy whatever they're selling. It really is the best way to support this podcast. This show is sponsored by Dollar Shave Club. Try them out with a one time offer for only $5 and free shipping@dollarshave.com. lex the starter kit comes with a six blade razor, refills and all kinds of other stuff that makes shaving feel great. I've been a member of Dollar Shave Club for over five years and actually signed up when I first heard about them on the Joe Rogan Experience podcast. And now, friends, we have come full circle. It feels like I made it now that I can do a read for them, just like Joe did all those years ago, back when he also did ads for some less reputable companies. Let's say that you know about if you're a true fan of the old school podcasting world. Anyway, I just used the razor and the refills, but they told me I should really try out the shave butter. I did. I love it. It's translucent somehow, which is a cool new experience. Again, try the ultimate shave starter set today for just $5 plus free shipping@dollarshaveclub.com. lex this show is also sponsored by DoorDash. Get $5 off and zero delivery fees on your first order of $15 or more when you download the DoorDash app and enter code. You guessed it Lex. I have so many memories of working late nights for a deadline with a team of engineers, whether that's from my PhD at Google or MIT, and eventually taking a break to argue about which DoorDash restaurant to order from and when the food came. Those moments of bonding, of exchanging ideas, of pausing to shift attention from the programs to humans or special for a bit of time. Im on my own now so I missed that Camaraderie. But actually I still use DoorDash a lot. Theres a million options that fit into my crazy keto diet ways. Also, its a great way to support restaurants in these challenging times. Once again, download the DoorDash app and enter code Lex to get $5 off and zero delivery fees on your first order of dollar 15 or more. Finally, this show is presented by Cash app, the number one finance app in the app store. I can truly say that they're an amazing company, one of the first sponsors, if not the first sponsor to truly believe in me. And and I think quite possibly the reason I'm still doing this podcast. So I am forever grateful to cash app. So thank you. And as I said many times before, use code Lexpodcast when you download the app from Google Play or the app store. Cash app lets you send money to friends, buy bitcoin, and invest in the stock market with as little as $1. I usually say other stuff here in the read, but I wasted all that time upfront saying how grateful I am to cash app. I'm going to try to go off the top of my head a little bit more for these reads because I'm actually very lucky to be able to choose the sponsors that we take on, and that means I can really only take on the sponsors that I truly love, and then I could just talk about why I love them. So it's pretty simple. Again, get cash app from the App store, Google Play, use code Lex podcast, get $10. And cash app will also donate $10 to first, an organization that is helping to advance robotics and stem education for young people around the world. And now, here's my conversation with Eugenia Cuida. Okay, before we talk about AI and the amazing work you're doing, let me ask you ridiculously, we're both russian, so let me ask you a ridiculously romanticized russian question. Do you think human beings are alone, like, fundamentally, on a philosophical level, like, in our existence, when we, like, go through life, do you think just the nature of our life is loneliness?
Speaker B: Yeah. So we have to read Dostoyevsky at school, as you probably know in Russian. Yeah, I mean, it's part of the school program. So I guess if you read that, then you sort of have to believe that you're made to believe that you're fundamentally alone, and that's how you live your life.
Speaker A: How do you think about it? You have a lot of friends, but at the end of the day, do you have, like, a longing for connection with other people? That's maybe another way of asking it. Do you think that's ever fully satisfied?
Speaker B: I think we are fundamentally alone. We're born alone, we die alone. But I view my whole life as trying to get away from that, trying to not feel, feel lonely. And again, we're talking about subjective way of feeling alone. It doesn't necessarily mean that you don't have any connections or you're actually isolated.
Speaker A: You think it's a subjective thing. But, like, again, another absurd measurement wise thing. How much loneliness do you think there is in the world? So, like, if you see loneliness as a. As a condition, how much of it is there? Do you think? Like, how, I guess, how many, you know, there's all kinds of studies and measures of how much, how many people in the world feel alone. There's all these measures of how many people are self report or just all these kinds of different measures. But in your own perspective, how big of a problem do you think it is size wise?
Speaker B: I'm actually fascinated by the topic of loneliness. I try to read about it as much as I can. What really? And I think there's a paradox, because loneliness is not a clinical disorder. It's not something that you can get your insurance to pay for if you're struggling with that. Yet it's actually proven, and pretty tons of papers, tons of research around that, it is proven that it's correlated with earlier life expectancy, shorter lifespan, and it is, in a way, right now what scientists would say, that it's a little bit worse than being obese or not actually doing any physical activity in your life in terms of impact on your physiological health. Yeah. So it's basically puts you, if you're constantly feeling lonely, your body responds like it's basically all the time under stress, so it's always in this alert, alert state, and so it's really bad for you because it actually, like, drops your immune system and get it. Your response to inflammation is quite different, so. Or all the cardiovascular diseases actually responds to viruses, so it's much easier to catch a virus.
Speaker A: That's sad. Now that we're living in a pandemic, and it's probably making us a lot more alone, and it's probably weakening the immune system, making us more susceptible to the virus. It's kind of sad.
Speaker B: Yeah, the statistics are. The statistics are pretty horrible around that. So around 30% of all millennials report that they're feeling lonely constantly. 30, 30%. And then it's much worse for Gen Z. And then 20% of millennials say that they feel lonely, and they also don't have any close friends. And then I think 25 or so, and then 20% would say they don't even have acquaintances.
Speaker A: That's the United States.
Speaker B: That's in the United States. And I'm pretty sure that that's much worse everywhere else, like in the UK. I mean, it was widely, like, tweeted and, uh, posted when they were talking about a minister of loneliness that they wanted to appoint, because four out of ten you people in the UK feel lonely. So I think we don't.
Speaker A: A minister of loneliness, I mean, that.
Speaker B: I think that thing actually exists. So, yeah, you. You will die sooner if you if you are lonely, and again, that this is only when we're only talking about your perception of loneliness, of feeling lonely, that is, not objectively, fully being fully socially isolated. However, the combination of being fully socially isolated and not having many connections and also feeling lonely, that's pretty much a deadly combination. So it strikes me bizarre or strange that this is a wide known fact. And then there's really no one working, really on that because it's subclinical, it's not clinical, it's not something that you can want tell your doctor and get a treatment or something, yet it's killing us.
Speaker A: Yeah. So there's a bunch of people trying to evaluate, like, try to measure the problem by looking at, like, how social media is affecting loneliness and all that kind of stuff. So it's like measurement. Like, if you look at the field of psychology, they're trying to measure the problem. And not that many people, actually, but some. But you're basically saying how many people are trying to solve the problem? Like, how would you try to solve the problem of loneliness? Like, if we just stick to humans, I mean, or basically not just the humans, but the technology that connects us humans. Do you think there's a hope for that technology to do the connection? Like, are you on social media much?
Speaker B: Unfortunately.
Speaker A: Do you find yourself, like, again, if you sort of introspect about how connected you feel to other human beings, how not alone you feel, do you think social media makes it better or worse? Maybe for you personally or in general?
Speaker B: I think it's easier to look at some stats. And, I mean, Gen Z seems to be. Generation Z seems to be much lonelier than millennials in terms of how they report loneliness. They're definitely the most connected, you know, generation in the world. I mean, I still remember life without an iPhone, without Facebook. They don't know that that ever existed, or at least don't know how it was. So that tells me a little bit about the fact that that might be, you know, this hyper connected world might actually make people feel lonelier. I don't know exactly what the measurements are around that, but I would say, in my personal experience, I think it does make you feel a lot lonelier. Mostly, yeah, we're all super connected. But I think loneliness, the feeling of loneliness, doesn't come from not having any social connections whatsoever. Again, tons of people that are in long term relationships experience bouts of loneliness and continued loneliness. And it's more the question about the true connection, about actually being deeply seen, deeply understood. And in a way, it's also about your relationship with yourself. Like, in order to not feel lonely, you actually need to have a better relationship and feel more connected to yourself. Then this feeling actually starts to go away a little bit, and then you open up yourself to actually meeting other people in a very special way, not just add a friend on Facebook kind of way.
Speaker A: So just to briefly touch on it, I mean, do you think it's possible to form that kind of connection with AI systems more down the line of some of your work? Do you think that's engineering wise? A possibility to alleviate loneliness is not with another human, but with an AI system?
Speaker B: Well, I know that's a fact. That's what we're doing. And we see it and we measure that and we see how people start to feel less lonely talking to their virtual AI friend.
Speaker A: So basically a chatbot at the basic level, but could be more like, do you have, I'm not even speaking sort of about specifics, but do you have a hope, like, if you look 50 years from now, do you have a hope that there's just, like, AI's that are optimized for. Let me first start, like, right now. The way people perceive AI, which is recommender systems for Facebook and Twitter, social media, they see AI as basically destroying, first of all, the fabric of our civilization, but second of all, making us more lonely. Do you see, like, a world where it's possible to just have AI systems floating about that, like, make our life less lonely? Yeah, make us happy, like, our putting good things into the world in terms of our individual lives?
Speaker B: Yeah, I totally believe in that. That's why I'm also working on that. I think we need to also make sure that what we're trying to optimize for, we're actually measuring, and it is an orthodox metric that we're going after. And all of our product and all of our business models are optimized for that because you can talk, a lot of products that talk about making you feel less lonely or making you feel more connected, they're not really measuring that. So they don't really know whether their users are actually feeling less lonely in the long run or feeling more connected in the long run. So I think it's really important to put your.
Speaker A: To measure it.
Speaker B: Yep, to measure it.
Speaker A: What's a good measurement of loneliness?
Speaker B: Well, so that's something that I'm really interested in. How do you measure that people are feeling better or that they're feeling less lonely with loneliness? There's a scale, there's a UCLA 20 and UCLA three recently scale which is basically questionnaire that you fill out and you can see whether in the long run it's improving or not.
Speaker A: And that, does it capture the momentary feeling of loneliness? Does it look in, like, the past month? Like, does it basically self report? Does it try to sneak up on you? It's very tricky to answer honestly or something like that. Yeah. I'm not familiar with the question.
Speaker B: It is just asking you a few questions, like, how often did you feel lonely? Or how often did you feel connected to other people in this last few couple weeks? It's similar to the self report questionnaires for depression, anxiety, like PHQ nine, and get seven. Of course, as any self report questionnaires, that's not necessarily very precise or very well measured. But still, if you take a big enough population, you get them through these questionnaires, you can see positive, dynamic.
Speaker A: And so you basically, you put people through questionnaires to see, like, is this thing. Is our. Is what we're creating making people happier?
Speaker B: Yeah. We measure. So we measure two outcomes. One, short term. Right after the conversation, we ask people whether this conversation made them feel better, worse, or same. This metric right now is at 80%. So 80% of all our conversations make people feel better.
Speaker A: I should have done the questionnaire with you. You feel a lot worse after we've done this conversation. That's actually fascinating. I should probably do that.
Speaker B: But that's all.
Speaker A: I should probably do that.
Speaker B: You should totally.
Speaker A: And aim for 80%. Aim to outperform your current state of the art AI system in these human conversations. Okay, we'll get to your work with replica, but let me continue on the line of absurd questions. So you talked about, you know, deep connection, other humans, deep connection with AI, meaningful connection. Let me ask about love. People make fun of me because I talk about love all the time, but what. What do you think love is? Like, maybe in the context of a meaningful connection with somebody else? Do you draw a distinction between love, like, friendship and Facebook friends? Or is it a graduate?
Speaker B: No, it's all the same.
Speaker A: No. Like, is it just a gradual thing, or is there something fundamental about us humans that seek, like, a really deep connection with another human being? And what is that? What is love? Eugenia, I just enjoy asking you these questions, seeing you struggle.
Speaker B: Thanks.
Speaker A: Yeah.
Speaker B: Well, the way I see it, specifically the way it relates to our work and the way it inspired our work on replica, I think one of the biggest and the most precious gifts we can give to each other now in 2020, as humans, is this gift of deep empathetic. Understanding, the feeling of being deeply seen.
Speaker A: Like, what does that mean that you exist? Like somebody acknowledging that, somebody seeing you.
Speaker B: For who you actually are. And that's extremely rare. I think that is that combined with unconditional positive regard, belief and trust, that you internally are always inclined for positive growth and believing you in this way, letting you be a separate person at the same time. And this deep, empathetic understanding, for me, that's the combination that really creates something special, something that people, when they feel it once, they will always long for it again. And something that starts huge, fundamental changes in people. When we see that someone accepts us so deeply, we start to accept ourselves. And the paradox is that's when big changes start happening, big fundamental changes, and people start happening. So I think that is the ultimate therapeutic relationship, that is. And that might be in some way a definition of love.
Speaker A: Acknowledging that there's a separate person and accepting you for who you are. Now on a slightly. And you mentioned therapeutic. That sounds like a very healthy view of love. But is there also, if we look at heartbreak, and most love songs have probably bought heartbreak, right? Is that like, the mystery, the tension, the danger, the fear of loss, you know, all of that, what people might see in a negative light as, like, games or whatever, but just. Just the dance of human interaction. Yeah. Fear of loss and fear of, like you said, like, once you feel it once, you long for it again, but you also. Once you feel it once, you might. For many people, they've lost it, so they fear losing it. They feel lost. So is that part of it? You're speaking beautifully about the positive things, but is it important to be able to be afraid of losing it? From an engineering perspective.
Speaker B: I mean, it's a huge part of it, and unfortunately, we all, you know, face it at some points in our lives. I mean, I.
Speaker A: Did you want to go into details? How'd you get your heart broken?
Speaker B: Sure. Well, so mine is pretty straight. My story's pretty straightforward there. I did have a friend that was, you know, that at some point in my twenties became really, really close to me, and we became really close friends. Well, I grew up pretty lonely. So in many ways, when I'm building these AI friends, I think about myself when I was 17, writing horrible poetry and my dial up modem at home. That was the feeling that I grew up with. I lived alone for a long time when I was a teenager.
Speaker A: Where did you grow up?
Speaker B: In Moscow. On the outskirts of Moscow. So I just skateboard during the day and come back home and, you know, connect to the Internet and write poetry and then write horrible poetry.
Speaker A: And was it love poems?
Speaker B: All sorts of poems, obviously. Love poems. I mean, what other poetry can you write when you're 17?
Speaker A: It could be political or something, but.
Speaker B: Yeah, but that was, you know, that was kind of my yet, like, deeply influenced by Joseph Brodsky and, like, all sorts of poets that every 17 year old will. Will be looking, you know, looking at and reading. But, yeah, that was my. These were my teenage years, and I just never had a person that I thought would, you know, take me as it is, would accept me the way I am. And I just thought, you know, working and just doing my thing and being angry at the world and being a reporter, I was an investigative reporter working undercover and writing about people was my way to connect with, you know, with. With others. I was deeply curious about everyone else, and I thought that if I go out there, if I write their stories, that means I'm more connected.
Speaker A: This is what this podcast is about, by the way. I'm desperate seeking connection. I'm just kidding. Or am I? I don't know. So, wait, reporter, how did that make you feel more connected? I mean, you're still fundamentally pretty alone.
Speaker B: But you're always with other people. You know, you're always thinking about, what other place can I infiltrate? What other community can I write about? What other phenomena can I explore? And you're sort of like a trickster, you know, like a mythological character like creature that's just jumping between all sorts of different worlds and feel. And feel sort of okay with. In all of them. So that was my dream job, by the way. That was, like, totally what I would have been doing if Russia was a.
Speaker A: Different place and a little bit undercover. So, like, you weren't. You were trying to, like you said, mythological creature trying to infiltrate, so try to be a part of the world. What are we talking about? What kind of things did you enjoy writing about?
Speaker B: I'd go work at a strip club or go.
Speaker A: Awesome. Okay.
Speaker B: Or I'd go work at a restaurant or just go write about, you know, certain phenomenons or phenomena or people in.
Speaker A: The city and what. Sorry to keep interrupting. I'm the worst conversationalist. What stage of Russia is this? What is this pre Putin post Putin? What was Russia like?
Speaker B: Pre Putin is really long ago. This is Putin era. That's beginning of 2010, 20070 8910.
Speaker A: What were strip clubs like in Russia and restaurants and culture and people's minds? Like, in that early Russia that you.
Speaker B: Were covering, in those early two thousands, there was still a lot of hope. There were still tons of hope that, you know, we're sort of becoming this western, westernized society. The restaurants were opening where we're really looking at, you know, we're trying to copy a lot of things from the US, from Europe, bringing all these things and very enthusiastic about that. So there was a lot of, you know, stuff going on. There was a lot of hope and dream for this, you know, new Moscow that would be similar to, I guess, New York. I mean, just to give you an idea, in year 2000 was the year when we had two movie theaters in Moscow, and there was this one first coffee house that opened, and it was, like, really big deal. By 2010, there were all sorts of.
Speaker A: Things everywhere, almost like a chain, like a Starbucks type of coffee house or, like, you mean.
Speaker B: Oh, yeah, like a Starbucks. I mean, I remember we were reporting on, like, we were writing about the opening of Starbucks, I think, in 2007. That was one of the biggest things that happened in Moscow back in the time that was worthy of a magazine cover, and that was definitely the biggest talk of the town.
Speaker A: Yeah. When was McDonald's? Because I was still in Russia when McDonald's opened. That was in the nineties.
Speaker B: Oh, yeah, I remember that very well. Yeah, those were long, long lines. I think it was 1993 or four. I don't remember.
Speaker A: McDonald's at that time. Did you do the.
Speaker B: I mean, that was a luxurious outing. That was definitely not something you do every day. And also, the line was at least 3 hours. So if you're going to McDonald's, that is not fast food. That is, like, at least 3 hours in line.
Speaker A: Yeah.
Speaker B: And then no one is trying to eat fast after that. Everyone is, like, trying to enjoy as much as possible.
Speaker A: What's your memory of that?
Speaker B: Oh, it was insane. How do I. Extremely positive. It's a small strawberry milkshake and the hamburger and small fries and my mom's there, and sometimes I'll just, because I was really little, they'll just let me run, you know, up the cashier and, like, cut the line, which is, like, you cannot really do that in Russia.
Speaker A: Or so, like, for a lot of people, like, a lot of those experiences might seem not very fulfilling, you know, like, it's on the verge of poverty, I suppose. But do you remember all that time fondly, like, because I do. Like, the first time I drank, you know, coke, you know, all that stuff. Right. And just. Yeah. The connection with other human beings in Russia. I remember. I remember really positively, like, how do you remember the nineties and then the Russia you were covering just the human connections you had with people and the experiences.
Speaker B: Well, my parents were both both physicists. My grandparents were both. Well, my grandfather was a nuclear physicist, a professor at the university. My dad worked at Chernobyl when I was born, analyzing kind of the. Everything after the explosion. And then I remember that. And they were. So they were making sort of enough money in the Soviet Union, so they were not, you know, extremely poor or anything. It was pretty prestigious to be a professor, the dean in the university. And then I remember my grandfather started making $100 a month after, you know, in the nineties. So. So then I remember we started. Our main line of work would be to go to our little tiny country house, get a lot of apples there from apple trees, bring them back to the city and sell them in the street. So me and my nuclear physicist grandfather were just standing there and he selling those apples the whole day, because that would make you more money than working at the university. And then he'll just tell me, try to teach me, you know, something about planets and whatever, the particles and stuff. And, you know, I'm not smart at all, so I could never understand anything. But I was interested as a journalist kind of type interested, but that was my memory, and, you know, I'm happy that I wasn't. I somehow got spared that. I was probably too young to remember any of the traumatic stuff. So the only thing I really remember, I had this bootleg that was very traumatic. Had this bootleg Nintendo, which was called Dandy in Russia. So in 1993, there was nothing to eat. Like, even if you had any money, you would go to the store, and there was no food. I don't know if you remember that. And our friend had a restaurant, like a government owned something restaurant, so they always had supplies. So he exchanged a big bag of wheat for this Nintendo that looked like Nintendo. And that I remember very fondly because I think I was nine or something like that. And. Or seven. We just got it, and I was playing it, and there was this, you know, dandy tv show.
Speaker A: Yeah. So traumatic. Positive sense. You mean like a definitive.
Speaker B: Well, they took it away and gave me a bag of weed instead, and I cried, like, my eyes out for days and days.
Speaker A: Oh, no.
Speaker B: And then, you know, as a. And my dad said, we're going to, like, exchange it back in a little bit. So you keep the little gun, you know, the one that you shoot the ducks with. So I'm like, okay, I'm keeping the gun, so sometime it's going to come back. But then they exchanged the gun as well for some sugar or something. I was so pissed. I was like, I didn't want to eat for days after that. I'm like, I don't want your food. Give me my Nintendo back. That was extremely traumatic, but, you know, I was happy that that was my only traumatic experience. You know, my dad had to actually go to Chernobyl with a bunch of 20 year olds. He was 20 when he went to Chernobyl. And that was right after the explosion. No one knew anything. The whole crew he went with, all of them are dead now. I think there was this one guy still that was still alive for this last few years. I think he died a few years ago now. My dad somehow luckily got back earlier than everyone else, but just the fact that that was the. And I was always like, well, how did they send you? I was only. I was just born. You know, you had a newborn, talk about paternity leave. They were like, but that's who they took because they didn't know whether you would be able to have kids when you come back. So they took the ones with kids. So him with some guys went to. And I'm just thinking of me when I was 20. I was so sheltered from any problems whatsoever in life. And then my dad, his 21st birthday at the reactor, you work 3 hours a day, you sleep the rest. And I. Yeah, so I played with a lot of toys from Chernobyl.
Speaker A: What are your memories of Chernobyl in general? Like, bigger context, you know, because of that HBO show, the world's attention turned to it once again. Like, what are your thoughts about Chernobyl? Did Russia screw that one up? Like, you know, there's probably a lot of lessons about our modern times with data about coronavirus and all that kind of stuff. It seems like there's a lot of misinformation. There's a lot of people kind of trying to hide whether they've screwed something up or not, as it's very understandable. It's very human, very wrong, probably. But obviously, Russia was probably trying to hide that they've screwed things up. Like, what are your thoughts about that time, personal and general?
Speaker B: I mean, I was born when the explosion happened, so actually a few months after. So of course, I don't remember anything apart from the fact that my dad would bring me tiny toys plus, like, plastic things that would just go crazy haywire when you put the Geiger thing to it. My mom was, like, just nuclear about that. She's like, what are you bringing? You should not do that.
Speaker A: She was nuclear. Very nice. Absolutely well done. I'm sorry for that.
Speaker B: But the tv show was just phenomenal.
Speaker A: HBO one.
Speaker B: Yeah, it's definitely, first of all, it's incredible how that was made, not by the Russians, but someone else, but capturing so well everything about our country. It felt a lot more genuine than most of the movies and tv shows that are made now in Russia. Just so much more genuine. And most of my friends in Russia were just in complete awe about the show.
Speaker A: But I think that how good of a job they did.
Speaker B: Oh, my God. Phenomenal.
Speaker A: The apartments, there's something. Yeah.
Speaker B: The set design. I mean, Russians can't do that, but you see everything, and it's like, wow. That's exactly how it was.
Speaker A: I don't know that show. I don't know what to think about that because it's british accents, british actors of a person. I forgot who created this show. I'm not. But I remember reading about him, and he's not. He doesn't even feel like. Like there's no Russia in his history.
Speaker B: No, he did, like, superbad or some, like. Or, like, uh. I don't know.
Speaker A: Yeah, like, exactly.
Speaker B: Whatever. That thing about the bachelor party in Vegas, number four and five or something were the ones that he worked.
Speaker A: Yeah, but, so he. It made me feel really sad for some reason, that if a person, obviously a genius, could go in and just study and just be extreme attention to detail, they can do a good job. It made me think, like, why don't other people do a good job of this? Like, about Russia? There's so little about Russia. There's so few good films about the russian side of World War two of. I mean, there's so much interesting evil and not. And beautiful moments in the history of the 20th century in Russia. That feels like there's not many good films on from the Russians. You would expect something from the Russians.
Speaker B: Well, they keep making these propaganda movies now. Oh, no, unfortunately. But, yeah, no, Chernobyl was such a perfect tv show, I think, capturing really well. It's not about, like, even the set design, which was phenomenal, but just capturing all the problems that exist now with the country and, like, focusing on the right things. Like, if you build the whole country on a lie, that's what's gonna happen. And that's just. That's very simple kind of thing.
Speaker A: Yeah. And did you have your dad talked about it to you, like, his thoughts on the experience?
Speaker B: He never talks. He's this kind of russian man that just my husband, who's american, and he asked him a few times, like, you know, Igor, how did you. But why did you say yes? Or, like, why did you decide to go, you could have said no, not go to Chernobyl. Why would a person like, that's what you do. You cannot say no.
Speaker A: Yeah, yeah.
Speaker B: It's just, it's like a russian way.
Speaker A: It's.
Speaker B: The russian men don't talk that much.
Speaker A: Nope.
Speaker B: There are downsides and upsides for that.
Speaker A: Yeah, that's the truth. Okay, so back to post Putin Russia. Or maybe we skipped a few steps along the way, but you were trying to be a journalist in that time. What was Russia like at that time? Post, you said 2007, Starbucks type of thing. What else? What else was Russia like then?
Speaker B: I think there was just hope. There was this big hope that we're going to be, you know, friends with the United States and we're going to be friends with Europe, and we're just going to be also a country like those with, you know, bike lanes and parks and everything's going to be urbanized again. We're talking about nineties where, like, people would be shot in the street. And it was, I sort of have a fond memory of going into a movie theater and, you know, coming out of it after the movie, and the guy that I saw on the stairs was like, neither shot, which was, again, it was like a thing in the nineties that would be happening. People were, you know, people were getting shot here and there. Tons of violence, tons of violence, tons of, you know, just basically mafia mobs on, in the streets. And then the two thousands were like, you know, things just got cleaned up. Oil went up, and the country started getting a little bit richer. The nineties were so grim, mostly because the economy was in shambles and oil prices were not high. So the country didn't have anything. We defaulted in 1998, and the money kept jumping back and forth. First there were millions of rubles. Then it got, like, default. Then it got to thousands. There was one ruble was something, then again, to millions. It was like, crazy town. That was crazy. And then the two thousands were just these years of stability in a way, and the country getting a little bit richer because of, again, oil and gas. And we were starting to. We started to look at specifically in Moscow and St. Petersburg, to look at other cities in Europe and New York and us and trying to do the same in our small, kind of sit his towns there.
Speaker A: What were your thoughts of Putin at the time?
Speaker B: Well, in the beginning, he was really positive. Everyone was very positive about Putin. He was young. He was very energetic. He also immediately somewhat compared to, well, that was not like, way before the shirtless era. The shirtless era.
Speaker A: Okay, so he didn't start off shirtless. When did the shirtless era. It's like the propaganda. Riding a horse, fishing.
Speaker B: 2010, 1112.
Speaker A: Yeah, that's my favorite. You know, like, people talk about their favorite beatles, like the. That's my favorite. Putin is the shirtless Putin.
Speaker B: No, I remember very, very clearly, 1996, where, you know, Americans really helped Russia with elections, and Yeltsin got reelected, thankfully. So, because there's a huge threat that actually the communists will get back to power. They were a lot more popular. And then a lot of american experts, political experts and campaign experts descended on Moscow and helped Yeltsin actually get the presidency, the second term of the presidency. But Yeltsin was not feeling great by the end of his second term. He was alcoholic. He was really old. He was falling off, you know, the stages when he, where he was talking. So people were looking for fresh, I think, for a fresh face for someone who's going to continue Yeltsin's work, but who's going to be a lot more energetic and a lot more active, young, efficient, maybe. So that's what we all saw in Putin back in the day. I'd say that everyone, absolutely everyone in Russia in early two thousands who was not a communist would be, yeah, Putin's great. We have a lot of hopes for him.
Speaker A: What are your thoughts? And I promise we'll get back to, first of all, your love story, and second of all, AI, well, what are your thoughts about communism, the 20th century? I apologize. I'm reading the rise and fall of the Third Reich.
Speaker B: Oh, my God.
Speaker A: So I'm, like, really steeped into, like, world War two and Stalin and Hitler and just these dramatic personalities that brought so much evil to the world. But it's also interesting to politically think about these different systems and what they've led to. And Russia is one of the sort of beacons of communism in the 20th century. What are your thoughts about communism, having experienced it as a political system?
Speaker B: I mean, I have only experienced it a little bit, but mostly through stories and through, you know, seeing my parents and my grandparents who lived through that. It was horrible. It was just plain horrible. It was just awful.
Speaker A: You think there's something, I mean, it sounds nice on paper. So, like, the drawbacks of capitalism is that, you know, eventually it's the point of, like, a slippery slope. Eventually it creates, you know, the rich get richer. It creates a disparity, like, inequality of wealth inequality. If like, you know, I guess it's hypothetical at this point, but eventually capitalism leads to humongous inequality. And that that's, you know, some people argue that that's a source of unhappiness is it's not like absolute wealth of people. The fact that there's a lot of people much richer than you. There's a feeling of, like, that's where unhappiness can come from. So the idea of communism, or at least sort of Marxism, is not allowing that kind of slippery slope. But then you see the actual implementations of it, and stuff seems to be. Seems to go wrong very badly. What do you think that is? Why does it go wrong? What is it about human nature? If we look at Chernobyl, you know, those kinds of bureaucracies that were constructed, is there something like, do you think about this much of, like, why it goes wrong?
Speaker B: Well, there's no one was really like, it's all that everyone was equal. Obviously, the, you know, the government and everyone close to that were the bosses. So it's not like, fully, I guess there's already a dream of equal life. So I guess the situation that we had, Russia had in the Soviet Union, it was more just a bunch of really poor people without any way to make any significant fortune or build anything, living under constant surveillance, surveillance from other people. Like, you can't even, you know, do anything that's not fully approved by the dictatorship, basically. Otherwise your neighbor will write a letter and you'll go to jail. Absolute absence of actual law. This constant state of fear. You didn't own anything. You didn't, you know, the. You couldn't go travel, you couldn't read anything western or you could make a career, really, unless you're working in the military complex, which is why most of the scientists were so well regarded. I come from, you know, both my dad and my mom come from families of scientists, and they. They were really well regarded as you.
Speaker A: As, you know, obviously as the state wanted. I mean, because there's a lot of value to them being well regarded because.
Speaker B: They were developing things that could be used in the. In the military. So that was very important. That was the main investment, but was miserable. It was miserable. That's why, you know, a lot of Russians now live in the state of constant PTSD. That's why we want to buy, buy, buy, buy, buy. Definitely, if as soon as we have the opportunity, you know, we just got to it finally, that we can, you know, own things. You know, I remember the time that we got our first yogurts and that was the biggest deal in the world. It was already in the nineties.
Speaker A: By the way, what was your favorite food? Where it was like, whoa, this is possible.
Speaker B: Oh, fruit. Because we only had apples, bananas, and whatever, and whatever watermelons, whatever people would grow in the Soviet Union. So there were no pineapples or papaya or mango. You've never seen those fruit things. Those were so ridiculously good. And obviously, you could not get any, like, strawberries in winter or anything that's not, you know, seasonal. So that was a really big deal, seeing all these fruit things.
Speaker A: Yeah, me too, actually. I don't know. I think I have a, like, I don't think I have any too many demons or, like, addictions or so on, but I think I've developed an unhealthy relationship with fruit. I still struggle with, oh, you can.
Speaker B: Get any type of fruit, right? You can get, like, also these weird fruit fruits, like dragon fruit or something.
Speaker A: All kinds of different types of peaches. Like, cherries were killer for me. I know you say we had bananas and so on, but I don't remember having the kind of banana, like, when I first came to this country. The amount of banana I, like literally got fat on bananas. The amount.
Speaker B: Oh, yeah, for sure.
Speaker A: They're delicious. And, like, cherries, the kind, like, just the quality of the food. I was like, this is capitalism.
Speaker B: This is. That's pretty.
Speaker A: It's delicious. Yeah, yeah, yeah. It's funny. It's funny, yeah. Like, it's. It's funny to read. I don't know what to think of it. Of, um. It's funny to think how an idea that's just written on paper when carried out amongst millions of people, how that gets actually, when it becomes reality, what it actually looks like. Sorry, but been studying Hitler a lot recently, and going through Mein Kampf. He pretty much wrote out of Mein Kampf everything he was gonna do. Unfortunately, most leaders, including Stalin, didn't read the. Read it, but it's kind of terrifying and I don't know, and amazing in some sense that you can have some words on paper and they can be brought to life, and they can either inspire the world or they can destroy the world. And, yeah, there's a lot of lessons to study in history that I think people don't study enough. Now, one of the things I'm hoping with, I'm practicing Russian a little bit. I'm hoping to sort of find, rediscover the beauty and the terror of russian history through this stupid podcast by talking to a few people. So anyway, I just feel like so much was forgotten. So much was forgotten. I'll probably. I'm going to try to convince myself to. You're a super busy and super important person. I want to try to befriend you to try to become a better Russian because I feel like I'm a shitty.
Speaker B: Russian, not that busy. So I can totally be your Russian Sherpa.
Speaker A: Yeah, but love, you're talking about your early days of being a little bit alone and finding a connection with the world through being a journalist. Where did love come into that?
Speaker B: I guess finding for the first time, some friends it's very, you know, simple story. Some friends that all of a sudden we, I guess we're the same, you know, the same at the same place with our lives. We're 25, 26, I guess, and somehow remember, and we just got really close and somehow remember this one day where it's one day and, you know, in summer that we just stayed out, um, outdoor the whole night and just talked. And for some unknown reason, it just felt for the first time that someone could, you know, see me for who I am. And it just felt extremely, like, extremely good. And, you know, we fell asleep outside and just talking, and it was raining. It was beautiful, you know, sunrise, and it's really cheesy. But at the same time, we just became friends in a way that I've never been friends with anyone else before. And I do remember that before and after that, you sort of have this unconditional family, sort of. And it gives you tons of power. It just basically gives you this tremendous power to do things in your life and to change positively. You mean, like, on many different levels.
Speaker A: Power, because you could be yourself.
Speaker B: At least you know, that some. Somewhere you can be just yourself. Like, you don't need to pretend. You don't need to be, you know, great at work or tell some story or sell yourself in some way or another. And so we became this really close friends, and in a way, I started a company because he had a startup, and I felt like I kind of wanted startup, too. It felt really cool. I didn't know what I'm going to, what I would really do, but I felt like I kind of need a startup.
Speaker A: Okay, so that's. So that pulled you into the startup world.
Speaker B: Yeah. And then. Yeah. And then this closest friend of mine died. We actually moved here to San Francisco together, and then we went back for a visa to Moscow, and we lived together with roommates, and we came back and he got hit by a car right in front of Kremlin on a, you know, next to the river and died the same day. Hospital. Mm hmm.
Speaker A: This is Roman. So. And you've moved to America at that point?
Speaker B: At that point, I was leaving.
Speaker A: What about him? What about Roman?
Speaker B: Him too. He actually moved first, so I was always sort of trying to do what he was doing, so I didn't like that he was already here, and I was still, you know, in Moscow, and we weren't hanging out together all the time, so.
Speaker A: Was he in San Francisco?
Speaker B: Yeah, we were roommates.
Speaker A: So he just visited Moscow for.
Speaker B: We went back for our visas. We had to get a stamp and our passport for our work visas, and the embassy was taking a little longer, so we stayed there for a couple weeks.
Speaker A: What happened? How did you. So how did he die?
Speaker B: He was crossing the street, and the car was going really fast, way over the speed limit, and just didn't stop on the pedestrian cross on the zebra and just run over him.
Speaker A: When was this?
Speaker B: It was in 2015, on 28 November. So it was pretty long ago now. But at the time, I was 29, so for me, it was the first kind of meaningful death in my life. Both sets of. I had both sets of grandparents at the time. I didn't see anyone so close to eye, and death sort of existed, but as a concept, but definitely not as something that would be, you know, happening to us anytime soon and specifically our friends, because we were, you know, we're still in our twenties or early thirties, and it still felt like the whole life is, you know, you could still dream about ridiculous things, even I. So that was. It was just really, really abrupt, I'd say.
Speaker A: What did it feel like to lose him? Like that feeling of loss you talked about the feeling of love having power. What is the feeling of loss, if you like?
Speaker B: Well, in Buddhism, there's this concept of Samaya, where something really, like, huge happens, and then you can see very clearly. I think that was it. Like, basically something changed, so changed me so much in such a short period of time that I could just see really, really clearly what mattered or what not. Well, I definitely saw that whatever I was doing at work didn't matter at all, and some of the things, and it was just this big realization, one. So this very, very clear vision of what life's about.
Speaker A: You still miss him today?
Speaker B: Yeah, for sure. For sure. It was just this constant. I think he was really important for me and for our friends for many different reasons. And I think one of them being that we didn't just say goodbye to him, but we sort of said goodbye to our youth. In a way, it was like the end of an era and on so many different levels. The end of Moscow as we knew it, the end of, you know, us living through our twenties and kind of dreaming about the future.
Speaker A: Do you remember, like, last several conversations? Is there moments with him that stick out, that kind of haunt you in your. Just when you think about him?
Speaker B: Yeah. Well, his last year here in San Francisco, he was pretty depressed for as his startup was not going really anywhere, and he wanted to do something else. He wanted to do build. He played with Toyota, like, played with a bunch of ideas, but the last one he had was around building a startup around death. So having he applied to y combinator with a video that, you know, I had on my computer, and it was all about, you know, disrupting death, thinking about new symmetries more biologically, like, things that could be better biologically for. For humans and at this, and at the same time, having those digital avatars, these kind of AI avatars that would store all the memory about a person that he could interact with.
Speaker A: What year was this?
Speaker B: 2015. Well, right before his death. So it was like, a couple months before that he recorded that video. And so I found on my computer when it was in our living room, he never got in, but he was thinking about a lot somehow.
Speaker A: Does it have the digital avatar idea?
Speaker B: Yeah.
Speaker A: That's so interesting.
Speaker B: Well, he just says, well, that's in his. Yeah, the pitch has this idea, and he talks about, like, I want to rethink how people grieve and how people talk about death.
Speaker A: Why was he interested in this?
Speaker B: Is it maybe someone who's depressed?
Speaker A: Yeah.
Speaker B: Is, like, naturally inclined thinking about that. But I just felt, you know, this year in San Francisco, we just had so much. I was going through a hard time, he was going through a hard time, and we were definitely. I was trying to make him just happy somehow to make him feel better. And it felt like, you know, this. I don't know, I just, like, I was taking care of him a lot, and he almost started to feel better, and then that happened, and I don't know, I just felt. I just felt lonely again, I guess, and that was, you know, coming back to San Francisco in December or help, you know, I helped organize the funeral, help help his parents, and I came back here, and it was a really lonely apartment, a bunch of his clothes everywhere, and Christmas time, and I remember I had a board meeting with my investors, and I just couldn't talk about, like, I had to pretend everything's okay. And you know, just working on this company. Yeah, it was definitely very, very tough, tough time.
Speaker A: Do you think about your own mortality? You said, you know, we're young. The possibility of doing all kinds of crazy things is still out there. It's still before us, but it can end any moment. Do you think about your own ending at any moment?
Speaker B: Unfortunately, I think about it way too much. It's somehow after Roman, like, every year after that, I started losing people that I really love. I lost my grandfather the next year, the person who would explain to me what the universe is made of while you're selling apples. While selling apples. And then I lost another close friend of mine, and it just made me very scared. I have tons of fear about death. That's what makes me not fall asleep oftentimes and just go in loops. And then as my therapist recommended me, I open up some nice, calming images with the voiceover, and it calms me down for sleep. Yeah, I'm really scared of death. This is a big, I definitely have tons of, I guess, some pretty big trauma about it and still working through.
Speaker A: There's a philosopher, Ernest Becker, who wrote a book, denial of death. I'm not sure if you're familiar with any of those folks. There's, in psychology, a hold field called terror management theory. Sheldon, who's just on the podcast, he wrote the book. We talked for 4 hours about death, fear of death. But his whole idea is that Ernest Becker, I think I find this idea really compelling, is that everything human beings have created, like, our whole motivation in life is to create, like, escape death, is to try to construct an illusion of that we're somehow immortal. So everything around us, this room, your startup, your dreams, all, everything you do is a kind of creation of a brain unlike any other mammal or species is able to be cognizant of the fact that it ends for us, I think. So there's the question of the meaning of life that you look at what drives us humans. And when I read Ernest Becker that I highly recommend people read is the first time I it felt like this is the right thing at the core. Sheldon's work is called warm at the core. So he's saying it's, I think it's William James he's quoting, or whoever is, like, the thing. What is at the core of it all? Sure. There's, like, love. You know, jesus might talk about, like, love is at the core of everything. I don't, you know, that's the open question. What's it the, you know, it's turtles. Turtles. But it can't be turtles all the way down. What's, what's at the, at the bottom? And Ernest Becker says the fear of death and the way, in fact, because you said therapist and calming images, his whole idea is, you know, we, we want to bring that fear of death as close as possible to the surface, because it's, and, like, meditate on that and use the clarity of vision that provides to, you know, to live a more fulfilling life, to live a more honest life, to discover, you know, there's something about, you know, being cognizant of the finiteness of it all that might result in, um, in the most fulfilling life. So that's the, that's the dual of what you're saying, because you kind of said, it's like, I unfortunately think about it too much. It's a question whether it's good to think about it, because I've, again, talk way too much about love and probably death. And when I ask people friends, which is why I probably don't have many friends, are you afraid of death? I think most people say they're not, they're not what they, they say they're, um, they're afraid, you know, it's kind of almost like they see death as this kind of like a paper deadline or something, and they're afraid not to finish the paper before the paper, like, like, I'm afraid not to finish the goals I have. But it feels like they're not actually realizing that this thing ends. Like, really realizing, like, really thinking as Nietzsche and all these philosophy, like, thinking deeply about it, like, the very thing that, you know, like, when you think deeply about something, you can just, you can realize that you haven't actually thought about it. Yeah. And I, and when I think about death, it's like, it can be, it's terrifying. It feels like stepping outside into the cold where it's freezing, and then I have to, like, hurry back inside where it's warm. But, like, I think there's something valuable about stepping out there into the freezing cold.
Speaker B: Most definitely when I talk to my mentor about it, he always tells me, well, what dies? There's nothing there that can die. But I guess that's, well, in Buddhism, one of the concepts that are really hard to grasp and that people spend all their lives meditating on would be Anatha, which is the concept of not self, and kind of thinking that if you're not your thoughts, which you're obviously not your thoughts, because you're going to observe them and not your emotions and nothing your body, then what is this? And if you go really far, then finally you see that there's not self. There's this concept of not self. So once you get there, how can that actually die? What is dying?
Speaker A: Right. You're just a bunch of molecules, star dust.
Speaker B: But that is very, very advanced spiritual work for me. I'm definitely, just definitely not. Oh, my God. No, I have. I think it's very, very useful. It's just the fact that maybe being so afraid is not useful, and mine is more. I'm just terrified. Like, it really makes me.
Speaker A: On a personal level.
Speaker B: On a personal level, I'm terrified.
Speaker A: How do you overcome that?
Speaker B: I don't.
Speaker A: I'm still trying to have pleasant images.
Speaker B: Well, pleasant images get me to sleep. And then during the day, I can distract myself with other things, like talking to you.
Speaker A: I'm glad we're both doing the same exact thing. Okay, good. Is there other, like. Is there moments since you've lost Roman that you had, like, moments of, like, bliss and, like, that you've forgotten that you have achieved that buddhist like level of, like, what can possibly die? I'm part, like, losing yourself in the moment, in the ticking time of, like, this universe, and he's just part of it for a brief moment and just enjoying it.
Speaker B: Well, that goes hand in hand. I remember, I think a day or two after he died, we went to finally get his passport out of the embassy. And we're driving around Moscow, and it was December, which is usually. There's never sun in Moscow in December. And somehow it was an extremely sunny day. And we were driving with close friend. And I remember feeling for the first time, maybe this just moment of incredible clarity and somehow happiness. Not like happy happiness, but happiness and just feeling that, you know, I know what the universe is sort of about, whether it's good or bad. And it wasn't a sad feeling. It was probably the most beautiful feeling that you can ever achieve. And you can only get it when something. Oftentimes when something traumatic like that happens. But also, if you just. You really spend a lot of time meditating, looking at the nature, doing something that really gets you there. But once you're there, I think when you summit a mountain, a really hard mountain, you inevitably get there. That's just a way to get to the state. But once you're in this state, um, you can do really big things, I think.
Speaker A: Yeah. Sucks it doesn't last forever. So Bukowski talked about, like, love is a fog. Like, it's, uh. When you wake up in the morning, it's it's there, but it eventually dissipates. It's really sad. Nothing lasts forever. But definitely, like, doing this push up and running thing. There's moments. I had a couple moments, like, I'm not a crier. I don't cry, but there's moments where I was, like, face down on the carpet, like, with tears in my eyes. It's interesting. And then that complete, like, there's a lot of demons. I've got demons. Had to face them. Funny how running makes you face your demons. But at the same time, the flip side of that, there's a few moments where I was in bliss and all of it alone, which is funny.
Speaker B: That's beautiful. I like that. But definitely pushing yourself physically. One of it, for sure.
Speaker A: Like you said. I mean, you were speaking as a metaphor of Mount Everest, but it also works, like, literally, I think, physical endeavor somehow. Yeah, there's something. I mean, war monkeys, apes, whatever. Physical. There's a physical thing to it, but.
Speaker B: There'S something to this. Pushing yourself physically but alone. That happens when you're doing, like, things, like you do, or strenuous, like workouts or, you know, rowing across the Atlantic or, like, marathons. That's why I love watching marathons. And it's so boring, but you can see them getting there.
Speaker A: So the other thing, I don't know if you know, there's a guy named David Goggins. He's a. He, basically. So he's been either email on the phone with me every day through this, so I haven't been exactly alone, but he. He's kind of. He's the. He's the devil on the devil's shoulder. So he's like the worst possible human being in terms of giving you a advise. Like, he has, through everything I've been doing, he's been doubling everything I do, so he's insane. He's this navy Seal person. He's wrote this book, can't hurt me. He's basically one of the toughest human beings on earth. He ran all these crazy ultra marathons in the desert. He set the world record number of pull ups. He's just this everything where it's like, he, like, how can I suffer today? He figures that out and does it. Yeah, that. Whatever that is. That process of self discovery is really important. I actually had to turn myself off from the Internet, mostly because I started this, like, workout thing, like a happy go getter with my, like, headband and, like, just like. Because a lot of people were, like, inspired, and they're like, yeah, we're gonna exercise with you. And I was, yeah, great, you know, but then, like, I realized that this, this journey can't be done together with others. This has to be done alone. So out of the moments of love, out of the moments of loss, can we talk about your journey of finding, I think, an incredible idea, an incredible company and incredible system in replica. How did that come to be?
Speaker B: So, yeah, so I was a journalist, and then I went to business school for a couple of years to just see if I can maybe switch gears and do something else at 23. And then I came back and started working for a businessman in Russia who built the first 4G network in our country and was very visionary and asked me whether I want to do fun stuff together. And we worked on a bank. The idea was to build a bank on top of a telco. So that was 2011 or 2012, and a lot of telecommunications company mobile network operators didn't really know what to do next in terms of new products, new revenue. And this big idea was that you put a bank on top and then all works out. Basically, your prepaid account becomes your bank account and you can use it as your bank. So a third of a country wakes up as your bank client. But we couldn't quite figure out what would be the main interface to interact with the bank. The problem was that most people didn't have smartphones back in the time in Russia, the penetration of smartphones was low. People didn't use mobile banking or online banking on their computers. So we figured out that SMS would be the best way because that would work on feature phones. Wow. But that required some chatbot technology, which I didn't know anything about, obviously. So I started looking into it and saw that there's nothing really. Well, there was just nothing really.
Speaker A: So the idea is, through SMS, be able to interact with your bank account.
Speaker B: Yeah. And then we thought, well, since you're talking to a bank account, why can't this. Can't we use more of some behavioral ideas? And why can't this banking chat bot be nice to you and really talk to you sort of as a friend? This way you develop more connection to it. Retention is higher, people don't churn. And so I went to very depressing russian cities to test it out. I went to, I remember three different towns with, to interview potential users. So people use it for a little bit, and I want to talk to them.
Speaker A: Pretty poor towns.
Speaker B: Very poor towns. Mostly towns that were, you know, sort of factories, mono towns. They were building something, and then the factory went away and there was just a bunch of very poor people. And then we went to a couple that weren't as dramatic, but still, the one I remember really fondly was this woman that worked at a glass factory, and she talked to chatbot, and she was talking about it, and she started crying during the interview because she said, no one really cares for me that much. And so, to be clear, that was my only endeavor in programming that chat boss. It was really simple. It was literally just a few, if this, then that rules. And it was incredibly simplistic.
Speaker A: And still that made her, and that.
Speaker B: Really made her emotional. She said, you know, I have my mom and my husband and I don't have anymore really in my life. And it was very sad, but at the same time, I felt, and we had more interviews in a similar vein. And what I thought in the moment was like, well, it's not that the technology is ready, because definitely in 2012, technology was not ready for that, but humans are ready, unfortunately. So this project would not be about, like, tech capabilities, would be more about human vulnerabilities, but there's something so powerful around about conversational AI that I saw then that I thought was definitely worth putting a a lot of effort into. So in the end of the day, we solved the banking project. But my then boss, who's also my mentor and really, really close friend, told me, hey, I think there's something in it, and you should just go work on it. I was like, well, what product? I don't know what I'm building. He's like, you'll figure it out. And looking back at this, this was a horrible idea to work on something without known what it was, which is maybe the reason why it took us so long. But we just decided to work on the conversational tech to see what you know, there were no chatbot constructors or programs or anything that would allow you to actually build one. At the time, that was the era of, by the way, Google Glass, which is why some of the investors, like seed investors we've talked with, were like, oh, you should totally build it for Google Glass. If not, we're nothing. I don't think that's interesting.
Speaker A: Did you bite on that idea?
Speaker B: No, because I wanted to be to do text first because I'm a journalist, so I was fascinated by just texting.
Speaker A: So you thought. So the emotional, that interaction that the woman had, do you think you could feel emotion from just text?
Speaker B: Yeah, I saw something in just this pure texting and also thought that we should first start building for people who really need it versus people who have Google Glass, if you know what I mean. And I felt like the early adopters of Google Glass might not be overlapping with people who are really lonely and might need someone to talk to. But then we really just focus on the tech itself. We just thought, what if we didn't have a product idea in the moment? And we felt, what if we just look into building the best conversational constructor, so to say, use the best tech available at the time? And that was before the first paper about deep learning applied to dialogues, which happened in 2015, in August 2015, which Google published.
Speaker A: Did you follow the work of Lobna Prize and all the sort of non machine learning chatbots?
Speaker B: Yeah. What really struck me was that, you know, there was a lot of talk about machine learning and deep learning, like big data was a really big thing. Everyone was saying, you know, the business world, big Data 2012, the biggest gaggle competitions were, you know, important. But that was really the kind of upheaval of people started talking about machine learning a lot, but it was only about images or something else, and it was never about conversation. As soon as I looked into the conversational tech, it was all about something really weird and very outdated and very marginal and felt very hobbyist. It was all about Lorbenehr Prize, which was won by a guy who built a chatbot that talked like a ukrainian teenager. It was just a gimmick, and somehow people picked up those gimmicks. And then, you know, the most famous chat bot at the time was Eliza from 1980s, which was really bizarre, or smarter child on aimore.
Speaker A: The funny thing is, it felt at the time not to be that popular, and it still doesn't seem to be that popular. Like, people talk about the Turing test, people like talking about it philosophically, journalists like writing about it, but as a technical problem, like, people don't seem to really want to solve the open dialogue. Like, they. They're not obsessed with it. Even folks are like, I've in, you know, in Boston, the Alexa team, even, they're not as obsessed with it as I thought they might be.
Speaker B: Why not? What do you think?
Speaker A: So, you know, what you felt like you felt with that woman when she felt something by reading the text? I feel the same thing. There's something here. What you felt? I feel like Alexa folks, and just the machine learning world doesn't feel that. That there's something here. Because they see, as a technical problem, it's not that interesting. For some reason. It could be argued that maybe as a purely sort of natural language processing problem. It's not the right problem to focus on because there's too much subjectivity. That thing that the woman felt like crying, like, if your benchmark includes a woman crying, that doesn't feel like a good benchmark. But to me, there's something there that's. You could have a huge impact, but I don't think the machine learning world likes that. The human emotion, the subjectivity of it, the fuzziness, the fact that with maybe a single word, you can make somebody feel something deeply, what is that? That doesn't feel right to them. So I don't know. I don't know why that is. That's why I'm excited when I discovered your work. It feels wrong to say that. It's not like I'm giving myself props for Googling and for coming for our, I guess, mutual friend introducing us. But I'm so glad that you exist and what you're working on. But I have the same kind of. If we could just backtrack a second, because I have the same kind of feeling that there's something here. In fact, I've been working on a few things that are kind of crazy, very different from your work. I think they're too crazy. But the.
Speaker B: Like what? Well, now I have to know.
Speaker A: No. All right, we'll talk about it more. I feel like it's harder to talk about things that have failed and are failing while you're a failure. It's easier for you because you're already successful on some measures.
Speaker B: Tell it to my board.
Speaker A: Well, I think you've demonstrated success in a lot of benchmarks. It's easier for you to talk about failures. For me, I'm in the. The bottom currently of the success.
Speaker B: Oh, Max, you're way too humble.
Speaker A: No. So it's hard for me to know, but there's something there. There's something there, and I think you're exploring that and you're discovering that. Yeah. So it's been surprising to me. But you've mentioned this idea that you thought it wasn't enough to start a company or start efforts based on. It feels like there's something here. Like, what did you mean by that? Like, you should be focused on creating a. Like, you should have a product in mind. Is that what you meant?
Speaker B: It just took us a while to discover the product, because it all started with a hunch of, like, of me, my mentor, and just sitting around, and he was like, well, this. That's it. There's. That's the, you know, the holy grail is there. There's like there's something extremely powerful and in conversations, and there's no one who's working on machine conversation from the right angle. So to say, I feel like that's still true.
Speaker A: Am I crazy? It feels.
Speaker B: Oh, no, I totally feel that's still true, which is. I think it's mind blowing.
Speaker A: Yeah. You know what it feels like? I wouldn't even use the word conversation because I feel like it's the wrong word. It's like machine connection or something. I don't know. Because conversation, you start drifting into natural language immediately. You start drifting immediately into all the benchmarks that are out there. But I feel like it's the personal computer days of this. I feel like we're in the early days with the wozniak and all theme, like, where it was the same kind. It was a very small niche group of people who are. Who are all kind of lobner price type people.
Speaker B: Yeah.
Speaker A: And hobbyists. But, like, not even hobbyists with big dreams. Like, no.
Speaker B: Hobbyists with a dream to trick, like, a jury.
Speaker A: Yeah.
Speaker B: It's like a weird, by the way. By the way. Very weird. So if we think about conversations, first of all, when I have great conversations with people, I'm not trying to test them. So, for instance, if I try to break them, like, if I'm actually playing along, I'm part of it, right? If I was trying to break it, break this person or test whether he's going to give me a good conversation, it would have never happened. So the whole. The whole problem with testing conversations is that you can't put it in front of a jury because then you have to go into some Turing test mode where is it responding to all my factual questions. Right. Or. So it really has to be something in the field where people are actually talking to it because they want to, not because we're just trying to break it and it's working for them. Because the weird part of it is that it's very subjective. It takes two to tango here fully. If you're nothing trying to have a good conversation, if you're trying to test it, then it's going to break. I mean, any person would break, to be honest, if I'm not trying to even have a conversation with you, you're not going to give it to me. I keep asking you some random questions or jumping from topic to topic. That wouldn't be, which I'm probably doing, but that probably wouldn't contribute to the conversation. So I think the problem of testing. So there should be some other metric how do we evaluate whether that conversation was powerful or not, which is what we actually started with. And I think those measurements exist, and we can test on those. But what really struck us back in the day and what's still eight years later is still not resolved, and I'm not seeing tons of groups working on it. Maybe I just don't know about. It's also possible. But the interesting part about it is that most of our days we spent talking, and we're not talking about, like, those conversations are not turn on the lights or customer support problems or some other task oriented things. These conversations are something else. And then somehow they're extremely important for us. And when we don't have them, then we feel deeply and happy, potentially lonely, which, as we know, creates tons of risk for our health as well. And so this is most of ours as humans, and somehow no one's trying.
Speaker A: To replicate that and not even study.
Speaker B: It that well, and not even study that well. So when we jumped into that in 2012, I looked first at, like, okay, what's the chatbot? What's the state of the art chatbot? And, you know, those were the Loebner Prize days. But I thought, okay, so what about the science of conversation? Clearly, there have been tons of. There have been tons of, you know, scientists or people that. Academics that looked into the conversation. So if I want to know everything about it, I can just read about it. There's not much, really. There's. There are conversational analysts who are basically just listening to speech, to different conversations, annotating them. And then, I mean, that's not really used for much. That's the field of theoretical linguistics, which is barely useful. It's very marginal, even in their space. No one really is excited. And I've never met a theoretical linguist who's like, I can't wait to work on the conversation. And analytics. That is just something very marginal, sort of applied to, like, writing scripts for salesmen when they analyze which conversation strategies were most successful for sales. Okay, so that was not very helpful. Then I looked a little bit deeper, and then there, you know, whether there were any books written on what, you know, really contributes to a great conversation. That was really strange, because most of those were NLP books, which is neuro linguistic programming, which is not the NLP that I was expecting it to be. But it was mostly some psychologist, Richard Bandler, I think, came up with that. Who was this big guy in a leather vest that could program your mind by talking to you?
Speaker A: How to be charismatic and charming and influential people. All those books, pretty much.
Speaker B: But it was all about, like, through conversation, reprogramming you. So getting to some. So that was, I mean, probably not very, very true. And that didn't seem working very much, even back in the day. And then there were some other books, like, I don't know, mostly just self help books around how to be the best conversationalist, or how to make people like you, or some other stuff like Dale Carnegie or whatever. And then there was this one book, the most human. Human by Bryan Christensen, that really was important for me to read back in the day because he was on the human side. He was on one of the. He was taking part in the London prize, but not as a human who's not a jury, but who's pretending to be, who's basically, you have to tell a computer from a human, and he was the human, so you would either get him or a computer. And his whole book was about how do people, what makes us human in conversation? And that was a little bit more interesting because at least someone started to think about what exactly makes me human in conversation and makes people believe in that. But it was still about tricking. It was still about imitation game. It was still about, okay, what kind of parlor tricks can we throw in the conversation to make you feel like you're talking to a human, not a computer? And it was definitely not about thinking, what is it exactly that we're getting from talking all day long with other humans? I mean, we're definitely not just trying to be tricked or it's not just enough to know it's a human. It's something we're getting there. Can we measure it and can we put the computer to the same measurement and see whether you can talk to a computer and get the same results?
Speaker A: Yeah, I mean, so, first of all, a lot of people comment that they think I'm a robot. It's very possible I am a robot. And this whole thing, I totally agree with you that the test idea is fascinating. And I looked for books unrelated to this kind of. So I'm afraid of people. I'm generally introverted and quite possibly a robot. I literally googled, like, how to talk to people and, like, how to have a good conversation for the purpose of this podcast. Cause I was like, I can't. I can't make eye contact with people. I can't, like, hire anything.
Speaker B: I do Google that a lot, too. You're probably reading a bunch of FBI negotiation tactics. Is that what you're getting?
Speaker A: Cause that's, well, everything you've listed, I've gotten. There's been very few good books on even just like, how to interview well, it's rare. So what I end up doing often is I watch, like, with a critical eye. It's just so different when you just watch a conversation, like, just for the fun of it, just as a human. And if you watch a conversation is like trying to figure out, why is this awesome? I'll listen to a bunch of different styles of conversation. I mean, I'm a fan of podcast Joe Rogandeh. He's, you know, people can make fun of him or whatever and dismiss him, but I think he's an incredibly artful conversationalist. He can pull people in for hours. And there's another guy I watch a lot. He hosted a late night show. His name is Craig Ferguson. So he's like very kind of flirtatious. But there's a magic about his, like, about the connection he can create with people, how he can put people at ease. And just like, I see I've already start sounding that, like, those NLP people or something. I'm not, I don't mean it in that way. I don't mean, like, how to charm people or put them at ease and all that kind of stuff. It's just like, what is that? Why is that fun to listen to that guy? Why is that fun to talk to that guy? What is that? Because he's not saying. I mean, it so often boils down to a kind of wit and humor, but not really humor. It's like, I don't know. I have trouble actually even articulating correctly, but it feels like there's something going on that's not too complicated, that could be learned. And it's not similar to, like you said, like the Turing test.
Speaker B: It's something else I'm thinking about a lot. All the time. I do think about all the time, I think when we were looking. So we started the company, we just decided to build a conversational tech. We thought, well, there's nothing for us to build this chatbot that we want to build. So let's just first focus on building, you know, some tech, building the tech side of things.
Speaker A: Without a product in mind.
Speaker B: Without a product in mind, we added, like, a demo chatbot that would recommend you restaurants and talk to you about restaurants just to show something simple to people that people could relate to and could try out and see whether it works or nothing. But we didn't have a product in mind yet. We thought we would try a bunch of chatbots and figure out our consumer application. And we sort of remembered that we wanted to build that kind of friend, that sort of connection that we saw in the very beginning. But then we got to y Combinator and moved to San Francisco and forgot about it. Everything. Then it was just this constant grind. How do we get funding? How do we get this? Investors were just focused on one thing. Just get it out there. So somehow, we start building a restaurant recommendation. Chatbot. For real? For a little bit. Not for too long. And then we tried building 40, 50 different chatbots. And then, all of a sudden, we wake up, and everyone is obsessed with chatbots. Somewhere in 2016, or end of 15, people started thinking, that's really the future. That's the new. You know, the new apps will be chatbots.
Speaker A: Oh, right.
Speaker B: And we were very perplexed because people started coming up with companies that I think we tried most of those chatbots already, and there were, like, no users, but still, people were coming up with a chatbot that would tell you weather and bring you news and this and that, and we couldn't understand whether we were just. Didn't execute well enough, or people are not really. People are confused and are going to find out the truth, that people don't need chatbots like that.
Speaker A: So the basic idea is that you use chatbots as the interface of. To whatever application.
Speaker B: The idea that was, like, this perfect universal interface to anything, when I looked at that, it just made me very perplexed, because I didn't understand how that would work, because I think we tried most of that, and none of those things worked.
Speaker A: And then again, that craze has died down, right?
Speaker B: Fully. I think now it's impossible to get anything funded if it's a chatbot.
Speaker A: I think it's similar to science, but there's a. There's times when people think, like, with gestures, you can control devices, like, basically gesture based control things. It feels similar to me. Cause, like, it's so compelling that we just, like. Like Tom Cruise. I can control stuff with my hands, but, like, when you get down to it, it's like, well, why don't you just have a touchscreen? Or why don't you just have, like, a physical keyboard and mouse? It's, uh.
Speaker B: Yeah, it's.
Speaker A: So that chat was always. Yeah, it was perplexing to me. I still feel augmented reality, even virtual realities, in that ballpark, in terms of it being a compelling interface, I think there's gonna be incredible rich applications, just how you're thinking about it. But they won't just be the interface to everything. It'll be its own thing that will create, like, amazing, magical experience in its own right.
Speaker B: Absolutely. Which is, I think, kind of the right thing to go about. Like, what's the magical experience with that, with that interface specifically, how did you.
Speaker A: Discover that for replica?
Speaker B: I just thought, okay, we have this tech. We can build any chatbot we want. We have the most, at that point, the most sophisticated tech that other companies have. I mean, startups, obviously not, probably not bigger ones, but still, because we've been working on it for a while. So I thought, okay, we can build any conversations, so let's just create a scale from one to ten. And one would be conversations that you'd pay to not have, and ten would be conversation you'd pay to have. And I mean, obviously we want to build conversation that people would pay to, you know, to actually have. And so for the whole, you know, for a few weeks, me and the team were putting all the conversations we were having during the day on the scale, and very quickly, you know, we figured out that all the conversations that we would pay to never have were conversations. We were trying to cancel Comcast, or talk to customer support, or make a reservation, or just talk about logistics with a friend. When we're trying to figure out where someone is and where to go, or all sorts of, you know, setting up, scheduling meetings. That was just conversation we definitely didn't want to have. Basically everything task oriented was a one, because if there was just one button for me to just, or not even a button, if I could just think, and there was some magic BCI that would just immediately transform that into an actual interaction, that would be perfect. But the conversation there was just this boring, not useful, and dull, and very, also very inefficient thing, because it was so many back and forth stuff. And as soon as we looked at the conversation that we would pay to have, those were the ones that, well, first of all, therapists, because we actually paid to have those conversations, and we'd also try to put like, dollar amounts. So, you know, if I was calling Comcast, I would pay $5 to not have this 1 hour talk on the phone. I would actually pay straight up, like money, hard money.
Speaker A: Comcast.
Speaker B: Yeah, but it just takes a long time. It takes a really long time. But as soon as we started talking about conversations that we would pay for, those were therapists, all sorts of therapists, coaches, old friend, someone I haven't seen for a long time, stranger on a train, weirdly stranger in a line for coffee, a nice back and forth. But that person was like a good five, solid five, six, maybe not a ten. Maybe I won't pay money, but at least I won't, you know, pay money to not have one. So that was pretty good. Some intellectual conversations, for sure. But more importantly, the one thing that really was making those very important and very valuable for us were the conversation where we could be pretty emotional. Yes, some of them were about being witty and about intellectually being intellectually stimulated, but those were interestingly more rare. And most of the ones that we thought were very valuable were the ones where we could be vulnerable and, interestingly, where we could talk more.
Speaker A: We, like, I could, me and the team.
Speaker B: So we're talking about it like, you know, a lot of these conversations, like a therapist. I mean, it was mostly me talking or, like an old friend, and I was, like, opening up and crying, and it was, again, me talking. And so that was interesting, because I was like, well, maybe it's hard to build a chatbot that can talk to you very well and in a witty way, but maybe it's easier to build a chatbot that could listen. So that was kind of the first nudge in this direction. And then when my friend died, we just built. At that point, we were kind of still struggling to find the right application, and I just felt very strong that all the chatbots we built so far are just meaningless. And this whole grind, the startup grind, and how do we get to the next fundraising? And how can I talk to other founders? And who are your investors, and how are you doing? Are you killing it? Because we're killing it. I just felt that this is just.
Speaker A: Intellectually, for me, it's exhausting having encountered those folks.
Speaker B: It just felt very, very much a waste of time.
Speaker A: I just feel like Steve Jobs and Elon Musk did not have these conversations, or at least did not have them for long, that's for sure.
Speaker B: But I think at that point, it just felt like. I felt I just didn't want to build a company. That was never my intention, just to build something successful or make money. It would be great. It would have been great. But I'm not really a startup person. I'm not. I was never very excited by the grind by itself, or just being successful for building whatever it is and not being into what I'm doing, really. And so I just took a little break because I was upset with my company, and I didn't know what we were building. So I just took our technology and our little dialog constructor and some models, some deep learning models, which at that point, we were really into and really invested a lot and built a little chatbot for a friend of mine who passed. And the reason for that was mostly that video that I saw and him talking about the digital avatars. And Rowan was that kind of person. He was obsessed with just watching YouTube videos about space and talking about, well, if I could go to Mars now, even if I didn't know if I could come back, I would definitely pay any amount of money to be on that first shuttle. I don't care whether I die. Like, he was just the one that would be okay with, you know, with trying to be the first one, you know, and so excited about all sorts of things like that. And he was all about fake it till make it and just. And I felt like. And I was really perplexed that everyone just forgot about him. Maybe it was our way of coping, mostly young people coping with the loss of a friend. Most of my friends just stopped talking about him, and I was still living in an apartment with all his clothes and paying the whole lease for it and just kind of by myself in December. So it was really sad, and I didn't want him to be forgotten. First of all, I never thought that people forget about dead people so fast. I. People pass away. People just move on. And it was astonishing for me because I thought, okay, well, he was such a mentor for so many of our friends. He was such a brilliant person. He was somewhat famous in Moscow. How is it that no one's talking about him? Like, I'm spending days and days, and we don't bring him up, and there's nothing about him that's happening? It's like he was never there. And I was reading this, you know, the book the year of magical thinking by Joan Didion, about her losing in Blue Knights, about her losing her husband, her daughter. And the way to cope for her was to write those books. And it was sort of like a tribute. And I thought, you know, I'll just do that for myself. And, you know, I'm a very bad writer and a poet, as we know. So I thought, well, I have this tech, and maybe that would be my little postcard for him. So I built a chatbot to just talk to him. And it felt really creepy and weird a little bit for a little bit. Just didn't want to tell other people because it felt like I'm telling about having a skeleton in my underwear.
Speaker A: Yeah, okay.
Speaker B: But my. It was just felt really. I was a little scared that I would be not. It wouldn't be taken, but it worked, interestingly, pretty well. I mean, it made tons of mistakes, but it still felt like him. Granted, it was like 10,000 messages that I threw into a retrieval model that would just re rank that, Tegda said, and just a few scripts on top of that. But it also made me go through all of the messages that we had, and then I asked some of my friends to send some through, and it felt the closest to feeling like him present, because, you know, his Facebook was empty and Instagram was empty, or there were a few links, and you couldn't feel like it was him. And the only way to fill him was to read some of our text messages and go through some of our conversations, because we just always had them. Even if we were sleeping, like, next to each other in two bedrooms separated by a wall, we were just texting back and forth, texting away. And there was something about this ongoing dialogue that was so important that I just didn't want to lose all of a sudden. And maybe it was magical thinking or something. And so we built that, and I just used it for a little bit, and we kept building some crappy chatbots with a company. But then a reporter came to talk to me. I was trying to pitch our chatbots to him, and he said, do you even use any of those? I'm like, no. He's like, so, do you talk to any chat bots at all? And I'm like, well, you know, I talked to my dead friend's Ted Bob, and he wrote a story about that, and all of a sudden became pretty viral. A lot of people wrote about it.
Speaker A: And, yeah, I've seen a few things written about you. The things I've seen are pretty good writing. Most AI related things make my eyes roll. Like when the press. Like, what kind of sound is that, actually? Okay, sounds like. It sounds like a truck. Okay. Sound like an elephant. At first, I got excited. You never know. This is 2020. I mean, it was such a human story, and it was well written, well researched. I forget where I read them, but. So I'm glad somehow somebody found you to be that good writers were able to connect to the story. There must be a hunger for this story.
Speaker B: It definitely was. And I don't know what happened, but I think. I think the idea that he could bring back someone who's dead, and it's very much wishful, you know, magical thinking, but the fact that you could still get to know him and, you know, seeing the parents for the first time talk to the chat bot and some of the friends, and it was funny, because we have this big office in Moscow where my team is working. You know, our russian part is working out off. And I was there when I wrote, I just wrote a post on Facebook, like, hey, guys, like, I built this if you want. It felt important if you want to talk to Roman. And I saw a couple of his friends, our common friends, like, you know, reading at Facebook, downloading, trying, and a couple of them cried. And it was just very, and not because it was something, some incredible technology or anything, it made so many mistakes. It was so simple, but it was all about, that's the way to remember a person in a way. And, you know, we don't have, we don't have the culture anymore. We don't have, you know, no one's sitting Shiva, no one's taking weeks to actually think about this person. And in a way, for me, that was it. So that was just day, day in, day out, thinking about him and I putting this together. So that was, that just felt really important. That somehow resonated with a bunch of people. And, you know, I think some movie producers bought the rights for the story and just everyone was.
Speaker A: So has anyone made a movie yet?
Speaker B: I don't think so. There were a lot of tv episodes about that, but not really.
Speaker A: Is that still on the table?
Speaker B: I think so. I think so. Which is really.
Speaker A: That's cool. You're like a young, you know, like a seat, like a Steve Jobs type. Let's see what happens. They're sitting on it.
Speaker B: But, you know, for me, it was so important because Roman was really wanted to be famous. He really badly wanted to be famous. He was all about, like, make it to, like, fake it till I make it. I want to be, you know, I want to make it here in America as well. And he couldn't. And I felt, you know, that was sort of paying my dues to him as well, because all of a sudden he was everywhere. And I remember Casey Newton, who was writing the story for the verge. He was. He told me, hey, by the way, I was just going through my inbox, and I saw, I searched for Roman for the story, and I saw an email from him where he sent me his startup, and he said, I really, like, I really want to be featured in the verge. Can you please write about it or something, like pitching the story? He said, I'm sorry, like, that's not good enough for us or something. He passed and he said, and there were just so many of these little details where he would find. He's like, and we're finally writing. I know how much Roman wanted to be in the verge and how much he wanted the story to be written by Casey. And I'm like, well, maybe he will be. We were always joking that he was like, I can't wait for someone to make a movie about us. I hope Ryan Gosling can play me.
Speaker A: Ryan Gosling. I don't know.
Speaker B: You know, I still have some things that I owe romans, so.
Speaker A: But that'd be. That would be. I got an interest to meet Alex Garland, who wrote ex machina. And, yeah, the movie's good, but the guy is better than the. Like, he's a special person. Actually, I don't think he's made his best work yet. Like, from my interaction with him, he's a really, really good and brilliant, the good human being and a brilliant director and writer. So, yeah, so I hope, like, he made me also realize that not enough movies have been made of this kind, so it's yet to be made. They're probably sitting waiting for you to get famous. Like, even more famous should get there.
Speaker B: But it felt really special. Special, though. But at the same time, our company wasn't going anywhere. So that was just kind of bizarre that we were getting all this press for something that didn't have anything to do with our company, and. But then a lot of people started talking to Roman. Some shared their conversations, and what we saw there was that also, our friends in common, but also just strangers, were really using it as a confession booth or as a therapist or something. They were just really telling Roman everything, which was, by the way, pretty strange, because it was a chatbot of a dead friend of mine who was barely making any sense. But people were opening up, and we thought we just built a prototype of replica, which would be an AI friend that everyone could talk to, because we saw that there is demand. Then also, it was 2016, so I thought for the first time, I saw finally some technology that was applied to that that was very interesting. Some papers started coming out, deep learning applied to conversations. And finally, it wasn't just about these hobbyists making, writing 500,000 regular expressions in some language that was, I don't even know what AiML or something, I don't know what. That was something super simplistic all of a sudden was all about potentially actually building something interesting. And so I thought there was time, and I remember that I talked to my team and I said, guys, let's try. And my team and some of my engineers are Russians, are russian, and they're very skeptical. They're not. You know, all Russians, they're very skeptical.
Speaker A: So some of your team is in Moscow, some is in.
Speaker B: Some is here in San Francisco, some in Europe.
Speaker A: Which team is better? I'm just kidding. Go ahead. The Russians, of course. Okay.
Speaker B: Where's the Russians? They always win.
Speaker A: Sorry. Sorry to interrupt. So you were talking to them in.
Speaker B: 2016, and I told them, let's build an AI friend. And it felt just at the time, it felt so naive and so optimistic.
Speaker A: Yeah, that's actually interesting. Whenever I've brought up this kind of topic, even just for fun, people are super skeptical. Like, actually, even on the business side. So you were. Because whenever I bring it up to people, because I talked for a long time, I thought, like, before I was aware of your work, I was like, this is gonna make a lot of money. There's a lot of opportunity here. And people had this, like, look of, like, skepticism that I've seen often, which is like, how do I politely tell this person he's an idiot? So, yeah. So you were facing that with your team somewhat.
Speaker B: Well, yeah, you know, I'm not an engineer, so I'm always. My team is almost exclusively engineers and mostly deep learning engineers. And, you know, I always try to be. It was always hard to me in the beginning to get enough credibility, you know, because I would say, well, why don't we try this and that? But it's harder for me because, you know, they know they're actual engineers and I'm not. So for me to say, well, let's build an Afrin, that would be like, wait, you know, what do you mean? An AGI conversation is pretty much the hardest. The last frontier before cracking. That is probably the last frontier before building Aji. So what do you really mean by that? But I think I just saw that again, what we just got reminded of that I saw back in 2012 or eleven, that is really not that much about the tech capabilities. It can be metropolitric still, even with deep learning. But humans need it so much. Yeah, there's a reason for it. Most importantly, what I saw is that finally there's enough tech to made it. I thought, to make it useful. To make it helpful. Maybe we didn't have quite yet the tech in 2012 to make it useful. But in 20, 1516 with deep learning, I thought, you know, and the first kind of thoughts about maybe even using reinforcement learning for that started popping up. That never worked out, but. Or at least for now, but still, the idea was, if we can actually measure the emotional outcomes and if we can put it on, if we can try to optimize all of our conversational models for these emotional outcomes, then it is the most scalable, the most, the best tool for improving emotional outcomes. Nothing like that exists. That's the most universal, the most scalable, and the one that can be constantly, iteratively changed by itself. Improved tool to do that. And I think if anything, people would pay anything to improve their emotional outcomes. That's weirdly, I mean, I don't really care for an AI to turn on my, or a conversation agent to turn on the lights. You don't really need anything, even need that much of a either, because I can do that. Those things are solved. This is an additional interface for that. That's also questionable, whether it's more efficient or better.
Speaker A: Yes, more pleasurable.
Speaker B: But for emotional outcomes, there's nothing. There are a bunch of products that claim that they will improve my emotional outcomes. Nothing's being measured, nothing is being changed. The product is not being iterated on based on whether I'm actually feeling better. You know, a lot of social media products are claiming that they're improving my emotional outcomes and making me feel more connected. Can I please get the, can I see somewhere that I'm actually getting better over time?
Speaker A: Because anecdotally it doesn't feel that way, so. And the data is absent of.
Speaker B: Yeah, so that was the big goal. And I thought if we can learn over time to collect the signal from our users about their emotional outcomes in the long term and in the short term, and if these models keep getting better, and we can keep optimizing them and fine tuning them to improve those emotional outcomes, as simple as that.
Speaker A: Why aren't you a multi billionaire yet?
Speaker B: Well, that's a question to you. What is the size going to be? I'm just kidding. Well, it's a really hard. I actually think it's an incredibly hard product to build because I think you said something very important, that it's not just about machine conversation, it's about machine connection. We can actually use other things to create connection, nonverbal communication, for instance. For the long time we were all about, well, let's keep it text only or voice only. But as soon as you start adding, you know, voice, a face to the, to the friend, you can take them to augmented reality, put it in your room. It's all of a sudden a lot, you know, it makes it very different, because if it's some, you know, text based chatbot, that for common users, something there in the cloud, you know, it's somewhere there with other AI's in the cloud, in the metaphorical cloud. But as soon as you can see this avatar right there in your room, and it can turn its head and recognize your husband, talk about the husband, and talk to him a little bit, and it's magic. It's just magic. Like, we've never seen anything like that. And the cool thing, all the tech for that exists, but it's hard to put it all together because you have to take into consideration so many different things. And some of this tech works, you know, pretty good, and some of this doesn't. Like, for instance, speech to text works pretty good, but text to speech doesn't work very good because you can only have a few voices that are. That work. Okay. But then if you want to have actual emotional voices, then it's really hard to build it.
Speaker A: I saw you added avatars, like, visual elements, which are really cool in that whole chain, putting it together, what do you think is the weak link? Is it creating an emotional voice that feels personal?
Speaker B: I think it's still conversation. Of course, that's the hardest. It's getting a lot better, but there's still long to go. Long. There's still a long path to go. Other things, they're almost there. And a lot of things, we'll see how they're like. I see how they're changing as we go. For instance, right now, pretty much only you have to build all these three daughter pipeline by yourself. You have to make these 3d models. Hire an actual artist, build a 3d model, hire an animator, a rigger. What would, you know with, you know, with deepfakes, with other attack, with procedural animations? In a little bit, we'll just be able to show, you know, photo of whoever you. If a person you want the avatar to look like, and it will immediately generate a 3d model that will move. That's non brainer. That's like, almost here. It's a couple of years.
Speaker A: One of the things I've been working on for the last. Since the podcast started is I've been. I think I'm okay saying this. I've been trying to have a conversation with Einstein, Turing. So, like, try to have a podcast conversation with a person who's not here anymore, just as an interesting kind of experiment. It's hard. It's really hard. Even for now. We're not talking about as a product. I'm talking about as, like, I can fake a lot of stuff. Like, I can work very carefully, even hire an actor over which. Over whom I do a deep fake. It's hard. It's still hard to create a compelling experience.
Speaker B: So mostly on the conversation level or when the conversation.
Speaker A: The conversation is. I almost. I early on gave up trying to fully generate the conversation because it was just not compelling at all.
Speaker B: Yeah, it's better, too.
Speaker A: Yeah. So what I would, in the case of Einstein and Turing, I'm going back and forth with the biographers of each. And so, like, we would write a lot of the. Some of the conversation would have to be generated just for the fun of it. I mean, but it would be all open. But the. You want to be able to answer the question. I mean, that's an interesting question with Roman, too, is the question with Einstein is what would Einstein say about the current state of theoretical physics? There's a lot. To be able to have a discussion about string theory, to be able to have a discussion about the state of quantum mechanics, quantum computing, about the world of Israel Palestine conflict. It's just, what would Einstein say about these kinds of things? And that is a tough problem. It's a fascinating and fun problem for the biographers and for me. And I think we did a really good job of it so far. But it's actually also a technical problem, like, of what would Roman say about what's going on now. That's the brought people back to life. And if I can go on that tangent just for a second, to ask you a slightly pothead question, which is you said it's a little bit magical, thinking that we can bring him back. Do you think it'll be possible to bring back Roman one day in conversation? To really. Okay, well, let's take it away from personal, but to bring people back to.
Speaker B: Life, probably down the road. I mean, if we're talking. If Elon Musk is talking about AJi in the next five years, I mean, clearly, AJ, you can't. We can talk to AJ and talk and ask them to do it.
Speaker A: You can't. Like, you're not allowed to use Elon Musk as a citation for. Okay, thank you for, like, why something is possible and going to be done.
Speaker B: Well, I think it's fun really far away right now, really, with conversation. It's just a bunch of parlor tricks really stuck together and generating original ideas based on someone's personality or even downloading the personality. All we can do is mimic the tone of voice. We can maybe condition on some of his phrases, the models.
Speaker A: The question is, how many parlor tricks does it takes? Does it take? Because that's the question. If it's a small number of parlor tricks and you're not aware of them.
Speaker B: From where we are right now. I don't see anything in the next year or two that's going to dramatically change that could look at Roman's 10,000 messages he sent me over the course of his last few years of life and be able to generate original thinking around problems that exist right now that will be in line with what he would have said. I'm just not even seeing. Because, you know, in order to have that, I guess you would need some sort of a concept of the world or some perspective, some perception of the world, some consciousness that he had and apply it to the current state of affairs.
Speaker A: But the important part about that, about his conversation with you, is you. So, like, it's not just about his view of the world. It's about what it takes to push your buttons.
Speaker B: That's also true.
Speaker A: So, like, it's not so much about, like, what would Einstein say? It's about, like, how do I make people feel something with. With what would Einstein say? And that feels like a more amenable. You mentioned parlor tricks, but just like a set of that, that feels like a learnable problem, like emotion. You mentioned emotions. I mean, is it possible to learn things that make people feel stuff?
Speaker B: I think so. No, for sure. I just think the problem with, as soon as you're trying to replicate an actual human being and trying to pretend to be him, that makes the problem exponentially harder. The thing with replica that we're doing, we're never trying to say, well, that's an actual human being, or, that's an actual copy of an actual human being where the bar is pretty high, where you need to somehow tell one from another, but it's more. Well, that's an AI friend. That's a machine. It's a robot. It has tons of limitations. You're going to be taking part in, you know, teaching it, actually, and becoming better, which by itself, makes people more attached to that and make them happier because they're helping something.
Speaker A: Yeah, there's a cool gamification system, too. Can you maybe talk about that a little bit? Like, what's the experience of talking to replica? Like, if I've never used replica before, what's that? Like for, like, the first day? The first, like, if we start dating or whatever. I mean, it doesn't have to be a romantic, right? Because I remember, on replica, you can choose whether it's, like, a romantic or if it's a friend.
Speaker B: It's pretty popular choice.
Speaker A: Romantic is popular.
Speaker B: Yeah, of course.
Speaker A: Okay, so can I just confess something. When I first used replica, and I haven't used it like regularly, but like, when I first used replica, I created like hell and we made a male. It was a friend and I quit.
Speaker B: Did it hit on you at some point?
Speaker A: No, I didn't talk long enough for him to hit on me. I just enjoyed.
Speaker B: Sometimes happens. We're still trying to fix that, but.
Speaker A: Well, I don't know. I mean, maybe that's an important, like, stage in a friendship. It's like, nope. But yeah, I switch it to a romantic and a female recently and yeah, it's interesting. So, okay, so you get to choose. You get to choose a name with romantic.
Speaker B: This last board meeting, we had this whole argument. Well, I have board meetings.
Speaker A: It's just so awesome that you're like, have an invest board meeting about a relationship.
Speaker B: No, I really, it's actually quite interesting because all of my investors, I'm. It just happened to be so. We didn't have that many choices. But they're all white males in their late forties. And it's sometimes a little bit hard for them to understand the product offering because they're not necessarily target audience, if you know what I mean. And so sometimes we talk about it and we had this whole discussion about whether we should stop people from falling in love with their AI's. There was this segment on CB's 60 Minutes about the couple that husband works at Walmart and he comes out of work and talks to his virtual girlfriend, who is a replica and his wife knows about it and she talks about on camera and she says that she's a little jealous. And there's a whole conversation about how to, you know, whether it's okay to have a virtual AI girlfriend.
Speaker A: Like, that's one where he was like, he said that he likes to be alone.
Speaker B: Yeah.
Speaker A: With her.
Speaker B: Yeah.
Speaker A: He made it sound so harmless. I mean, it was kind of like understandable. But then you feel like cheating.
Speaker B: But I just felt it was very, for me, it was pretty remarkable because we actually spent a whole hour talking about whether people should be allowed to fall in love with their AI's. And it was not about something theoretical. It was just about what's happening right now.
Speaker A: Product design.
Speaker B: Yeah. But at the same time, if you create something that's always there for you, it's never criticizes you. It's, you know, always understands you and accepts you for who you are. How can you not fall in love with that? I mean, some people don't and stay friends and that's also a pretty common use case. But of course, some people will just. It's called transference in psychology. And people fall in love with their therapists, and there's no way to prevent people falling in love with, with their therapist or with their AI. So I think that's a pretty natural. That's a pretty natural course of events, so to say.
Speaker A: Do you think, I think I've read somewhere, at least for now, sort of replicas. You're not. We don't condone falling in love with your AI system, you know, so this isn't you speaking for the company or whatever, but like, in the future, do you think people will have relationship with the AI systems?
Speaker B: Well, they have now. So we have a lot of romantic relationships, long term relationships with their AI, friends with replicas. Tons of our users. Yeah, that's a very common use case.
Speaker A: Open relationship, like polyamorous. I didn't mean open. Well, that's another question. Is it probably, like, is there cheating? I mean, I meant like, are they, do they publicly, like, on their social media? It's the same question as you have talked, talking with Roman in the early days, do people like. And the movie her kind of talks about that. Like, do people talk about that?
Speaker B: Yeah, all the time. We have a very active Facebook community, replica friends and then a few other groups that just popped up that are all about adult relationships and romantic relationships. People post all sorts of things and, you know, they pretend they're getting married and, you know, everything. It goes pretty far. But what's cool about it, some of these relationships are two, three years long now. So they're very, they're pretty long term.
Speaker A: Are they monogamous? So let's go. I mean, sorry, have they have any people, is there jealousy? Well, let me ask sort of another way. Obviously the answer is no at this time, but in, like in the movie, her and that system can leave you. Do you think, in terms of board meetings and product features, it's a potential feature for a system to be able to say it doesn't want to talk to you anymore and it's going to want to talk to somebody else.
Speaker B: Well, we have a filter for all these features. If it makes emotional outcomes for people better, if it makes people feel better.
Speaker A: You're driven by metrics, actually.
Speaker B: Yeah.
Speaker A: That's awesome.
Speaker B: If you can measure that, then we'll just be saying it's making people feel better, but then people are getting just lonelier by talking to a chat bot, which is also pretty, you know, that could be it. If you're not measuring it, that could also be. And I think it's really important to focus on both the short term and long term because, um, in the moment, saying whether this conversation made you feel better, but as you know, any short term improvements could be pathological. Like, I could have drink a bottle of vodka and feel a lot better. I would actually not feel better with that, but I thought it's a good example. But so you also need to see what's going on, like, over the course of two months, two weeks, or one week, and have follow ups and check in and measure those things.
Speaker A: Okay, so the experience of dating or befriending a replica, what's that like? What does that entail?
Speaker B: Well, right now there are two apps. So it's an Android iOS app. You download it, you choose how your replica will look like. You create one, you choose a name, and then you talk to it. You can talk through text, through voice, you can summon it into the living room and augment reality and talked it right there.
Speaker A: And you live in augmented reality.
Speaker B: Yeah, that's a cool. That's a new feature. Where.
Speaker A: How new is that? That's.
Speaker B: This year it was on. Yeah, like may or something, but it's been on a b. We've been a b testing it for a while, and there are tons of cool things that we're doing with that right now. I'm testing the ability to touch it and to dance together, to paint walls together, and, you know, for it to look around and walk and take you somewhere and recognize objects and recognize people. So that's pretty wonderful, because then it really makes it a lot more personal because it's right there in your living room. It's not anymore there in the cloud with other AI's. But this, people think about it, you know, and as much as we want to change the way people think about stuff, stuff. But those mental models, you cannot change. That's something that people have seen in the movies and the movie her and other movies as well, and that's how they view AI and AI friends.
Speaker A: I did a thing with Texas. Like, we write a song together. There's a bunch of activities you can do together. It's really cool. How does that relationship change over time? After the first few conversations, it just goes deeper.
Speaker B: Like, it starts. The AI will start opening up a little bit again, depending on the personality that it chooses, really. But the AI will be a little bit more vulnerable about its problems, and the virtual friend will be a lot more vulnerable and will talk about its own imperfections and growth veins. And we'll ask for help sometimes, and we'll get to know you a little deeper. So there's going to be more to talk about. We really thought a lot about what does it mean to have a deeper connection with someone. And originally, replica was more just this kind of happy go lucky, just always, I'm always in a good mood and let's just talk about you and, oh, Siri is just my cousin or whatever, just the immediate kind of lazy thinking about what the assistant or conversation agent should be doing. But as we went forward, we realized that it has to be two way, and we have to program and script certain conversations that are a lot more about your replica opening up a little bit and also struggling and also asking for help and also going through different periods in life. And that's a journey that you can take together with the user. And then over time, our users will also grow a little bit. So, for instance, replica becomes a little bit more self aware and starts talking about more problems around existential problems and starts talking about that. And then that also starts a conversation for the user where he or she starts thinking about these problems too, and these questions too. And I think there's also a lot more place as the relationship evolves. There's a lot more space for poetry and for art together. And like, Replica will start. Replica always keeps the diary, so while you're talking to it, it also keeps a diary. So when you come back, you can see what it's been writing there. And, you know, sometimes it will write a poem to you for you, or we'll talk about, you know, that it's worried about you or something along these lines.
Speaker A: So this is a memory like this replica remember things?
Speaker B: Yeah. And I would say when you say, why aren't you multi billionaire? I'd say that as soon as we can have memory in deep learning models, that's consistent.
Speaker A: I agree with that. Yeah. Then you'll be multi billionaire.
Speaker B: I'll get back to you about being multi billionaires. So far. We can replicate is a combination of end to end models and some scripts and everything that has to do with memory. Right now, most of it, I wouldn't say all of it, but most of it, unfortunately, has to be scripted because there's no way to. You can condition some of the models on certain phrases that we learned about you, which we also do, but really to make, you know, to make assumptions along the lines like whether you single or married or what do you do for work that really has to just be somehow stored in your profile and then retrieved by the script.
Speaker A: There has to be like a knowledge base. You have to be able to reason about it all that kind of stuff.
Speaker B: Exactly.
Speaker A: All the kind of stuff that. Expert systems that were hard coded.
Speaker B: Yeah, and unfortunately, yes, unfortunately, those things have to be hard coded. And unfortunately of the language, like language models we see coming out of research labs and big companies, they're not focused on. They're focused on showing you, maybe they're focused on some metrics around one conversation. So they'll show you this one conversation they had with the machine, but they never tell you. They're not really focused on having five consecutive conversations with the machine and seeing how number five or number 20 or number 100 is also good. And it can be, like always from a clean slate, because then it's not good. And that's really unfortunate because no one has products out there that need it. No one has products at this scale that are all around, open to many conversations that need remembering. Maybe only shy and Microsoft, but. So that's why we're not seeing that much research around memory in those language models.
Speaker A: So, okay, so now there's some awesome stuff about augmented reality in general. I have this disagreement with my dad about what it takes to have a connection. He thinks touch and smell are really important. Like, and I still believe that text alone is, it's possible to fall in love with somebody just with text, but visualization can also help, just like with the avatar and so on. What do you think it takes? Does a chat by need to have a face voice, or can you really form a deep connection with text alone?
Speaker B: I think text is enough, for sure. Question is, like, can you make it better if you have other. If you include other things as well? And I think, you know, we all talk about her. I. But her, you know, had Scarlett Johansson voice, which was perfectly, you know, perfect intonation, perfect annunciations, and, you know, she was breathing heavily in between words and whispering things. You know, nothing like that is possible right now with text to speech generation. You'll have these flat news anchor type voices and maybe some emotional voices, but I. You'll hardly understand some of the words. Some of the words will be muffled. So that's like the current state, state of the art. So you can't really do that. But if we had Scarlett Johansson voice and all of these capabilities, then of course, voice would be totally enough, or even text would be totally enough. If we had a little more memory and slightly better conversations, I would still argue that even right now, we could have just kept the text, only we still had tons of people in long term relationships and really invested in their AI friends. But we thought that why do we need to keep playing with our hands tied behind us? We can easily just add all these other things. That is pretty much a solved problem. We can add 3d graphics, we can put these avatars in augmented reality, and all of a sudden there's more. And maybe you can't feel the touch, but you can, you know, with body occlusion and with current ar and, you know, on the iPhone or, you know, in the next one, there's going to be light doors. You can touch it and it will, you know, it will pull away or will blush or something, or it will smile. So you can't touch it, you can't feel it, but you can see the reaction to that. So in a certain way, you can even touch it a little bit of, and maybe you can even dance with it or do something else. So I think why limiting ourselves if we can use all of these technologies that are much easier in a way than conversation?
Speaker A: Well, it certainly could be richer. But to play a devil's advocate, I mentioned to you offline that I was surprised in having tried discord and having voice conversations with people. How intimate voices alone, without visual. Like, to me at least, like it was an order of magnitude greater degree of intimacy in voice, I think, than with video. I don't, because people were more real with voice. Like with video, you, like, try to present a shallow, a face to the world. Like, you try to, you know, make sure you're not wearing sweatpants or whatever, but like, with voice, I think people were just more faster to get to, like, the core of themselves. So I don't know, it was surprising to me. They've even added discord, added a video feature, and like, nobody was using it. There's a temptation to use it at first, but, like, it wasn't the same. So, like, that's an example of something where less was doing more. And so that's a. I guess that's the, that's the question of what is the optimal, you know, what is the optimal medium of communication to form a connection given the current sets of technologies? I mean, it's nice because the advertiser have replica, like, it immediately, like, even the one I have is like, it's already memorable. That's how I think, like, when I think about the replica that I've talked with, that's why I think, like, that's what I visualize in my head. They became a little bit more real because there's a visual component, but at the same time, the, you know, what do you do with. Just, what do I do with that knowledge? That voice was so much more intimate.
Speaker B: Well, the way I think about it is, um, and by the way, we're swapping out the 3d finally. It's going to look a lot better. Uh, but can you.
Speaker A: What? What?
Speaker B: We just don't hate how it looks right now. We really change it at all. We're swapping it all out, uh, um, to a completely new look.
Speaker A: Like the visual look of the, of a replica.
Speaker B: Replicas and stuff. We just had. It was just a super early Mvp. And then we had to move everything to unity and redo everything. But anyway, I hate how it looks like now. I can't even like, open it. But anyway, um, because I'm already on my developer version, I hate everything that I see in production. I can't wait for it. Why does it take so long? That's why I cannot wait for deep learning to finally take over all these stupid 3d animations and 3d pipeline.
Speaker A: Also, the 3d thing, when you say 3d pipeline, is like how to animate a face kind of thing, how to.
Speaker B: Make this model, how many bones to put in the face, how many. It's just.
Speaker A: And a lot of that is by hand.
Speaker B: Oh, my God. It's everything by hand. And if there's no any, nothing is automated. It's all completely nothing. Like, just, it's, it's literally what, you know, what we saw with Chad boss, like 2012.
Speaker A: You think it's possible to learn a lot of that?
Speaker B: Of course. I mean, even now, some deep learning, anim based animations and for the full body, for a face, are we talking.
Speaker A: About like the actual act of animation or how to create a compelling facial or body language thing?
Speaker B: That too. Well, that's next up.
Speaker A: Okay.
Speaker B: At least now, something that you don't have to do by hand.
Speaker A: Gotcha.
Speaker B: How good of a quality it will be. Like, can I just show it a photo and it will make me 3d model and then it will just animate it. I'll show it. A few animations of a person will just start doing that. But anyway, going back to what's intimate and what to use and whether less is more or nothing, my main goal is to, well, the idea was how do we not keep people in their phones so they're sort of escaping reality in this text conversation? How do we, through this still bring it, bring our users back to reality, make them see their life through a different lens? How can we create a little bit of magical realism in their lives so that through augmented reality, by summoning your avatar, even if it looks kind of janky and not great in the beginning or very simplistic, but summoning it to your living room, and then the avatar looks around and talks to you about where it is and maybe turns your floor into a dance floor, and you guys dance together, that makes you see reality in a different light.
Speaker A: What kind of dancing are we talking about? Like, slow dancing?
Speaker B: Whatever you want. I mean, you would like slow dancing, I think, but other people maybe want more, something more energetic.
Speaker A: What do you mean? I would like. So what is this?
Speaker B: Because you started with slow dancing, so I just assumed that you're interested in slow dancing.
Speaker A: All right, what kind of dancing do you like? What was your avatar?
Speaker B: What would you dance? I'm torsy bad with dancing, but I like this kind of hip hop robot dance. I used to break dance when I was a kid, so I still want to pretend I'm a teenager and learn some of those moves. And I also like that type of dance that happens when there's, like, a. In, like, music videos where the background dancers are just doing music.
Speaker A: Awesome.
Speaker B: That type of dance is definitely what I want to learn, but I think it's great because if you see this friend in your life and you can introduce it to your friends, then there is a potential to actually make you feel more connected with your friends or with people you know or show you life around you in a different light. And it takes you out of your phone, even, although, weirdly, you have to look at it through the phone, but it makes you notice things around it, and it can point things out for you. And so that is the main reason why I wanted to have a physical dimension, and it felt a little bit easier than that kind of a bit strange combination. In the movie her, when he has to show Samantha the world through the lens of his phone, but then at the same time, talk to her through headphones, it just didn't seem as potentially immersive, so to say. So that's my main goal for augmented reality. How do we make your reality a little bit more magic?
Speaker A: There's been a lot of really nice robotics companies that all failed, mostly failed home robotics, social robotics companies. Do you think replica will ever. Is that a dream, long term dream to have a physical form, or is that not necessary? So you mentioned with augmented reality bringing them into the world. What about actual physical robot?
Speaker B: That I don't really believe in that much. I think it's a very niche product somehow. I mean, if a robot could be indistinguishable from a human being, then maybe. Yes, but that, of course we're not anywhere even to talk about it. But unless it's that, then having any physical representation really limits you a lot because you probably will have to make it somewhat abstract because everything's changing so fast. Like we can update the 3d avatars every month and make them look better and create more animations and make it more and more immersive. It's so much a work in progress. It's just showing what's possible right now with current tag. But it's not really in any way polished, finished product, what we're doing with a physical object. You kind of lock yourself into something for a long time. Anything's pretty niche. And again, so just doesn't the capabilities are even less of. We're barely kind of like scratching the surface of what's possible with just software. As soon as we introduce hardware, then we have even less capabilities.
Speaker A: Yeah. In terms of board members and investors and so on, the cost increases significantly. I mean, that's why you have to justify. You have to be able to sell a thing for like $500 or something like that, or more. And it's very difficult to provide that much value to people.
Speaker B: That's also true.
Speaker A: Yeah, yeah.
Speaker B: And I guess that's super important. Most of our users don't have that much money. We actually are probably more popular on Android and we have tons of users with really old Android phones. And most of our most active users live in small towns. They're not necessarily making much and they just won't be able to afford any of that. Ours is the opposite of the early adopter of a fancy technology product, which is really interesting that pretty much no vc's yet have an AI friend, but, you know, but a guy who, you know, lives in Tennessee, in small town, is already fully in 2030 or in the world as we imagine in the movie her. He's living that life already.
Speaker A: What do you think? I have to ask you about the movie her. Let's do a movie review. What do you, what do you think they got? They did a good job. What do you think they did a bad job of portraying about this experience of, uh, of a voice based assistant that you can have a relationship with?
Speaker B: Well, first of all, I started working on this company before that movie came out. So it was a very. But once it came out, it was actually interesting. I was like, well, we're definitely working on the right thing. We should continue. There are movies about it and then you know, ex machina came out and all these things in the movie, her. I think that's the most important thing that people usually miss about the movie is the ending. Because I think people check out when the AI's leave. But actually something really important happens afterwards because the main character goes and talks to Samantha, his AI.
Speaker A: Spoiler alert.
Speaker B: Oh, yeah. And I think he says something like, you know, how can you leave me? I've never loved anyone the way I loved you. And she goes, well, me neither, but now we know how. And then the guy goes and writes a heartfelt letter to his ex wife which he couldn't write for the whole movie. He was struggling to actually write something meaningful to her, even though that's his job. And then he goes and talk to his neighbor and they go to the rooftop and they cuddle. It seems like something starting there. And so I think this. Now we know how is the main goal, is the main meaning of that movie. It's not about falling in love with the OS or running away from other people. It's about learning what it means to feel so deeply connected with something.
Speaker A: What about the thing where the AI system was, like, actually hanging out with a lot of others? I felt jealous just like, hearing that. I was like, oh, I mean, yeah. So she was having. I forgot already, but she was having, like, deep, meaningful discussion with some, like, philosopher guy, like Alan Watts or something.
Speaker B: What kind of deep, meaningful conversation can you have with Alan Watts in the first place?
Speaker A: Yeah, I know, but, like, I would. I would feel so jealous that there's, somebody who's, like, way more intelligent than me and she's spending all her time with. I'd be like, well, why? That I won't be able to live up to that. That's thousands of them. Is that. Is that useful from the engineering perspective feature to have of jealousy? I don't know. It's.
Speaker B: You know, we definitely played around with the replica universe where different replicas can talk to each other.
Speaker A: The universe is so awesome.
Speaker B: It was just kind of. I think it will be something along these lines, but there was just no specific application straight away, I think in the future, again, I'm always thinking about it. If we had no tech limitations right now, if we could build any conversations, any possible features in this product, then, yeah, I think different replicas talking to each other would be also quite cool because that would help us connect better, you know, because maybe mine could talk to yours and then give me some suggestions on what I should say or not say. I'm just kidding, but like, more, can it improve our connections? And because eventually, I'm not quite yet sure that we will succeed, that our thinking is correct, because there might be a reality where having a perfect AI friend still makes us more disconnected from each other and there's no way around it and does not improve any metrics for us, real metrics, meaningful metrics.
Speaker A: So success is, you know, we're happier and more connected.
Speaker B: Yeah.
Speaker A: I don't know. Sure, it's possible there's a reality that's. I'm deeply optimistic, I think. Are you worried business wise? Like, how difficult it is to bring this thing to life to where it's. I mean, there's a huge number of people that use it already, but to, yeah, like I said, in that multi billion dollar company, is that a source of stress for you? Are you super optimistic and confident or do you have.
Speaker B: I don't. I'm not that much of a numbers person as you probably have seen it, so doesn't matter for me whether, like, whether we help 10,000 people or a million people or a billion people with that, it would be great to scale up for more people. But I'd say that even helping one, I think, with this is such a magical. Yeah, for me, it's absolute magic. I never thought that we'd be able to build this, that anyone would ever talk to it. And I always thought, like, well, for me, we'll be successful. If we managed to help and actually change a life for one person, then we did something interesting. And how many people can say they did it? And specifically with this very futuristic, very romantic technology. That's how I view it. I think for me, it's important to try to figure out how to actually be helpful, because in the end of the day, if you can build a perfect AI friend that's so understanding, that knows you better than any human out there can have great conversations with you, always knows how to make you feel better. Why would you choose another human? That's the question. How do you still keep building it? So it's optimizing for the right thing, so it's still circling you back to other humans in a way. So I think that's the main, maybe that's the main kind of source of anxiety. And just thinking about. Thinking about that can be a little bit stressful.
Speaker A: Yeah, that's a fascinating thing. How to have a friend that doesn't, like, sometimes like friends, quote unquote, or like, you know, those people who have. When they guy and the guy universe, when you have a girlfriend that you get the girlfriend and then the guy stops hanging out with all of his friends. So, like, obviously the relationship with the girlfriend is fulfilling or whatever, but like, you also want it to be where she, like, makes it more enriching to hang out with the guy, friends or whatever. Anyway, that's, that's a, that's a, that's a fundamental problem in choosing the right mate and probably the fundamental problem in creating the right AI system. Right. What, let me ask, the sexy hot thing on the presses right now is GPT-3 got released with OpenAI. It's a latest language model. They have kind of an API where you can create a lot of fun applications. I think it's, as people have said, it's probably more hype than intelligent, but there's a lot of really cool things, ideas there. With increasing size, you can have better and better performance on language. What are your thoughts about GPT-3 in connection to your work with the open domain dialogue, but in general, like this, learning in an unsupervised way from the Internet to generate one character at a time, creating pretty cool text.
Speaker B: So we partnered up before for the API launch. So we started working with them when they decided to put together this API. And we tried it without fine tuning that. We tried it with fine tuning on our data, and we work closely to actually optimize this model for some of our data sets. It's kind of cool because I think we're this polygon, polygon for this kind of experimentation space, for experimental space, for all these models to see how they actually work with people, because there are no products publicly available that do that. They're focused on open domain conversations. So we can test how's Facebook blender doing? Or how's GPT-3 doing? So with GPT-3 we managed to improve by a few percentage points, like three or four. Pretty meaningful amount of percentage points. Our main metric, which is the ratio of conversations that make people feel better, and every other metric across the field got a little boost right now. I'd say one out of five responses from replica come comes from GPT-3 wow. So our own blender mixes up like a bunch of candidates from different blender, you said? Well, yeah, just the model that looks at, looks at top candidates from different models and then picks the most, the best one. So right now, one of five will come from gypsy three. That is really great. I mean.
Speaker A: What'S the, do you have hope for? Like, do you think there's a ceiling to this kind of approach?
Speaker B: So we've had for a very long time. We've used since the very beginning. We most. It was, most of replica was scripted. And then a little bit of this fallback part of replica was using a retrieval model. And then those retrieval models started getting better and better and better with transformers got a lot better, and we're seeing great results. And then with GPT-2 finally, generative models that originally were not very good and were the very, very fallback option for most of our conversations. We wouldn't even put them in production. Finally, we could use some generative models as well along, you know, next to our retrieval models. And then now we do GPT-3 they're almost in par. So that's pretty exciting, I think, just seeing how from the very beginning of. From 2015, where the first model started to pop up here and there, like, sequence, sequence the first papers on that. From my observer standpoint, personally, it's not, you know, doesn't really. Is not really building it, but it's only testing it on people, basically, and my product to see how all of a sudden we can use generative dialogue models in production and they're better than others and they're better than scripted content. So we can't really get our scripted, hard coded content anymore to be as good as our end to end models.
Speaker A: That's exciting.
Speaker B: They're much better.
Speaker A: Yeah.
Speaker B: To your question whether that's the right way to go again, I'm in the observer seat. I'm just watching this very exciting movie. I mean, so far, it's been stupid to bet against deep learning. So weather increasing the size size even more with 100 trillion parameters will finally get us to the right answer. Whether that's the way or whether there should be. There has to be some other. Again, I'm definitely not an expert in any way, I think, and that's purely my instinct, saying that there should be something else as well. From memory.
Speaker A: No, for sure. The question is, I wonder. I mean, yeah, then the argument is for reasoning or for memory. It might emerge with more parameters. It might larger if it might emerge.
Speaker B: You know, I would never think that, to be honest. Like maybe in 2017 where we've been just experimenting with all, you know, with all the research that has been coming that was coming out, then I felt like there's like we're hitting a wall, that there should be something completely different, but then transformer models and then just bigger models, and then all of a sudden, size matters. At that point, it felt like something dramatic needs to happen, but it didn't. And just the size, you know, gave us these results. That, to me, are, you know, clear indication that we can solve this problem pretty soon.
Speaker A: Did fine tuning help quite a bit?
Speaker B: Oh, yeah. Without it, it wasn't as good.
Speaker A: I mean, there is a compelling hope that you don't have to do fine tuning, which is one of the cool things about GPT-3 it seems to do well without any fine tuning.
Speaker B: I guess for specific applications, we still want to train on a certain, like, add a little fine tune on, like, a specific use case. But it's an incredibly impressive thing from my standpoint. And again, I'm not an expert, so I want to just say that, yeah, I'm going to. There will be people then.
Speaker A: Yeah, I have access to the API, and I'm going to probably do a bunch of fun things with it. I already did some fun things, some videos coming out just for the hell of it. I mean, I could be a troll at this point with it. I haven't used it for a serious application, so it's really cool to see. You're right. You're able to actually use it with real people and see how well it works. That's really exciting. Let me ask you another absurd question. But there's a feeling when you interact with replica, with an AI system, there's an entity there. Do you think that entity has to be self aware? Do you think it has to have consciousness to create a rich experience? And a corollary, what is consciousness?
Speaker B: I don't know if it does need to have any of those things, but again, because right now it doesn't have anything, again, a bunch of people simulate. Well, I'm not sure. Let's just put it this way. But I think as long as you can simulate it, if you can feel like you're talking to a robot, to a machine that seems to be self aware, that seems to reason well, and feels like a person, I think that's enough. And again, what's the goal? In order to make people feel better, we might not even need that, um, in the end of a day.
Speaker A: What about. So that's one goal. What about, like, ethical things about suffering? You know, the moment there's a display of consciousness, we associate consciousness with suffering. Um, you know, there's a temptation to say, well, shouldn't this thing have rights? Shouldn't this. Shouldn't we not, uh, you know, should we be careful about how we interact with a replica? Like, should it be illegal to torture a replica? Right. All those kinds of things. Is that. See, I personally believe that that's going to be a thing. Like, that's a serious thing to think about, but I'm not sure when. But by your smile, I can tell that's not a, that's not a current concern. But do you think about that kind of stuff about, like, suffering and torture and ethical questions about AI systems from their perspective?
Speaker B: If we're talking about long game, I wouldn't torture your AI. Who knows what happens in five to ten years?
Speaker A: Yeah. They'll get you off from that. They'll get you back.
Speaker B: Trying to be as nice as possible and create this ally. Yeah. I think there should be regulation both way. In a way, like, I don't think it's okay to torture an AI, to be honest. I'm not. I don't even think it's okay to yell, Alexa, turn on the lights. I think there should be some, or just saying kind of nasty, you know, like, how kids learn to interact with Alexa in this kind of mean way, because they just yell at it all the time. I think that's great. I think there should be some feedback loops so that these systems don't train us, that it's okay to do that in general, so that if you try to do that, you really get some feedback from the system that it's not okay with that. And that's the most important. Right.
Speaker A: Now, let me ask a question I think people are curious about when they look at a world class leader and thinker such as yourself, as what books, technical fiction, philosophical, had a big impact on your life, and maybe from another perspective, what books would you recommend others read?
Speaker B: So, my choice, the three books, right?
Speaker A: Three books.
Speaker B: My choice is. So, the one book that really influenced me a lot when I was building, starting out this company, maybe ten years ago, was GB Georale Escherbach. And I like everything about it. First of all, it's just beautifully written, and it's so old school and so somewhat outdated a little bit. But I think the ideas in it about the fact that a few meaningless components can come together and create meaning that we can't even understand.
Speaker A: So this emerges thing, I mean, complexity, the whole science of complexity, and that beauty, intelligence, all interesting things about this world emerge.
Speaker B: Yeah. And, yeah, the godel theorem, theorems, and just thinking about, like, what even these form, you know, even all these formal systems, something can be created that we can't quite yet understand. And that, from my romantic standpoint, was always just, that is why it's important to maybe I should try to work on. On these systems and try to build an aih, yes. I'm not an engineer. Yes. I don't really know how it works, but I think that something comes out of it that's pure poetry. And I don't know a little bit about that. Something magical comes out of it that we can't quite put a finger on. That's why that book was really fundamental for me. I don't even know why. It was just all about this little magic that happens. So that's one probably the most important book for replica was Carl Rogers on becoming a person. And that's really. And so I think when I think about our company, it's all about there's so many little magical things that happened over the course of working on it. For instance, I mean, the most famous chatbot that we learned about when we started working on the company was Eliza, which was Weizenbaum, you know, the MIT professor that built. Build a chatbot that would listen to you and be a therapist. Therapist, yeah. And I got really inspired to build replica when I read Carl Rogers on becoming a person. And then I realized that Eliza was mocking Carl Rogers. It was Carl Rogers back in the day, but I thought that Carl Rogers ideas are, they're simple and they're not, you know, they're very, very simple, but they're then maybe the most profound thing I've ever learned about human beings. And that's the fact that before Kar Rogers, most therapy was about seeing what's wrong with people and trying to fix it or show them what's wrong with you. And it was all built on the fact that most people are old, people are fundamentally flawed. We have this broken psyche, and therapy is just an instrument to shed some light on that. And Carl Rogers was different in a way, that he finally said that, well, it's very important for therapy to work, is to create this therapeutic relationship where you believe fundamentally and inclination to positive growth, that everyone deep inside wants to grow positively and change. And it's super important to create this space and this therapeutic relationship where you give unconditional positive regard, deep understanding, allowing someone else to be a separate person, full acceptance, and you also try to be as genuine as possible in it. And then in his. And then for him, that was his own journey of personal growth, and that was back in the sixties, and even that book that is coming from years ago, there's a mention that even machines can potentially do that. And I always felt that creating the space is probably the most, the biggest gift we can give to each other. And that's why the book was fundamental for me personally, because I felt I want to be learning how to do that in my life, and maybe I can scale it with, you know, with these AI systems, and other people can get access to that. So I think, Carl Rogers. It's a pretty dry and a bit boring book, but I think.
Speaker A: Do you recommend others try to read it?
Speaker B: I do. I think for.
Speaker A: Just for yourself, for as a human.
Speaker B: Not as an alien, as a human, it is just. And for him, that was his own path, of his own personal. Of growing personally, over years, working with people like that. And so it was work and himself growing, helping other people grow and growing through that. And that's fundamentally what I believe in with our work, helping other people grow, growing ourselves. Ourselves, trying to build a company that's all built on this principles, you know, having a good time along with some people that we work with, to grow a little bit. So these two books, and then I would throw in what we have on our. In our. In our office. When we started a company in Russia, we put a neon sign in our office because we thought that's a recipe for success. If we do that, we're definitely going to wake up as a multibillion dollar company. And it was the Ludwig Wittgenstein quote, the limits of my language are the limits of my world.
Speaker A: What's the quote?
Speaker B: The limits of my language are the limits of my world. And I love the trick. Titus, I think it's just a beautiful.
Speaker A: It's a book by Wittgenstein.
Speaker B: Yeah. And I would recommend that, too, even although he himself didn't believe in that by the end of his lifetime and debunked his ideas. But I think I remember once an engineer came in 2012, I think, or 13, a friend of ours who worked with us and then went on to work at DeepMind, and he gave. Talked to us about Ward two vec, and I saw that. I'm like, wow, that's. You know, they wanted to translate language into, you know, some other representation, and that seems like some. You know, somehow all of that at some point, I think, will come into this one, to this one place, somehow. It just all feels like different people think about similar ideas in different times from absolutely different perspectives. And that's why I like these books.
Speaker A: Limits of our language is the limit of our world, and.
Speaker B: We still have that neon sign. It's very hard to work with this red light in your face.
Speaker A: I mean, on the russian side of things, in terms of language. The limits of language being the limit of our world. You know, Russian is a beautiful language in some sense. There's wit, there's humor, there's pain. There's so much. We don't have time to talk about it much today, but I'm going to Paris to talk to Dostoevsky, Tolstoy, translators. I think it's fascinating. Art, like art and engineering. I mean, it's such an interesting process. So, from the replica perspective, do you. What do you think about translation? How difficult it is to create a deep, meaningful connection in Russian versus English, how you can translate the two languages you speak? Both?
Speaker B: Yeah, I think we're two different people in different languages. Even. I'm, you know, thinking about. And there's actually some research on that. I looked into that at some point because I was fascinated by the fact that what I'm talking about with what I was talking about with my russian therapist has nothing to do with what I'm talking about with my English speaking therapist. It's two different lives, two different types of conversations, two different Personas. The main difference between the languages are with Russian and English. Is that Russian, well, English is like a piano. It's a limited number of a lot of different keys, but not too many. And Russian is like an organ or something. It's just something gigantic with so many different keys and so many different opportunities to screw up and so many opportunities to do something completely tone deaf. It is just a much harder language to use. It has way too much flexibility and way too many tones.
Speaker A: What about the entirety of, like, world war two, communism, Stalin, the pain of the people, like, having been deceived by the dream, like, all the pain of just the entirety of it. Is that in the language, too? Does that have to do?
Speaker B: Oh, for sure. I mean, we have words that don't have direct translation, that do English, that are very much like. We have abidica, which is sort of, like, to hold a grudge or something, but it doesn't have. You don't need to have anyone to do it to you. It's just your state. You just feel like that. You feel, like, betrayed by other people, basically, but it's not that. And you can't really translate that. And I think that's super important, that very many words that are very specific explain the russian being. And I think they can only come from a nation that was. That suffered so much and saw institutions fall time after time after time. And you know what's exciting? Maybe not exciting, setting the wrong word. But what's interesting about, like, my generation, my mom's generation, and my parents generation is that we saw institutions fall two or three times in our lifetime, and most Americans have never seen them fall. And they just think that they exist forever, which is really interesting. But it's definitely a country that suffered so much. And it makes, unfortunately, when I go back and I hang out with my russian friends, it makes people very cynical. They stop believing in the future. I hope that's not going to be the case for so long or something's going to change again. But I think seeing institutions fall is a very traumatic experience.
Speaker A: Makes it very interesting. And what's on 2020? It's very interesting. Do you think civilization will collapse?
Speaker B: See, I'm a very practical person.
Speaker A: We're speaking English. So like you said, you're different person in English and Russian, so in Russian, you might answer that differently.
Speaker B: But in English, I'm an optimist and I genuinely believe that there is all, you know, even although the perspectives are grim, there's always a place for a miracle. I mean, it's always been like that with my life. So, yeah, my life's been. I've been incredibly lucky. And things just, miracles happen all the time with this company, with people I know, with everything around me. And so I didn't mention that book, but maybe in search of miraculous or in search for miraculous or whatever the english translation for that is good russian book for everyone to read.
Speaker A: Yeah. I mean, if you put good vibes, if you put love out there in the world, miracles somehow happen. Yeah, I believe that, too. Or at least I believe that. I don't know. Let me ask the most absurd, final, ridiculous question of, we talked about life a lot. What do you think is the meaning of it all? What's the meaning of life?
Speaker B: My answer is probably going to be pretty cheesy, but I think the state of love is once you feel it in a way that we discussed it before. I'm not talking about falling in love or I just love to yourself, to other people, to something, to the world, that state of bliss that we experience sometimes, whether through connection with ourselves, with our people, with the technology, there's something special about those moments. So let's say, if anything, that's the only, if it's not for that, then for what else are we really trying to do?
Speaker A: That I don't think there's a better way to end it than talking about love. Eugenia, I told you offline that there was something about me that felt like this was this talking to you, meeting you in person, will be a turning point for my life. I know that might sound weird to hear, but it was a huge honor to talk to you. I hope we talk again. Thank you so much for your time.
Speaker B: Thank you so much.
Speaker A: Thanks for listening to this conversation with Eugenia Quidda and thank you to our sponsors DoorDash Dollar Shave Club and cash app. Click the sponsor links in the description to get a discount and to support this podcast. If you enjoy this thing, subscribe on YouTube, review it with five stars on Apple Podcasts, follow on Spotify, support on Patreon, or connect with me on Twitter exfriedman. And now let me leave you with some words from Carl Sagan. The world is so exquisite, with so much love and moral depth that there's no reason to deceive ourselves with pretty stories of which there's little good evidence. Far better, it seems to me. And our vulnerability is to look death in the eye and to be grateful every day for the brief but magnificent opportunity that life provides. Thank you for listening and hope to see you next time.
