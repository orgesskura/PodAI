Transcription for Peter Wang： Python and the Source Code of Humans, Computers, and Reality ｜ Lex Fridman Podcast #250.mp3:
Full transcript: The following is a conversation with Peter Wang, one of the most impactful leaders and developers in the Python community, former physicist, current philosopher, and someone who many people told me about and praised as a truly special mind that I absolutely should talk to recommendations ranging from Travis Oliphant to Eric Weinstein. So here we are. This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now here's my conversation with Peter Wang. You're one of the most impactful humans in the Python ecosystem. So you're an engineer, leader of engineers, but you're also a philosopher. So let's talk both in this conversation about programming and philosophy. First, programming, what to you is the best, or maybe the most beautiful feature of python? Or maybe the thing they made you fall in love or stay in love with Python? Well, those are three different things. What I think is the most beautiful, what made me fall in love with me, stay in love. When I first started using it was when I was a C computer graphics performance nerd. In the nineties. Yeah, in the late nineties. And that was my first job out of college. And we kept trying to do more and more like abstract and higher order programming in C, which at the time was quite difficult with templates, the compiler support wasn't great, et cetera. So when I started playing around with Python, that was my first time encountering really first class support for types, for functions and things like that. And it felt so incredibly expressive. So that was what made me fall in love with it a little bit. And also, once you spend a lot of time in a C dev environment, the ability to just whip something together that basically runs and works the first time is amazing. So really productive scripting language. I mean, I knew Perl, I knew bash, I was decent at both, but Python just made everything, it made the whole world accessible, right? I could script this and that and the other network things, you know, little hard drive utilities. I could write all of these things in the space of an afternoon. And that was really, really cool. So that's what made me fall in love. Is there something specific you could put your finger on that you're not programming in Perl today? Like why? Why Python for scripting? I think there's not a specific thing. As much as the design motif of both the creator of the language and the core group of people that built the standard library around him, there was a taste to it. I mean, Steve Jobs used that term in somewhat of an arrogant way, but I think it's a real thing that it was designed to fit. A friend of mine actually expressed this really well. He said, python just fits in my head, and there's nothing better to say than that. Now, people might argue modern Python, there's a lot more complexity, but certainly as version 5152, I think, is my first version that fit in my head very easily. So that's what made me fall in love with it. Okay, so the most beautiful feature of Python that made you stay in love, it's like over the years, what has, like, you know, you do a double take and you return too often as a thing that just brings you a smile. I really still like the, the ability to play with meta classes and express higher order things when I have to create some new object model, to model something, it's easy for me because I'm pretty expert as a Python programmer, I can easily put all sorts of lovely things together and use properties and decorators and other kinds of things and create something that feels very nice. I would say that's tied with the numpy and vectorization capabilities. I love thinking in terms of the matrices and the vectors and these kind of data structures, so I would say those two are kind of tied for me. So the elegance of the numpy data structure, like slicing through the different multi dimensions. Yeah, there's just enough things there. It's like a very, it's a very simple, comfortable tool. Just, it's easy to reason about what it does when you don't stray too far afield. Can you put your finger on how to design a language such that it fits in your head? Certain things like the colon or the certain notation aspects of python that just kind of work? Is it something you have to kind of write out on paper, look and say, it's just right? Is it a taste thing or is there a systematic process? What's your sense? I think it's more of a taste thing. But one thing that should be said is that you have to pick your audience. So the better defined the user audience or the users are, the easier it is to build something that fits in their minds. Because their needs will be more compact and coherent. It is possible to find a projection, a compact projection, for their needs. The more diverse the user base, the harder that is. As Python has grown in popularity, that's also naturally created more complexity. As people try to design any given thing, there will be multiple valid opinions about a particular design approach. And so I do think that's the downside of popularity. It's almost an intrinsic aspect of the complexity of the problem. Well, at the very beginning, aren't you an audience of one isn't ultimately, aren't all the greatest projects in history? We're just solving a problem that you yourself had. Well. So Clay Shirky, in his book on crowdsourcing, or in his kind of thoughts on crowdsourcing, he identifies the first step of crowdsourcing is me first collaboration. You first have to make something that works well for yourself. It's very telling that when you look at all of the impactful big projects, while they're fundamental projects now in the scipy and PI data ecosystem, they all started with the people in the domain trying to scratch their own itch. And the whole idea of scratching our own itch is something that the open source or the free software world has known for a long time. But in the scientific computing areas, these are assistant professors or electrical engineering grad students. They didn't have really a lot of programming skill necessarily, but Python was just good enough for them to put something together that fit in their domain, right? So it's almost like a, it's a necessity as a mother of invention aspect, and also it was a really harsh filter for utility and compactness and expressiveness. Like it was too hard to use, then they wouldn't have built it, because that was just too much trouble, right? It was a side project for them. And also necessity creates a kind of deadline. It seems like a lot of these projects are quickly thrown together in the first step, and that even though it's flawed, that just seems to work well for software projects. Well, it does work well for software projects in general and in this particular space. One of my colleagues, Stan Sieber, identified this, that all the projects in the scipy ecosystem, if we just rattle them off, there's numpy, there's scipy built by different collaborations of people, although Travis is the heart of both of them. But numpy coming from numeric and numerous, these are different people. And then you've got pandas, you've got Jupyter or ipython, there's Matplotlib, there's just so many others. I'm not going to do justice if I try to name them all, but all of them are actually different people. And as they rolled out their projects, the fact that they had limited resources meant that they were humble about scope. A great famous hacker, Jamie Zawiski, once said that every geeks dream is to build the ultimate middleware. The thing is, with these scientists turned programmers, they had no such dream. They were just trying to write something that was a little bit better. For what? They needed, the Matlab, and they were going to leverage what everyone else had built. So naturally, almost in this annealing process or whatever, we built a very modular cover of the basic needs of a scientific computing library. If you look at the whole human story, how much of a leap is it? We've developed all kinds of languages, all kinds of methodologies for communication. It just kind of like grew this collective intelligence, the civilization grew, it expanded. We wrote a bunch of books, and now we tweet, how big of a leap is programming? If programming is yet another language, is it just a nice little trick that's temporary in our human history? Or is it like a big leap in the almost us becoming another organism at a higher level of abstraction, something else? I think the act of programming or using grammatical constructions of some underlying primitives, that is something that humans do learn. But every human learns this. Anyone who can speak learns how to do this. What makes programming different has been that up to this point, when we try to give instructions to computing systems, all of our computers. Well, actually this is not quite true, but I'll first say it and then I'll tell you why it's not true. But for the most part, we can think of computers as being these iterated systems. So when we program, we're giving very precise instructions to iterated systems that then run at incomprehensible speed and run those instructions. In my experience, some people are just better equipped to model systematic iterated systems. Well, whatever iterated systems in their head, some people are really good at that and other people are not. And so when you have, like for instance, sometimes people have tried to build systems that make programming easier by making it visual drag and drop. And the issue is you can have a drag and drop thing, but once you start having to iterate the system with conditional logic, handling case statements and branch statements and all these other things, the visual drag and drop part doesn't save you anything. You still have to reason about this giant iterated system with all these different conditions around it. That's the hard part. Handling iterated logic, that's the hard part. The languages we use then emerge to give us ability and capability over these things. Now the one exception to this rule, of course, is the most popular programming system in the world, which is Excel, which is a data flow and a data driven immediate mode data transformation oriented programming system. And it's actually not an accident that that system is the most popular programming system because it's so accessible to a much broader group of people. I do think as we build future computing systems. You're actually already seeing this a little bit. It's much more about composition of modular blocks. They themselves actually maintain all their internal state, and the interfaces between them are well defined data schemas. And so to stitch these things together using, like, IFTTT or Zapier or any of these kind of, I would say, composition, additional scripting kinds of things, I mean, hypercard was also a little bit in this vein that's much more accessible to most people. It's really that implicit state that's so hard for people to track. Yeah, okay, so that's modular stuff. But there's also an aspect where you're standing on the shoulders of giants. You're building, like, higher and higher levels of abstraction. You do that a little bit with language. So with language, you develop sort of ideas, philosophies, Plato and so on, and then you kind of leverage those philosophies as you try to have deeper and deeper conversations. But with programming, it seems like you can build much more complicated systems, like, without knowing how everything works, you can build on top of the work of others, and it seems like you're developing more and more sophisticated expressions, ability to express ideas in a computational space. I think it's worth pondering the difference here between complexity and complication. Okay, right back to excel. Well, not quite back to excel, but the idea is, when we have a human conversation, all languages for humans emerged to support human relational communications, which is that the person we're communicating with is a person, and they would communicate back to us. And so we sort of hit a resonance point, right, when we actually agree on some concepts. So there's a messiness to it, and there's a fluidity to it. With computing systems, when we express something to the computer and it's wrong, we just try again. So we can basically live many virtual worlds of having failed at expressing ourselves to the computer. Until the one time we expressed ourselves right. Then we kind of put in production and then discover that it's still wrong, you know, a few days down the road. So I think the sophistication of things that we build with computing, one has to really pay attention to the difference between when an end user is expressing something onto a system that exists versus when they're extending the system to increase the system's capability for someone else to then interface with. We happen to use the same language for both of those things, and in most cases, but it doesn't have to be that. Excel is actually a great example of this, of kind of a counterpoint to that. Okay, so what about the idea of, you said messiness? Wouldn't you put the software 2.0 idea, this idea of machine learning, into the further and further steps into the world of messiness, the same kind of beautiful messiness of human communication? Isn't that what machine learning is, is building on levels of abstraction that don't have messiness in them? That at the operating system level? Then there's Python, the programming languages that have more and more power. But then finally there's neural networks that ultimately work with data. And so the programming is almost in the space of data, and the data is allowed to be messy. Isn't that a kind of program? So the idea of software 2.0 is a lot of the programming happens in the space of data. So back to excel. All roads lead back to excel in the space of data. And also the hyper parameters of the neural networks, and all of those allow the same kind of messiness that human communication allows. It does. But my background is a physics. I took two cs courses in college, so I don't have now. I did cram a bunch of cs in prep when I applied for grad school, but still, I don't have a formal background in computer science. But what I have observed in studying programming languages and programming systems and things like that is that there seems to be this triangle. It's one of these beautiful little iron triangles that you find in life sometimes, and it's the connection between the code correctness and expressiveness of code, the semantics of the data, and then the correctness or parameters of the underlying hardware compute system. So there's the algorithms that you want to apply. There's what the bits that are stored on whatever media actually represent. So the semantics of the data within the representation. And then there's what the computer can actually do. And every programming system, every information system, ultimately finds some spot in the middle of this little triangle. Sometimes some systems collapse them into just one edge. Are we including humans as a system in this? No, no, I'm just thinking about computing systems here. The reason I bring this up is because I believe there's no free lunch around this stuff. If we build machine learning systems to write the correct code, that is, at a certain level of performance, it'll select with the hyperparameters. We can tune how we want the performance boundary in SLA to look like for transforming some set of inputs into certain kinds of outputs. That training process itself is intrinsically sensitive to the kinds of inputs we put into it. It's quite sensitive to the boundary conditions we put around the performance. I think even as we move to using automated systems to build this transformation, as opposed to humans, explicitly from a top down perspective, figuring out, well, this schema and this database and these columns get selected for this algorithm. And here we put a Fibonacci heap for some other thing, human design or computer design. Ultimately, what we hit and the boundaries that we hit with these information systems is when the representation of the data hits the real world is where there's a lot of slop and a lot of interpretation. And that's where actually I think a lot of the work will go in the future is actually understanding how to better, in the view of these live data systems, how to better encode the semantics of the world for those things, there'll be less about the details of how we write a particular SQL query. Okay? But given the semantics of the real world and the messiness of that, what does the word correctness mean when you're talking about code? There's a lot of dimensions to correctness historically. And this is one of the reasons I say that we're coming to the end of the era of software, because for the last 40 years or so, software correctness was really defined about functional correctness. I write a function, it's got some inputs. Does it produce the right outputs? If so, then I can turn it on, hook it up to the live database, and it goes. And more and more now we have, I mean, in fact, I think the bright line in the sand between machine learning systems or modern data driven systems versus classical software systems is that the values of the input actually have to be considered with the function together to say this whole thing is correct or not. And usually there's a performance SLA as well. Like did it actually finish making SLA? Sorry, service level agreement. So it has to return within some time. You have a ten millisecond time budget to return a prediction of this level of accuracy. Right? So these are things that were not traditionally in most business computing systems for the last 20 years at all. People didn't think about it. But now we have value dependence on functional correctness. So that question of correctness is becoming a bigger and bigger question. Why does that map to the end of software? We've thought about software as just this thing that you can do in isolation with some test trial inputs and in a very sandboxed environment. And we can quantify how does it scale, how does it perform, how many nodes do we need to allocate if we want to scale this many inputs? When we start turning this stuff into prediction systems, real cybernetic systems, you're going to find scenarios where you get inputs that you're going to want to spend a little more time thinking about. You're going to find inputs that are not. It's not clear what you should do then. The software has a varying amount of runtime and correctness with regard to input, and that is a different kind of system altogether. Now, it's a full on cybernetic system. It's a next generation information system that is not like traditional software systems. Can you maybe describe what is a cybernetic system? Do you include humans in that picture? So is a human in the loop kind of complex mess of the whole kind of interactivity of software with the real world, or is this something more concrete? Well, when I say cybernetic, I really do mean that the software itself is closing the observe, orient, decide, act loop by itself. So humans being out of the loop is the fact. What, for me, makes it a cybernetic system? Humans are out of that loop when. Humans are out of the loop, when the machine is actually sort of deciding on its own what it should do next to get more information, that makes it a cybernetic system. So we're just at the dawn of this, right? I think everyone talking about Mlai. It's great. But really, the thing we should be talking about is when we really enter the cybernetic era and all of the questions of ethics and governance and correctness and all these things, they really are the most important questions. Okay, can we just linger on this? What does it mean for the human to be out of the loop in a cybernetic system? Because isn't this cybernetic system that's ultimately accomplished in some kind of purpose, that at the bottom, the turtles, all the way down at the bottom, turtle is a human. Well, the human may have set some criteria, but the human wasn't precise. So, for instance, I just read the other day that earlier this year, or maybe it was last year, at some point, the libyan army, I think, sent out some automated killer drones with explosives, and there was no human in the loop at that point. Put them in a geofenced area, said, find any moving target, like a truck or vehicle that looks like this, and boom, um, that's not a human in the loop. Right. So, increasingly, the less human there is in the loop, the more concerned you are about these kinds of systems, because, uh, there's unintended consequences. Like, less the original designer and engineer of the system is able to predict even one with good intent is able to predict the consequences of such a system is. That's right. There are some software systems that run without humans in the loop that are quite complex, and that's like the electronic markets. And we get flash crashes all the time. We get in the heyday of high frequency trading, there's a lot of market microstructure, of people doing all sorts of weird stuff that the market designers had never really thought about, contemplated or intended. When we run these full on systems with these automated trading bots, now, they become automated killer drones and then all sorts of other stuff. That's what I mean by we're at the dawn of the cybernetic era and the end of the era of just pure software. Are you more concerned if you're thinking about cybernetic systems or even like, self replicating systems? So systems that aren't just doing a particular task, but are able to sort of multiply and scale in some dimension in the digital or even the physical world? Are you more concerned about like the lobster being boiled? So a gradual, with us not noticing collapse of civilization, or a big explosion, like, oops, kind of a big thing where everyone notices, but it's too late. I think that it will be a different experience for different people. I do. I do share a common point of view with some of the climate people who are concerned about climate change and just the big existential risks that we have. But unlike a lot of people who share my level of concern, I think the collapse will not be quite so dramatic as some of them think. And what I mean is that I think that for certain tiers of, let's say, economic class or certain locations in the world, people will experience dramatic collapse scenarios. But for a lot of people, especially in the developed world, the realities of collapse will be managed. There will be narrative management around it, so that they essentially insulate the middle class will be used to insulate the upper class from the pitchforks and the flaming torches and everything. It's interesting because my specific question wasn't as general. My question is more about cybernetic systems or software. Okay, it's interesting, but it would nevertheless, perhaps be about class. So the effect of algorithms might affect certain classes more than others? Absolutely. I was more thinking about whether it's social media algorithms or actual robots. Is there going to be a gradual effect on us where we wake up one day and don't recognize the humans we are? Or is it something truly dramatic where there's, you know, like a meltdown of a nuclear reactor kind of thing. Chernobyl, like catastrophic events that are almost bugs in a program that scaled itself too quickly. Yeah. I'm not as concerned about the visible stuff. And the reason is because the big visible explosions, I mean, this is something I said about social media is that at least with nuclear weapons, when a nuke goes off, you can see it and you're like, well, that's really. Wow, that's kind of bad, right? I mean, Oppenheimer was reciting the Bhagavad Gita, right, when he saw one of those things go off. So we can see nukes are really bad. He's not reciting anything about Twitter. Well, right. But then when you have social media, when you have all these different things that conspire to create a layer of virtual experience for people that alienates them from reality and from each other, that's very pernicious. It's impossible to see. Right. And it kind of slowly gets in there. So you've written about this idea of virtuality on this topic, which you define as the subjective phenomenon of knowingly engaging with virtual sensation and perception and suspending or forgetting the context that it's simulacrum. So let me ask, what is real? Is there a hard line between reality and virtuality? Like perception drifts from some kind of physical reality? We have to kind of have a sense of what is the line. That's too. We've gone too far. Right. Right. For me, it's not about any hard line about physical reality as much as a simple question of does the particular technology help people connect in a more integral way with other people, with their environment, with all of the full spectrum of things around them? So it's less about, oh, this is a virtual thing and this is a hard real thing. More about when we create virtual representations of the real things. Always some things are lost in translation. Usually many, many dimensions are lost in translation. Right. We're now coming to almost two years of COVID people on Zoom all the time. You know, it's different when you meet somebody in person than when you see them on. I've seen you on YouTube lots. Right. But the seeing in person is very different. And so I think when we engage in virtual experiences all the time and we only do that, there is absolutely a level of embodiment, theres a level of embodied experience, some participatory interaction that is lost. And its very hard to put your finger on exactly what it is. Its hard to say, oh, were going to spend $100 million building a new system that captures this 5% better, higher fidelity, human expression, no ones going to pay for that. When we rush madly into a world of simulacrum and virtuality, the things that are lost, it's difficult. Once everyone moves there, it can be hard to look back and see what we've lost. So is it irrecoverably lost? Or rather, when you put it all on the table, is it possible for more to be gained than is lost? If you look at video games, they create virtual experiences that are surreal and can bring joy to a lot of people, can connect a lot of people, and can get people to talk a lot of trash, so they can bring out the best and the worst in people. So is it possible to have a future world where the pros outweigh the cons? It is. I mean, it's possible to have that in the current world. But when literally trillions of dollars of capital are tied to using those things to groom the worst of our inclinations and to attack our weaknesses in the limbic system, to create these things into id machines versus connection machines, then those good things don't stand a chance. Can you make a lot of money by building connection machines? Is it possible, do you think, to bring out the best in human nature, to create fulfilling connections and relationships in the digital world and make a shit ton of money? If I figure it out, I'll let you know. What's your intuition? Without concretely knowing what my intuition is. That a lot of our digital technologies give us the ability to have synthetic connections or to experience virtuality. They have co evolved with sort of the human expectations. It's sort of like sugary drinks. As people have more sugary drinks, they get. They need more sugary drinks to get that same hit, right? So with these virtual things and with tv and fast cuts and tiktoks and all these different kinds of things, we're co creating essentially humanity that sort of asks and needs those things. And now it becomes very difficult to get people to slow down. It gets difficult for people to hold their attention on slow things and actually feel that embodied experience, right? So mindfulness, now more than ever, is so important in schools and as a therapy technique for people, because our environment has been accelerated. And McLuhan actually talks about this in the electric environment of the television, and that was before TikTok and before front facing cameras. So I think for me, the concern is that it's not like we can ever switch to doing something better, but more of the humans and technology, they're not independent of each other. The technology that we use kind of molds what we need for the next generation of technology. Yeah, but humans are intelligent, and they're introspective, and they can reflect on the experiences of their life. So, for example, there's been many years in my life where I ate an excessive amount of sugar, and then a certain moment, I woke up and said, why do I keep doing this? This doesn't feel good, like, long term. And I think, so going through the TikTok process of realizing, okay, when I shorten my attention span, actually, that does not make me feel good longer term, and realizing that and then going to platforms, going to places that are away from the sugar. So in so doing, you can create platforms that can make a lot of money to help people wake up to what actually makes them feel good long term, develop, grow as human beings. And it just feels like humans are more intelligent than mice looking for cheese. They're able to sort of think. I mean, we can think. We can contemplate our own mortality. We can contemplate things like long term love, and we can have a long term fear of certain things like mortality. We can contemplate whether the experiences, the sort of the drugs of daily life that we've been partaking in is making us happier, better people. And then once we contemplate that, we can make financial decisions in using services and paying for services that are making us better people. So it just seems that we're in the very first stages of social networks that just were able to make a lot of money really quickly. But in bringing out sometimes the bad parts of human nature, they didn't destroy humans. They just. They just fed everybody a lot of sugar. And now everyone's going to wake up and say, hey, we're going to start having, like, sugar free social media. Right? Right. Well, there's a lot to unpack there. I think some people certainly have the capacity for that. And I certainly think, I mean, it's very interesting, even the way you said it, you woke up one day and you thought, well, this doesn't feel very good. Yeah. Well, still your limbic system saying, this doesn't feel very good. Right. You have a cat brain's worth of neurons around your gut and. Right. And so maybe that saturated. And that was telling you, hey, this isn't good. Humans are more than just mice looking for cheese or monkeys looking for sex and power. Right? So let's slow down. Now. You're, now, a lot of people would argue with you on that one, but. Yes, but we're more than just that. But we're at least that. And we're very, very seldom not that. So my, I don't actually disagree with you that we could be better and that we can, that better platforms exist and people are voluntarily noping out of things like Facebook and noping out of. That's an awesome verb. It's a great term. Yeah, I love it. I use it all the time. You're one of the best. Out of that. I want to. Nope, out of that. Right. That's going to be a hard pass. And, and that's, and that's, that's great. But that's, again, to your point, that's the first generation of front facing cameras of social pressures. And you as a, you know, self starter, self awareness adult, have the capacity to say, yeah, I'm not going to do that. I'm going to go and spend time on long form reads. I'm going to spend time managing my attention. I'm going to do some yoga. If you're a 15 year old in high school and your entire social environment is everyone doing these things, guess what you're going to do? You're going to kind of have to do that because your limbic system says, hey, I need to get the guy or the girl or the whatever, and that's what I'm going to do. And so one of the things that we have to reason about here is the social media systems, or social media, I think, is our first encounter with a technological system that runs a bit of a loop around our own cognition and attention. It's not the last, it's far from the last. And it gets to the heart of some of the philosophical, Achilles Heel of the western philosophical system, which is each person gets to make their own determination. Each person is an individual that's, you know, sacrosanct in their agency and their sovereignty and all these things. The problem with these systems is they come down and they are able to manage everyone en masse. And so every person is making their own decision, but together, the bigger system is causing them to act with a group dynamic that's very profitable for people. So this is the issue that we have, is that our philosophies are actually not geared to understand what is it for a person to be, to have a high trust connection as part of a collective, and for that collective to have its right to coherency and agency. That's something like when a social media app causes a family to break apart, it's done harm to more than just individuals. So that concept is not something we really talk about or think about very much. But that's actually the problem, is that we're vaporizing molecules into atomic units, and then we're hitting all the atoms with certain things. That's like, yeah, well, that person chose to look at my app. So our understanding of human nature is at the individual level. It emphasizes the individual too much, because ultimately, society operates at the collective level. And these apps do as well, and. The apps do as well. So for us to understand the progression, the development of this organism we call human civilization, we have to think at the collective level, too. I would say multi tiered. Multi tiered. Multi tiered. So individual as well. Individuals, family units, social collectives, and all the way up. Okay, so you've said that individual humans are multi layered, susceptible to signals and waves and multiple strata, the physical, the biological, social, cultural, intellectual. So, sort of going along these lines, can you describe the layers of the cake that that is a human being and maybe the human collective human society? So I'm just stealing wholesale here from Robert Persig, who is the author of Zen and the Art of Motorcycle Maintenance, and in his follow on book has a sequel to it called Lila. He goes into this in a little more detail, but it's a crude approach to thinking about people. But I think it's still an advancement over traditional subject object metaphysics, where we look at people as a dualist would say, well, is your mind, your consciousness? Is that just merely the matter that's in your brain, or is there something more beyond that? And they would say, yes, there's a soul, sort of ineffable soul beyond just merely the physical body. And I'm not one of those people. I think that we don't have to draw a line between are things only this or only that. Collectives of things can emerge, structures and patterns that are just as real as the underlying pieces, but they're transcendent, but they're still of the underlying pieces. So your body is this way. I mean, we just know. Physically, you consist of atoms and whatnot. And then the atoms are arranged into molecules, which then arrange into certain kinds of structures that seem to have a homeostasis to them. We call them cells, and those cells form sort of biological structures. Those biological structures give your body its physical ability and the biological ability to consume energy and to maintain homeostasis. But humans are social animals. Human by themselves is not very long for the world. So we also, part of our biology is wire to connect to other people, from the mirror neurons to our language centers and all these other things. So we are intrinsically, there's a layer. There's a part of us that wants to be part of a thing. If we're around other people not saying a word, but they're just up and down, jumping and dancing, laughing, we're going to feel better. Right? And there was no exchange of physical anything. They didn't give us, like five atoms of happiness. Right. But there's an induction in our own sense of self that is at that social level. And then beyond that, Persig puts the intellectual level kind of one level higher than social. I think they're actually more intertwined than that. But the intellectual level is the level of pure ideas that you are a vessel for memes, you're a vessel for philosophies. You will conduct yourself in a particular way. I mean, I think part of this is, if we think about it from a physics perspective, theres the joke that physicists like to approximate things and well say, well approximate a spherical cow, right? Youre not a spherical cow. Youre not a spherical human. Youre a messy human. And we cant even say what the dynamics of your motion will be unless we analyze all four of these layers. Right? If youre Muslim at a certain time of day, guess what, youre going to be on the ground, kneeling and praying. And that has nothing to do with your biological need to get on the ground or physics of gravity. It is an intellectual drive that you have. It's a cultural phenomenon and an intellectual belief that you carry. So that's what the four layered stack is all about. It's that a person is not only one of these things, they're all of these things at the same time. It's a superposition of dynamics that run through us, that make us who we are. So no layers special? Not so much. No layer is special. Each layer is just different. But we are. Each layer gets a participation trophy. Yeah. Each layer is a part of what you are. You are a layer cake of all these things. And if we try to deny so many philosophies, do try to deny the reality of some of these things, some people will say, well, we're only atoms. Well, we're not only atoms, because there's a lot of other things that are only atoms. I can reduce a human being to a bunch of soup, and they're not the same thing, even though it's the same atoms. So I think the order and the patterns that emerge within humans to understand, to really think about what a next generation philosophy would look like that would allow us to reason about extending humans into the digital realm or to interact with autonomous intelligences that are not biological in nature. We really need to appreciate what human beings actually are. Is the superposition of these different layers. You mentioned consciousness. Are each of these layers of cake conscious? Is consciousness a particular quality of one of the layers? Is there like a spike if you have a consciousness detector at these layers, or is something that just permeates all of these layers and just takes different form? I believe what humans experience as consciousness is something that sits on a gradient scale of a general principle in the universe that seems to look for order and reach for order. When there's an excess of energy, it would be odd to say a proton is alive. It'd be odd to say this particular atom or molecule of hydrogen gas is alive. But there's certainly something we can make assemblages of these things that have auto poetic aspects to them that will create structures that will. Crystalline solids will form very interesting and beautiful structures. This gets into weird mathematical territories. We start thinking about Penrose and game of life stuff about the generativity and math itself, like the hyper real numbers, things like that. But without going down that rabbit hole, I would say that there seems to be a tendency in the world that when there is excess energy, things will structure and pattern themselves, and they will then actually, furthermore, try to create an environment that furthers their continued stability. It's the concept of externalized, extended phenotype or niche construction. So this is ultimately what leads to certain kinds of amino acids forming certain kinds of structures and so on and so forth, until you get the ladder of life. So what we experience as consciousness, no, I don't think cells are conscious of that level. But is there something beyond mere equilibrium state biology and chemistry and biochemistry that drives a. What makes things work? I think there is. So Adrian Bajan has this constructal law. There's other things you look at when you look at the life sciences and you look at any kind of statistical physics and statistical mechanics. When you look at things far out of equilibrium, when you have excess energy, what happens then? Life doesn't just make a hotter soup. It starts making structure. There's something there. The poetry of reaches for order when there's an excess of energy. Mm hmm. Because you brought up game of life. You did it. Not me. My, I love cellular automata, so I have to sort of linger on that for a little bit. So cellular automata, I guess, is, or game of life, is a very simple example of reaching for order when there's an excess of energy or reaching for order and somehow creating complexity within, like, this explosion of just turmoil, somehow trying to construct structures and so doing creates very elaborate organism looking type things. What intuition do you draw from this simple mechanism? Well, I like to turn that around in its head and look at it as what if every single one of the patterns created life, or created not life, but created interesting patterns because some of them don't. And sometimes you make cool gliders and other times you start with certain things and you make gliders and other things that then construct, like, and gates and not gates. And you build computers on them. All of these rules that create these patterns that we can see. Those are just the patterns we can see. What if our subjectivity is actually limiting our ability to perceive the order in all of it? What if some of the things that we think are random are actually not that random? We're simply not integrating at a fine enough level across a broad enough time horizon? And this is, again, I said we go down the rabbit holes in the Penrose stuff, or like Wolfram's explorations on these things. There is something deep and beautiful in the mathematics of all this that is, hopefully one day I'll have enough money to where I can retire and just ponder those questions. But there's something there. But you're saying there's a ceiling to when you have enough money and you retire and you ponder it, there's a ceiling to how much you can truly ponderous because there's cognitive limitations in what you're able to perceive as a pattern. Yeah. And maybe mathematics extends your perception capabilities, but it's still finite. It's just like, yeah, the mathematics we use is the mathematics that can fit in our head. Yeah. You know, did God really create the integers or did God create all of it and we just happen at this point in time to be able to perceive integers? Well, he just did the positive energy. She created and then we. She just graded the natural numbers and then we screwed all up with zero. And then I guess. Okay, but we did. We created mathematical operations so we can have iterated steps to approach bigger problems. Right? I mean, the entire point of the arabic numeral system, and it's a rubric for mapping a certain set of operations, of folding them into a simple little expression. But that's just the operations that we can fit in our heads. There are many other operations besides. Right. The thing that worries me the most about aliens and humans is that aliens are all around us and we're too dumb to see them. Oh, certainly, yeah. Or life. I say just life. Life of all kinds of forms or organisms. You know what? Just even the intelligence of organisms is imperceptible to us because we're too dumb and self centered. That word. Well, we're looking for a particular kind of thing. When I was at Cornell, I had a lovely professor of asian religions, J. Marie Law, and she would tell this story about a musical, a musician, a western musician who went to Japan, and he taught classical music and could play all sorts of instruments. He went to Japan, and he would ask people. He would basically be looking for things in the style of western chromatic scale and these kinds of things, and then finding none of it. He would say, well, there's really no music in Japan, but they're using a different scale, they're playing different kinds of instruments. The same thing she was using as a metaphor for religion as well. In the west, we center a lot of religion, certainly the religions of Abraham, we center them around belief. And in the east, it's more about practice, spirituality and practice rather than belief. So, anyway, the point is here, to your point, life, I think so many people are so fixated on certain aspects of self replication or homeostasis or whatever, but if we kind of broaden and generalize this thing of things reaching for order, under which conditions can they then create an environment that sustains that order, that allows them? The invention of death is an interesting thing. There are some organisms on earth that are thousands of years old, and it's not like they're incredibly complex. They're actually simpler than the cells that comprise us, but they never die. So at some point, death was invented somewhere along the eukaryotic scale. I mean, even the protists, right, there's death. And why is that? Along with the sexual reproduction, right. There is something about the renewal process, something about the ability to respond to a changing environment wherever it just becomes. Just killing off the old generation and letting new generations try seems to be the best way to fit into the niche. You know, human historian seems to write about wheels and fire as the greatest inventions, but it seems like death and sex are pretty good, and they're kind of essential inventions at the very beginning. At the very beginning, yeah. Well, we didn't invent them. Right. Well, broad, we, you didn't invent life. I see us as one, you, particular homo sapien did not invent them, but we together, it's a team project, just like you're saying. I think the greatest homo sapien invention is collaboration. So when you say collaboration, peter, where do ideas come from, and how do they take hold in society is that the nature of collaboration is that the basic atom of collaboration is ideas. It's not not ideas, but it's not only ideas. There's a book I just started reading called death from a distance. Have you heard of this? No. It's a really fascinating thesis, which is that humans are the only con specific, the only species that can kill other members of the species from range. And maybe there's a few exceptions, but if you look in the animal world, you see, like, pronghorns butting heads, right? You see the alpha lion and the beta lion, and they take each other down. Humans, we develop the ability to chuck rocks at each other. Well, at prey, but also at each other. And that means the beta male can chunk a rock at the alpha male and take them down. He can throw a lot of rocks, actually miss a bunch of times, but just hit once and be good. So this ability to actually kill members of our own species from range without a threat of harm to ourselves created essentially mutually assured destruction where we had to evolve cooperation. If we didn't, then if we just continue to try to do, like, I'm the biggest monkey in the tribe and I'm going to own this tribe and you have to go. If we do it that way, then those tribes basically failed. And the tribes that persisted and that have now given rise to the modern homo sapiens are the ones where respecting the fact that we can kill each other from range without har, like, there's an asymmetric ability to snipe the leader from range. That meant that we sort of had to learn how to cooperate with each other. Come back here. Don't throw that rock at me. Let's talk our. So violence is also part of collaboration? The threat of violence, let's say. Well, the recognition, maybe the better way to put it, is the recognition that we have more to gain by working together than the prisoner's dilemma of both of us defecting. So mutually sure destruction in all its forms is part of this idea of collaboration. Well, and Eric Weinstein talks about our nuclear peace, right? I mean, it kind of sucks that with thousands of warheads aimed at each other, Russia and the US, it's like, on the other hand, we only fought proxy wars. We did not have another World War III of hundreds of millions of people dying to machine gun fire and giant guided missiles. So the original nuclear weapon is a rock that we learned how to throw, essentially, yeah. Well, the original scope of the world for any human being was their little tribe, I would say it still is. For the most part, Eric Weinstein speaks very highly of you, which was very surprising to me at first because I didn't know there's this depth to you. Cause I knew you as an amazing leader of engineers and engineer yourself and so on. So it's fascinating. Maybe just as a comment, a side tangent that we can take. What's your nature of your friendship with Eric Weinstein? How did the two, how did such two interesting paths crossed? Your origins in physics? Is it your interest in philosophy and the ideas of how the world works? What is it? It's actually. It's very random. Eric found me. He actually found Travis and I. Travis Oliphant. Oliphant. Yeah. We were both working at a company called Enthought back in the mid two thousands, and we're doing a lot of consulting around scientific python. And we'd made some tools, and Eric was trying to use some of these python tools to visualize. He had a fiber bundle approach to modeling certain aspects of economics. He was doing this, and that's how he kind of got in touch with us. And so this was in the early. This was in the mid two thousands zero seven time frame 0607. Eric Weinstein trying to use Python, visualize. Fiber bundles using some of the tools that we built in the open source. That's somehow entertaining to me, the thought of that. It was really funny. But then we met with him a couple of times, a really interesting guy. And then in the wake of the. The 0708 financial collapse, he helped organize with Lee Smolin, a symposium at the perimeter institute about. Okay, well, clearly big finance can't be trusted. Government's in its pockets with regulatory capture. What the f. Do we do? And all sorts of people. Nassim Talaib was there, and Andy Lowe from MIT was there, and Bill Janeway. I mean, just a lot of top billing people were there. And he invited me and Travis and another one of our co workers, Robert Kern, who was a. Anyone in the sci PI numpy community knows Robert. Really great guy. So the three of us also got invited to go to this thing. And that's where I met Brett Weinstein for the first time as well. Yeah, I knew him before he got all famous, for unfortunate reasons, I guess. But anyway, so we met then and kind of had a friendship. Since then, you have a depth of thinking that kind of runs with Eric in terms of just thinking about the world deeply and thinking philosophically. And then there's Eric's interest in programming. I actually never, you know, he'll bring up programming to me quite a bit as a metaphor for stuff. Right. But I never kind of pushed the point of, like, what's the nature of your interest in programming? I think he saw it probably as a tool. Yeah, absolutely. That to visualize, to explore mathematics and explore physics. But I was wondering, like, what's the. His depth of interest and also his vision for what programming would look like in the future. Have you had interaction with him, like, discussion in the space of python and programming? Well, in the sense of sometimes he asks me, why is this stuff still so hard? Yeah, everybody's a critic. But actually, no, Eric. Programming, you mean? Yes, yes. Well, not programming in general. Certain things in the python ecosystem. But he actually. I think what I find in listening to some of his stuff is that he does use programming metaphors a lot. Right. He'll talk about APIs or object oriented and things like that. So I think that's a useful set of frames for him to draw upon for discourse. I haven't pair programmed with him in a very long time. Well, I mean, trying to help put together some of the visualizations around these things, but it's been a very not really pair program. But, like, even looked at his code. Right. I mean, how legendary would be. Is that like get repo with Peter Wang and Eric Weinstein? Well, honestly, honestly, Robert Kern did all the heavy lifting, so I have to give credit where credit is due. Robert is. Is the silent but incredibly deep quiet. Not silent, but quiet, but incredibly deep individual at the heart of a lot of those things that Eric was trying to do. But we did have, you know, in the. As Travis and I were starting our company in 2012 timeframe, we went to New York. Eric was still in New York at the time. He hadn't moved to. This was before he joined Teal capital. We just had like, a steak dinner somewhere. Maybe it was Keynes, I don't know, somewhere in New York. So it's me, Travis, Eric, and then Wes McKinney, the creator of pandas, and then Wes's then business partner, Adam. The five of us sat around having this just a hilarious time, amazing dinner. I forget what all we talked about, but it was. It was one of those conversations which I wish, as soon as Covid is over, maybe Eric and I can sit down, recreate, recreate it somewhere in LA. Or maybe he comes here because a lot of cool people are here in Austin. Right? Exactly. Yeah, we're all here. He should come here, come here. So he uses the metaphor source code sometimes to talk about physics. We figure out our own source code. So, you with a physics background and somebody who's quite a bit of an expert in source code, do you think we'll ever figure out our own source code in the way that Eric means? Do you think we'll figure out the nature of. I'm constantly working on that problem. I mean, I think we'll make more and more progress. For me, there's some things I don't really doubt too much. I don't really doubt that one day we will create a synthetic, maybe not fully in silicon, but a synthetic approach to cognition that rivals the biological 20 watt computers in our heads. What's cognition here? Cognition, perception, attention, memory, recall, asking better questions. That, for me, is a measure of intelligence. Doesn't Roomba vacuum cleaner already do that? Or do you mean. Oh, it doesn't ask questions? I mean, no, it's. I mean, I have a roomba, but it's. Well, it's not even as smart as my cat, right? So, yeah, but it asks questions about, what is this wall it now new feature asks, is this poop or not? Apparently, yes. A lot of our current cybernetic system. It's a cybernetic system. It will go and it will happily vacuum up some poop, right? The older generations would. New one just released does not vacuum up the poop. This is a commercial for me. I wonder if it still gets stuck under my first rung of my stare. In any case, these cybernetic systems we have, they're designed to be sent off into a relatively static environment. And whatever dynamic things happen in the environment, they have a very limited capacity to respond to a human baby. A human toddler of 18 months of age has more capacity to manage its own attention and its own capacity to make better sense of the world than the most advanced robots today. So, again, my cat, I think, can do a better job of my two, and they're both pretty clever. So I do think, though, back to my kind of original point, I think that it's not, for me, it's not question at all that we will be able to create synthetic systems that are able to do this better than the human at an equal level or better than the human mind. It's also, for me, not a question that we will be able to put them alongside humans so that they capture the full, broad spectrum of what we are seeing as well, and also looking at our responses, listening to our responses, even maybe measuring certain vital signs about us. So, in this sidecar mode, a greater intelligence could use us and our whatever 80 years of life to train itself up and then be a very good simulacrum of us moving forward. So who is in the sidecar in that picture of the future? Exactly. The baby version of our immortal selves. Okay, so once the baby grows up, is there any use for humans? I think so. I think that out of epistemic humility, we need to keep humans around for a long time. And I would hope that anyone making those systems would believe that to be true. Out of epistemic humility, what's the nature of the humility? That we don't know. What we don't know. So we don't. Right, so we don't know. I mean, first we have to build systems that. That help us do the things that we do know about, that can then probe the unknowns that we know about. But the unknown unknowns we don't know. We could always. Nature is the one thing that is infinitely able to surprise us. So we should keep biological humans around for a very, very, very long time, even after our immortal selves have transcended, have gone off to explore other worlds, gone to go communicate with the life forms living in the sun or whatever else. So I think, for me, these seem like things that are going to happen. I don't really question that, that they're going to happen. Assuming we don't completely destroy ourselves, is. It possible to create an AI system that you fall in love with and it falls in love with you, and you have a romantic relationship with it, or a deep friendship, let's say. I would hope that that is the design criteria for any of these systems. If we cannot have a meaningful relationship with it, then it's still just a chunk of silicon. So then what is meaningful? Because back to sugar. Well, sugar doesn't love you back, right? So the computer has to love you back. And what does love mean? Well, in this context, for me, love, I'm going to take a page from Ellen de Bouton. Love means that it wants to help us become the best version of ourselves. Yes. That's beautiful. That's a beautiful definition of love. So what role does love play in the human condition at the individual level and at the group level? Because you were kind of saying that humans, we should really consider humans both at the individual and the group and the societal level. What's the role of love in this whole thing? We talked about sex. We talked about death, thanks to the bacteria that invented it. At which point did we invent love, by the way? I mean, is that also. No, I think love is the start of it all and the feelings of. And this gets beyond just romantic, sensual, whatever kind of things, but actually genuine love as we have for another person, love as it would be used in a religious text, right. I think that capacity to feel love more than consciousness, that is the universal thing. Our feeling of love is actually a sense of that generativity. When we can look at another person and see that they can be something more than they are and more than just what we a pigeonhole, we might stick them in. I mean, I think there's, in any religious text you'll find a voiced some concept of this, that you should see the grace of God in the other person, right? They're made in the spirit of what the love that God feels for his creation or her creation. And so I think this thing is actually the root of it. So I would say, I don't think molecules of water feel consciousness, have consciousness, but there is some proto micro quantum thing of love. That's the generativity, when theres more energy than what they need to maintain equilibrium. And that when you sum it all up, is something that leads to, I mean, I had my mind blown one day as an undergrad at the physics computer lab. I logged in, and when you log into bash for a long time, there was a little fortune that would come out and it said man was created by water to carry itself uphill. I was logging in to work on some problem set, and I logged in and I saw that and I just said, son of a bitch. I logged out, I went to the coffee shop and I got a coffee and I sat there on the quad, like, you know, it's not wrong. And yet, WTF? Right? So when you look at it that way, it's like, yeah, okay, non equilibrium physics is a thing. And so when we think about love, when we think about these kinds of things, I would say that in the modern day human condition, theres a lot of talk about freedom and individual liberty and rights and all these things. But thats very hegelian. Its very kind of following from the western philosophy of the individual as sacrosanct. But its not really couched, I think, the right way because it should be. How do we maximize peoples ability to love each other, to love themselves first, to love each other, their responsibilities to the previous generation, to the future generations. Those are the kinds of things that should be our design criteria. Those should be what we start with to then come up with the philosophies of self and of rights and responsibilities. But that love being at the center of it. I think when we design systems for cognition, it should absolutely be built that way. I think if we simply focus on efficiency and productivity, these kind of very industrial era, all the things that Marx had issues with, right. Thats a way to go, and really, I think, go off the deep end in the wrong way. So one of the interesting consequences of thinking of life in this hierarchical way of an individual human, and then theres groups and theres societies is, I believe that you believe that corporations are people. So this is kind of a politically dense idea and all those kinds of things. If we just throw politics aside, if we throw all of that aside, in which sense do you believe that corporations are people? And how does love connect to that? Right. So the belief is that groups of people have some kind of higher level, I would say mesoscopic claim to agency. Let's start with this. Most people would say, okay, individuals have claims to agency and sovereignty. Nations, we certainly act as if nations. So at a very large, large scale nations have rights to sovereignty and agency. Like everyone plays the game of modernity as if that's true. Right. We believe France is a thing. We believe the United States is a thing. But to say that groups of people at a smaller level than that, like a family unit, is the thing. Well, in our laws, we actually do encode this concept. I believe that in a relationship and a marriage, one partner can sue for loss of consortium if someone breaks up the marriage or whatever. So these are concepts that even in law, we do respect, that there is something about the union and about the family. So for me, I don't think it's so weird to think that groups of people have a claim to rights and sovereignty of some degree. I mean, we look at our clubs, we look at churches, we talk about these collectives of people as if they have a real agency to them, and then they do. But I think if we take that one step further and say, okay, they can accrue resources, well, yes, check by law, they can. They can own land, they can engage in contracts. They can do all these different kinds of things. So we, in legal terms, support this idea that groups of people have rights. Where we go wrong on this stuff is that the most popular version of this is the for profit, absentee owner corporation that then is able to amass larger resources than anyone else in the landscape. Anything else, any other entity of equivalent size. And they're able to essentially bully around individuals, whether it's laborers, whether it's people whose resources they want to capture. They're also able to bully around our system of representation, which is still tied to individuals, right? So I don't believe that's correct. I don't think it's good that they're people, but they're assholes. I don't think that corporations as people acting like assholes is a good thing. But the idea that collectives and collections of people, that we should treat them philosophically as having some agency, some agency, and some mass, at a mesoscopic level, I think that's an important thing, because one thing I do think we underappreciate sometimes is the fact that relationships have relationships. So it's not just individuals having relationships with each other, but if you have eight people seated around a table, each person has a relationship with each of the others. And that's a obvious. But then if it's four couples, each couple also has a relationship with each of the other couples. The dyads do. And if it's couples, but one is the father mother older, and then one of their children and their spouse, that family unit of four has a relationship with the other family unit of four. So the idea that relationships have relationships is something that we intuitively know in navigating the social landscape. But it's not something I hear expressed like that. It's certainly not something that is, I think, taken into account very well when we design these kinds of things. So I think the reason why I care a lot about this is because I think the future of humanity requires us to form better sense, make collective sense, making units at something around Dunbar, number half to five x Dunbar. And that's very different than right now, where we defer sense making to massive, aging, zombie institutions, or we just do it ourselves. We go it alone, go into the dark force of the Internet by ourselves. So that's really interesting. So you've talked about agency, I think, maybe calling it a convenient fiction at all these different levels. So even at the human individual level, it's kind of a fiction we all believe because we are, like you said, made of cells, and cells are made of atoms. So that's a useful fiction. And then there's nations. That seems to be a useful fiction, but it seems like some fictions are better than others. There's a lot of people that argue the fiction of nation is a bad idea. One of them lives two doors down from me, Michael Malus. He's an anarchist. I'm sure there's a lot of people who are into meditation that believe the idea. This useful fiction of agency of an individual is troublesome as well. We need to let go of that in order to truly transcend. I don't know. I don't know what words you want to use, but suffering, or to elevate the experience of life. You're arguing that. Okay, so we have some of these useful fictions of agency. We should add a. A stronger fiction that we tell ourselves about the agency of groups in the hundreds of half a. Dunbar's number five X. Dunbar's number. Yeah. Something on that order. And we call them fictions, but really they're rules of the game, right? Rules that we feel are fair, or rules that we consent to. I always question the rules when I lose. Like a monopoly. That's when I usually question. When I'm winning, I don't question the rules. We should play game Monopoly someday. There's a trippy version of it that we could do. Contract Monopoly is introduced by a friend of mine to me, where you can write contracts on future earnings or landing on various things, and you can hand out, like, you can land the first three times, you land on park places free or whatever. Then you can start trading those contracts for money. And then you create a human civilization, and somehow bitcoin comes into it. But some of these, actually, I bet. If me and you and Eric sat down to play a game of monopoly, and we were to make NFTs out of the contracts we wrote, we could make a lot of money. Now. It's a terrible idea. I would never do it, but I bet we could actually sell the NFTs around. I have other ideas to make money that I could tell you, and they're all terrible ideas, including cat videos on the Internet. Okay, but some of these rules of the game, some of these fictions are, it seems like they're better than others. They have worked this far to cohere human, to organize human collective action. But you're saying something about, especially this technological age, requires modified fictions, stories of agency. Why the Dunbar number? And also, how do you select the group of people? Dunbar numbers. I think I have the sense that it's overused as a kind of law, that somehow we can have deep human connection at this scale. Like, some of it feels like an interface problem, too. It feels like if I have the right tools, I can deeply connect with a large number, larger number of people. It just feels like there's a huge value to interacting just in person, getting to share traumatic experiences together, beautiful experiences together. But there's other experiences. Like, um, that in the digital space that you can share. It just feels like Dunbar's number could expand it significantly, perhaps not to, to the level of millions and billions, but it feels like it could be expended. So how. Yeah, how do we find the right interface, you think, for having a little bit of a collective here that has agency? You're right that there's many different ways that we can build trust with each other. My friend Joe Edelman talks about a few different ways that. Mutual appreciation, trustful conflict, just experiencing something. There's a variety of different things that we can do, but all those things take time, and you have to be present. The less present you are. There's just, again, a no free lunch principle here. The less present you are, the more of them you can do, but then the less connection you build. So I think there is sort of a human capacity issue around some of these things. Now, that being said, if we can use certain technologies. So, for instance, if I write a little monograph on my view of the world, you read it asynchronously at some point, and you're like, wow, Peter, this is great. Here's mine. I read it. I'm like, wow, Lex, this is awesome. We can be friends without having to spend ten years figuring all this stuff out together. We just read each other's thing and be like, oh, yeah, this guy's exactly in my wheelhouse. And vice versa. And we can then connect just a few times a year and maintain a high trust relationship. It can be expanded a little bit, but it also requires. These things are not all technological in nature. It requires the individual themselves to have a certain level of capacity, to have a certain lack of neuroticism. If you want to use the, the ocean, big five sort of model, people have to be pretty centered. The less centered you are, the fewer authentic connections you can really build for a particular unit of time. It just takes more time. Other people have to put up with your crap. There's just a lot of the stuff that you have to deal with if you are not so well balanced. Yes, we can help people get better to where they can develop more relationships faster. And then you can maybe expand Dunbar number by quite a bit. But you're not going to do it. I think it's going to be hard to get it beyond ten x. Kind of the rough swag of what it is, you know? Well, don't you think that AI systems could be an addition to Dunbar's number? So, like, why do you count as. One system or multiple AI systems? Multiple AI systems. So I do believe that AI systems, for them to integrate into human society, as it is now, have to have a sense of agency. So there has to be a individual because otherwise we wouldn't relate to them. We could engage certain kinds of individuals to make sense of them for us and be almost like, did you ever watch Star Trek? Like Voyager? There's the Volta. Who are the interfaces? The ambassadors for the Dominion. We may have ambassadors that speak on behalf of these systems. They're like the mentats of dune, maybe, or something like this. I mean, we already have this to some extent. If you look at the biggest sort of, I wouldn't say AI system, but the biggest cybernetic system in the world is the financial markets. It runs outside of any individual's control. And you have an entire stack of people on Wall Street, Wall street analysts to CNBC reporters, whatever. They're all helping to communicate. What does this mean? You know, Jim Cramer, like, running around and yelling stuff. Like all of these people are part of that lowering of the complexity there to meet sense, you know, to help do sense making for people at whatever capacity they're at. And I don't see this changing with AI systems. I think you would have ringside commentators talking about all this stuff that this AI system is trying to do over here, over here, because it's actually a super intelligence. So if you want to talk about humans interfacing, making first contact with super intelligence, we're already there. We do it pretty poorly. And if you look at the gradient of power and money, what happens is the people closest to it will absolutely exploit their distance for personal financial gain. So we should look at that and be like, oh, well, that's probably what the future will look like as well. But nonetheless, we're already doing this kind of thing. So in the future we can have AI systems, but you're still gonna have to trust people to bridge the sense making gap to them. See, I don't. I just feel like there could be like millions of AI systems that have. Have agencies you have. When you say one super intelligence. Superintelligence in that context means it's able to solve particular problems extremely well. But there's some aspect of human like intelligence that's necessary to be integrated into human society. So not financial markets, not sort of weather prediction systems or, I don't know, logistics optimization. I'm more referring to things that you interact with on the intellectual level. Yeah. And that, I think requires. There has to be a backstory. There has to be a personality. I believe it has to fear its own mortality in a genuine way. Like, there has to be all many of the elements that we humans experience that are fundamental to the human condition, because otherwise we would not have a deep connection with it. But I don't think having a deep connection with it is necessarily going to stop us from building a thing that has quite an alien intelligence aspect. Sure. So the other kind of alien intelligence on this planet is octopuses or octopodies or whatever you want to call them. Octopi. Yeah. There's a little controversy as to what the plural is, I guess. Butters an octopuse. It really acts as a collective intelligence of eight intelligent arms. Its arms have a tremendous amount of neural density to them. And I see if we can build, I mean, lets go with what youre saying. If we build a singular intelligence that interfaces with humans, that has a sense of agency, so it can run the cybernetic loop and develop its own theory of mind as well as its a theory of action, all these things, I agree with you that thats the necessary components to build a real intelligence. There's got to be something at stake. It's got to make a decision. It's got to then run the Ooda loop. We build one of those? Well, if we can build one of those, we can probably build 5 million of them. So build 5 million of them. And if their cognitive systems are already digitized and already kind of there, we stick an antenna on each of them, bring it all back to a hive mind that maybe doesn't make all the individual decisions for them, but treats each one as almost like a neuronal input at a much higher bandwidth and fidelity going back to a central system that is then able to perceive much broader dynamics that we can't see in the same way that a phased array radar. You think about how phased array radar works. It's just sensitivity, it's just radars, and then it's hypersensitivity and really great timing between all of them. And with a flat array, it's as good as a curved radar dish with these things. It's a phased array of cybernetic systems that'll give the centralized intelligence much, much better, much higher fidelity understanding of what's actually happening in the environment. But the more power, the more understanding the central superintelligence has, the dumber the individual fingers of this intelligence are, I think not necessarily. I don't see what it has to be this argument. There has to be the experience of the individual agent has to have the full richness of the human like experience. You have to be able to be driving the car in the rain, listening to Bruce Springsteen and all of a sudden break out in tears. Because remembering something that happened to you. In high school, we can implant those memories if that's really needed. But no, but the central agency, I guess I'm saying, in my view, for intelligence to be born, you have to have a decentralization. Like, each one has to struggle and reach. So each one, in excess of energy has to reach for order, as opposed to a central place doing so. Have you ever read, like, some Sci-Fi where there's, like, hive minds? Like the Werner vinge, I think, has one of these, and then some of the stuff from. Yes, on the Commonwealth saga. The idea that you're an individual, but you're connected with a few other individuals telepathically as well, and together you form a swarm. So if you are, I need to ask you, what do you think is the experience of. If you are like, well, a borg, right? If you are one, if you're part of this hive mind, outside of all the aesthetics, forget the aesthetics. Internally, what is your experience like? Cause I have a theory as to what that looks like. The one question I have for you about that experience is how much is there a feeling of freedom, of free will? Because I obviously, as a human, very unbiased, but also somebody who values freedom and biased. It feels like the experience of freedom is essential for trying stuff out to being creative and doing something truly novel, which is at the core of. Yeah, well, I don't think you have to lose any freedom when you're in that mode. Because I think what happens is we think. We still think. And I mean, you're still thinking about this in a sense of a top down command and control hierarchy, which is not what it has to be at all. I think the experience. So I'll just show my carts here. I think the experience of being a robot in that robot swarm, a robot who has agency over their own local environment, that's doing sense making and reporting it back to the hive mind. I think that robots experience would be one of. When the hive mind is working well, it would be an experience of talking to God that you essentially are reporting. Two, you're sort of saying, here's what I see. I think this is what's going to happen over here. I'm going to go do this thing, because I think if I'm going to do this, this will make this change happen in the environment. And God, she may tell you, that's great. And in fact, your brothers and sisters will join you to help make this go better. Then she can let your brothers and sisters know, hey, Peter is going to go do this thing. Would you like to help him? Because we think that this will make this thing go better. And they'll say, yes, we'll help him. The whole thing could be actually a very emergent. The sense of what does it feel like to be a cell in a network that is alive, that is generative? And I think actually the feeling is serendipity, that there is random order. Not random disorder or chaos, but random order. Just when you need it to hear Bruce Springsteen, you turn on the radio and bam, it's Bruce Springsteen. That feeling of serendipity. I feel like this is a bit of a flight of fancy, but every cell in your body must have like, what does it feel like to be a cell in your body? When it needs sugar, there's sugar. When it needs oxygen, there's just oxygen. Now, when it needs to go and do its work and pull like as one of your muscle fibers, right. It does its work and it's great. It contributes to the cause. Right? So this is all, again a flight of fancy. But I think as we extrapolate up, what does it feel like to be an independent individual with some bounded sense of freedom? All sense of freedom is actually bounded, but with a bounded sense of freedom that still lives within a network that has order to it. And I feel like it has to be a feeling of serendipity. So the cell, there's a feeling of serendipity even though it has no way. Of explaining why it's getting oxygen and sugar when it gets it. So you have to, each individual component has to be too dumb to understand the big picture? No, the big picture is bigger than what it can understand. But isn't that an essential characteristic of the individual is to be too dumb to understand the bigger picture? Like, not dumb necessarily, but limited in its capacity to understand. Because the mo, okay, the moment you understand, I feel like that leads to if you tell me now that there's some bigger intelligence controlling everything I do, intelligence, broadly defined. Meaning like, you know, even the Sam Harris thing, there's no free will. If I'm smart enough to truly understand that, that's the case. That's gonna, I don't know if I, well, yeah. Philosophical breakdown. Yeah, right. Because we're in the west and we're pumped full of this stuff of like, you are a golden, fully free individual with all your freedoms and all your liberties and go grab a gun and shoot whatever you want to. No, it's actually you don't actually have a lot of these. You're not unconstrained, but the areas where you can manifest agency, you're free to do those things. You can say whatever you want on this podcast. You can create a podcast, right? Yeah, you have a lot of this kind of freedom. But even as you're doing this, you are actually, I guess, where the denouement of this is that we are already intelligent agents in such a system, in that one of these robots of one of 5 million little swarm robots, or one of the Borg, they're just posting an internal bulletin board. I mean, maybe the Borg cube is just a giant Facebook machine floating in space, and everyone's just posting on there. They're just posting really fast and like. Oh, yeah, that's called the metaverse now. The net's called the metaverse. That's right. Here's the enterprise. Maybe we should all go shoot it. Yeah, everyone upvotes and they're going to go shoot it. Right. But we already are part of a human online collaborative environment and collaborative sense making system. It's not very good yet. It's got the overhangs of zombie sense making institutions all over it. But as that washes away and as we get better at this, we are going to see humanity improving at speeds that are unthinkable in the past. And it's not because anyone's freedoms were limited. In fact, the open source, we started this with open source software, right? The collaboration. What the Internet surfaced was the ability for people all over the world to collaborate and produce some of the most foundational software that's in use today. That entire ecosystem was created by collaborators all over the place. So these online kind of swarm kind of things are not novel. It's just, I'm just suggesting that future AI systems, if you can build one smart system, you have no reason not to build multiple. If you build multiple, there's no reason not to integrate them all into a collective sense making substrate. And that thing will certainly have emergent intelligence that none of the individuals and probably not any of the human designers will be able to really, you know, put a bow around and explain. But in some sense, would that AI system still be able to go, like, rural Texas, buy a ranch, go off the grid, go full survivalist? Can you disconnect from the hive mind? You may not want to. So to be ineffective, to be intelligent. You have access to way more intelligence capability. If you're plugged into 5 million other really, really smart cyborgs, why would you. Leave so, like, there's a word control that comes to mind. So it doesn't, it doesn't feel like control, like over overbearing control. It's just, I think systems, well, this is to your point. I mean, look at, look at how much, how uncomfortable you are with this concept, right? I think systems that feel like overbearing control will not evolutionarily win out. I think systems that give their individual elements the feeling of serendipity and the feeling of agency that those systems will win. But that's not to say that there will not be emergent, higher level order on top of it. And that's the thing. That's the philosophical breakdown that we're staring right at, which is in the western mind. I think there's a very sharp delineation between explicit control, cartesian like, what is the vector? Where is the position? Where is it going to? It's completely deterministic and kind of this idea that things emerge, everything we see is the emergent patterns of other things, and there is agency when there's extra energy. Nate so you have spoken about a kind of meaning crisis that we're going through, but it feels like since we invented sex and death, we, broadly speaking, we've been searching for a kind of meaning. So it feels like human civilization has been going through a meaning crisis of different flavors throughout its history. Why is, how is this particular meaning crisis different? Or is it really a crisis and it wasn't previously? What's your sense? A lot of human history, there wasn't so much a meaning crisis. There was just a like, food and not getting eaten by bears crisis. Right. Once you get to a point where you can make food, there was the not getting killed by other humans crisis. So sitting around wondering what is it all about? Is actually a relatively recent luxury. And to some extent, the meaning crisis coming out of that is precisely because. Well, not precisely because I believe that meaning is the consequence of when we make consequential decisions. It's tied to agency. When we make consequential decisions, that generates meaning. So if we make a lot of decisions, but we dont see the consequences of them, then it feels like, what was the point? Right? But if theres all these big things happening, but were just along for the ride, then it also does not feel very meaningful. Meaning, as far as I can tell, this is my working definition of circa 2021, is generally the result of a person making a consequential decision, acting on it, and then seeing the consequences of it. So historically, just when humans are in survival mode, you're making consequential decisions all the time, so there's not a lack of meaning because you either got eaten or you didn't. You got some food, and that's great, you feel good. These are all consequential decisions. Only in the post fossil fuel and industrial revolution could we create a massive leisure class. I could sit around not being threatened by bears, not starving to death, making decisions somewhat, but a lot of times not seeing the consequences of any decisions they make. The general sort of sense of anomie. I think there's the french term for it. In the wake of the consumer society, in the wake of mass media telling everyone, hey, choosing between Hermes and Chanel is a meaningful decision. No, it's not. I don't know what either of those mean. There's high end luxury purses and crap like that. But the point is that we give people the idea that consumption is meaning, that making a choice of this team versus that team spectating has meaning. So we produce all of these different things that are as if meaning, but really making a decision that has no consequences for us. And so that creates the meaning crisis. Well, you're saying choosing between Chanel and the other one is that has no consequence. I mean, why is one more meaningful than the other? It's not that it's more meaningful than the other. It's that you make a decision between these two brands and you're told, this brand will make me look better in front of other people if I buy this brand of car, if I wear that brand of apparel. A lot of the decisions we make are around consumption. But consumption by itself doesn't actually yield meaning. Gaining social status does provide meaning. So that's why in this era of abundant production, we so many things turn into status games. The NFT kind of explosion is a similar kind of thing. Everywhere there are status games because we just have so much excess production. But aren't those status games a source of meaning? Why do the games we play have to be grounded in physical reality like they are when you're trying to run away from. From lions? Why can't we, in this virtuality world, on social media? Why can't we play the games on social media? Even the dark ones? Right, we can. But you're saying that's great. There's a meaning crisis. Well, there's a meaning crisis in that there's two aspects of it. Number one, playing those kinds of status games oftentimes requires destroying the planet because it ties to consumption. Consuming the latest and greatest version of a thing, buying the latest limited edition sneaker and throwing out all the old ones. Maybe you keep some of the old ones, but the amount of sneakers we have to cut up and destroy every year to create artificial scarcity for the next generation, this is kind of stuff that's not great. It's not great at all. So conspicuous consumption, fueling status games is really bad for the planet, not sustainable. The second thing is you can play these kinds of status games, but then what it does is it renders you captured to the virtual environment. The status games that the really wealthy people are playing are all around the hard resources where they're going to build the factories, they're going to have the fuel in the rare earths to make the next generation of robots. They're then going to run game, run circles around you and your children. So that's another reason not to play those virtual status games. So you're saying ultimately the big picture game is one if by people who have access or control over actual hard resources. So you can't, you don't see a society where most of the games are played in the virtual space, they'll be. Captured in the physical space. It's it all, it all builds. It's just like the stat, the stack of human being, right? If you only play the game at the cultural and then intellectual level, then the people with the hard resources and access to layer zero physical, are going to own you. But isn't money not connected to, or less and less connected to hard resources? And money still seems to work. It's a virtual technology. There's different kinds of money. Part of the reason that some of the stuff is able to go a little unhinged is because the big sovereignties where one spends money and uses money and plays money games and inflates money, their ability to adjudicate the physical resources and hard resources on land and things like that, those have not been challenged in a very long time. So we went off the gold standard. Most money is not connected to physical resources. It's an idea. And that idea is very closely connected to status. But it's also tied to, like, it's actually tied to law, it is tied to some physical hard things. So you have to pay your taxes. Yes. So it's always at the end going to be connected to the blockchain of physical reality. So in the case of law and taxes, it's connected to government. And government is what violence is. The, I'm playing the monopoly violence of devil's advocates here and popping one devil off the stack at a time isn't. Ultimately, of course, it'll be connected to physical reality. But just because people control the physical reality doesn't mean the status. LeBron James, in theory, could make more money than the owners of the teams in theory. And to me, that's a virtual idea. So somebody else constructed a game, and now you're playing in the space of virtual. In the virtual space of the game. So it just feels like there could be games where status we build realities that give us meaning in the virtual space. I can imagine such things being possible. Oh, yeah. Okay. So I think I see what you're saying there with the idea there. I mean, we'll take the LeBron James side and put in some YouTube influencer. Yes, sure. So the YouTube influencer, it is status games, but at a certain level, it precipitates into real dollars and into, like, well, you look at MrBeast, right? He's like sending off half a million dollars worth of fireworks or something. Right. On a YouTube video. And also, like, saving. Saving trees and so on. Sure. Right. Trying to plant a million trees with Mark Rober or whatever it was. Yeah. Not that those kinds of games can't lead to real consequences. It's that for the vast majority of people in consumer culture, they are incented by the. I would say mostly I'm thinking about middle class consumers. They're incented by advertisements. They're incented by their memetic environment to treat the purchasing of certain things, the need to buy the latest model, whatever the need to appear, however, the need to pursue status games as a driver of meaning. And my point would be that it's a very hollow driver of meaning. And that is what creates a meaning crisis. Because at the end of the day, it's like eating a lot of empty calories. Right? Yeah, it tasted good going down a lot of sugar, but, man, it did not. It was not enough protein to help build your muscles. And you kind of feel that in your gut. And I think that's, I mean, all the stuff aside and setting aside our discussion on currency, which I hope we get back. Get back to. That's what I mean about the meaning crisis. Part of it being created by the fact that we don't, we're not encouraged to have more and more direct relationships. We're actually alienated from relating to even our family members sometimes, right. We're encouraged to relate to brands. We're encouraged to relate to these kinds of things that then tell us to do things that are really of low consequence. And that's where the meaning crisis comes from. So the role of technology in this. So there's somebody you mentioned, who's Jacques Eliot, his view of technology. He warns about the towering piles of technique, which I guess is a broad idea of technology. Yes. So I think, correct me if I'm wrong. For him, technology is bad, moving away from human nature, and it's ultimately destructive. My question, broadly speaking, this meaning crisis, can technology, what are the pros and cons of technology? Can it be good? Yeah, I think it can be. I certainly draw on some of those ideas and I think some of them are pretty good. But the way he defines technique is, well, also Simondon as well. I mean, he speaks to the general mentality of efficiency. Homogenized processes, homogenized production, homogenized labor to produce homogenized artifacts that then are not actually, they don't sit well in the environment. So it's essentially, you can think of it as the antonym of craft. Whereas a craftsman will come to a problem. It may be a piece of wood and they need to make into a chair. It may be a site to build a house or build a stable, or build whatever. And they will consider how to bring a various things in to build something, well, contextualized, that's in right relationship with that environment. But the way we have driven technology over the last 100, 150 years is not that at all. It is how can we make sure the input materials are homogenized, cut to the same size, diluted and doped exactly the right alloy concentrations? How do we create machines that then consume exactly the right kind of energy to be able to run at this high speed to stamp out the same part parts which then go out the door. Everyone gets the same tickle me Elmo. And the reason why everyone wants it is because we have broadcast that tells everyone this is the cool thing. So we homogenize demand. And where like Baudelaire and other critiques of modernity coming from that direction, the situationalists as well. Their point is that at this point in time, consumption is the thing that drives a lot of the economic stuff. Not the need, but the need to consume and build status games on top. So we have homogenized. When we discovered, I think this is really like Bernays and stuff, right? In the early 20th century, we discovered we can create, we can create demand, we can create desire in a way that was not possible before because of broadcast media. And not only do we create desire, we don't create a desire for each person to connect to some bespoke thing, to build a relationship with their neighbor or their spouse. We are telling them, you need to consume this brand. You need to drive this vehicle. You got to listen to this music. Have you seen this movie? So, creating homogenized demand makes it really cheap to create homogenized product. And now you have economics of scale. So we make the same tickle me Elmo, give it to all the kids. And all the kids are like, hey, I got a tickle me Elmo. Right? So this is ultimately where this ties in, then, to runaway hyper capitalism, is that we then capitalism is always looking for growth. It's always looking for growth. And growth only happens in the margins. So you have to squeeze more and more demand out. You got to make it cheaper and cheaper to make the same thing. But tell everyone they're still getting meaning from it. You're still like, this is still your tickle me Elmo, right? And we see little bits of this dripping critiques of this dripping in popular culture. You see it sometimes. It's when Buzz Lightyear walks into the thing, he's like, oh, my God, at the toy store. I'm just a toy. Like, there's millions of other, or there's hundreds of other buzz lightyears just like me, right? That is, I think, you know, a fun Pixar critique on this homogenization dynamic. I agree with you on most of the things you're saying. So I'm playing devil's advocate here. But this homogenized machine of capitalism is also the thing that is able to fund, if channeled correctly, innovation, invention, and development of totally new things that in the best possible world, create all kinds of new experiences that can enrich lives, the quality of lives for all kinds of people. So isn't this the machine that actually enables the experiences and more and more experiences that would then give meaning? It has done that to some extent. I mean, it's not all good or bad in my perspective. We can always look backwards and offer a critique of the path we've taken to get to this point in time. But that's a different. That's somewhat different and informs the discussion, but it's somewhat different than the question of where do we go in the future, right? Is this still the same rocket we need to ride to get to the next point? Will it even get us to the next point? Well, how does this. So you're predicting the future. How does it go wrong, in your view? We have the mechanisms, we have now explored enough technologies to where we can actually, I think, sustainably produce what most people in the world need to live. We have also created the infrastructures to allow continued research and development of additional science and medicine and various other kinds of things. The organizing principles that we use to govern all these things today, a lot of them have been just inherited from, honestly, medieval times. Some of them have refactored a little bit in the industrial era. But a lot of these modes of organizing people are deeply problematic. And furthermore, theyre rooted in, I think, a very industrial mode perspective on human labor. This is one of those things. Im going to go back to the open source thing. There was a point in time when, well, let me ask you this. If you look at the core scipy collection of libraries, that's scipy, numpy, matplotlib, there's ipython notebook. Let's throw pandas in there, scikit, learn a few of these things. How much value do you think, economic value would you say they drive in the world today? That's one of the fascinating things about talking to you and Travis, is like, it's immeasurable. It's like at least a billion dollars a day. Maybe a billion dollars, sure. I mean, it's a similar question of like, how much value does Wikipedia create? Right. It's like all of it. I don't know. Well, I mean, if you look at our systems, when you do a Google search right now, some of that stuff runs through Tensorflow, but when you look at Siri, when you do credit card transaction fraud, like just everything, right? Every intelligence agency under the sun, they're using some aspect of these kinds of tools. So I would say that, um, these create billions of dollars of value. Oh, you mean like direct use of tools that leverage. Yes, direct, yeah, yeah. Even that's billions a day. Yeah, yeah, right. Easily. I think like the things they could not do if they didn't have these tools, right? Yes. So that's billions of dollars a day. Great. I think that's about right. Now, if we take, how many people did it take to make that right? And there was a point in time, not anymore, but there was a point in time when they could fit in a van. I could have fit them in my Mercedes sprinter. Right? And so if you look at that like, holy crap, literally a van of maybe a dozen people could create value to the tune of billions of dollars a day. What lesson do you draw from that? Well, here's the thing. What can we do to do more of that? Like, that's open source. The way I've talked about this in other environments is when we use generative participatory, crowdsourced approaches. We unlock human potential at a level that is better than what capitalism can do. I would challenge anyone to go and try to hire the right twelve people in the world to build that entire stack. The way those twelve people did that, they would be very, very hard pressed to do that. If a hedge fund could just hire a dozen people and create something that is worth billions of dollars a day, every single one of them would be racing to do it. But finding the right people, fostering the right collaborations, getting it adopted by the right other people to then refine it, that is a thing that was organic in nature, that took crowdsourcing, that took a lot of the open source ethos, and it took the right kinds of people. None of those people who started that said, I need to have a part of a multibillion dollar a day enterprise. They're like, I'm doing this cool thing to solve my problem. For my friends, the point of telling the story is to say that our way of thinking about value, our way of thinking about allocation of resources, our ways of thinking about property rights and all these kinds of things, they come from finite game, scarcity mentality, medieval institutions. As we are now entering to some extent, we are sort of in a post scarcity era. Although some people are hoarding a whole lot of stuff, we are at a point where, if not now, soon, we'll be in a post scarcity era. The question of how we allocate resources has to be revisited at a fundamental level. Because the kind of software these people built, the modalities that those human ecologies that built that software, it treats software as unproperty. Actually sharing creates value. Restricting and forking reduces value. So that's different than any other physical resource that we've ever dealt with. It's different than how most corporations treat software ip, right? So if treating software in this way created this much value so efficiently, so cheaply, because feeding a dozen people for ten years is really cheap, right? That's the, that's the reason I care about this right now, is because looking forward, when we can automate a lot of labor where we can. In fact, the, the programming for your robot in your part, neck of the woods, and you're part of the Amazon to build something sustainable for you and your tribe, to deliver the right medicines, to take care of the kids, that's just software, that's just code that could be totally open sourced. We can actually get to a mode where all of this additional generative things that humans are doing, they don't have to be wrapped up in a container. And then we charge for all the exponential dynamics out of it. That's what Facebook did. That's what modern social media did, because the old Internet was connecting people just fine. Facebook came along and said, well, anyone can post a picture. Anyone can post some text, and we're going to amplify the crap out of it to everyone else. And it exploded this generative network of human interaction. And then I said, how do I make money off that? Oh, yeah, I'm going to be a gatekeeper on everybody's attention. And that's how I make money. So how do we create more than one van? How do we have millions of vans full of people that create numpy scipi, that create python? So the story of those people is often they have some kind of job outside of this. This is what they're doing for fun. Don't you need to have a job? Don't you have to be connected, plugged in to the capitalist system? Isn't that what, like, isn't this consumerism, the engine that results in the individuals that kind of take a break from it every once in a while to create something magical, like at the edges. Is the question of surplus, right? This is the. This is the question. Like, if everyone were to go and run their own farm, no one would have time to go and write numpy sci PI, right? Maybe, but that's what I'm talking about when I say we're maybe at a post scarcity point. For a lot of people, the question that we're never encouraged to ask in a super bowl ad is, how much do you need? How much is enough? Do you need to have a new car every two years? Every five? If you have a reliable car, can you drive one for ten years? Is that all right? I had a car for ten years. It was fine. Your iPhone, did you have to upgrade every two years? I mean, sort of. You're using the same apps you did four years ago, right? This should be a Super bowl ad. This should be a Super bowl ad. That's great. Maybe you really need a new iPhone. Maybe one of our listeners will fund something like this of like. No, but just actually bringing it back. Bringing it back to actually the question of what do you need? How do we create the infrastructure for collectives of people to live on the basis of providing what we need, meeting people's needs with a little bit of excess to handle emergencies, things like that. Pulling our resources together to handle the really, really big emergencies. Somebody with a really rare form of cancer or some massive fire sweeps through half the village or whatever, but can we actually unscale things and solve for people's needs and then give them the capacity to explore how to be the best version of themselves? And for Travis, that was throwing away his shot of tenure in order to write numpy for others. There is a saying in the Sci-Fi community that Sci-Fi advances one failed postdoc at a time. We can do these things. We can actually do this collaboration because code, software, information, organization, that's cheap. Those bits are very cheap to fling across the oceans. So you mentioned Travis. We've been talking, and we'll continue to talk about open source. Maybe you can comment. How did you meet Travis? Who is Travis Aliphont? What's your relationship been like through the years? Where did you work together? How did you meet? What's the present and the future look like? Yeah, so the first time I met Travis was at a scipie conference in Pasadena. Do you remember the year 2005? I was working at again at nthought, working on scientific computing consulting. And a couple of years later, he joined us at nthot, I think, 2007, and he came in as president. One of the founders of n thought was the CEO, Eric Jones. And we were all very excited that Travis was joining us, and that was great fun. And so I worked with Travis on a number of consulting projects and we worked on some open source stuff. I mean, it was just a really. It was a good time there and. Then it was primarily Python related? Oh, yeah, it was all python numpy Sci-Fi consulting kind of stuff. Towards the end of that time, we started getting called into more and more finance shops. They were adopting Python pretty heavily. I did some work at a high frequency trading shop, working on some stuff, and then we worked together at a couple of investment banks in Manhattan. We started seeing that there was a potential to take Python in the direction of business computing more than just being this niche like Matlab replacement for big vector computing. What we were seeing was, oh, yeah, you could actually use Python as a swiss army knife to do a lot of shadow data transformation kind of stuff. So that's when we realized the potential is much greater. And so we started anaconda. I mean, it was called continuum analytics at the time, but we started in January of 2012 with a vision of shoring up the parts of Python that needed to get expanded to handle data at scale, to do web visualization, application development, et cetera. And that was that. Yeah. So he was CEO and I was president for the first five years, and then we raised some money, and then the board put in a new CEO. They hired a kind of professional CEO. And then Travis, you laugh at that. I took over the CTo role. Travis then left after a year to do his own thing, to do quant site, which was more oriented around some of the bootstrap years that we did at continuum, where it was open source and consulting. It wasn't gung ho product development, and it wasn't focused on. We accidentally stumbled into the package management problem at Anaconda, but we had a lot of other visions of other technology that we built in the open source. And Travis was really trying to push again the frontiers of numerical computing, vector computing, handling things like auto differentiation and stuff intrinsically in the open ecosystem. So I think that's kind of the direction he's working on and some of his work. We remain great friends and colleagues and collaborators, even though he's no longer day to day working at Anaconda. But he gives me a lot of feedback about this and that and the other. What's a big lesson you've learned from Travis? About life or about programming? About leadership? Wow. There's a lot. There's a lot. Travis is a really, really good guy. His heart is really in it. He cares a lot of. I've gotten that sense having to interact with them. It's so interesting. Such a good human. He's a really good dude. And he and I, it's so interesting. We come from very different backgrounds. We're quite different as people, but I think we can not talk for a long time and then be on a conversation and be eye to eye on 90% of things. And so he's someone who, I believe no matter how much fog settles in over the ocean, his ship, my ship, are pointed sort of in the same direction to the same star. Wow, that's a beautiful way to phrase it. No matter how much fog there is, we're pointing at the same star. Yeah. And I hope he feels the same way. I mean, I hope he knows that over the years now, we both care a lot about the community. For someone who cares so deeply, I would say this about Travis, that's interesting. For someone who cares so deeply about the nerd details of type, system design and vector computing and efficiency of expressing this and that and the other memory layouts and all that stuff, he cares even more about the people in the ecosystem, the community. And I have a similar kind of alignment. I care a lot about the tech, I really do. But for me, the beauty of what this human ecology has produced is, I think, a touchstone. It's an early version. We should look at it and say, how do we replicate this for humanity at scale, what this open source collaboration was able to produce? How can we be generative in human collaboration moving forward and create that as a civilizational kind of dynamic? Can we seize this moment to do that? Because a lot of the other open source movements, it's all nerds, nerding out on code for nerds, and this because it's scientists, because it's people working on data, that all of it faces real human problems. I think we have an opportunity to actually make a bigger impact. Is there a way for this kind of open source vision to make money? Absolutely. To fund the people involved is that it's hard. But we're trying to do that in our own way at anaconda, because we know that business users, as they use more of the stuff they have, needs, business specific needs around security, provenance. They really can't tell their vps and their investors, hey, our data scientists are installing random packages from who knows where and running on customer data. So they have to have someone to talk to, and that's what Anaconda does. So we are a governed source of packages for them. And that's great, that makes some money. We take some of that and we just take that as a dividend. We take a percentage of our revenues and write that as a dividend for the open source community. But beyond that, I really see the development of a marketplace for people to create notebooks, models, data sets, curation of these different kinds of things, and to really have a long tail marketplace dynamic with that. Can you speak about this problem that you stumbled into of package management, Python package management, what is that? A lot of people speak very highly of condo, which is part of Anaconda, which is a package manager. There's a ton of packages. So first, what are package managers? And second, what was there before? What is Pip? And why is Conda more awesome? The package problem is this, which is that in order to do numerical computing efficiently with Python, there are a lot of low level libraries that need to be compiled, compiled with a C compiler, or a C compiler or Fortran compiler. They need to not just be compiled, but they need to be compiled with all of the right settings. Oftentimes those settings are tuned for specific chip architectures. When you add GPU's to the mix, when you look at different operating systems, you may be on the same chip, but if you're running Mac versus Linux versus windows on the same x 86 chip, you compile link differently. All of this complexity is beyond the capability of most data scientists to reason about. And it's also beyond what most of the package developers want to deal with too. Because if you're a package developer, you're like, I code on Linux. This works for me, I'm good. It is not my problem to figure out how to build this on an ancient version of Windows. That's just simply not my problem. What we end up with is we have a creator economy or create a very creative crowdsourced environment where people want to use this stuff, but they can't. We ended up creating a new set of technologies like a build recipe system, a build system, and an installer system that is able to, well, to put it simply, it's able to build these packages correctly on each of these different kinds of platforms and operating systems and make it so when people want to install something, they can. It's just one command. They don't have to set up a big compiler system and do all these things. So when it works well, it works great. Now the difficulty is we have literally thousands of people writing code in the ecosystem, building all sorts of stuff, and each person writing code, they may take a dependency on something else. You have all this web, incredibly complex web of dependencies. So installing the correct package for any given set of packages you want, getting that right subgraph is an incredibly hard problem. Again, most data scientists don't want to think about this. They're like, I want to install numpy and pandas. I want this version of some geospatial library. I want this other thing. Like, why is this hard? These exist, right? And it is hard because it's, well, you're installing this on a version of Windows, and half of these libraries are not built for Windows, or the latest version isn't available. But the old version was. If you go to the old version of this library, that means you need to go to a different version of that library. And so the Python ecosystem, by virtue of being crowdsourced, we were able to fill 100,000 different niches. But then we also suffer this problem that because it's crowdsourced and no one, it's like a tragedy of the commons, right? No one really wants to support their thousands of other dependencies. So we end up sort of having to do a lot of this. And of course the Conda forged community also steps up as an open source community that maintains some of these recipes. That's what Conda does. Now Pip is a tool that came along after Conda to some extent. It came along as an easier way for the, for the Python developers writing Python code that didn't have as much compiled stuff, they could then install different packages. What ended up happening in the Python ecosystem was that a lot of the core Python and web Python developers, they never ran into any of this compilation stuff at all. On video we have Guido van Rossum saying the scientific community's packaging problems are just too exotic and different. I mean you're talking about Fortran compilers, right? Like you guys just need to build your own solution perhaps. Right? So the Python, core Python community went and built its own sort of packaging technologies, not really contemplating the complexity of this stuff over here. And so now we have the challenge where you can pip install some things in some libraries, if you just want to get started with them, you can pip install tensorflow. And that works great. The instant you want to also install some other packages that use different versions of numpy or some graphics library or some OpenCV thing, or some other thing, you now run into dependency hell because open cv cant have a different version of Lib JPEG over here than Pytorch over here. They all have to use that. If you want to use GPU acceleration, they have to all use the same underlying drivers and same GPU CudA things. So it gets to be very gnarly. And its a level of technology that both the makers and the users dont really want to think too much about. And that's where you step in and try to solve the. We try to solve it, how much is that? And you said that you don't want to think, they don't want to think about it, but how much is it? A little bit on the developer and providing them tools to be a little bit more clear of that subgraph of dependency that's necessary. It is getting to a point where we do have to think about, look, can we pull some of the most popular packages together and get them to work on a coordinated release timeline, get them to build against the same test matrix, et cetera, et cetera. Right. And there is a little bit of dynamic around this, but again, it is a volunteer community. People working on these different projects have their own timelines and their own things they're trying to meet. So we end up trying to pull these things together and then it's this incredibly, and I would recommend just as a business tip, don't ever go into business where when your hard work works, you're invisible. And when it breaks because of someone else's problem, you get flack for it. Because in our situation, when something doesn't condo install properly, usually it's some upstream issue, but it looks like condos broken. It looks like anaconda screws something up. When things do work, though, it's like, oh yeah, cool, I just worked assuming, naturally, of course, that's very easy to make that work. So we end up in this problematic scenario. But it's okay, because I think we're still our hearts in the right place. We're trying to move this forward as a community sort of affair. I think most of the people in the community also appreciate the work we've done over the years to try to move these things forward in a collaborative fashion. One of the sub graphs of dependencies that became super complicated is the move from Python two to Python three. There's all these ways to mess with these kinds of ecosystems, of packages and so on. So I just want to ask you about that particular one. What do you think about the move from Python two to three? Why did it take so long? What were, from your perspective, just seeing the packages all struggle and the community all struggle through this process, what lessons do you take away from it? Why did it take so long? Looking back, some people perhaps underestimated how much adoption Python two had. I think some people also underestimated how much, or they overestimated how much value some of the new features in Python three really provided. And the things they really loved about Python three just didn't matter to some of these people on Python two, because this change was happening as Python Scipy was starting to take off, really past a hockey stick of adoption in the early data science era, in the early two thousand ten s, a lot of people were learning and onboarding in whatever just worked. And the teachers were like, well, yeah, these libraries I need are not supported on Python three yet. I'm going to teach you Python two took a lot of advocacy to get people to move over to Python three. So I think it wasn't any particular single thing, but it was one of those death by a dozen cuts which just really made it hard to move off of Python two, and also Python three itself, as they were breaking things and changing these around and reorganizing the standard library. There's a lot of stuff that was happening there that it kept giving people an excuse to say, I'll put off till the next version two is working fine enough for me right now. So I think that's essentially what happened there. And I will say this, though, the strength of the Python data science movement, I think, is what kept Python alive in that transition, because a lot of languages have died and left their user bases behind. If there wasn't the use of python for data, there's a good chunk of python users that during that transition would have just left for go and rust and stayed. In fact, some people did. They moved to go and rust and they just never looked back. The fact that we were able to grow by millions of users, the Python data community, that is what kept the momentum for Python going. And now the usage of Python for data is over 50% of the overall Python user base. So I'm happy to debate that on stage somewhere icon with someone, if they really want to take issue with that statement. But from where I sit, I think that's true. The statement there, the idea is that the switch from Python two to Python three would have probably destroyed Python if it didn't also coincide with Python for whatever reason, just overtaking the data science community, anything that processes data. So, like, the timing was perfect, that this maybe imperfect decision was coupled with great timing on the value of data in our world. I would say the troubled execution of a good decision, it was a decision that was necessary. It's possible if we had more resources, we could have done in a way that was a little bit smoother. But ultimately, the arguments for Python three, I bought them at the time and I buy them now. Having great text handling is a non negotiable table stakes thing you need to have in a language. So that's great. But the execution, Python is the. It's volunteer driven. It's like now the most popular language on the planet, but it's all literally volunteers. So the lack of resources meant that they had to really, they had to do things in a very hamstrung way. And I think to carry the Python momentum and the language through that time, the data movement was a critical part of that. So some of it is carrot and stick. I actually have to shamefully admit that it took me a very long time to switch from Python two and Python three, because I'm a machine learning person. Just for the longest time, you could just do fine with Python two. Right? But I think the moment where I switched everybody I worked with and switched myself for small projects and big is when finally, when Numpy announced that they're going to end support, like in 2020 or something like that. So when I realized, oh, this isn't going, this is going to end. So that's the stake. That's not a carrot. That's not. So for the longest time was carrots. It was like all of these packages were saying, okay, we have Python three support now come join us. We have Python two and Python three. But when numpy, one of the packages I sort of love and depend on said like, nope, it's over. That's when I decided to switch. I wonder if you think it was possible much earlier for somebody like, like numpy or some major package to step into the cold. Well, it's chicken and egg problem too, right? You don't want to cut off a lot of users unless you see the user momentum going too. So the decisions for the scientific community, for each of the different projects, there's not a monolith. Some projects are like, we'll only be releasing new features on Python three. And that was more of a sticky carrot, a firm carrot, if you will. A firm carrot, a stick shaped carrot. But then for others, numpy in particular, because it's at the base of the dependency stack for so many things. That was the final stick. That was a stick shaped stick. People were saying, look, if I have to keep maintaining my releases for Python two, that's that much less energy that I can put into making things better for the python three folks, or in my new version, which is of course going to be Python three. So people were also getting kind of pulled by this tension. So the overall community sort of had a lot of input into when the numpy core folks decided that they would end of life on Python two. So as these numbers are a little bit loose, but there are about 10 million Python programmers in the world, you could argue that number, but let's say 10 million. There's actually where I was looking, said 27 million total programmers developers in the world. You mentioned in a talk that changes need to be made for there to be 100 million Python programmers. First of all, do you see a future where there's 100 million Python programmers? And second, what kind of changes need. To be made so Anaconda miniconda get downloaded about a million times a week? I think the idea that there's only 10 million Python programmers in the world is a little bit undercounting. There are a lot of people who escape traditional counting that are using Python and data in their jobs. I do believe that the future world for it to, well, the world I would like to see is one where people are data literate, so they are able to use tools that let them express their questions and ideas fluidly. And the data variety and data complexity will not go down, it will only keep increasing. So I think some level of code or code like things will continue to be relevant. And so my hope is that we can build systems that allow people to more seamlessly integrate python kinds of expressitivity with data systems and operationalization methods that are much more seamless. And what I mean by that is right now you can't punch Python code into an Excel cell. I mean, there's some tools you can do to do this. We didn't built a thing for doing this back in the day, but I feel like the total addressable market for Python users, if we do the things right, is on the order of the Excel users, which is a few hundred million. I think Python has to get better at being embedded, being a smaller thing that pulls in just the right parts of the ecosystem to run numerics and do data exploration, meeting people where they're already at with their data and their data tools. And then I think also it has to be easier to take some of those things they've written and flow those back into deployed systems or apps or visualizations. I think if we don't do those things, then we will always be kept in a silo as an expert user's tool and not a tool for the masses. I work with a bunch of folks in the Adobe creative suite, and I'm kind of forcing them or inspired them to learn Python to do a bunch of stuff that helps them. And it's interesting because they probably wouldn't call themselves Python programmers, but they're all using Python. I would love it if the tools like Photoshop and Premiere and all those kinds of tools that are targeted towards creative people. I guess that's where Excel, Excel is targeted towards a certain kind of audience that works with data, financial people, all that kind of stuff. If there would be easy ways to leverage to use Python for quick scripting tasks. Yeah, and there's an exciting application of artificial intelligence in this space that I'm hopeful about looking at OpenAI codecs with generating programs. So almost helping people bridge the gap from kind of visual interface to generating programs to something formal, and then they can modify it and so on, but without having to read the manual, without having to do a Google search and stack overflow, which is essentially what a neural network does when it's doing code generation, is actually generating code and allowing a human to communicate with multiple programs, and then maybe even programs to communicate with each other via Python. That to me is a really exciting possibility, because I think there's a friction to kind of like, how do I learn how to use Python in my life? There's oftentimes you kind of, what? Start a class? You start learning about types? Yes. I don't know, functions like this is, you know, Python is the first language with which you start to learn to program. But I feel like that's going to take a long time for you to understand why it's useful. You almost want to start with a script. Well, you do. In fact, I think starting with the theory behind programming languages and types and all that, I mean, types are there to make the compiler writer's jobs easier. Types are not. I mean, heck, do you have an ontology of types or just the objects in this table? No. So types are there because compiler writers are human and they're limited in what they can do. But I think that the beauty of scripting, there's a Python book that's called Automate the boring stuff, which is exactly the right mentality. I grew up with computers in a time when I could, when Steve Job was still pitching these things as bicycles for the mind, they were supposed to not be just media consumption devices, but they were actually, you could write some code, you could write basic, you could write some stuff to do some things. And that feeling of a computer as a thing that we can use to extend ourselves has all but evaporated for a lot of people. So you see a little bit in parts in the generation of youth around Minecraft or roadblocks. And I think Python circuit Python, these things could be a renaissance of that, of people actually shaping and using their computers as computers, as an extension of their minds and their curiosity, their creativity. So you talk about scripting the adobe suite with Python in the 3d graphics world. Python is a scripting language that some of these 3d graphics suites use. And I think that's great. We should better support those kinds of things. But ultimately, the idea that I should be able to have power over my computing environment, if I want these things to happen repeatedly all the time, I should be able to say that somehow to the computer. Now, whether the operating systems get there faster by having some Siri backed with OpenAI, with whatever. So you can just say, Siri, make this, do this and this every other Friday, right? We probably will get there somewhere. And Apple's always had these ideas. There's the Apple script in the menu that no one ever uses, but you can do these kinds of things. But when you start doing that kind of scripting, the challenge isn't learning the type system or even the syntax of the language. The challenge is all of the dictionaries and all the objects of all their properties and attributes and parameters, who's got time to learn all that stuff? That's when then programming by prototype or by example becomes the right way to get the user to express their desire. So there's a lot of these different ways that we can approach programming. But I do think, as you were talking about the Adobe scripting thing, I was thinking about when we do use something like numpy, when we use things in the Python data and scientific expression system, there's a reason we use that, which is that it gives us mathematical precision. It gives us actually quite a lot of precision over precisely what we mean about this data set, that data set. And it's the fact that we can have that precision that lets python be powerful. Over as a duct tape for data, you give me a TSV or a CSV, and if you give me some massively expensive vendor tool for data transformation, I don't know I'm going to be able to solve your problem. But if you give me a Python prompt, you can throw whatever data you want at me. I will be able to mash it into shape. So that ability to take it as this machete out into the data jungle is really powerful. I think that's why at some level, we're not going to get away from some of these expressions and APIs and libraries in Python for data transformation. You've been at the center of the python community for many years. If you could change one thing about the community to help it grow, to help it improve, to help it flourish and prosper, what would it be? I mean, it doesn't have to be one thing, but what kind of comes to mind? What are the challenges? Humility is one of the values that we have at Anaconda, at the company, but it's also one of the values in the community that it's been breached a little bit in the last few years. But in general, people are quite decent and reasonable and nice, and that humility prevents them from seeing the greatness that they could have. I don't know how many people in the core Python community really understand that they stand and perched at the edge of an opportunity to transform how people use computers. And actually Pycon, I think his last physical Pycon I went to Russell, Keith McGee gave a great keynote about very much along the lines of the challenges I have, which is Python for a language that doesn't actually put an interface up on the most popular computing devices, it's done really well as a language, hasn't it? You can't write a web front end with Python, really. I mean, everyone uses JavaScript. You certainly can't write native apps. So for a language that you can't actually write apps in any runtime environments, Python's done exceedingly well. That wasn't to pat ourselves in the back, that was to challenge ourselves as a community. To say, we, through our current volunteer dynamic, have gotten to this point. What comes next and how do we seize, you know, we've caught the tiger by the tail, how do we make sure we keep up with it as it goes forward? So that's one of the questions I have about sort of open source communities is at its best. There's a kind of humility, is that humility prevent you to have a vision for creating something like very new and. Powerful, and you've brought us back to consciousness again. The collaboration is a swarm, emergent dynamic. Humility lets these people work together without anyone trouncing anyone else, else. How do they, you know, in consciousness, there's the question of the binding problem. How does a singular, our attention, how does that emerge from, you know, billions of neurons? Yes. So how can you have a swarm of people emerge a consensus that has a singular vision, to say, we will do this, and most importantly, we're not going to do these things. Emerging a coherent, pointed, focused leadership dynamic from a collaboration, being able to do that kind of, and then dissolve it so people can still do the swarm thing, that's a problem. There's a question. So you have to have a charismatic leader for some reason. Linus Torvald comes to mind, but he, you know, there's people who criticize. He rules the iron fist, man. But there's still charisma. There's charisma, right? There's a charisma to that iron fist. There's. Every leader is different, I would say, in their success. So he doesn't. I don't even know if you can say he doesn't have humility. There's such a meritocracy of ideas that this is a good idea and this is a bad idea. There's a step function to it. Once you clear a threshold, he's open. Once you clear the bozo threshold, he's open to your ideas. I think the interesting thing is, obviously that will not stand in an open source community if that threshold that is defined by that one particular person is not actually that good. So you actually have to be really excellent at what you do. So he's very good at what he does. And so there's some aspect of leadership where you can get thrown out. People can just leave. You know, that's how it works with open source, the fork. But at the same time, you want to sometimes be a leader with a strong opinion, because people. I mean, there's some kind of balance here for this hive mind to get behind. Leadership is a big topic, and I didn't. I'm not one of these guys that went to MBA school and said, I'm going to be an entrepreneur and I'm going to be a leader, and I'm going to read all these Harvard Business review articles on leadership and all this other stuff. I was a physicist, turned into a software nerd who then really nerded out on Python. Now I am entrepreneurial. I saw business opportunity around the use of Python for data, but for me, what has been interesting over this journey with the last ten years is how much I started really enjoying the understanding, thinking deeper about organizational dynamics and leadership. And leadership does come down to a few core things. Number one, a leader has to create belief, or at least has to dispel disbelief. Leadership, also, you have to have vision, loyalty and experience. So can you say belief in a singular vision? What does belief mean? Yeah, belief means a few things. Belief means, here's what we need to do, and this is a valid thing to do, and we can do it. You have to be able to drive that belief, and every step of leadership along the way has to help you amplify that belief to more people. I mean, I think at a fundamental level, that's what it is. You have to have a vision. You have to be able to show people that, or you have to convince people to believe in the vision and to get behind you. And that's where the loyalty part comes in and the experience part comes in. There's all different flavors of leadership. So if we talk about Linus, we could talk about Elon Musk and Steve Jobs. There's Sandra Prachai, there's people that kind of put themselves at the center and are strongly opinionated, and some people are more like consensus builders. What works well for open source? What works well in the space of programmers? So you've been a programmer, you've led many programmers, and are now sort of at the center of this ecosystem. What works well in the programming world, would you say? It really depends on the people, what style leadership is best, and depends on the programming community. I think for the Python community, servant leadership is one of the values. At the end of the day, the leader has to also be the high priest of values. So any collection of people has values of their living. And if you want to maintain certain values and those values help you as an organization become more powerful, then the leader has to live those values unequivocally and has to. Has to hold the values. So in our case, in this collaborative community around Python, I think that the humility is one of those values. Servant leadership, you actually have to kind of do the stuff. You have to walk the walk, not just talk the talk. I don't feel like the Python community really demands that much from a vision standpoint, and they should, and I think they should. This is the interesting thing, is, like, so many people use Python, from where comes the vision? You have a Elon Musk type character who has makes bold statements about the vision for particular companies he's involved with. And it's like, I think a lot of people that work at those companies kind of can only last if they believe that vision, because, and some of it is super bold. So my question is, and by the way, those companies often use Python, how do you establish a vision like, get to 100 million users, get to where Python is at the center of the machine learning, and was it data science, machine learning, deep learning, artificial intelligence revolution? In many ways, perhaps the Python community is not thinking of it that way, but it's leading the way on this. The tooling is essential, right? Well, for a while, Pycon people in the scientific Python and the PI data community, they would submit talks. Those are early 2010s, mid 2010s, they would submit talks to Pycon, and the talks would all be rejected because there was the separate sort of PI data conferences and like, well, these probably belong more to PI data. And instead there'd be yet another talk about threads and whatever, some web framework. And it's like, that was an interesting dynamic to see that there was. I mean, at the time, it was a little annoying because we wanted to try to get more users and get more people talking about these things. And Pycon is a huge venue. It's thousands of Python programmers, but then also came to appreciate that parallel, having an ecosystem that allows parallel innovation is not bad. There are people doing embedded python stuff. There's people doing web programming, people doing scripting. There's cyber uses of Python. I think ultimately, at some point, if your slide mold covers so much stuff, you have to respect that different things are growing in different areas and different niches. Now, at some point, that has to come together and the central body has to provide resources. The principle here is subsidiarity. Give resources to the various groups to then allocate as they see fit in their niches. That would be a really helpful dynamic. But again, it's a volunteer community. It's not like they had that many resources to start with. What was or is your favorite programming setup? What operating system, what keyboard, how many screens you're listening to? What time of day are you drinking? Coffee? Tea? Tea. Sometimes coffee, depending how well I slept. I used to have how sleep do you get? A unite owl? I remember somebody asked you somewhere a question about work life balance and like, not just work life balance, but like a family, you know, you lead a company and your answer was, was basically like, I still haven't figured it out. Yeah, I think I've gotten a little bit better balanced. I have a really great leadership team now supporting me and so that takes a lot of the day to day stuff off my plate and my kids are getting a little older, so that helps. So. And of course I have a wonderful wife who takes care of a lot of the things that I'm not able to take care of and she's great. I try to get to sleep earlier now, um, because I have to get up every morning at six to take my kid down to the bus stop. Oh wow. So there's a hard, there's a hard thing. Yeah. For a while I was doing polyphasic sleep, which is really interesting. Like I go to bed at nine, wake up at like 02:00 a.m. work till five, sleep 3 hours, wake up at eight. Like that was actually, it was interesting, it wasn't too bad. How did it feel? It was good. I didn't keep it up for years, but once I have travel then it's just everything goes out the window. Right. Because then you're like time zones and all these things. Socially, was it accepted, like were you able to live outside of how you felt, were you able to live normal society? Oh yeah, because like on the nights that wasn't out hanging out with people or whatever, going to bed at nine, no one cares. I wake up at two, I'm still responding to their slacks, emails, whatever. And you know, shitposting on Twitter or whatever at two in the morning is exactly right. And then you go to bed for a few hours and you wake up, it's like you had an extra day in the middle. Yes. And I'd read somewhere that, you know, humans naturally have biphasic sleep or something. I don't know. But um, I, I read basically everything somewhere. So every option of everything is every option of everything. I will say that that worked out for me for a while, although I don't do it anymore. Um, in terms of programming setup, I had a 27 inch, um, high, high DPI, um, setup that I really liked. Um, but then I moved to a curved monitor just because when I moved to the new house I want to have a bit more screen for zoom plus communications plus you know, like various kinds of things. Like one large monitor, one large curve monitor. What operating system? Mac. Okay. Yeah. Is that what happens when you become important as you stop using Linux and windows? No, I actually have a windows box as well on the next table over. But I have, I have three desks, right? Yes. So a main one is the standing desk so that I can, you know, whatever. When I'm like, I have a teleprompter set up and everything else. And then I've got my imac and then Egpu and then windows PC. The reason I moved to Mac was it's got a Linux prompt or, sorry, it's got a Unix prompt so I can do all my stuff. But then I don't have to worry when I'm presenting for clients or investors or whatever. I don't have to worry about any ACPI related FSIC things in the middle of a presentation. None of that. It will always wake from sleep and it won't kernel panic on me. And this is not a dig against Linux, except that I feel really bad. I feel like a traitor to my community saying this, but in 2012 I was just like, okay, start my own company, what do I get? And Linux laptops were just not quite there. I've just stuck with Macs. Can I just defend something that nobody respectable seems to do, which is I do a boot on Linux, Windows. But in windows I have windows subsystems for Linux or whatever, WSL, WSL. And I find myself being able to handle everything I need, almost everything I need in Linux for basic tasks, scripting tasks within WSL. And it creates a really nice environment. But whenever I hang out with especially important people, theyre all on iPhone and a Mac and its like, yeah, there is a messiness to windows and a messiness to Linux that makes me feel like you're still in it. Well, the Linux stuff, Windows subsystem for Linux is very tempting, but there's still the windows on the outside where I don't know where I've used DOS since version 1.11 or 1.21 or something. I've been a longtime Microsoft user, and I will say that it's really hard for me to know where anything is, how to get to the details behind something when something screws up, as it invariably does, and just things like changing group permissions on some shared folders and stuff. Just everything seems a little bit more awkward, more clicks than it needs to be. Not to say there aren't weird things like hidden attributes and all this other happy stuff on Mac, but for the most part, well, actually, especially now with the new hardware coming out on Mac, it'll be very interesting, you know, with the new m one. Um, there were some dark years in the last few years when I was like, I think maybe I have to move off of Mac as a platform dark. But this, I mean, like, my keyboard was just not working. Like, literally, my keyboard just wasn't working right. I had this touch bar, didn't have a physical escape button like I needed to because I used vim. And now I think we're back, so. So you use vim and you have a what kind of keyboard? So I use a real force 87 u. It's a mechanical, as a topra key. Switch, because we are shaped, there's a normal shape shift. I say that because I use a kinesis. And I had, you said some dark. You said you had dark moments. I recently had a dark moment, like, what am I doing with my life? So I remember sort of flying in a very kind of tight space. And as I'm working, this is what I do on an airplane, I pull out a laptop, and on top of the laptop I'll put a kinesis keyboard. That's hardcore, man. I was thinking, is this who I am? Is this what I'm becoming? Will I be this person? Cause I'm on emacs with this kinesis keyboard sitting like, with everybody around. Emacs on Windows? On WSL? Yeah, yeah. Emacs on Linux? On Windows? Yeah, on windows. And like, everybody around me is using their iPhone to look at TikTok. So I'm like, in this land. And I thought, you know what? Maybe I need to become an adult and put the nineties behind me and use like a normal keyboard. And then I did some soul searching and I decided, like, this is who I am. This is me, like, coming out of the closet to saying, I'm kinesis keyboard all the way. I'm going to use emacs, you know. You know who else is a kinesis fan? Wes McKinney, the creator. Pandas. Oh, he just, he banged out pandas on a kinesis keyboard, I believe. I don't know if he's still using one. Maybe, but certainly ten years ago, like he was. If anyone's out there, maybe we need to have a kinesis support group. Please reach out. Isn't there already one? Is there one? I don't know. There's got to be an IRC channel. Mandy. Oh, no. And you access it through emacs. Okay. Do you still program these days? I do a little bit. Honestly, the last thing I did was I had written. I was working with my son to script some Minecraft stuff, so I was doing a little bit of that. That was literally the last code I wrote. Oh, you know what? Also, I wrote some code to do some cap table evaluation, waterfall modeling kind of stuff. What advice would you give to a young person? You said your son today in high school, maybe even college, about career, about life. This may be where I get into trouble a little bit. We are coming to the end. We are rapidly entering a time between worlds. We have a world now that's starting to really crumble under the weight of aging institutions that no longer even pretend to serve the purposes they were created for. We are creating technologies that are hurtling billions of people headlong into philosophical crises who they don't even know, the philosophical operating systems in their firmware. And they're heading into a time when that gets vaporized. So, for people in high school, and certainly I tell my son this as well, he's in middle school, people in college, you are going to have to find your own way. You're going to have to have a pioneer spirit. Even if you live in the middle of the most dense urban environment. All of human reality around you is the result of the last few generations of humans agreeing to play certain kinds of games. A lot of those games no longer operate according to the rules they used to. Collapse is nonlinear, but it will be managed. So if you are in a particular social caste or economic caste, and it's not. I think it's not kosher to say that about America, but America is a very stratified and classist society. There's some mobility, but it's really quite classist. And in America, unless you're in the upper middle class, you are headed into very choppy waters. So it is really, really good to think and understand the fundamentals of what you need to build a meaningful life for you, your loved ones, with your family. And almost all of the technology being created that's consumer facing is designed to own people, to take the four stack of people, to delaminate them and to own certain portions of that stack. And so if you want to be an integral human being, if you want to have your agency and you want to find your own way in the world when you're young, would be a great time to spend time looking at some of the classics around what it means to live a good life, what it means to build connection with people. And so much of the status game, so much of the stuff. One of the things that I talk about, as we create more and more technology, there's a gradient technology, and a gradient technology always leads to a gradient of power. And this is Jacques Aul's point to some extent as well. That gradient of power is not going to go away. The technologies are going so fast that even people like me, who helped create some of the stuff, I'm being left behind. That's some cutting edge research. I don't know what's going on in Gantz today. I go read some proceedings. So as the world gets more and more technological, it will create more and more gradients where people will seize power, economic fortunes. And the way they make a. The people who are left behind, okay, with their lot in life, is they create lottery systems. They make you take part in the narrative of your own being trapped in your own economic sort of zone. So avoiding those kinds of things is really important, knowing when someone is running game on you, basically. So these are things I would tell young people. It's a dark message, but it's realism. I mean, it's what I see. So after you gave some realism, you sit back. You sit back with your son, you looking out at the sunset. What to him can you give as words of hope? And to you, from where do you derive hope for the future of our world? So you said at the individual level, you have to have a pioneer mindset to go back to the classics to understand what is in human nature. You can find meaning, but at the societal level, what trajectory? When you look at possible trajectories, what gives you hope? What gives me hope is that we have little tremors now shaking people out of the reverie of the fiction of modernity that they've been living in kind of a late 20th century style modernity. That's good, I think. And also, to your point, earlier, people are burning out on some of the social media stuff. They're sort of seeing the ugly side, especially the latest news with Facebook and the whistleblower. Right. It's quite clear these things are not all they're cracked up to be. So do you believe like, I believe better social media can be built because they are burning out and they'll incentivize other competitors to be built. Do you think that's possible? Well, the thing about it is that when you have extractive return on returns, capital coming in and saying, look, you own a network, give me some exponential dynamics out of this network, what are you going to do? You're going to just basically put a toll keeper at every single node and every single graph edge, every node, every vertex, every edge. But if you don't have that need for it, if no one's sitting there saying, hey, Wikipedia, monetize every character, every byte, every phrase, then generative human dynamics will naturally arise. Assuming we respect a few principles around online communications. The greatest and biggest social network in the world is still email, sms. Yes. So we are fine there. The issue with the social media, as we call it now, is they're actually just new amplification systems now. It's benefit of certain people like yourself who have interesting content to be amplified. So it's created a creator economy, and that's cool. There's a lot of great content out there, but giving everyone a shot at the fame lottery saying, hey, you could also have your, if you wiggle your butt the right way on TikTok, you could have your 15 seconds of microfame. Thats not healthy for society at large. So I think if we can create tools that help people be conscientious about their attention, spend time looking at the past and really retrieving memory and not calling, but processing and thinking about that, I think thats certainly possible. And hopefully thats what we get. The bigger picture. The bigger question youre asking about, what gives me hope is that these early shocks of COVID lockdowns and remote work and all these different kinds of things, I think it's getting people to a point where they're sort of no longer in the reverie. As my friend Jim Rutt says, there's more people with ears to hear now with the pandemic and education, everyone's like, wait, wait, what have you guys been doing with my kids? Like, how are you teaching them? What is this crap you're giving them as homework? Right? So I think these are the kinds of things that are getting in the supply chain, disruptions, getting more people to think about. How do we actually just make stuff? This is all good, but the concern is that it's still going to take a while for these things for people to learn how to be agentic again. And to be in right relationship with each other and with the world. So the message of hope is still, people are resilient, and we are building some really amazing technology. And I also like, to me, I derive a lot of hope from individuals in that van. The power of a single individual to transform the world, to do positive things to the world, is quite incredible. Now you've been talking about, it's nice to have as many of those individuals as possible, but even the power of one, it's kind of magical. It is. It is. We're in a mode now where we can do that, I think, also. So part of what I try to do is in coming to podcasts like yours and then spamming you with all this philosophical stuff that I've got going on. There are a lot of good people out there trying to put words around the current technological, social, economic crises that we're facing and the space of a few short years. I think there has been a lot of great content produced around this stuff for people who want to find out more or think more about this. We're popularizing certain kinds of philosophical ideas that move people beyond just the, oh, you're communist, owe your capitalist kind of stuff. Like, it's sort of, we're way past that now. So that also gives me hope that I feel like I myself am getting a handle on how to think about these things. It makes me feel like I can hopefully affect change for the better. We've been sneaking up on this question all over the place. Let me ask the big ridiculous question. What is the meaning of life? Wow. The meaning of life? Yeah. I don't know. I mean, I've never really understood that question. When you say meaning crisis, you're saying that there is a search for a kind of experience that could be described as fulfillment, as like the haha. Moment of just like. Like joy. And maybe when you see something beautiful, or maybe you have created something beautiful, that experience that you get, it feels like it all makes sense. So some of that is just chemicals coming together in your mind and all kinds of things. But it seems like we're building a sophisticated collective intelligence that's providing meaning in all kinds of ways to its members, and there's a theme to that meaning. So for a lot of history, I think faith played an important role. Faith in God, sort of religion. I think technology in the modern era is kind of serving a little bit of a source of meaning for people. Like innovation of different kinds. I think the old school things of the love and the basics of just being good at stuff. But you were a physicist, so there's a desire to say, okay, yeah, but these seem to be like symptoms of something deeper, right? Like why. Yeah, what's capital m? Meaning why are we reaching for order when there is excess of energy? I don't know if I can answer the why. Any why that I come up with, I think is going to be. I'd have to think about that a little more, maybe get back to you on that. But I will say this. We do look at the world through a traditional. I think most people look at the world through what I would say is a subject object kind of metaphysical lens, that we have our own subjectivity. And then there's all of these object things that are not us. So I'm me, and these things are not me, right. And I'm interacting with them, I'm doing things to them, but a different view of the world that looks at it as much more connected, that realizes, oh, I'm really quite embedded in a soup of other things, and I'm simply almost like a standing wave pattern of different things. Right. So when you look at the world in that kind of connected sense, I've recently taken a shine to this particular thought experiment, which is, what if it was the case that everything that we touch with our hands, that we pay attention to, that we actually give intimacy to? What if there's actually all the mumbo jumbo, people with the magnetic healing crystals and all this other kind of stuff, and quantum energy stuff? What if that was a thing? What if. If literally, when your hand touches an object, when you really look at something and you concentrate and you focus on it, and you really give it attention, you actually give it. There is some physical residue of something, a part of you, a bit of your life force that goes into it. Okay, now, this is, of course, completely mumbo jumbo stuff. This is not like. I don't actually think this is real, but let's do the thought experiment. What if it was. What if there actually was some quantum magnetic crystal and energy field thing that just by touching this can. This can has changed a little bit somehow. And it's not much unless you put a lot into it and you touch it all the time, like your phone. These things gained. They gain meaning to you a little bit. But what if there's something that. But technical objects. The phone is a technical object. It does not really receive attention or intimacy and then allow itself to be transformed by it. But if it's a piece of wood, if it's the handle of a knife that your mother used for 20 years to make dinner for you. Right? What if it's a keyboard that you banged out your world transforming software library on? These are technical objects, and these are physical objects, but somehow there's something to them. We feel an attraction to these objects as if we have imbued them with life energy. Yeah. Right. So if you walk that thought experiment through, what happens when we touch another person, when we hug them, when we hold them. And the reason this ties into my answer for your question is that if there is such a thing, if we were to hypothesize hypotheses, such a thing, it could be that the purpose of our lives is to imbue as many things with that love as possible. That's a beautiful answer and a beautiful way to end it. Peter, you're an incredible person. Thank you. Spending so much in the space of engineering and in the space of philosophy. I'm really proud to be living in the same city as, and I'm really grateful that you would spend your valuable time with me today. Thanks. Well, thank you. I appreciate the opportunity to speak with you. Thanks for listening to this conversation with Peter Wang. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Peter Wang himself. We tend to think of people as either malicious or incompetent. But in a world filled with corruptible and unchecked institutions, there exists a third thing, malicious incompetence. It's a social cancer. And it only appears once human organizations scale beyond personal accountability. Thank you for listening and hope to see you next time.

Utterances:
Speaker A: The following is a conversation with Peter Wang, one of the most impactful leaders and developers in the Python community, former physicist, current philosopher, and someone who many people told me about and praised as a truly special mind that I absolutely should talk to recommendations ranging from Travis Oliphant to Eric Weinstein. So here we are. This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. And now here's my conversation with Peter Wang. You're one of the most impactful humans in the Python ecosystem. So you're an engineer, leader of engineers, but you're also a philosopher. So let's talk both in this conversation about programming and philosophy. First, programming, what to you is the best, or maybe the most beautiful feature of python? Or maybe the thing they made you fall in love or stay in love with Python?
Speaker B: Well, those are three different things. What I think is the most beautiful, what made me fall in love with me, stay in love. When I first started using it was when I was a C computer graphics performance nerd.
Speaker A: In the nineties.
Speaker B: Yeah, in the late nineties. And that was my first job out of college. And we kept trying to do more and more like abstract and higher order programming in C, which at the time was quite difficult with templates, the compiler support wasn't great, et cetera. So when I started playing around with Python, that was my first time encountering really first class support for types, for functions and things like that. And it felt so incredibly expressive. So that was what made me fall in love with it a little bit. And also, once you spend a lot of time in a C dev environment, the ability to just whip something together that basically runs and works the first time is amazing. So really productive scripting language. I mean, I knew Perl, I knew bash, I was decent at both, but Python just made everything, it made the whole world accessible, right? I could script this and that and the other network things, you know, little hard drive utilities. I could write all of these things in the space of an afternoon. And that was really, really cool. So that's what made me fall in love.
Speaker A: Is there something specific you could put your finger on that you're not programming in Perl today? Like why? Why Python for scripting?
Speaker B: I think there's not a specific thing. As much as the design motif of both the creator of the language and the core group of people that built the standard library around him, there was a taste to it. I mean, Steve Jobs used that term in somewhat of an arrogant way, but I think it's a real thing that it was designed to fit. A friend of mine actually expressed this really well. He said, python just fits in my head, and there's nothing better to say than that. Now, people might argue modern Python, there's a lot more complexity, but certainly as version 5152, I think, is my first version that fit in my head very easily. So that's what made me fall in love with it.
Speaker A: Okay, so the most beautiful feature of Python that made you stay in love, it's like over the years, what has, like, you know, you do a double take and you return too often as a thing that just brings you a smile.
Speaker B: I really still like the, the ability to play with meta classes and express higher order things when I have to create some new object model, to model something, it's easy for me because I'm pretty expert as a Python programmer, I can easily put all sorts of lovely things together and use properties and decorators and other kinds of things and create something that feels very nice. I would say that's tied with the numpy and vectorization capabilities. I love thinking in terms of the matrices and the vectors and these kind of data structures, so I would say those two are kind of tied for me.
Speaker A: So the elegance of the numpy data structure, like slicing through the different multi dimensions.
Speaker B: Yeah, there's just enough things there. It's like a very, it's a very simple, comfortable tool. Just, it's easy to reason about what it does when you don't stray too far afield.
Speaker A: Can you put your finger on how to design a language such that it fits in your head? Certain things like the colon or the certain notation aspects of python that just kind of work? Is it something you have to kind of write out on paper, look and say, it's just right? Is it a taste thing or is there a systematic process? What's your sense?
Speaker B: I think it's more of a taste thing. But one thing that should be said is that you have to pick your audience. So the better defined the user audience or the users are, the easier it is to build something that fits in their minds. Because their needs will be more compact and coherent. It is possible to find a projection, a compact projection, for their needs. The more diverse the user base, the harder that is. As Python has grown in popularity, that's also naturally created more complexity. As people try to design any given thing, there will be multiple valid opinions about a particular design approach. And so I do think that's the downside of popularity. It's almost an intrinsic aspect of the complexity of the problem.
Speaker A: Well, at the very beginning, aren't you an audience of one isn't ultimately, aren't all the greatest projects in history? We're just solving a problem that you yourself had.
Speaker B: Well. So Clay Shirky, in his book on crowdsourcing, or in his kind of thoughts on crowdsourcing, he identifies the first step of crowdsourcing is me first collaboration. You first have to make something that works well for yourself. It's very telling that when you look at all of the impactful big projects, while they're fundamental projects now in the scipy and PI data ecosystem, they all started with the people in the domain trying to scratch their own itch. And the whole idea of scratching our own itch is something that the open source or the free software world has known for a long time. But in the scientific computing areas, these are assistant professors or electrical engineering grad students. They didn't have really a lot of programming skill necessarily, but Python was just good enough for them to put something together that fit in their domain, right? So it's almost like a, it's a necessity as a mother of invention aspect, and also it was a really harsh filter for utility and compactness and expressiveness. Like it was too hard to use, then they wouldn't have built it, because that was just too much trouble, right? It was a side project for them.
Speaker A: And also necessity creates a kind of deadline. It seems like a lot of these projects are quickly thrown together in the first step, and that even though it's flawed, that just seems to work well for software projects.
Speaker B: Well, it does work well for software projects in general and in this particular space. One of my colleagues, Stan Sieber, identified this, that all the projects in the scipy ecosystem, if we just rattle them off, there's numpy, there's scipy built by different collaborations of people, although Travis is the heart of both of them. But numpy coming from numeric and numerous, these are different people. And then you've got pandas, you've got Jupyter or ipython, there's Matplotlib, there's just so many others. I'm not going to do justice if I try to name them all, but all of them are actually different people. And as they rolled out their projects, the fact that they had limited resources meant that they were humble about scope. A great famous hacker, Jamie Zawiski, once said that every geeks dream is to build the ultimate middleware. The thing is, with these scientists turned programmers, they had no such dream. They were just trying to write something that was a little bit better. For what? They needed, the Matlab, and they were going to leverage what everyone else had built. So naturally, almost in this annealing process or whatever, we built a very modular cover of the basic needs of a scientific computing library.
Speaker A: If you look at the whole human story, how much of a leap is it? We've developed all kinds of languages, all kinds of methodologies for communication. It just kind of like grew this collective intelligence, the civilization grew, it expanded. We wrote a bunch of books, and now we tweet, how big of a leap is programming? If programming is yet another language, is it just a nice little trick that's temporary in our human history? Or is it like a big leap in the almost us becoming another organism at a higher level of abstraction, something else?
Speaker B: I think the act of programming or using grammatical constructions of some underlying primitives, that is something that humans do learn. But every human learns this. Anyone who can speak learns how to do this. What makes programming different has been that up to this point, when we try to give instructions to computing systems, all of our computers. Well, actually this is not quite true, but I'll first say it and then I'll tell you why it's not true. But for the most part, we can think of computers as being these iterated systems. So when we program, we're giving very precise instructions to iterated systems that then run at incomprehensible speed and run those instructions. In my experience, some people are just better equipped to model systematic iterated systems. Well, whatever iterated systems in their head, some people are really good at that and other people are not. And so when you have, like for instance, sometimes people have tried to build systems that make programming easier by making it visual drag and drop. And the issue is you can have a drag and drop thing, but once you start having to iterate the system with conditional logic, handling case statements and branch statements and all these other things, the visual drag and drop part doesn't save you anything. You still have to reason about this giant iterated system with all these different conditions around it. That's the hard part. Handling iterated logic, that's the hard part. The languages we use then emerge to give us ability and capability over these things. Now the one exception to this rule, of course, is the most popular programming system in the world, which is Excel, which is a data flow and a data driven immediate mode data transformation oriented programming system. And it's actually not an accident that that system is the most popular programming system because it's so accessible to a much broader group of people. I do think as we build future computing systems. You're actually already seeing this a little bit. It's much more about composition of modular blocks. They themselves actually maintain all their internal state, and the interfaces between them are well defined data schemas. And so to stitch these things together using, like, IFTTT or Zapier or any of these kind of, I would say, composition, additional scripting kinds of things, I mean, hypercard was also a little bit in this vein that's much more accessible to most people. It's really that implicit state that's so hard for people to track.
Speaker A: Yeah, okay, so that's modular stuff. But there's also an aspect where you're standing on the shoulders of giants. You're building, like, higher and higher levels of abstraction. You do that a little bit with language. So with language, you develop sort of ideas, philosophies, Plato and so on, and then you kind of leverage those philosophies as you try to have deeper and deeper conversations. But with programming, it seems like you can build much more complicated systems, like, without knowing how everything works, you can build on top of the work of others, and it seems like you're developing more and more sophisticated expressions, ability to express ideas in a computational space.
Speaker B: I think it's worth pondering the difference here between complexity and complication.
Speaker A: Okay, right back to excel.
Speaker B: Well, not quite back to excel, but the idea is, when we have a human conversation, all languages for humans emerged to support human relational communications, which is that the person we're communicating with is a person, and they would communicate back to us. And so we sort of hit a resonance point, right, when we actually agree on some concepts. So there's a messiness to it, and there's a fluidity to it. With computing systems, when we express something to the computer and it's wrong, we just try again. So we can basically live many virtual worlds of having failed at expressing ourselves to the computer. Until the one time we expressed ourselves right. Then we kind of put in production and then discover that it's still wrong, you know, a few days down the road. So I think the sophistication of things that we build with computing, one has to really pay attention to the difference between when an end user is expressing something onto a system that exists versus when they're extending the system to increase the system's capability for someone else to then interface with. We happen to use the same language for both of those things, and in most cases, but it doesn't have to be that. Excel is actually a great example of this, of kind of a counterpoint to that.
Speaker A: Okay, so what about the idea of, you said messiness? Wouldn't you put the software 2.0 idea, this idea of machine learning, into the further and further steps into the world of messiness, the same kind of beautiful messiness of human communication? Isn't that what machine learning is, is building on levels of abstraction that don't have messiness in them? That at the operating system level? Then there's Python, the programming languages that have more and more power. But then finally there's neural networks that ultimately work with data. And so the programming is almost in the space of data, and the data is allowed to be messy. Isn't that a kind of program? So the idea of software 2.0 is a lot of the programming happens in the space of data. So back to excel. All roads lead back to excel in the space of data. And also the hyper parameters of the neural networks, and all of those allow the same kind of messiness that human communication allows.
Speaker B: It does. But my background is a physics. I took two cs courses in college, so I don't have now. I did cram a bunch of cs in prep when I applied for grad school, but still, I don't have a formal background in computer science. But what I have observed in studying programming languages and programming systems and things like that is that there seems to be this triangle. It's one of these beautiful little iron triangles that you find in life sometimes, and it's the connection between the code correctness and expressiveness of code, the semantics of the data, and then the correctness or parameters of the underlying hardware compute system. So there's the algorithms that you want to apply. There's what the bits that are stored on whatever media actually represent. So the semantics of the data within the representation. And then there's what the computer can actually do. And every programming system, every information system, ultimately finds some spot in the middle of this little triangle. Sometimes some systems collapse them into just one edge.
Speaker A: Are we including humans as a system in this?
Speaker B: No, no, I'm just thinking about computing systems here. The reason I bring this up is because I believe there's no free lunch around this stuff. If we build machine learning systems to write the correct code, that is, at a certain level of performance, it'll select with the hyperparameters. We can tune how we want the performance boundary in SLA to look like for transforming some set of inputs into certain kinds of outputs. That training process itself is intrinsically sensitive to the kinds of inputs we put into it. It's quite sensitive to the boundary conditions we put around the performance. I think even as we move to using automated systems to build this transformation, as opposed to humans, explicitly from a top down perspective, figuring out, well, this schema and this database and these columns get selected for this algorithm. And here we put a Fibonacci heap for some other thing, human design or computer design. Ultimately, what we hit and the boundaries that we hit with these information systems is when the representation of the data hits the real world is where there's a lot of slop and a lot of interpretation. And that's where actually I think a lot of the work will go in the future is actually understanding how to better, in the view of these live data systems, how to better encode the semantics of the world for those things, there'll be less about the details of how we write a particular SQL query.
Speaker A: Okay? But given the semantics of the real world and the messiness of that, what does the word correctness mean when you're talking about code?
Speaker B: There's a lot of dimensions to correctness historically. And this is one of the reasons I say that we're coming to the end of the era of software, because for the last 40 years or so, software correctness was really defined about functional correctness. I write a function, it's got some inputs. Does it produce the right outputs? If so, then I can turn it on, hook it up to the live database, and it goes. And more and more now we have, I mean, in fact, I think the bright line in the sand between machine learning systems or modern data driven systems versus classical software systems is that the values of the input actually have to be considered with the function together to say this whole thing is correct or not. And usually there's a performance SLA as well. Like did it actually finish making SLA? Sorry, service level agreement. So it has to return within some time. You have a ten millisecond time budget to return a prediction of this level of accuracy. Right? So these are things that were not traditionally in most business computing systems for the last 20 years at all. People didn't think about it. But now we have value dependence on functional correctness. So that question of correctness is becoming a bigger and bigger question.
Speaker A: Why does that map to the end of software?
Speaker B: We've thought about software as just this thing that you can do in isolation with some test trial inputs and in a very sandboxed environment. And we can quantify how does it scale, how does it perform, how many nodes do we need to allocate if we want to scale this many inputs? When we start turning this stuff into prediction systems, real cybernetic systems, you're going to find scenarios where you get inputs that you're going to want to spend a little more time thinking about. You're going to find inputs that are not. It's not clear what you should do then. The software has a varying amount of runtime and correctness with regard to input, and that is a different kind of system altogether. Now, it's a full on cybernetic system. It's a next generation information system that is not like traditional software systems.
Speaker A: Can you maybe describe what is a cybernetic system? Do you include humans in that picture? So is a human in the loop kind of complex mess of the whole kind of interactivity of software with the real world, or is this something more concrete?
Speaker B: Well, when I say cybernetic, I really do mean that the software itself is closing the observe, orient, decide, act loop by itself. So humans being out of the loop is the fact. What, for me, makes it a cybernetic system?
Speaker A: Humans are out of that loop when.
Speaker B: Humans are out of the loop, when the machine is actually sort of deciding on its own what it should do next to get more information, that makes it a cybernetic system. So we're just at the dawn of this, right? I think everyone talking about Mlai. It's great. But really, the thing we should be talking about is when we really enter the cybernetic era and all of the questions of ethics and governance and correctness and all these things, they really are the most important questions.
Speaker A: Okay, can we just linger on this? What does it mean for the human to be out of the loop in a cybernetic system? Because isn't this cybernetic system that's ultimately accomplished in some kind of purpose, that at the bottom, the turtles, all the way down at the bottom, turtle is a human.
Speaker B: Well, the human may have set some criteria, but the human wasn't precise. So, for instance, I just read the other day that earlier this year, or maybe it was last year, at some point, the libyan army, I think, sent out some automated killer drones with explosives, and there was no human in the loop at that point. Put them in a geofenced area, said, find any moving target, like a truck or vehicle that looks like this, and boom, um, that's not a human in the loop. Right.
Speaker A: So, increasingly, the less human there is in the loop, the more concerned you are about these kinds of systems, because, uh, there's unintended consequences. Like, less the original designer and engineer of the system is able to predict even one with good intent is able to predict the consequences of such a system is. That's right.
Speaker B: There are some software systems that run without humans in the loop that are quite complex, and that's like the electronic markets. And we get flash crashes all the time. We get in the heyday of high frequency trading, there's a lot of market microstructure, of people doing all sorts of weird stuff that the market designers had never really thought about, contemplated or intended. When we run these full on systems with these automated trading bots, now, they become automated killer drones and then all sorts of other stuff. That's what I mean by we're at the dawn of the cybernetic era and the end of the era of just pure software.
Speaker A: Are you more concerned if you're thinking about cybernetic systems or even like, self replicating systems? So systems that aren't just doing a particular task, but are able to sort of multiply and scale in some dimension in the digital or even the physical world? Are you more concerned about like the lobster being boiled? So a gradual, with us not noticing collapse of civilization, or a big explosion, like, oops, kind of a big thing where everyone notices, but it's too late.
Speaker B: I think that it will be a different experience for different people. I do. I do share a common point of view with some of the climate people who are concerned about climate change and just the big existential risks that we have. But unlike a lot of people who share my level of concern, I think the collapse will not be quite so dramatic as some of them think. And what I mean is that I think that for certain tiers of, let's say, economic class or certain locations in the world, people will experience dramatic collapse scenarios. But for a lot of people, especially in the developed world, the realities of collapse will be managed. There will be narrative management around it, so that they essentially insulate the middle class will be used to insulate the upper class from the pitchforks and the flaming torches and everything.
Speaker A: It's interesting because my specific question wasn't as general. My question is more about cybernetic systems or software. Okay, it's interesting, but it would nevertheless, perhaps be about class. So the effect of algorithms might affect certain classes more than others?
Speaker B: Absolutely.
Speaker A: I was more thinking about whether it's social media algorithms or actual robots. Is there going to be a gradual effect on us where we wake up one day and don't recognize the humans we are? Or is it something truly dramatic where there's, you know, like a meltdown of a nuclear reactor kind of thing. Chernobyl, like catastrophic events that are almost bugs in a program that scaled itself too quickly.
Speaker B: Yeah. I'm not as concerned about the visible stuff. And the reason is because the big visible explosions, I mean, this is something I said about social media is that at least with nuclear weapons, when a nuke goes off, you can see it and you're like, well, that's really. Wow, that's kind of bad, right? I mean, Oppenheimer was reciting the Bhagavad Gita, right, when he saw one of those things go off. So we can see nukes are really bad.
Speaker A: He's not reciting anything about Twitter.
Speaker B: Well, right. But then when you have social media, when you have all these different things that conspire to create a layer of virtual experience for people that alienates them from reality and from each other, that's very pernicious. It's impossible to see. Right. And it kind of slowly gets in there.
Speaker A: So you've written about this idea of virtuality on this topic, which you define as the subjective phenomenon of knowingly engaging with virtual sensation and perception and suspending or forgetting the context that it's simulacrum. So let me ask, what is real? Is there a hard line between reality and virtuality? Like perception drifts from some kind of physical reality? We have to kind of have a sense of what is the line. That's too. We've gone too far.
Speaker B: Right. Right. For me, it's not about any hard line about physical reality as much as a simple question of does the particular technology help people connect in a more integral way with other people, with their environment, with all of the full spectrum of things around them? So it's less about, oh, this is a virtual thing and this is a hard real thing. More about when we create virtual representations of the real things. Always some things are lost in translation. Usually many, many dimensions are lost in translation. Right. We're now coming to almost two years of COVID people on Zoom all the time. You know, it's different when you meet somebody in person than when you see them on. I've seen you on YouTube lots. Right. But the seeing in person is very different. And so I think when we engage in virtual experiences all the time and we only do that, there is absolutely a level of embodiment, theres a level of embodied experience, some participatory interaction that is lost. And its very hard to put your finger on exactly what it is. Its hard to say, oh, were going to spend $100 million building a new system that captures this 5% better, higher fidelity, human expression, no ones going to pay for that. When we rush madly into a world of simulacrum and virtuality, the things that are lost, it's difficult. Once everyone moves there, it can be hard to look back and see what we've lost.
Speaker A: So is it irrecoverably lost? Or rather, when you put it all on the table, is it possible for more to be gained than is lost? If you look at video games, they create virtual experiences that are surreal and can bring joy to a lot of people, can connect a lot of people, and can get people to talk a lot of trash, so they can bring out the best and the worst in people. So is it possible to have a future world where the pros outweigh the cons?
Speaker B: It is. I mean, it's possible to have that in the current world. But when literally trillions of dollars of capital are tied to using those things to groom the worst of our inclinations and to attack our weaknesses in the limbic system, to create these things into id machines versus connection machines, then those good things don't stand a chance.
Speaker A: Can you make a lot of money by building connection machines? Is it possible, do you think, to bring out the best in human nature, to create fulfilling connections and relationships in the digital world and make a shit ton of money?
Speaker B: If I figure it out, I'll let you know.
Speaker A: What's your intuition? Without concretely knowing what my intuition is.
Speaker B: That a lot of our digital technologies give us the ability to have synthetic connections or to experience virtuality. They have co evolved with sort of the human expectations. It's sort of like sugary drinks. As people have more sugary drinks, they get. They need more sugary drinks to get that same hit, right? So with these virtual things and with tv and fast cuts and tiktoks and all these different kinds of things, we're co creating essentially humanity that sort of asks and needs those things. And now it becomes very difficult to get people to slow down. It gets difficult for people to hold their attention on slow things and actually feel that embodied experience, right? So mindfulness, now more than ever, is so important in schools and as a therapy technique for people, because our environment has been accelerated. And McLuhan actually talks about this in the electric environment of the television, and that was before TikTok and before front facing cameras. So I think for me, the concern is that it's not like we can ever switch to doing something better, but more of the humans and technology, they're not independent of each other. The technology that we use kind of molds what we need for the next generation of technology.
Speaker A: Yeah, but humans are intelligent, and they're introspective, and they can reflect on the experiences of their life. So, for example, there's been many years in my life where I ate an excessive amount of sugar, and then a certain moment, I woke up and said, why do I keep doing this? This doesn't feel good, like, long term. And I think, so going through the TikTok process of realizing, okay, when I shorten my attention span, actually, that does not make me feel good longer term, and realizing that and then going to platforms, going to places that are away from the sugar. So in so doing, you can create platforms that can make a lot of money to help people wake up to what actually makes them feel good long term, develop, grow as human beings. And it just feels like humans are more intelligent than mice looking for cheese. They're able to sort of think. I mean, we can think. We can contemplate our own mortality. We can contemplate things like long term love, and we can have a long term fear of certain things like mortality. We can contemplate whether the experiences, the sort of the drugs of daily life that we've been partaking in is making us happier, better people. And then once we contemplate that, we can make financial decisions in using services and paying for services that are making us better people. So it just seems that we're in the very first stages of social networks that just were able to make a lot of money really quickly. But in bringing out sometimes the bad parts of human nature, they didn't destroy humans. They just. They just fed everybody a lot of sugar. And now everyone's going to wake up and say, hey, we're going to start having, like, sugar free social media.
Speaker B: Right? Right. Well, there's a lot to unpack there. I think some people certainly have the capacity for that. And I certainly think, I mean, it's very interesting, even the way you said it, you woke up one day and you thought, well, this doesn't feel very good.
Speaker A: Yeah.
Speaker B: Well, still your limbic system saying, this doesn't feel very good. Right. You have a cat brain's worth of neurons around your gut and. Right. And so maybe that saturated. And that was telling you, hey, this isn't good. Humans are more than just mice looking for cheese or monkeys looking for sex and power. Right? So let's slow down.
Speaker A: Now. You're, now, a lot of people would argue with you on that one, but.
Speaker B: Yes, but we're more than just that. But we're at least that. And we're very, very seldom not that. So my, I don't actually disagree with you that we could be better and that we can, that better platforms exist and people are voluntarily noping out of things like Facebook and noping out of.
Speaker A: That's an awesome verb.
Speaker B: It's a great term. Yeah, I love it. I use it all the time. You're one of the best.
Speaker A: Out of that.
Speaker B: I want to. Nope, out of that. Right. That's going to be a hard pass. And, and that's, and that's, that's great. But that's, again, to your point, that's the first generation of front facing cameras of social pressures. And you as a, you know, self starter, self awareness adult, have the capacity to say, yeah, I'm not going to do that. I'm going to go and spend time on long form reads. I'm going to spend time managing my attention. I'm going to do some yoga. If you're a 15 year old in high school and your entire social environment is everyone doing these things, guess what you're going to do? You're going to kind of have to do that because your limbic system says, hey, I need to get the guy or the girl or the whatever, and that's what I'm going to do. And so one of the things that we have to reason about here is the social media systems, or social media, I think, is our first encounter with a technological system that runs a bit of a loop around our own cognition and attention. It's not the last, it's far from the last. And it gets to the heart of some of the philosophical, Achilles Heel of the western philosophical system, which is each person gets to make their own determination. Each person is an individual that's, you know, sacrosanct in their agency and their sovereignty and all these things. The problem with these systems is they come down and they are able to manage everyone en masse. And so every person is making their own decision, but together, the bigger system is causing them to act with a group dynamic that's very profitable for people. So this is the issue that we have, is that our philosophies are actually not geared to understand what is it for a person to be, to have a high trust connection as part of a collective, and for that collective to have its right to coherency and agency. That's something like when a social media app causes a family to break apart, it's done harm to more than just individuals. So that concept is not something we really talk about or think about very much. But that's actually the problem, is that we're vaporizing molecules into atomic units, and then we're hitting all the atoms with certain things. That's like, yeah, well, that person chose to look at my app.
Speaker A: So our understanding of human nature is at the individual level. It emphasizes the individual too much, because ultimately, society operates at the collective level.
Speaker B: And these apps do as well, and.
Speaker A: The apps do as well. So for us to understand the progression, the development of this organism we call human civilization, we have to think at the collective level, too.
Speaker B: I would say multi tiered.
Speaker A: Multi tiered.
Speaker B: Multi tiered.
Speaker A: So individual as well.
Speaker B: Individuals, family units, social collectives, and all the way up.
Speaker A: Okay, so you've said that individual humans are multi layered, susceptible to signals and waves and multiple strata, the physical, the biological, social, cultural, intellectual. So, sort of going along these lines, can you describe the layers of the cake that that is a human being and maybe the human collective human society?
Speaker B: So I'm just stealing wholesale here from Robert Persig, who is the author of Zen and the Art of Motorcycle Maintenance, and in his follow on book has a sequel to it called Lila. He goes into this in a little more detail, but it's a crude approach to thinking about people. But I think it's still an advancement over traditional subject object metaphysics, where we look at people as a dualist would say, well, is your mind, your consciousness? Is that just merely the matter that's in your brain, or is there something more beyond that? And they would say, yes, there's a soul, sort of ineffable soul beyond just merely the physical body. And I'm not one of those people. I think that we don't have to draw a line between are things only this or only that. Collectives of things can emerge, structures and patterns that are just as real as the underlying pieces, but they're transcendent, but they're still of the underlying pieces. So your body is this way. I mean, we just know. Physically, you consist of atoms and whatnot. And then the atoms are arranged into molecules, which then arrange into certain kinds of structures that seem to have a homeostasis to them. We call them cells, and those cells form sort of biological structures. Those biological structures give your body its physical ability and the biological ability to consume energy and to maintain homeostasis. But humans are social animals. Human by themselves is not very long for the world. So we also, part of our biology is wire to connect to other people, from the mirror neurons to our language centers and all these other things. So we are intrinsically, there's a layer. There's a part of us that wants to be part of a thing. If we're around other people not saying a word, but they're just up and down, jumping and dancing, laughing, we're going to feel better. Right? And there was no exchange of physical anything. They didn't give us, like five atoms of happiness. Right. But there's an induction in our own sense of self that is at that social level. And then beyond that, Persig puts the intellectual level kind of one level higher than social. I think they're actually more intertwined than that. But the intellectual level is the level of pure ideas that you are a vessel for memes, you're a vessel for philosophies. You will conduct yourself in a particular way. I mean, I think part of this is, if we think about it from a physics perspective, theres the joke that physicists like to approximate things and well say, well approximate a spherical cow, right? Youre not a spherical cow. Youre not a spherical human. Youre a messy human. And we cant even say what the dynamics of your motion will be unless we analyze all four of these layers. Right? If youre Muslim at a certain time of day, guess what, youre going to be on the ground, kneeling and praying. And that has nothing to do with your biological need to get on the ground or physics of gravity. It is an intellectual drive that you have. It's a cultural phenomenon and an intellectual belief that you carry. So that's what the four layered stack is all about. It's that a person is not only one of these things, they're all of these things at the same time. It's a superposition of dynamics that run through us, that make us who we are.
Speaker A: So no layers special?
Speaker B: Not so much. No layer is special. Each layer is just different. But we are.
Speaker A: Each layer gets a participation trophy.
Speaker B: Yeah. Each layer is a part of what you are. You are a layer cake of all these things. And if we try to deny so many philosophies, do try to deny the reality of some of these things, some people will say, well, we're only atoms. Well, we're not only atoms, because there's a lot of other things that are only atoms. I can reduce a human being to a bunch of soup, and they're not the same thing, even though it's the same atoms. So I think the order and the patterns that emerge within humans to understand, to really think about what a next generation philosophy would look like that would allow us to reason about extending humans into the digital realm or to interact with autonomous intelligences that are not biological in nature. We really need to appreciate what human beings actually are. Is the superposition of these different layers.
Speaker A: You mentioned consciousness. Are each of these layers of cake conscious? Is consciousness a particular quality of one of the layers? Is there like a spike if you have a consciousness detector at these layers, or is something that just permeates all of these layers and just takes different form?
Speaker B: I believe what humans experience as consciousness is something that sits on a gradient scale of a general principle in the universe that seems to look for order and reach for order. When there's an excess of energy, it would be odd to say a proton is alive. It'd be odd to say this particular atom or molecule of hydrogen gas is alive. But there's certainly something we can make assemblages of these things that have auto poetic aspects to them that will create structures that will. Crystalline solids will form very interesting and beautiful structures. This gets into weird mathematical territories. We start thinking about Penrose and game of life stuff about the generativity and math itself, like the hyper real numbers, things like that. But without going down that rabbit hole, I would say that there seems to be a tendency in the world that when there is excess energy, things will structure and pattern themselves, and they will then actually, furthermore, try to create an environment that furthers their continued stability. It's the concept of externalized, extended phenotype or niche construction. So this is ultimately what leads to certain kinds of amino acids forming certain kinds of structures and so on and so forth, until you get the ladder of life. So what we experience as consciousness, no, I don't think cells are conscious of that level. But is there something beyond mere equilibrium state biology and chemistry and biochemistry that drives a. What makes things work? I think there is. So Adrian Bajan has this constructal law. There's other things you look at when you look at the life sciences and you look at any kind of statistical physics and statistical mechanics. When you look at things far out of equilibrium, when you have excess energy, what happens then? Life doesn't just make a hotter soup. It starts making structure. There's something there.
Speaker A: The poetry of reaches for order when there's an excess of energy. Mm hmm. Because you brought up game of life. You did it. Not me. My, I love cellular automata, so I have to sort of linger on that for a little bit. So cellular automata, I guess, is, or game of life, is a very simple example of reaching for order when there's an excess of energy or reaching for order and somehow creating complexity within, like, this explosion of just turmoil, somehow trying to construct structures and so doing creates very elaborate organism looking type things. What intuition do you draw from this simple mechanism?
Speaker B: Well, I like to turn that around in its head and look at it as what if every single one of the patterns created life, or created not life, but created interesting patterns because some of them don't. And sometimes you make cool gliders and other times you start with certain things and you make gliders and other things that then construct, like, and gates and not gates. And you build computers on them. All of these rules that create these patterns that we can see. Those are just the patterns we can see. What if our subjectivity is actually limiting our ability to perceive the order in all of it? What if some of the things that we think are random are actually not that random? We're simply not integrating at a fine enough level across a broad enough time horizon? And this is, again, I said we go down the rabbit holes in the Penrose stuff, or like Wolfram's explorations on these things. There is something deep and beautiful in the mathematics of all this that is, hopefully one day I'll have enough money to where I can retire and just ponder those questions. But there's something there.
Speaker A: But you're saying there's a ceiling to when you have enough money and you retire and you ponder it, there's a ceiling to how much you can truly ponderous because there's cognitive limitations in what you're able to perceive as a pattern.
Speaker B: Yeah.
Speaker A: And maybe mathematics extends your perception capabilities, but it's still finite.
Speaker B: It's just like, yeah, the mathematics we use is the mathematics that can fit in our head.
Speaker A: Yeah.
Speaker B: You know, did God really create the integers or did God create all of it and we just happen at this point in time to be able to perceive integers?
Speaker A: Well, he just did the positive energy.
Speaker B: She created and then we.
Speaker A: She just graded the natural numbers and then we screwed all up with zero. And then I guess. Okay, but we did.
Speaker B: We created mathematical operations so we can have iterated steps to approach bigger problems. Right? I mean, the entire point of the arabic numeral system, and it's a rubric for mapping a certain set of operations, of folding them into a simple little expression. But that's just the operations that we can fit in our heads. There are many other operations besides. Right.
Speaker A: The thing that worries me the most about aliens and humans is that aliens are all around us and we're too dumb to see them.
Speaker B: Oh, certainly, yeah.
Speaker A: Or life. I say just life. Life of all kinds of forms or organisms. You know what? Just even the intelligence of organisms is imperceptible to us because we're too dumb and self centered. That word.
Speaker B: Well, we're looking for a particular kind of thing. When I was at Cornell, I had a lovely professor of asian religions, J. Marie Law, and she would tell this story about a musical, a musician, a western musician who went to Japan, and he taught classical music and could play all sorts of instruments. He went to Japan, and he would ask people. He would basically be looking for things in the style of western chromatic scale and these kinds of things, and then finding none of it. He would say, well, there's really no music in Japan, but they're using a different scale, they're playing different kinds of instruments. The same thing she was using as a metaphor for religion as well. In the west, we center a lot of religion, certainly the religions of Abraham, we center them around belief. And in the east, it's more about practice, spirituality and practice rather than belief. So, anyway, the point is here, to your point, life, I think so many people are so fixated on certain aspects of self replication or homeostasis or whatever, but if we kind of broaden and generalize this thing of things reaching for order, under which conditions can they then create an environment that sustains that order, that allows them? The invention of death is an interesting thing. There are some organisms on earth that are thousands of years old, and it's not like they're incredibly complex. They're actually simpler than the cells that comprise us, but they never die. So at some point, death was invented somewhere along the eukaryotic scale. I mean, even the protists, right, there's death. And why is that? Along with the sexual reproduction, right. There is something about the renewal process, something about the ability to respond to a changing environment wherever it just becomes. Just killing off the old generation and letting new generations try seems to be the best way to fit into the niche.
Speaker A: You know, human historian seems to write about wheels and fire as the greatest inventions, but it seems like death and sex are pretty good, and they're kind of essential inventions at the very beginning.
Speaker B: At the very beginning, yeah. Well, we didn't invent them. Right.
Speaker A: Well, broad, we, you didn't invent life. I see us as one, you, particular homo sapien did not invent them, but we together, it's a team project, just like you're saying.
Speaker B: I think the greatest homo sapien invention is collaboration.
Speaker A: So when you say collaboration, peter, where do ideas come from, and how do they take hold in society is that the nature of collaboration is that the basic atom of collaboration is ideas.
Speaker B: It's not not ideas, but it's not only ideas. There's a book I just started reading called death from a distance. Have you heard of this?
Speaker A: No.
Speaker B: It's a really fascinating thesis, which is that humans are the only con specific, the only species that can kill other members of the species from range. And maybe there's a few exceptions, but if you look in the animal world, you see, like, pronghorns butting heads, right? You see the alpha lion and the beta lion, and they take each other down. Humans, we develop the ability to chuck rocks at each other. Well, at prey, but also at each other. And that means the beta male can chunk a rock at the alpha male and take them down. He can throw a lot of rocks, actually miss a bunch of times, but just hit once and be good. So this ability to actually kill members of our own species from range without a threat of harm to ourselves created essentially mutually assured destruction where we had to evolve cooperation. If we didn't, then if we just continue to try to do, like, I'm the biggest monkey in the tribe and I'm going to own this tribe and you have to go. If we do it that way, then those tribes basically failed. And the tribes that persisted and that have now given rise to the modern homo sapiens are the ones where respecting the fact that we can kill each other from range without har, like, there's an asymmetric ability to snipe the leader from range. That meant that we sort of had to learn how to cooperate with each other. Come back here. Don't throw that rock at me. Let's talk our.
Speaker A: So violence is also part of collaboration?
Speaker B: The threat of violence, let's say. Well, the recognition, maybe the better way to put it, is the recognition that we have more to gain by working together than the prisoner's dilemma of both of us defecting.
Speaker A: So mutually sure destruction in all its forms is part of this idea of collaboration.
Speaker B: Well, and Eric Weinstein talks about our nuclear peace, right? I mean, it kind of sucks that with thousands of warheads aimed at each other, Russia and the US, it's like, on the other hand, we only fought proxy wars. We did not have another World War III of hundreds of millions of people dying to machine gun fire and giant guided missiles.
Speaker A: So the original nuclear weapon is a rock that we learned how to throw, essentially, yeah.
Speaker B: Well, the original scope of the world for any human being was their little tribe, I would say it still is.
Speaker A: For the most part, Eric Weinstein speaks very highly of you, which was very surprising to me at first because I didn't know there's this depth to you. Cause I knew you as an amazing leader of engineers and engineer yourself and so on. So it's fascinating. Maybe just as a comment, a side tangent that we can take. What's your nature of your friendship with Eric Weinstein? How did the two, how did such two interesting paths crossed? Your origins in physics? Is it your interest in philosophy and the ideas of how the world works? What is it?
Speaker B: It's actually. It's very random. Eric found me. He actually found Travis and I. Travis Oliphant. Oliphant. Yeah. We were both working at a company called Enthought back in the mid two thousands, and we're doing a lot of consulting around scientific python. And we'd made some tools, and Eric was trying to use some of these python tools to visualize. He had a fiber bundle approach to modeling certain aspects of economics. He was doing this, and that's how he kind of got in touch with us. And so this was in the early. This was in the mid two thousands zero seven time frame 0607.
Speaker A: Eric Weinstein trying to use Python, visualize.
Speaker B: Fiber bundles using some of the tools that we built in the open source.
Speaker A: That's somehow entertaining to me, the thought of that.
Speaker B: It was really funny. But then we met with him a couple of times, a really interesting guy. And then in the wake of the. The 0708 financial collapse, he helped organize with Lee Smolin, a symposium at the perimeter institute about. Okay, well, clearly big finance can't be trusted. Government's in its pockets with regulatory capture. What the f. Do we do? And all sorts of people. Nassim Talaib was there, and Andy Lowe from MIT was there, and Bill Janeway. I mean, just a lot of top billing people were there. And he invited me and Travis and another one of our co workers, Robert Kern, who was a. Anyone in the sci PI numpy community knows Robert. Really great guy. So the three of us also got invited to go to this thing. And that's where I met Brett Weinstein for the first time as well. Yeah, I knew him before he got all famous, for unfortunate reasons, I guess. But anyway, so we met then and kind of had a friendship.
Speaker A: Since then, you have a depth of thinking that kind of runs with Eric in terms of just thinking about the world deeply and thinking philosophically. And then there's Eric's interest in programming. I actually never, you know, he'll bring up programming to me quite a bit as a metaphor for stuff.
Speaker B: Right.
Speaker A: But I never kind of pushed the point of, like, what's the nature of your interest in programming? I think he saw it probably as a tool.
Speaker B: Yeah, absolutely.
Speaker A: That to visualize, to explore mathematics and explore physics. But I was wondering, like, what's the. His depth of interest and also his vision for what programming would look like in the future. Have you had interaction with him, like, discussion in the space of python and programming?
Speaker B: Well, in the sense of sometimes he asks me, why is this stuff still so hard? Yeah, everybody's a critic. But actually, no, Eric.
Speaker A: Programming, you mean?
Speaker B: Yes, yes. Well, not programming in general. Certain things in the python ecosystem. But he actually. I think what I find in listening to some of his stuff is that he does use programming metaphors a lot. Right. He'll talk about APIs or object oriented and things like that. So I think that's a useful set of frames for him to draw upon for discourse. I haven't pair programmed with him in a very long time. Well, I mean, trying to help put together some of the visualizations around these things, but it's been a very not really pair program. But, like, even looked at his code. Right.
Speaker A: I mean, how legendary would be. Is that like get repo with Peter Wang and Eric Weinstein?
Speaker B: Well, honestly, honestly, Robert Kern did all the heavy lifting, so I have to give credit where credit is due. Robert is. Is the silent but incredibly deep quiet. Not silent, but quiet, but incredibly deep individual at the heart of a lot of those things that Eric was trying to do. But we did have, you know, in the. As Travis and I were starting our company in 2012 timeframe, we went to New York. Eric was still in New York at the time. He hadn't moved to. This was before he joined Teal capital. We just had like, a steak dinner somewhere. Maybe it was Keynes, I don't know, somewhere in New York. So it's me, Travis, Eric, and then Wes McKinney, the creator of pandas, and then Wes's then business partner, Adam. The five of us sat around having this just a hilarious time, amazing dinner. I forget what all we talked about, but it was. It was one of those conversations which I wish, as soon as Covid is over, maybe Eric and I can sit down, recreate, recreate it somewhere in LA. Or maybe he comes here because a lot of cool people are here in Austin. Right?
Speaker A: Exactly.
Speaker B: Yeah, we're all here.
Speaker A: He should come here, come here. So he uses the metaphor source code sometimes to talk about physics. We figure out our own source code. So, you with a physics background and somebody who's quite a bit of an expert in source code, do you think we'll ever figure out our own source code in the way that Eric means? Do you think we'll figure out the nature of.
Speaker B: I'm constantly working on that problem. I mean, I think we'll make more and more progress. For me, there's some things I don't really doubt too much. I don't really doubt that one day we will create a synthetic, maybe not fully in silicon, but a synthetic approach to cognition that rivals the biological 20 watt computers in our heads.
Speaker A: What's cognition here?
Speaker B: Cognition, perception, attention, memory, recall, asking better questions. That, for me, is a measure of intelligence.
Speaker A: Doesn't Roomba vacuum cleaner already do that? Or do you mean. Oh, it doesn't ask questions?
Speaker B: I mean, no, it's. I mean, I have a roomba, but it's. Well, it's not even as smart as my cat, right?
Speaker A: So, yeah, but it asks questions about, what is this wall it now new feature asks, is this poop or not? Apparently, yes.
Speaker B: A lot of our current cybernetic system. It's a cybernetic system. It will go and it will happily vacuum up some poop, right? The older generations would.
Speaker A: New one just released does not vacuum up the poop. This is a commercial for me.
Speaker B: I wonder if it still gets stuck under my first rung of my stare. In any case, these cybernetic systems we have, they're designed to be sent off into a relatively static environment. And whatever dynamic things happen in the environment, they have a very limited capacity to respond to a human baby. A human toddler of 18 months of age has more capacity to manage its own attention and its own capacity to make better sense of the world than the most advanced robots today. So, again, my cat, I think, can do a better job of my two, and they're both pretty clever. So I do think, though, back to my kind of original point, I think that it's not, for me, it's not question at all that we will be able to create synthetic systems that are able to do this better than the human at an equal level or better than the human mind. It's also, for me, not a question that we will be able to put them alongside humans so that they capture the full, broad spectrum of what we are seeing as well, and also looking at our responses, listening to our responses, even maybe measuring certain vital signs about us. So, in this sidecar mode, a greater intelligence could use us and our whatever 80 years of life to train itself up and then be a very good simulacrum of us moving forward.
Speaker A: So who is in the sidecar in that picture of the future? Exactly.
Speaker B: The baby version of our immortal selves.
Speaker A: Okay, so once the baby grows up, is there any use for humans?
Speaker B: I think so. I think that out of epistemic humility, we need to keep humans around for a long time. And I would hope that anyone making those systems would believe that to be true.
Speaker A: Out of epistemic humility, what's the nature of the humility?
Speaker B: That we don't know. What we don't know.
Speaker A: So we don't. Right, so we don't know.
Speaker B: I mean, first we have to build systems that. That help us do the things that we do know about, that can then probe the unknowns that we know about. But the unknown unknowns we don't know. We could always. Nature is the one thing that is infinitely able to surprise us. So we should keep biological humans around for a very, very, very long time, even after our immortal selves have transcended, have gone off to explore other worlds, gone to go communicate with the life forms living in the sun or whatever else. So I think, for me, these seem like things that are going to happen. I don't really question that, that they're going to happen. Assuming we don't completely destroy ourselves, is.
Speaker A: It possible to create an AI system that you fall in love with and it falls in love with you, and you have a romantic relationship with it, or a deep friendship, let's say.
Speaker B: I would hope that that is the design criteria for any of these systems. If we cannot have a meaningful relationship with it, then it's still just a chunk of silicon.
Speaker A: So then what is meaningful? Because back to sugar.
Speaker B: Well, sugar doesn't love you back, right? So the computer has to love you back. And what does love mean? Well, in this context, for me, love, I'm going to take a page from Ellen de Bouton. Love means that it wants to help us become the best version of ourselves.
Speaker A: Yes. That's beautiful. That's a beautiful definition of love. So what role does love play in the human condition at the individual level and at the group level? Because you were kind of saying that humans, we should really consider humans both at the individual and the group and the societal level. What's the role of love in this whole thing? We talked about sex. We talked about death, thanks to the bacteria that invented it. At which point did we invent love, by the way? I mean, is that also.
Speaker B: No, I think love is the start of it all and the feelings of. And this gets beyond just romantic, sensual, whatever kind of things, but actually genuine love as we have for another person, love as it would be used in a religious text, right. I think that capacity to feel love more than consciousness, that is the universal thing. Our feeling of love is actually a sense of that generativity. When we can look at another person and see that they can be something more than they are and more than just what we a pigeonhole, we might stick them in. I mean, I think there's, in any religious text you'll find a voiced some concept of this, that you should see the grace of God in the other person, right? They're made in the spirit of what the love that God feels for his creation or her creation. And so I think this thing is actually the root of it. So I would say, I don't think molecules of water feel consciousness, have consciousness, but there is some proto micro quantum thing of love. That's the generativity, when theres more energy than what they need to maintain equilibrium. And that when you sum it all up, is something that leads to, I mean, I had my mind blown one day as an undergrad at the physics computer lab. I logged in, and when you log into bash for a long time, there was a little fortune that would come out and it said man was created by water to carry itself uphill. I was logging in to work on some problem set, and I logged in and I saw that and I just said, son of a bitch. I logged out, I went to the coffee shop and I got a coffee and I sat there on the quad, like, you know, it's not wrong. And yet, WTF? Right? So when you look at it that way, it's like, yeah, okay, non equilibrium physics is a thing. And so when we think about love, when we think about these kinds of things, I would say that in the modern day human condition, theres a lot of talk about freedom and individual liberty and rights and all these things. But thats very hegelian. Its very kind of following from the western philosophy of the individual as sacrosanct. But its not really couched, I think, the right way because it should be. How do we maximize peoples ability to love each other, to love themselves first, to love each other, their responsibilities to the previous generation, to the future generations. Those are the kinds of things that should be our design criteria. Those should be what we start with to then come up with the philosophies of self and of rights and responsibilities. But that love being at the center of it. I think when we design systems for cognition, it should absolutely be built that way. I think if we simply focus on efficiency and productivity, these kind of very industrial era, all the things that Marx had issues with, right. Thats a way to go, and really, I think, go off the deep end in the wrong way.
Speaker A: So one of the interesting consequences of thinking of life in this hierarchical way of an individual human, and then theres groups and theres societies is, I believe that you believe that corporations are people. So this is kind of a politically dense idea and all those kinds of things. If we just throw politics aside, if we throw all of that aside, in which sense do you believe that corporations are people? And how does love connect to that?
Speaker B: Right. So the belief is that groups of people have some kind of higher level, I would say mesoscopic claim to agency. Let's start with this. Most people would say, okay, individuals have claims to agency and sovereignty. Nations, we certainly act as if nations. So at a very large, large scale nations have rights to sovereignty and agency. Like everyone plays the game of modernity as if that's true. Right. We believe France is a thing. We believe the United States is a thing. But to say that groups of people at a smaller level than that, like a family unit, is the thing. Well, in our laws, we actually do encode this concept. I believe that in a relationship and a marriage, one partner can sue for loss of consortium if someone breaks up the marriage or whatever. So these are concepts that even in law, we do respect, that there is something about the union and about the family. So for me, I don't think it's so weird to think that groups of people have a claim to rights and sovereignty of some degree. I mean, we look at our clubs, we look at churches, we talk about these collectives of people as if they have a real agency to them, and then they do. But I think if we take that one step further and say, okay, they can accrue resources, well, yes, check by law, they can. They can own land, they can engage in contracts. They can do all these different kinds of things. So we, in legal terms, support this idea that groups of people have rights. Where we go wrong on this stuff is that the most popular version of this is the for profit, absentee owner corporation that then is able to amass larger resources than anyone else in the landscape. Anything else, any other entity of equivalent size. And they're able to essentially bully around individuals, whether it's laborers, whether it's people whose resources they want to capture. They're also able to bully around our system of representation, which is still tied to individuals, right? So I don't believe that's correct. I don't think it's good that they're people, but they're assholes. I don't think that corporations as people acting like assholes is a good thing. But the idea that collectives and collections of people, that we should treat them philosophically as having some agency, some agency, and some mass, at a mesoscopic level, I think that's an important thing, because one thing I do think we underappreciate sometimes is the fact that relationships have relationships. So it's not just individuals having relationships with each other, but if you have eight people seated around a table, each person has a relationship with each of the others. And that's a obvious. But then if it's four couples, each couple also has a relationship with each of the other couples. The dyads do. And if it's couples, but one is the father mother older, and then one of their children and their spouse, that family unit of four has a relationship with the other family unit of four. So the idea that relationships have relationships is something that we intuitively know in navigating the social landscape. But it's not something I hear expressed like that. It's certainly not something that is, I think, taken into account very well when we design these kinds of things. So I think the reason why I care a lot about this is because I think the future of humanity requires us to form better sense, make collective sense, making units at something around Dunbar, number half to five x Dunbar. And that's very different than right now, where we defer sense making to massive, aging, zombie institutions, or we just do it ourselves. We go it alone, go into the dark force of the Internet by ourselves.
Speaker A: So that's really interesting. So you've talked about agency, I think, maybe calling it a convenient fiction at all these different levels. So even at the human individual level, it's kind of a fiction we all believe because we are, like you said, made of cells, and cells are made of atoms. So that's a useful fiction. And then there's nations. That seems to be a useful fiction, but it seems like some fictions are better than others. There's a lot of people that argue the fiction of nation is a bad idea. One of them lives two doors down from me, Michael Malus. He's an anarchist. I'm sure there's a lot of people who are into meditation that believe the idea. This useful fiction of agency of an individual is troublesome as well. We need to let go of that in order to truly transcend. I don't know. I don't know what words you want to use, but suffering, or to elevate the experience of life. You're arguing that. Okay, so we have some of these useful fictions of agency. We should add a. A stronger fiction that we tell ourselves about the agency of groups in the hundreds of half a. Dunbar's number five X. Dunbar's number.
Speaker B: Yeah. Something on that order. And we call them fictions, but really they're rules of the game, right? Rules that we feel are fair, or rules that we consent to.
Speaker A: I always question the rules when I lose. Like a monopoly. That's when I usually question. When I'm winning, I don't question the rules.
Speaker B: We should play game Monopoly someday. There's a trippy version of it that we could do. Contract Monopoly is introduced by a friend of mine to me, where you can write contracts on future earnings or landing on various things, and you can hand out, like, you can land the first three times, you land on park places free or whatever. Then you can start trading those contracts for money.
Speaker A: And then you create a human civilization, and somehow bitcoin comes into it. But some of these, actually, I bet.
Speaker B: If me and you and Eric sat down to play a game of monopoly, and we were to make NFTs out of the contracts we wrote, we could make a lot of money. Now. It's a terrible idea. I would never do it, but I bet we could actually sell the NFTs around.
Speaker A: I have other ideas to make money that I could tell you, and they're all terrible ideas, including cat videos on the Internet. Okay, but some of these rules of the game, some of these fictions are, it seems like they're better than others.
Speaker B: They have worked this far to cohere human, to organize human collective action.
Speaker A: But you're saying something about, especially this technological age, requires modified fictions, stories of agency. Why the Dunbar number? And also, how do you select the group of people? Dunbar numbers. I think I have the sense that it's overused as a kind of law, that somehow we can have deep human connection at this scale. Like, some of it feels like an interface problem, too. It feels like if I have the right tools, I can deeply connect with a large number, larger number of people. It just feels like there's a huge value to interacting just in person, getting to share traumatic experiences together, beautiful experiences together. But there's other experiences. Like, um, that in the digital space that you can share. It just feels like Dunbar's number could expand it significantly, perhaps not to, to the level of millions and billions, but it feels like it could be expended. So how. Yeah, how do we find the right interface, you think, for having a little bit of a collective here that has agency?
Speaker B: You're right that there's many different ways that we can build trust with each other. My friend Joe Edelman talks about a few different ways that. Mutual appreciation, trustful conflict, just experiencing something. There's a variety of different things that we can do, but all those things take time, and you have to be present. The less present you are. There's just, again, a no free lunch principle here. The less present you are, the more of them you can do, but then the less connection you build. So I think there is sort of a human capacity issue around some of these things. Now, that being said, if we can use certain technologies. So, for instance, if I write a little monograph on my view of the world, you read it asynchronously at some point, and you're like, wow, Peter, this is great. Here's mine. I read it. I'm like, wow, Lex, this is awesome. We can be friends without having to spend ten years figuring all this stuff out together. We just read each other's thing and be like, oh, yeah, this guy's exactly in my wheelhouse. And vice versa. And we can then connect just a few times a year and maintain a high trust relationship. It can be expanded a little bit, but it also requires. These things are not all technological in nature. It requires the individual themselves to have a certain level of capacity, to have a certain lack of neuroticism. If you want to use the, the ocean, big five sort of model, people have to be pretty centered. The less centered you are, the fewer authentic connections you can really build for a particular unit of time. It just takes more time. Other people have to put up with your crap. There's just a lot of the stuff that you have to deal with if you are not so well balanced. Yes, we can help people get better to where they can develop more relationships faster. And then you can maybe expand Dunbar number by quite a bit. But you're not going to do it. I think it's going to be hard to get it beyond ten x. Kind of the rough swag of what it is, you know?
Speaker A: Well, don't you think that AI systems could be an addition to Dunbar's number? So, like, why do you count as.
Speaker B: One system or multiple AI systems?
Speaker A: Multiple AI systems. So I do believe that AI systems, for them to integrate into human society, as it is now, have to have a sense of agency. So there has to be a individual because otherwise we wouldn't relate to them.
Speaker B: We could engage certain kinds of individuals to make sense of them for us and be almost like, did you ever watch Star Trek? Like Voyager? There's the Volta. Who are the interfaces? The ambassadors for the Dominion. We may have ambassadors that speak on behalf of these systems. They're like the mentats of dune, maybe, or something like this. I mean, we already have this to some extent. If you look at the biggest sort of, I wouldn't say AI system, but the biggest cybernetic system in the world is the financial markets. It runs outside of any individual's control. And you have an entire stack of people on Wall Street, Wall street analysts to CNBC reporters, whatever. They're all helping to communicate. What does this mean? You know, Jim Cramer, like, running around and yelling stuff. Like all of these people are part of that lowering of the complexity there to meet sense, you know, to help do sense making for people at whatever capacity they're at. And I don't see this changing with AI systems. I think you would have ringside commentators talking about all this stuff that this AI system is trying to do over here, over here, because it's actually a super intelligence. So if you want to talk about humans interfacing, making first contact with super intelligence, we're already there. We do it pretty poorly. And if you look at the gradient of power and money, what happens is the people closest to it will absolutely exploit their distance for personal financial gain. So we should look at that and be like, oh, well, that's probably what the future will look like as well. But nonetheless, we're already doing this kind of thing. So in the future we can have AI systems, but you're still gonna have to trust people to bridge the sense making gap to them.
Speaker A: See, I don't. I just feel like there could be like millions of AI systems that have. Have agencies you have. When you say one super intelligence. Superintelligence in that context means it's able to solve particular problems extremely well. But there's some aspect of human like intelligence that's necessary to be integrated into human society. So not financial markets, not sort of weather prediction systems or, I don't know, logistics optimization. I'm more referring to things that you interact with on the intellectual level.
Speaker B: Yeah.
Speaker A: And that, I think requires. There has to be a backstory. There has to be a personality. I believe it has to fear its own mortality in a genuine way. Like, there has to be all many of the elements that we humans experience that are fundamental to the human condition, because otherwise we would not have a deep connection with it.
Speaker B: But I don't think having a deep connection with it is necessarily going to stop us from building a thing that has quite an alien intelligence aspect.
Speaker A: Sure.
Speaker B: So the other kind of alien intelligence on this planet is octopuses or octopodies or whatever you want to call them. Octopi. Yeah. There's a little controversy as to what the plural is, I guess. Butters an octopuse. It really acts as a collective intelligence of eight intelligent arms. Its arms have a tremendous amount of neural density to them. And I see if we can build, I mean, lets go with what youre saying. If we build a singular intelligence that interfaces with humans, that has a sense of agency, so it can run the cybernetic loop and develop its own theory of mind as well as its a theory of action, all these things, I agree with you that thats the necessary components to build a real intelligence. There's got to be something at stake. It's got to make a decision. It's got to then run the Ooda loop. We build one of those? Well, if we can build one of those, we can probably build 5 million of them. So build 5 million of them. And if their cognitive systems are already digitized and already kind of there, we stick an antenna on each of them, bring it all back to a hive mind that maybe doesn't make all the individual decisions for them, but treats each one as almost like a neuronal input at a much higher bandwidth and fidelity going back to a central system that is then able to perceive much broader dynamics that we can't see in the same way that a phased array radar. You think about how phased array radar works. It's just sensitivity, it's just radars, and then it's hypersensitivity and really great timing between all of them. And with a flat array, it's as good as a curved radar dish with these things. It's a phased array of cybernetic systems that'll give the centralized intelligence much, much better, much higher fidelity understanding of what's actually happening in the environment.
Speaker A: But the more power, the more understanding the central superintelligence has, the dumber the individual fingers of this intelligence are, I think not necessarily. I don't see what it has to be this argument. There has to be the experience of the individual agent has to have the full richness of the human like experience. You have to be able to be driving the car in the rain, listening to Bruce Springsteen and all of a sudden break out in tears. Because remembering something that happened to you.
Speaker B: In high school, we can implant those memories if that's really needed.
Speaker A: But no, but the central agency, I guess I'm saying, in my view, for intelligence to be born, you have to have a decentralization. Like, each one has to struggle and reach. So each one, in excess of energy has to reach for order, as opposed to a central place doing so.
Speaker B: Have you ever read, like, some Sci-Fi where there's, like, hive minds? Like the Werner vinge, I think, has one of these, and then some of the stuff from. Yes, on the Commonwealth saga. The idea that you're an individual, but you're connected with a few other individuals telepathically as well, and together you form a swarm. So if you are, I need to ask you, what do you think is the experience of. If you are like, well, a borg, right? If you are one, if you're part of this hive mind, outside of all the aesthetics, forget the aesthetics. Internally, what is your experience like? Cause I have a theory as to what that looks like.
Speaker A: The one question I have for you about that experience is how much is there a feeling of freedom, of free will? Because I obviously, as a human, very unbiased, but also somebody who values freedom and biased. It feels like the experience of freedom is essential for trying stuff out to being creative and doing something truly novel, which is at the core of.
Speaker B: Yeah, well, I don't think you have to lose any freedom when you're in that mode. Because I think what happens is we think. We still think. And I mean, you're still thinking about this in a sense of a top down command and control hierarchy, which is not what it has to be at all. I think the experience. So I'll just show my carts here. I think the experience of being a robot in that robot swarm, a robot who has agency over their own local environment, that's doing sense making and reporting it back to the hive mind. I think that robots experience would be one of. When the hive mind is working well, it would be an experience of talking to God that you essentially are reporting. Two, you're sort of saying, here's what I see. I think this is what's going to happen over here. I'm going to go do this thing, because I think if I'm going to do this, this will make this change happen in the environment. And God, she may tell you, that's great. And in fact, your brothers and sisters will join you to help make this go better. Then she can let your brothers and sisters know, hey, Peter is going to go do this thing. Would you like to help him? Because we think that this will make this thing go better. And they'll say, yes, we'll help him. The whole thing could be actually a very emergent. The sense of what does it feel like to be a cell in a network that is alive, that is generative? And I think actually the feeling is serendipity, that there is random order. Not random disorder or chaos, but random order. Just when you need it to hear Bruce Springsteen, you turn on the radio and bam, it's Bruce Springsteen. That feeling of serendipity. I feel like this is a bit of a flight of fancy, but every cell in your body must have like, what does it feel like to be a cell in your body? When it needs sugar, there's sugar. When it needs oxygen, there's just oxygen. Now, when it needs to go and do its work and pull like as one of your muscle fibers, right. It does its work and it's great. It contributes to the cause. Right? So this is all, again a flight of fancy. But I think as we extrapolate up, what does it feel like to be an independent individual with some bounded sense of freedom? All sense of freedom is actually bounded, but with a bounded sense of freedom that still lives within a network that has order to it. And I feel like it has to be a feeling of serendipity.
Speaker A: So the cell, there's a feeling of serendipity even though it has no way.
Speaker B: Of explaining why it's getting oxygen and sugar when it gets it.
Speaker A: So you have to, each individual component has to be too dumb to understand the big picture?
Speaker B: No, the big picture is bigger than what it can understand.
Speaker A: But isn't that an essential characteristic of the individual is to be too dumb to understand the bigger picture? Like, not dumb necessarily, but limited in its capacity to understand. Because the mo, okay, the moment you understand, I feel like that leads to if you tell me now that there's some bigger intelligence controlling everything I do, intelligence, broadly defined. Meaning like, you know, even the Sam Harris thing, there's no free will. If I'm smart enough to truly understand that, that's the case. That's gonna, I don't know if I, well, yeah.
Speaker B: Philosophical breakdown. Yeah, right. Because we're in the west and we're pumped full of this stuff of like, you are a golden, fully free individual with all your freedoms and all your liberties and go grab a gun and shoot whatever you want to. No, it's actually you don't actually have a lot of these. You're not unconstrained, but the areas where you can manifest agency, you're free to do those things. You can say whatever you want on this podcast. You can create a podcast, right? Yeah, you have a lot of this kind of freedom. But even as you're doing this, you are actually, I guess, where the denouement of this is that we are already intelligent agents in such a system, in that one of these robots of one of 5 million little swarm robots, or one of the Borg, they're just posting an internal bulletin board. I mean, maybe the Borg cube is just a giant Facebook machine floating in space, and everyone's just posting on there. They're just posting really fast and like.
Speaker A: Oh, yeah, that's called the metaverse now.
Speaker B: The net's called the metaverse. That's right. Here's the enterprise. Maybe we should all go shoot it. Yeah, everyone upvotes and they're going to go shoot it. Right. But we already are part of a human online collaborative environment and collaborative sense making system. It's not very good yet. It's got the overhangs of zombie sense making institutions all over it. But as that washes away and as we get better at this, we are going to see humanity improving at speeds that are unthinkable in the past. And it's not because anyone's freedoms were limited. In fact, the open source, we started this with open source software, right? The collaboration. What the Internet surfaced was the ability for people all over the world to collaborate and produce some of the most foundational software that's in use today. That entire ecosystem was created by collaborators all over the place. So these online kind of swarm kind of things are not novel. It's just, I'm just suggesting that future AI systems, if you can build one smart system, you have no reason not to build multiple. If you build multiple, there's no reason not to integrate them all into a collective sense making substrate. And that thing will certainly have emergent intelligence that none of the individuals and probably not any of the human designers will be able to really, you know, put a bow around and explain.
Speaker A: But in some sense, would that AI system still be able to go, like, rural Texas, buy a ranch, go off the grid, go full survivalist? Can you disconnect from the hive mind?
Speaker B: You may not want to.
Speaker A: So to be ineffective, to be intelligent.
Speaker B: You have access to way more intelligence capability. If you're plugged into 5 million other really, really smart cyborgs, why would you.
Speaker A: Leave so, like, there's a word control that comes to mind. So it doesn't, it doesn't feel like control, like over overbearing control.
Speaker B: It's just, I think systems, well, this is to your point. I mean, look at, look at how much, how uncomfortable you are with this concept, right? I think systems that feel like overbearing control will not evolutionarily win out. I think systems that give their individual elements the feeling of serendipity and the feeling of agency that those systems will win. But that's not to say that there will not be emergent, higher level order on top of it. And that's the thing. That's the philosophical breakdown that we're staring right at, which is in the western mind. I think there's a very sharp delineation between explicit control, cartesian like, what is the vector? Where is the position? Where is it going to? It's completely deterministic and kind of this idea that things emerge, everything we see is the emergent patterns of other things, and there is agency when there's extra energy.
Speaker A: Nate so you have spoken about a kind of meaning crisis that we're going through, but it feels like since we invented sex and death, we, broadly speaking, we've been searching for a kind of meaning. So it feels like human civilization has been going through a meaning crisis of different flavors throughout its history. Why is, how is this particular meaning crisis different? Or is it really a crisis and it wasn't previously? What's your sense?
Speaker B: A lot of human history, there wasn't so much a meaning crisis. There was just a like, food and not getting eaten by bears crisis. Right. Once you get to a point where you can make food, there was the not getting killed by other humans crisis. So sitting around wondering what is it all about? Is actually a relatively recent luxury. And to some extent, the meaning crisis coming out of that is precisely because. Well, not precisely because I believe that meaning is the consequence of when we make consequential decisions. It's tied to agency. When we make consequential decisions, that generates meaning. So if we make a lot of decisions, but we dont see the consequences of them, then it feels like, what was the point? Right? But if theres all these big things happening, but were just along for the ride, then it also does not feel very meaningful. Meaning, as far as I can tell, this is my working definition of circa 2021, is generally the result of a person making a consequential decision, acting on it, and then seeing the consequences of it. So historically, just when humans are in survival mode, you're making consequential decisions all the time, so there's not a lack of meaning because you either got eaten or you didn't. You got some food, and that's great, you feel good. These are all consequential decisions. Only in the post fossil fuel and industrial revolution could we create a massive leisure class. I could sit around not being threatened by bears, not starving to death, making decisions somewhat, but a lot of times not seeing the consequences of any decisions they make. The general sort of sense of anomie. I think there's the french term for it. In the wake of the consumer society, in the wake of mass media telling everyone, hey, choosing between Hermes and Chanel is a meaningful decision. No, it's not.
Speaker A: I don't know what either of those mean.
Speaker B: There's high end luxury purses and crap like that. But the point is that we give people the idea that consumption is meaning, that making a choice of this team versus that team spectating has meaning. So we produce all of these different things that are as if meaning, but really making a decision that has no consequences for us. And so that creates the meaning crisis.
Speaker A: Well, you're saying choosing between Chanel and the other one is that has no consequence. I mean, why is one more meaningful than the other?
Speaker B: It's not that it's more meaningful than the other. It's that you make a decision between these two brands and you're told, this brand will make me look better in front of other people if I buy this brand of car, if I wear that brand of apparel. A lot of the decisions we make are around consumption. But consumption by itself doesn't actually yield meaning. Gaining social status does provide meaning. So that's why in this era of abundant production, we so many things turn into status games. The NFT kind of explosion is a similar kind of thing. Everywhere there are status games because we just have so much excess production.
Speaker A: But aren't those status games a source of meaning? Why do the games we play have to be grounded in physical reality like they are when you're trying to run away from. From lions? Why can't we, in this virtuality world, on social media? Why can't we play the games on social media? Even the dark ones?
Speaker B: Right, we can.
Speaker A: But you're saying that's great. There's a meaning crisis.
Speaker B: Well, there's a meaning crisis in that there's two aspects of it. Number one, playing those kinds of status games oftentimes requires destroying the planet because it ties to consumption. Consuming the latest and greatest version of a thing, buying the latest limited edition sneaker and throwing out all the old ones. Maybe you keep some of the old ones, but the amount of sneakers we have to cut up and destroy every year to create artificial scarcity for the next generation, this is kind of stuff that's not great. It's not great at all. So conspicuous consumption, fueling status games is really bad for the planet, not sustainable. The second thing is you can play these kinds of status games, but then what it does is it renders you captured to the virtual environment. The status games that the really wealthy people are playing are all around the hard resources where they're going to build the factories, they're going to have the fuel in the rare earths to make the next generation of robots. They're then going to run game, run circles around you and your children. So that's another reason not to play those virtual status games.
Speaker A: So you're saying ultimately the big picture game is one if by people who have access or control over actual hard resources. So you can't, you don't see a society where most of the games are played in the virtual space, they'll be.
Speaker B: Captured in the physical space. It's it all, it all builds. It's just like the stat, the stack of human being, right? If you only play the game at the cultural and then intellectual level, then the people with the hard resources and access to layer zero physical, are going to own you.
Speaker A: But isn't money not connected to, or less and less connected to hard resources? And money still seems to work. It's a virtual technology.
Speaker B: There's different kinds of money. Part of the reason that some of the stuff is able to go a little unhinged is because the big sovereignties where one spends money and uses money and plays money games and inflates money, their ability to adjudicate the physical resources and hard resources on land and things like that, those have not been challenged in a very long time.
Speaker A: So we went off the gold standard. Most money is not connected to physical resources. It's an idea. And that idea is very closely connected to status.
Speaker B: But it's also tied to, like, it's actually tied to law, it is tied to some physical hard things. So you have to pay your taxes.
Speaker A: Yes. So it's always at the end going to be connected to the blockchain of physical reality. So in the case of law and taxes, it's connected to government. And government is what violence is. The, I'm playing the monopoly violence of devil's advocates here and popping one devil off the stack at a time isn't. Ultimately, of course, it'll be connected to physical reality. But just because people control the physical reality doesn't mean the status. LeBron James, in theory, could make more money than the owners of the teams in theory. And to me, that's a virtual idea. So somebody else constructed a game, and now you're playing in the space of virtual. In the virtual space of the game. So it just feels like there could be games where status we build realities that give us meaning in the virtual space. I can imagine such things being possible.
Speaker B: Oh, yeah. Okay. So I think I see what you're saying there with the idea there. I mean, we'll take the LeBron James side and put in some YouTube influencer.
Speaker A: Yes, sure.
Speaker B: So the YouTube influencer, it is status games, but at a certain level, it precipitates into real dollars and into, like, well, you look at MrBeast, right? He's like sending off half a million dollars worth of fireworks or something. Right. On a YouTube video.
Speaker A: And also, like, saving. Saving trees and so on. Sure.
Speaker B: Right. Trying to plant a million trees with Mark Rober or whatever it was. Yeah. Not that those kinds of games can't lead to real consequences. It's that for the vast majority of people in consumer culture, they are incented by the. I would say mostly I'm thinking about middle class consumers. They're incented by advertisements. They're incented by their memetic environment to treat the purchasing of certain things, the need to buy the latest model, whatever the need to appear, however, the need to pursue status games as a driver of meaning. And my point would be that it's a very hollow driver of meaning. And that is what creates a meaning crisis. Because at the end of the day, it's like eating a lot of empty calories. Right? Yeah, it tasted good going down a lot of sugar, but, man, it did not. It was not enough protein to help build your muscles. And you kind of feel that in your gut. And I think that's, I mean, all the stuff aside and setting aside our discussion on currency, which I hope we get back. Get back to. That's what I mean about the meaning crisis. Part of it being created by the fact that we don't, we're not encouraged to have more and more direct relationships. We're actually alienated from relating to even our family members sometimes, right. We're encouraged to relate to brands. We're encouraged to relate to these kinds of things that then tell us to do things that are really of low consequence. And that's where the meaning crisis comes from.
Speaker A: So the role of technology in this. So there's somebody you mentioned, who's Jacques Eliot, his view of technology. He warns about the towering piles of technique, which I guess is a broad idea of technology.
Speaker B: Yes.
Speaker A: So I think, correct me if I'm wrong. For him, technology is bad, moving away from human nature, and it's ultimately destructive. My question, broadly speaking, this meaning crisis, can technology, what are the pros and cons of technology? Can it be good?
Speaker B: Yeah, I think it can be. I certainly draw on some of those ideas and I think some of them are pretty good. But the way he defines technique is, well, also Simondon as well. I mean, he speaks to the general mentality of efficiency. Homogenized processes, homogenized production, homogenized labor to produce homogenized artifacts that then are not actually, they don't sit well in the environment. So it's essentially, you can think of it as the antonym of craft. Whereas a craftsman will come to a problem. It may be a piece of wood and they need to make into a chair. It may be a site to build a house or build a stable, or build whatever. And they will consider how to bring a various things in to build something, well, contextualized, that's in right relationship with that environment. But the way we have driven technology over the last 100, 150 years is not that at all. It is how can we make sure the input materials are homogenized, cut to the same size, diluted and doped exactly the right alloy concentrations? How do we create machines that then consume exactly the right kind of energy to be able to run at this high speed to stamp out the same part parts which then go out the door. Everyone gets the same tickle me Elmo. And the reason why everyone wants it is because we have broadcast that tells everyone this is the cool thing. So we homogenize demand. And where like Baudelaire and other critiques of modernity coming from that direction, the situationalists as well. Their point is that at this point in time, consumption is the thing that drives a lot of the economic stuff. Not the need, but the need to consume and build status games on top. So we have homogenized. When we discovered, I think this is really like Bernays and stuff, right? In the early 20th century, we discovered we can create, we can create demand, we can create desire in a way that was not possible before because of broadcast media. And not only do we create desire, we don't create a desire for each person to connect to some bespoke thing, to build a relationship with their neighbor or their spouse. We are telling them, you need to consume this brand. You need to drive this vehicle. You got to listen to this music. Have you seen this movie? So, creating homogenized demand makes it really cheap to create homogenized product. And now you have economics of scale. So we make the same tickle me Elmo, give it to all the kids. And all the kids are like, hey, I got a tickle me Elmo. Right? So this is ultimately where this ties in, then, to runaway hyper capitalism, is that we then capitalism is always looking for growth. It's always looking for growth. And growth only happens in the margins. So you have to squeeze more and more demand out. You got to make it cheaper and cheaper to make the same thing. But tell everyone they're still getting meaning from it. You're still like, this is still your tickle me Elmo, right? And we see little bits of this dripping critiques of this dripping in popular culture. You see it sometimes. It's when Buzz Lightyear walks into the thing, he's like, oh, my God, at the toy store. I'm just a toy. Like, there's millions of other, or there's hundreds of other buzz lightyears just like me, right? That is, I think, you know, a fun Pixar critique on this homogenization dynamic.
Speaker A: I agree with you on most of the things you're saying. So I'm playing devil's advocate here. But this homogenized machine of capitalism is also the thing that is able to fund, if channeled correctly, innovation, invention, and development of totally new things that in the best possible world, create all kinds of new experiences that can enrich lives, the quality of lives for all kinds of people. So isn't this the machine that actually enables the experiences and more and more experiences that would then give meaning?
Speaker B: It has done that to some extent. I mean, it's not all good or bad in my perspective. We can always look backwards and offer a critique of the path we've taken to get to this point in time. But that's a different. That's somewhat different and informs the discussion, but it's somewhat different than the question of where do we go in the future, right? Is this still the same rocket we need to ride to get to the next point? Will it even get us to the next point?
Speaker A: Well, how does this. So you're predicting the future. How does it go wrong, in your view?
Speaker B: We have the mechanisms, we have now explored enough technologies to where we can actually, I think, sustainably produce what most people in the world need to live. We have also created the infrastructures to allow continued research and development of additional science and medicine and various other kinds of things. The organizing principles that we use to govern all these things today, a lot of them have been just inherited from, honestly, medieval times. Some of them have refactored a little bit in the industrial era. But a lot of these modes of organizing people are deeply problematic. And furthermore, theyre rooted in, I think, a very industrial mode perspective on human labor. This is one of those things. Im going to go back to the open source thing. There was a point in time when, well, let me ask you this. If you look at the core scipy collection of libraries, that's scipy, numpy, matplotlib, there's ipython notebook. Let's throw pandas in there, scikit, learn a few of these things. How much value do you think, economic value would you say they drive in the world today?
Speaker A: That's one of the fascinating things about talking to you and Travis, is like, it's immeasurable.
Speaker B: It's like at least a billion dollars a day.
Speaker A: Maybe a billion dollars, sure. I mean, it's a similar question of like, how much value does Wikipedia create?
Speaker B: Right.
Speaker A: It's like all of it. I don't know.
Speaker B: Well, I mean, if you look at our systems, when you do a Google search right now, some of that stuff runs through Tensorflow, but when you look at Siri, when you do credit card transaction fraud, like just everything, right? Every intelligence agency under the sun, they're using some aspect of these kinds of tools. So I would say that, um, these create billions of dollars of value.
Speaker A: Oh, you mean like direct use of tools that leverage.
Speaker B: Yes, direct, yeah, yeah.
Speaker A: Even that's billions a day.
Speaker B: Yeah, yeah, right. Easily. I think like the things they could not do if they didn't have these tools, right?
Speaker A: Yes.
Speaker B: So that's billions of dollars a day. Great. I think that's about right. Now, if we take, how many people did it take to make that right? And there was a point in time, not anymore, but there was a point in time when they could fit in a van. I could have fit them in my Mercedes sprinter. Right? And so if you look at that like, holy crap, literally a van of maybe a dozen people could create value to the tune of billions of dollars a day.
Speaker A: What lesson do you draw from that?
Speaker B: Well, here's the thing. What can we do to do more of that? Like, that's open source. The way I've talked about this in other environments is when we use generative participatory, crowdsourced approaches. We unlock human potential at a level that is better than what capitalism can do. I would challenge anyone to go and try to hire the right twelve people in the world to build that entire stack. The way those twelve people did that, they would be very, very hard pressed to do that. If a hedge fund could just hire a dozen people and create something that is worth billions of dollars a day, every single one of them would be racing to do it. But finding the right people, fostering the right collaborations, getting it adopted by the right other people to then refine it, that is a thing that was organic in nature, that took crowdsourcing, that took a lot of the open source ethos, and it took the right kinds of people. None of those people who started that said, I need to have a part of a multibillion dollar a day enterprise. They're like, I'm doing this cool thing to solve my problem. For my friends, the point of telling the story is to say that our way of thinking about value, our way of thinking about allocation of resources, our ways of thinking about property rights and all these kinds of things, they come from finite game, scarcity mentality, medieval institutions. As we are now entering to some extent, we are sort of in a post scarcity era. Although some people are hoarding a whole lot of stuff, we are at a point where, if not now, soon, we'll be in a post scarcity era. The question of how we allocate resources has to be revisited at a fundamental level. Because the kind of software these people built, the modalities that those human ecologies that built that software, it treats software as unproperty. Actually sharing creates value. Restricting and forking reduces value. So that's different than any other physical resource that we've ever dealt with. It's different than how most corporations treat software ip, right? So if treating software in this way created this much value so efficiently, so cheaply, because feeding a dozen people for ten years is really cheap, right? That's the, that's the reason I care about this right now, is because looking forward, when we can automate a lot of labor where we can. In fact, the, the programming for your robot in your part, neck of the woods, and you're part of the Amazon to build something sustainable for you and your tribe, to deliver the right medicines, to take care of the kids, that's just software, that's just code that could be totally open sourced. We can actually get to a mode where all of this additional generative things that humans are doing, they don't have to be wrapped up in a container. And then we charge for all the exponential dynamics out of it. That's what Facebook did. That's what modern social media did, because the old Internet was connecting people just fine. Facebook came along and said, well, anyone can post a picture. Anyone can post some text, and we're going to amplify the crap out of it to everyone else. And it exploded this generative network of human interaction. And then I said, how do I make money off that? Oh, yeah, I'm going to be a gatekeeper on everybody's attention. And that's how I make money.
Speaker A: So how do we create more than one van? How do we have millions of vans full of people that create numpy scipi, that create python? So the story of those people is often they have some kind of job outside of this. This is what they're doing for fun. Don't you need to have a job? Don't you have to be connected, plugged in to the capitalist system? Isn't that what, like, isn't this consumerism, the engine that results in the individuals that kind of take a break from it every once in a while to create something magical, like at the edges.
Speaker B: Is the question of surplus, right? This is the. This is the question. Like, if everyone were to go and run their own farm, no one would have time to go and write numpy sci PI, right? Maybe, but that's what I'm talking about when I say we're maybe at a post scarcity point. For a lot of people, the question that we're never encouraged to ask in a super bowl ad is, how much do you need? How much is enough? Do you need to have a new car every two years? Every five? If you have a reliable car, can you drive one for ten years? Is that all right? I had a car for ten years. It was fine. Your iPhone, did you have to upgrade every two years? I mean, sort of. You're using the same apps you did four years ago, right?
Speaker A: This should be a Super bowl ad.
Speaker B: This should be a Super bowl ad. That's great.
Speaker A: Maybe you really need a new iPhone.
Speaker B: Maybe one of our listeners will fund something like this of like. No, but just actually bringing it back. Bringing it back to actually the question of what do you need? How do we create the infrastructure for collectives of people to live on the basis of providing what we need, meeting people's needs with a little bit of excess to handle emergencies, things like that. Pulling our resources together to handle the really, really big emergencies. Somebody with a really rare form of cancer or some massive fire sweeps through half the village or whatever, but can we actually unscale things and solve for people's needs and then give them the capacity to explore how to be the best version of themselves? And for Travis, that was throwing away his shot of tenure in order to write numpy for others. There is a saying in the Sci-Fi community that Sci-Fi advances one failed postdoc at a time. We can do these things. We can actually do this collaboration because code, software, information, organization, that's cheap. Those bits are very cheap to fling across the oceans.
Speaker A: So you mentioned Travis. We've been talking, and we'll continue to talk about open source. Maybe you can comment. How did you meet Travis? Who is Travis Aliphont? What's your relationship been like through the years? Where did you work together? How did you meet? What's the present and the future look like?
Speaker B: Yeah, so the first time I met Travis was at a scipie conference in Pasadena.
Speaker A: Do you remember the year 2005?
Speaker B: I was working at again at nthought, working on scientific computing consulting. And a couple of years later, he joined us at nthot, I think, 2007, and he came in as president. One of the founders of n thought was the CEO, Eric Jones. And we were all very excited that Travis was joining us, and that was great fun. And so I worked with Travis on a number of consulting projects and we worked on some open source stuff. I mean, it was just a really. It was a good time there and.
Speaker A: Then it was primarily Python related?
Speaker B: Oh, yeah, it was all python numpy Sci-Fi consulting kind of stuff. Towards the end of that time, we started getting called into more and more finance shops. They were adopting Python pretty heavily. I did some work at a high frequency trading shop, working on some stuff, and then we worked together at a couple of investment banks in Manhattan. We started seeing that there was a potential to take Python in the direction of business computing more than just being this niche like Matlab replacement for big vector computing. What we were seeing was, oh, yeah, you could actually use Python as a swiss army knife to do a lot of shadow data transformation kind of stuff. So that's when we realized the potential is much greater. And so we started anaconda. I mean, it was called continuum analytics at the time, but we started in January of 2012 with a vision of shoring up the parts of Python that needed to get expanded to handle data at scale, to do web visualization, application development, et cetera. And that was that. Yeah. So he was CEO and I was president for the first five years, and then we raised some money, and then the board put in a new CEO. They hired a kind of professional CEO. And then Travis, you laugh at that. I took over the CTo role. Travis then left after a year to do his own thing, to do quant site, which was more oriented around some of the bootstrap years that we did at continuum, where it was open source and consulting. It wasn't gung ho product development, and it wasn't focused on. We accidentally stumbled into the package management problem at Anaconda, but we had a lot of other visions of other technology that we built in the open source. And Travis was really trying to push again the frontiers of numerical computing, vector computing, handling things like auto differentiation and stuff intrinsically in the open ecosystem. So I think that's kind of the direction he's working on and some of his work. We remain great friends and colleagues and collaborators, even though he's no longer day to day working at Anaconda. But he gives me a lot of feedback about this and that and the other.
Speaker A: What's a big lesson you've learned from Travis? About life or about programming? About leadership?
Speaker B: Wow. There's a lot. There's a lot. Travis is a really, really good guy. His heart is really in it. He cares a lot of.
Speaker A: I've gotten that sense having to interact with them. It's so interesting. Such a good human.
Speaker B: He's a really good dude. And he and I, it's so interesting. We come from very different backgrounds. We're quite different as people, but I think we can not talk for a long time and then be on a conversation and be eye to eye on 90% of things. And so he's someone who, I believe no matter how much fog settles in over the ocean, his ship, my ship, are pointed sort of in the same direction to the same star.
Speaker A: Wow, that's a beautiful way to phrase it. No matter how much fog there is, we're pointing at the same star.
Speaker B: Yeah. And I hope he feels the same way. I mean, I hope he knows that over the years now, we both care a lot about the community. For someone who cares so deeply, I would say this about Travis, that's interesting. For someone who cares so deeply about the nerd details of type, system design and vector computing and efficiency of expressing this and that and the other memory layouts and all that stuff, he cares even more about the people in the ecosystem, the community. And I have a similar kind of alignment. I care a lot about the tech, I really do. But for me, the beauty of what this human ecology has produced is, I think, a touchstone. It's an early version. We should look at it and say, how do we replicate this for humanity at scale, what this open source collaboration was able to produce? How can we be generative in human collaboration moving forward and create that as a civilizational kind of dynamic? Can we seize this moment to do that? Because a lot of the other open source movements, it's all nerds, nerding out on code for nerds, and this because it's scientists, because it's people working on data, that all of it faces real human problems. I think we have an opportunity to actually make a bigger impact.
Speaker A: Is there a way for this kind of open source vision to make money?
Speaker B: Absolutely.
Speaker A: To fund the people involved is that it's hard.
Speaker B: But we're trying to do that in our own way at anaconda, because we know that business users, as they use more of the stuff they have, needs, business specific needs around security, provenance. They really can't tell their vps and their investors, hey, our data scientists are installing random packages from who knows where and running on customer data. So they have to have someone to talk to, and that's what Anaconda does. So we are a governed source of packages for them. And that's great, that makes some money. We take some of that and we just take that as a dividend. We take a percentage of our revenues and write that as a dividend for the open source community. But beyond that, I really see the development of a marketplace for people to create notebooks, models, data sets, curation of these different kinds of things, and to really have a long tail marketplace dynamic with that.
Speaker A: Can you speak about this problem that you stumbled into of package management, Python package management, what is that? A lot of people speak very highly of condo, which is part of Anaconda, which is a package manager. There's a ton of packages. So first, what are package managers? And second, what was there before? What is Pip? And why is Conda more awesome?
Speaker B: The package problem is this, which is that in order to do numerical computing efficiently with Python, there are a lot of low level libraries that need to be compiled, compiled with a C compiler, or a C compiler or Fortran compiler. They need to not just be compiled, but they need to be compiled with all of the right settings. Oftentimes those settings are tuned for specific chip architectures. When you add GPU's to the mix, when you look at different operating systems, you may be on the same chip, but if you're running Mac versus Linux versus windows on the same x 86 chip, you compile link differently. All of this complexity is beyond the capability of most data scientists to reason about. And it's also beyond what most of the package developers want to deal with too. Because if you're a package developer, you're like, I code on Linux. This works for me, I'm good. It is not my problem to figure out how to build this on an ancient version of Windows. That's just simply not my problem. What we end up with is we have a creator economy or create a very creative crowdsourced environment where people want to use this stuff, but they can't. We ended up creating a new set of technologies like a build recipe system, a build system, and an installer system that is able to, well, to put it simply, it's able to build these packages correctly on each of these different kinds of platforms and operating systems and make it so when people want to install something, they can. It's just one command. They don't have to set up a big compiler system and do all these things. So when it works well, it works great. Now the difficulty is we have literally thousands of people writing code in the ecosystem, building all sorts of stuff, and each person writing code, they may take a dependency on something else. You have all this web, incredibly complex web of dependencies. So installing the correct package for any given set of packages you want, getting that right subgraph is an incredibly hard problem. Again, most data scientists don't want to think about this. They're like, I want to install numpy and pandas. I want this version of some geospatial library. I want this other thing. Like, why is this hard? These exist, right? And it is hard because it's, well, you're installing this on a version of Windows, and half of these libraries are not built for Windows, or the latest version isn't available. But the old version was. If you go to the old version of this library, that means you need to go to a different version of that library. And so the Python ecosystem, by virtue of being crowdsourced, we were able to fill 100,000 different niches. But then we also suffer this problem that because it's crowdsourced and no one, it's like a tragedy of the commons, right? No one really wants to support their thousands of other dependencies. So we end up sort of having to do a lot of this. And of course the Conda forged community also steps up as an open source community that maintains some of these recipes. That's what Conda does. Now Pip is a tool that came along after Conda to some extent. It came along as an easier way for the, for the Python developers writing Python code that didn't have as much compiled stuff, they could then install different packages. What ended up happening in the Python ecosystem was that a lot of the core Python and web Python developers, they never ran into any of this compilation stuff at all. On video we have Guido van Rossum saying the scientific community's packaging problems are just too exotic and different. I mean you're talking about Fortran compilers, right? Like you guys just need to build your own solution perhaps. Right? So the Python, core Python community went and built its own sort of packaging technologies, not really contemplating the complexity of this stuff over here. And so now we have the challenge where you can pip install some things in some libraries, if you just want to get started with them, you can pip install tensorflow. And that works great. The instant you want to also install some other packages that use different versions of numpy or some graphics library or some OpenCV thing, or some other thing, you now run into dependency hell because open cv cant have a different version of Lib JPEG over here than Pytorch over here. They all have to use that. If you want to use GPU acceleration, they have to all use the same underlying drivers and same GPU CudA things. So it gets to be very gnarly. And its a level of technology that both the makers and the users dont really want to think too much about.
Speaker A: And that's where you step in and try to solve the. We try to solve it, how much is that? And you said that you don't want to think, they don't want to think about it, but how much is it? A little bit on the developer and providing them tools to be a little bit more clear of that subgraph of dependency that's necessary.
Speaker B: It is getting to a point where we do have to think about, look, can we pull some of the most popular packages together and get them to work on a coordinated release timeline, get them to build against the same test matrix, et cetera, et cetera. Right. And there is a little bit of dynamic around this, but again, it is a volunteer community. People working on these different projects have their own timelines and their own things they're trying to meet. So we end up trying to pull these things together and then it's this incredibly, and I would recommend just as a business tip, don't ever go into business where when your hard work works, you're invisible. And when it breaks because of someone else's problem, you get flack for it. Because in our situation, when something doesn't condo install properly, usually it's some upstream issue, but it looks like condos broken. It looks like anaconda screws something up. When things do work, though, it's like, oh yeah, cool, I just worked assuming, naturally, of course, that's very easy to make that work. So we end up in this problematic scenario. But it's okay, because I think we're still our hearts in the right place. We're trying to move this forward as a community sort of affair. I think most of the people in the community also appreciate the work we've done over the years to try to move these things forward in a collaborative fashion.
Speaker A: One of the sub graphs of dependencies that became super complicated is the move from Python two to Python three. There's all these ways to mess with these kinds of ecosystems, of packages and so on. So I just want to ask you about that particular one. What do you think about the move from Python two to three? Why did it take so long? What were, from your perspective, just seeing the packages all struggle and the community all struggle through this process, what lessons do you take away from it? Why did it take so long?
Speaker B: Looking back, some people perhaps underestimated how much adoption Python two had. I think some people also underestimated how much, or they overestimated how much value some of the new features in Python three really provided. And the things they really loved about Python three just didn't matter to some of these people on Python two, because this change was happening as Python Scipy was starting to take off, really past a hockey stick of adoption in the early data science era, in the early two thousand ten s, a lot of people were learning and onboarding in whatever just worked. And the teachers were like, well, yeah, these libraries I need are not supported on Python three yet. I'm going to teach you Python two took a lot of advocacy to get people to move over to Python three. So I think it wasn't any particular single thing, but it was one of those death by a dozen cuts which just really made it hard to move off of Python two, and also Python three itself, as they were breaking things and changing these around and reorganizing the standard library. There's a lot of stuff that was happening there that it kept giving people an excuse to say, I'll put off till the next version two is working fine enough for me right now. So I think that's essentially what happened there. And I will say this, though, the strength of the Python data science movement, I think, is what kept Python alive in that transition, because a lot of languages have died and left their user bases behind. If there wasn't the use of python for data, there's a good chunk of python users that during that transition would have just left for go and rust and stayed. In fact, some people did. They moved to go and rust and they just never looked back. The fact that we were able to grow by millions of users, the Python data community, that is what kept the momentum for Python going. And now the usage of Python for data is over 50% of the overall Python user base. So I'm happy to debate that on stage somewhere icon with someone, if they really want to take issue with that statement. But from where I sit, I think that's true.
Speaker A: The statement there, the idea is that the switch from Python two to Python three would have probably destroyed Python if it didn't also coincide with Python for whatever reason, just overtaking the data science community, anything that processes data. So, like, the timing was perfect, that this maybe imperfect decision was coupled with great timing on the value of data in our world.
Speaker B: I would say the troubled execution of a good decision, it was a decision that was necessary. It's possible if we had more resources, we could have done in a way that was a little bit smoother. But ultimately, the arguments for Python three, I bought them at the time and I buy them now. Having great text handling is a non negotiable table stakes thing you need to have in a language. So that's great. But the execution, Python is the. It's volunteer driven. It's like now the most popular language on the planet, but it's all literally volunteers. So the lack of resources meant that they had to really, they had to do things in a very hamstrung way. And I think to carry the Python momentum and the language through that time, the data movement was a critical part of that.
Speaker A: So some of it is carrot and stick. I actually have to shamefully admit that it took me a very long time to switch from Python two and Python three, because I'm a machine learning person. Just for the longest time, you could just do fine with Python two.
Speaker B: Right?
Speaker A: But I think the moment where I switched everybody I worked with and switched myself for small projects and big is when finally, when Numpy announced that they're going to end support, like in 2020 or something like that. So when I realized, oh, this isn't going, this is going to end. So that's the stake.
Speaker B: That's not a carrot.
Speaker A: That's not. So for the longest time was carrots. It was like all of these packages were saying, okay, we have Python three support now come join us. We have Python two and Python three. But when numpy, one of the packages I sort of love and depend on said like, nope, it's over. That's when I decided to switch. I wonder if you think it was possible much earlier for somebody like, like numpy or some major package to step into the cold.
Speaker B: Well, it's chicken and egg problem too, right? You don't want to cut off a lot of users unless you see the user momentum going too. So the decisions for the scientific community, for each of the different projects, there's not a monolith. Some projects are like, we'll only be releasing new features on Python three. And that was more of a sticky carrot, a firm carrot, if you will. A firm carrot, a stick shaped carrot. But then for others, numpy in particular, because it's at the base of the dependency stack for so many things. That was the final stick. That was a stick shaped stick. People were saying, look, if I have to keep maintaining my releases for Python two, that's that much less energy that I can put into making things better for the python three folks, or in my new version, which is of course going to be Python three. So people were also getting kind of pulled by this tension. So the overall community sort of had a lot of input into when the numpy core folks decided that they would end of life on Python two.
Speaker A: So as these numbers are a little bit loose, but there are about 10 million Python programmers in the world, you could argue that number, but let's say 10 million. There's actually where I was looking, said 27 million total programmers developers in the world. You mentioned in a talk that changes need to be made for there to be 100 million Python programmers. First of all, do you see a future where there's 100 million Python programmers? And second, what kind of changes need.
Speaker B: To be made so Anaconda miniconda get downloaded about a million times a week? I think the idea that there's only 10 million Python programmers in the world is a little bit undercounting. There are a lot of people who escape traditional counting that are using Python and data in their jobs. I do believe that the future world for it to, well, the world I would like to see is one where people are data literate, so they are able to use tools that let them express their questions and ideas fluidly. And the data variety and data complexity will not go down, it will only keep increasing. So I think some level of code or code like things will continue to be relevant. And so my hope is that we can build systems that allow people to more seamlessly integrate python kinds of expressitivity with data systems and operationalization methods that are much more seamless. And what I mean by that is right now you can't punch Python code into an Excel cell. I mean, there's some tools you can do to do this. We didn't built a thing for doing this back in the day, but I feel like the total addressable market for Python users, if we do the things right, is on the order of the Excel users, which is a few hundred million. I think Python has to get better at being embedded, being a smaller thing that pulls in just the right parts of the ecosystem to run numerics and do data exploration, meeting people where they're already at with their data and their data tools. And then I think also it has to be easier to take some of those things they've written and flow those back into deployed systems or apps or visualizations. I think if we don't do those things, then we will always be kept in a silo as an expert user's tool and not a tool for the masses.
Speaker A: I work with a bunch of folks in the Adobe creative suite, and I'm kind of forcing them or inspired them to learn Python to do a bunch of stuff that helps them. And it's interesting because they probably wouldn't call themselves Python programmers, but they're all using Python. I would love it if the tools like Photoshop and Premiere and all those kinds of tools that are targeted towards creative people. I guess that's where Excel, Excel is targeted towards a certain kind of audience that works with data, financial people, all that kind of stuff. If there would be easy ways to leverage to use Python for quick scripting tasks. Yeah, and there's an exciting application of artificial intelligence in this space that I'm hopeful about looking at OpenAI codecs with generating programs. So almost helping people bridge the gap from kind of visual interface to generating programs to something formal, and then they can modify it and so on, but without having to read the manual, without having to do a Google search and stack overflow, which is essentially what a neural network does when it's doing code generation, is actually generating code and allowing a human to communicate with multiple programs, and then maybe even programs to communicate with each other via Python. That to me is a really exciting possibility, because I think there's a friction to kind of like, how do I learn how to use Python in my life? There's oftentimes you kind of, what? Start a class? You start learning about types? Yes. I don't know, functions like this is, you know, Python is the first language with which you start to learn to program. But I feel like that's going to take a long time for you to understand why it's useful. You almost want to start with a script.
Speaker B: Well, you do. In fact, I think starting with the theory behind programming languages and types and all that, I mean, types are there to make the compiler writer's jobs easier. Types are not. I mean, heck, do you have an ontology of types or just the objects in this table? No. So types are there because compiler writers are human and they're limited in what they can do. But I think that the beauty of scripting, there's a Python book that's called Automate the boring stuff, which is exactly the right mentality. I grew up with computers in a time when I could, when Steve Job was still pitching these things as bicycles for the mind, they were supposed to not be just media consumption devices, but they were actually, you could write some code, you could write basic, you could write some stuff to do some things. And that feeling of a computer as a thing that we can use to extend ourselves has all but evaporated for a lot of people. So you see a little bit in parts in the generation of youth around Minecraft or roadblocks. And I think Python circuit Python, these things could be a renaissance of that, of people actually shaping and using their computers as computers, as an extension of their minds and their curiosity, their creativity. So you talk about scripting the adobe suite with Python in the 3d graphics world. Python is a scripting language that some of these 3d graphics suites use. And I think that's great. We should better support those kinds of things. But ultimately, the idea that I should be able to have power over my computing environment, if I want these things to happen repeatedly all the time, I should be able to say that somehow to the computer. Now, whether the operating systems get there faster by having some Siri backed with OpenAI, with whatever. So you can just say, Siri, make this, do this and this every other Friday, right? We probably will get there somewhere. And Apple's always had these ideas. There's the Apple script in the menu that no one ever uses, but you can do these kinds of things. But when you start doing that kind of scripting, the challenge isn't learning the type system or even the syntax of the language. The challenge is all of the dictionaries and all the objects of all their properties and attributes and parameters, who's got time to learn all that stuff? That's when then programming by prototype or by example becomes the right way to get the user to express their desire. So there's a lot of these different ways that we can approach programming. But I do think, as you were talking about the Adobe scripting thing, I was thinking about when we do use something like numpy, when we use things in the Python data and scientific expression system, there's a reason we use that, which is that it gives us mathematical precision. It gives us actually quite a lot of precision over precisely what we mean about this data set, that data set. And it's the fact that we can have that precision that lets python be powerful. Over as a duct tape for data, you give me a TSV or a CSV, and if you give me some massively expensive vendor tool for data transformation, I don't know I'm going to be able to solve your problem. But if you give me a Python prompt, you can throw whatever data you want at me. I will be able to mash it into shape. So that ability to take it as this machete out into the data jungle is really powerful. I think that's why at some level, we're not going to get away from some of these expressions and APIs and libraries in Python for data transformation.
Speaker A: You've been at the center of the python community for many years. If you could change one thing about the community to help it grow, to help it improve, to help it flourish and prosper, what would it be? I mean, it doesn't have to be one thing, but what kind of comes to mind? What are the challenges?
Speaker B: Humility is one of the values that we have at Anaconda, at the company, but it's also one of the values in the community that it's been breached a little bit in the last few years. But in general, people are quite decent and reasonable and nice, and that humility prevents them from seeing the greatness that they could have. I don't know how many people in the core Python community really understand that they stand and perched at the edge of an opportunity to transform how people use computers. And actually Pycon, I think his last physical Pycon I went to Russell, Keith McGee gave a great keynote about very much along the lines of the challenges I have, which is Python for a language that doesn't actually put an interface up on the most popular computing devices, it's done really well as a language, hasn't it? You can't write a web front end with Python, really. I mean, everyone uses JavaScript. You certainly can't write native apps. So for a language that you can't actually write apps in any runtime environments, Python's done exceedingly well. That wasn't to pat ourselves in the back, that was to challenge ourselves as a community. To say, we, through our current volunteer dynamic, have gotten to this point. What comes next and how do we seize, you know, we've caught the tiger by the tail, how do we make sure we keep up with it as it goes forward?
Speaker A: So that's one of the questions I have about sort of open source communities is at its best. There's a kind of humility, is that humility prevent you to have a vision for creating something like very new and.
Speaker B: Powerful, and you've brought us back to consciousness again. The collaboration is a swarm, emergent dynamic. Humility lets these people work together without anyone trouncing anyone else, else. How do they, you know, in consciousness, there's the question of the binding problem. How does a singular, our attention, how does that emerge from, you know, billions of neurons?
Speaker A: Yes.
Speaker B: So how can you have a swarm of people emerge a consensus that has a singular vision, to say, we will do this, and most importantly, we're not going to do these things. Emerging a coherent, pointed, focused leadership dynamic from a collaboration, being able to do that kind of, and then dissolve it so people can still do the swarm thing, that's a problem. There's a question.
Speaker A: So you have to have a charismatic leader for some reason. Linus Torvald comes to mind, but he, you know, there's people who criticize.
Speaker B: He rules the iron fist, man.
Speaker A: But there's still charisma.
Speaker B: There's charisma, right?
Speaker A: There's a charisma to that iron fist. There's. Every leader is different, I would say, in their success. So he doesn't. I don't even know if you can say he doesn't have humility. There's such a meritocracy of ideas that this is a good idea and this is a bad idea.
Speaker B: There's a step function to it. Once you clear a threshold, he's open. Once you clear the bozo threshold, he's open to your ideas.
Speaker A: I think the interesting thing is, obviously that will not stand in an open source community if that threshold that is defined by that one particular person is not actually that good. So you actually have to be really excellent at what you do. So he's very good at what he does. And so there's some aspect of leadership where you can get thrown out. People can just leave. You know, that's how it works with open source, the fork. But at the same time, you want to sometimes be a leader with a strong opinion, because people. I mean, there's some kind of balance here for this hive mind to get behind.
Speaker B: Leadership is a big topic, and I didn't. I'm not one of these guys that went to MBA school and said, I'm going to be an entrepreneur and I'm going to be a leader, and I'm going to read all these Harvard Business review articles on leadership and all this other stuff. I was a physicist, turned into a software nerd who then really nerded out on Python. Now I am entrepreneurial. I saw business opportunity around the use of Python for data, but for me, what has been interesting over this journey with the last ten years is how much I started really enjoying the understanding, thinking deeper about organizational dynamics and leadership. And leadership does come down to a few core things. Number one, a leader has to create belief, or at least has to dispel disbelief. Leadership, also, you have to have vision, loyalty and experience.
Speaker A: So can you say belief in a singular vision? What does belief mean?
Speaker B: Yeah, belief means a few things. Belief means, here's what we need to do, and this is a valid thing to do, and we can do it. You have to be able to drive that belief, and every step of leadership along the way has to help you amplify that belief to more people. I mean, I think at a fundamental level, that's what it is. You have to have a vision. You have to be able to show people that, or you have to convince people to believe in the vision and to get behind you. And that's where the loyalty part comes in and the experience part comes in.
Speaker A: There's all different flavors of leadership. So if we talk about Linus, we could talk about Elon Musk and Steve Jobs. There's Sandra Prachai, there's people that kind of put themselves at the center and are strongly opinionated, and some people are more like consensus builders. What works well for open source? What works well in the space of programmers? So you've been a programmer, you've led many programmers, and are now sort of at the center of this ecosystem. What works well in the programming world, would you say?
Speaker B: It really depends on the people, what style leadership is best, and depends on the programming community. I think for the Python community, servant leadership is one of the values. At the end of the day, the leader has to also be the high priest of values. So any collection of people has values of their living. And if you want to maintain certain values and those values help you as an organization become more powerful, then the leader has to live those values unequivocally and has to. Has to hold the values. So in our case, in this collaborative community around Python, I think that the humility is one of those values. Servant leadership, you actually have to kind of do the stuff. You have to walk the walk, not just talk the talk. I don't feel like the Python community really demands that much from a vision standpoint, and they should, and I think they should.
Speaker A: This is the interesting thing, is, like, so many people use Python, from where comes the vision? You have a Elon Musk type character who has makes bold statements about the vision for particular companies he's involved with. And it's like, I think a lot of people that work at those companies kind of can only last if they believe that vision, because, and some of it is super bold. So my question is, and by the way, those companies often use Python, how do you establish a vision like, get to 100 million users, get to where Python is at the center of the machine learning, and was it data science, machine learning, deep learning, artificial intelligence revolution? In many ways, perhaps the Python community is not thinking of it that way, but it's leading the way on this. The tooling is essential, right?
Speaker B: Well, for a while, Pycon people in the scientific Python and the PI data community, they would submit talks. Those are early 2010s, mid 2010s, they would submit talks to Pycon, and the talks would all be rejected because there was the separate sort of PI data conferences and like, well, these probably belong more to PI data. And instead there'd be yet another talk about threads and whatever, some web framework. And it's like, that was an interesting dynamic to see that there was. I mean, at the time, it was a little annoying because we wanted to try to get more users and get more people talking about these things. And Pycon is a huge venue. It's thousands of Python programmers, but then also came to appreciate that parallel, having an ecosystem that allows parallel innovation is not bad. There are people doing embedded python stuff. There's people doing web programming, people doing scripting. There's cyber uses of Python. I think ultimately, at some point, if your slide mold covers so much stuff, you have to respect that different things are growing in different areas and different niches. Now, at some point, that has to come together and the central body has to provide resources. The principle here is subsidiarity. Give resources to the various groups to then allocate as they see fit in their niches. That would be a really helpful dynamic. But again, it's a volunteer community. It's not like they had that many resources to start with.
Speaker A: What was or is your favorite programming setup? What operating system, what keyboard, how many screens you're listening to? What time of day are you drinking? Coffee? Tea?
Speaker B: Tea. Sometimes coffee, depending how well I slept. I used to have how sleep do you get?
Speaker A: A unite owl? I remember somebody asked you somewhere a question about work life balance and like, not just work life balance, but like a family, you know, you lead a company and your answer was, was basically like, I still haven't figured it out.
Speaker B: Yeah, I think I've gotten a little bit better balanced. I have a really great leadership team now supporting me and so that takes a lot of the day to day stuff off my plate and my kids are getting a little older, so that helps. So. And of course I have a wonderful wife who takes care of a lot of the things that I'm not able to take care of and she's great. I try to get to sleep earlier now, um, because I have to get up every morning at six to take my kid down to the bus stop.
Speaker A: Oh wow.
Speaker B: So there's a hard, there's a hard thing.
Speaker A: Yeah.
Speaker B: For a while I was doing polyphasic sleep, which is really interesting. Like I go to bed at nine, wake up at like 02:00 a.m. work till five, sleep 3 hours, wake up at eight. Like that was actually, it was interesting, it wasn't too bad.
Speaker A: How did it feel?
Speaker B: It was good. I didn't keep it up for years, but once I have travel then it's just everything goes out the window. Right. Because then you're like time zones and all these things.
Speaker A: Socially, was it accepted, like were you able to live outside of how you felt, were you able to live normal society?
Speaker B: Oh yeah, because like on the nights that wasn't out hanging out with people or whatever, going to bed at nine, no one cares. I wake up at two, I'm still responding to their slacks, emails, whatever. And you know, shitposting on Twitter or whatever at two in the morning is exactly right. And then you go to bed for a few hours and you wake up, it's like you had an extra day in the middle.
Speaker A: Yes.
Speaker B: And I'd read somewhere that, you know, humans naturally have biphasic sleep or something. I don't know.
Speaker A: But um, I, I read basically everything somewhere. So every option of everything is every option of everything.
Speaker B: I will say that that worked out for me for a while, although I don't do it anymore. Um, in terms of programming setup, I had a 27 inch, um, high, high DPI, um, setup that I really liked. Um, but then I moved to a curved monitor just because when I moved to the new house I want to have a bit more screen for zoom plus communications plus you know, like various kinds of things.
Speaker A: Like one large monitor, one large curve monitor. What operating system?
Speaker B: Mac.
Speaker A: Okay.
Speaker B: Yeah.
Speaker A: Is that what happens when you become important as you stop using Linux and windows?
Speaker B: No, I actually have a windows box as well on the next table over. But I have, I have three desks, right?
Speaker A: Yes.
Speaker B: So a main one is the standing desk so that I can, you know, whatever. When I'm like, I have a teleprompter set up and everything else. And then I've got my imac and then Egpu and then windows PC. The reason I moved to Mac was it's got a Linux prompt or, sorry, it's got a Unix prompt so I can do all my stuff. But then I don't have to worry when I'm presenting for clients or investors or whatever. I don't have to worry about any ACPI related FSIC things in the middle of a presentation. None of that. It will always wake from sleep and it won't kernel panic on me. And this is not a dig against Linux, except that I feel really bad. I feel like a traitor to my community saying this, but in 2012 I was just like, okay, start my own company, what do I get? And Linux laptops were just not quite there. I've just stuck with Macs.
Speaker A: Can I just defend something that nobody respectable seems to do, which is I do a boot on Linux, Windows. But in windows I have windows subsystems for Linux or whatever, WSL, WSL. And I find myself being able to handle everything I need, almost everything I need in Linux for basic tasks, scripting tasks within WSL. And it creates a really nice environment. But whenever I hang out with especially important people, theyre all on iPhone and a Mac and its like, yeah, there is a messiness to windows and a messiness to Linux that makes me feel like you're still in it.
Speaker B: Well, the Linux stuff, Windows subsystem for Linux is very tempting, but there's still the windows on the outside where I don't know where I've used DOS since version 1.11 or 1.21 or something. I've been a longtime Microsoft user, and I will say that it's really hard for me to know where anything is, how to get to the details behind something when something screws up, as it invariably does, and just things like changing group permissions on some shared folders and stuff. Just everything seems a little bit more awkward, more clicks than it needs to be. Not to say there aren't weird things like hidden attributes and all this other happy stuff on Mac, but for the most part, well, actually, especially now with the new hardware coming out on Mac, it'll be very interesting, you know, with the new m one. Um, there were some dark years in the last few years when I was like, I think maybe I have to move off of Mac as a platform dark. But this, I mean, like, my keyboard was just not working. Like, literally, my keyboard just wasn't working right. I had this touch bar, didn't have a physical escape button like I needed to because I used vim. And now I think we're back, so.
Speaker A: So you use vim and you have a what kind of keyboard?
Speaker B: So I use a real force 87 u. It's a mechanical, as a topra key.
Speaker A: Switch, because we are shaped, there's a normal shape shift. I say that because I use a kinesis. And I had, you said some dark. You said you had dark moments. I recently had a dark moment, like, what am I doing with my life? So I remember sort of flying in a very kind of tight space. And as I'm working, this is what I do on an airplane, I pull out a laptop, and on top of the laptop I'll put a kinesis keyboard.
Speaker B: That's hardcore, man.
Speaker A: I was thinking, is this who I am? Is this what I'm becoming? Will I be this person? Cause I'm on emacs with this kinesis keyboard sitting like, with everybody around.
Speaker B: Emacs on Windows?
Speaker A: On WSL?
Speaker B: Yeah, yeah. Emacs on Linux? On Windows?
Speaker A: Yeah, on windows. And like, everybody around me is using their iPhone to look at TikTok. So I'm like, in this land. And I thought, you know what? Maybe I need to become an adult and put the nineties behind me and use like a normal keyboard. And then I did some soul searching and I decided, like, this is who I am. This is me, like, coming out of the closet to saying, I'm kinesis keyboard all the way. I'm going to use emacs, you know.
Speaker B: You know who else is a kinesis fan? Wes McKinney, the creator. Pandas. Oh, he just, he banged out pandas on a kinesis keyboard, I believe. I don't know if he's still using one. Maybe, but certainly ten years ago, like he was.
Speaker A: If anyone's out there, maybe we need to have a kinesis support group. Please reach out.
Speaker B: Isn't there already one?
Speaker A: Is there one?
Speaker B: I don't know. There's got to be an IRC channel. Mandy.
Speaker A: Oh, no. And you access it through emacs. Okay. Do you still program these days?
Speaker B: I do a little bit. Honestly, the last thing I did was I had written. I was working with my son to script some Minecraft stuff, so I was doing a little bit of that. That was literally the last code I wrote. Oh, you know what? Also, I wrote some code to do some cap table evaluation, waterfall modeling kind of stuff.
Speaker A: What advice would you give to a young person? You said your son today in high school, maybe even college, about career, about life.
Speaker B: This may be where I get into trouble a little bit. We are coming to the end. We are rapidly entering a time between worlds. We have a world now that's starting to really crumble under the weight of aging institutions that no longer even pretend to serve the purposes they were created for. We are creating technologies that are hurtling billions of people headlong into philosophical crises who they don't even know, the philosophical operating systems in their firmware. And they're heading into a time when that gets vaporized. So, for people in high school, and certainly I tell my son this as well, he's in middle school, people in college, you are going to have to find your own way. You're going to have to have a pioneer spirit. Even if you live in the middle of the most dense urban environment. All of human reality around you is the result of the last few generations of humans agreeing to play certain kinds of games. A lot of those games no longer operate according to the rules they used to. Collapse is nonlinear, but it will be managed. So if you are in a particular social caste or economic caste, and it's not. I think it's not kosher to say that about America, but America is a very stratified and classist society. There's some mobility, but it's really quite classist. And in America, unless you're in the upper middle class, you are headed into very choppy waters. So it is really, really good to think and understand the fundamentals of what you need to build a meaningful life for you, your loved ones, with your family. And almost all of the technology being created that's consumer facing is designed to own people, to take the four stack of people, to delaminate them and to own certain portions of that stack. And so if you want to be an integral human being, if you want to have your agency and you want to find your own way in the world when you're young, would be a great time to spend time looking at some of the classics around what it means to live a good life, what it means to build connection with people. And so much of the status game, so much of the stuff. One of the things that I talk about, as we create more and more technology, there's a gradient technology, and a gradient technology always leads to a gradient of power. And this is Jacques Aul's point to some extent as well. That gradient of power is not going to go away. The technologies are going so fast that even people like me, who helped create some of the stuff, I'm being left behind. That's some cutting edge research. I don't know what's going on in Gantz today. I go read some proceedings. So as the world gets more and more technological, it will create more and more gradients where people will seize power, economic fortunes. And the way they make a. The people who are left behind, okay, with their lot in life, is they create lottery systems. They make you take part in the narrative of your own being trapped in your own economic sort of zone. So avoiding those kinds of things is really important, knowing when someone is running game on you, basically. So these are things I would tell young people. It's a dark message, but it's realism. I mean, it's what I see.
Speaker A: So after you gave some realism, you sit back. You sit back with your son, you looking out at the sunset. What to him can you give as words of hope? And to you, from where do you derive hope for the future of our world? So you said at the individual level, you have to have a pioneer mindset to go back to the classics to understand what is in human nature. You can find meaning, but at the societal level, what trajectory? When you look at possible trajectories, what gives you hope?
Speaker B: What gives me hope is that we have little tremors now shaking people out of the reverie of the fiction of modernity that they've been living in kind of a late 20th century style modernity. That's good, I think. And also, to your point, earlier, people are burning out on some of the social media stuff. They're sort of seeing the ugly side, especially the latest news with Facebook and the whistleblower. Right. It's quite clear these things are not all they're cracked up to be.
Speaker A: So do you believe like, I believe better social media can be built because they are burning out and they'll incentivize other competitors to be built. Do you think that's possible?
Speaker B: Well, the thing about it is that when you have extractive return on returns, capital coming in and saying, look, you own a network, give me some exponential dynamics out of this network, what are you going to do? You're going to just basically put a toll keeper at every single node and every single graph edge, every node, every vertex, every edge. But if you don't have that need for it, if no one's sitting there saying, hey, Wikipedia, monetize every character, every byte, every phrase, then generative human dynamics will naturally arise. Assuming we respect a few principles around online communications. The greatest and biggest social network in the world is still email, sms.
Speaker A: Yes.
Speaker B: So we are fine there. The issue with the social media, as we call it now, is they're actually just new amplification systems now. It's benefit of certain people like yourself who have interesting content to be amplified. So it's created a creator economy, and that's cool. There's a lot of great content out there, but giving everyone a shot at the fame lottery saying, hey, you could also have your, if you wiggle your butt the right way on TikTok, you could have your 15 seconds of microfame. Thats not healthy for society at large. So I think if we can create tools that help people be conscientious about their attention, spend time looking at the past and really retrieving memory and not calling, but processing and thinking about that, I think thats certainly possible. And hopefully thats what we get. The bigger picture. The bigger question youre asking about, what gives me hope is that these early shocks of COVID lockdowns and remote work and all these different kinds of things, I think it's getting people to a point where they're sort of no longer in the reverie. As my friend Jim Rutt says, there's more people with ears to hear now with the pandemic and education, everyone's like, wait, wait, what have you guys been doing with my kids? Like, how are you teaching them? What is this crap you're giving them as homework? Right? So I think these are the kinds of things that are getting in the supply chain, disruptions, getting more people to think about. How do we actually just make stuff? This is all good, but the concern is that it's still going to take a while for these things for people to learn how to be agentic again. And to be in right relationship with each other and with the world. So the message of hope is still, people are resilient, and we are building some really amazing technology.
Speaker A: And I also like, to me, I derive a lot of hope from individuals in that van. The power of a single individual to transform the world, to do positive things to the world, is quite incredible. Now you've been talking about, it's nice to have as many of those individuals as possible, but even the power of one, it's kind of magical.
Speaker B: It is. It is. We're in a mode now where we can do that, I think, also. So part of what I try to do is in coming to podcasts like yours and then spamming you with all this philosophical stuff that I've got going on. There are a lot of good people out there trying to put words around the current technological, social, economic crises that we're facing and the space of a few short years. I think there has been a lot of great content produced around this stuff for people who want to find out more or think more about this. We're popularizing certain kinds of philosophical ideas that move people beyond just the, oh, you're communist, owe your capitalist kind of stuff. Like, it's sort of, we're way past that now. So that also gives me hope that I feel like I myself am getting a handle on how to think about these things. It makes me feel like I can hopefully affect change for the better.
Speaker A: We've been sneaking up on this question all over the place. Let me ask the big ridiculous question. What is the meaning of life?
Speaker B: Wow. The meaning of life? Yeah. I don't know. I mean, I've never really understood that question.
Speaker A: When you say meaning crisis, you're saying that there is a search for a kind of experience that could be described as fulfillment, as like the haha. Moment of just like. Like joy. And maybe when you see something beautiful, or maybe you have created something beautiful, that experience that you get, it feels like it all makes sense. So some of that is just chemicals coming together in your mind and all kinds of things. But it seems like we're building a sophisticated collective intelligence that's providing meaning in all kinds of ways to its members, and there's a theme to that meaning. So for a lot of history, I think faith played an important role. Faith in God, sort of religion. I think technology in the modern era is kind of serving a little bit of a source of meaning for people. Like innovation of different kinds. I think the old school things of the love and the basics of just being good at stuff. But you were a physicist, so there's a desire to say, okay, yeah, but these seem to be like symptoms of something deeper, right? Like why. Yeah, what's capital m? Meaning why are we reaching for order when there is excess of energy?
Speaker B: I don't know if I can answer the why. Any why that I come up with, I think is going to be. I'd have to think about that a little more, maybe get back to you on that. But I will say this. We do look at the world through a traditional. I think most people look at the world through what I would say is a subject object kind of metaphysical lens, that we have our own subjectivity. And then there's all of these object things that are not us. So I'm me, and these things are not me, right. And I'm interacting with them, I'm doing things to them, but a different view of the world that looks at it as much more connected, that realizes, oh, I'm really quite embedded in a soup of other things, and I'm simply almost like a standing wave pattern of different things. Right. So when you look at the world in that kind of connected sense, I've recently taken a shine to this particular thought experiment, which is, what if it was the case that everything that we touch with our hands, that we pay attention to, that we actually give intimacy to? What if there's actually all the mumbo jumbo, people with the magnetic healing crystals and all this other kind of stuff, and quantum energy stuff? What if that was a thing? What if. If literally, when your hand touches an object, when you really look at something and you concentrate and you focus on it, and you really give it attention, you actually give it. There is some physical residue of something, a part of you, a bit of your life force that goes into it. Okay, now, this is, of course, completely mumbo jumbo stuff. This is not like. I don't actually think this is real, but let's do the thought experiment. What if it was. What if there actually was some quantum magnetic crystal and energy field thing that just by touching this can. This can has changed a little bit somehow. And it's not much unless you put a lot into it and you touch it all the time, like your phone. These things gained. They gain meaning to you a little bit. But what if there's something that. But technical objects. The phone is a technical object. It does not really receive attention or intimacy and then allow itself to be transformed by it. But if it's a piece of wood, if it's the handle of a knife that your mother used for 20 years to make dinner for you. Right? What if it's a keyboard that you banged out your world transforming software library on? These are technical objects, and these are physical objects, but somehow there's something to them. We feel an attraction to these objects as if we have imbued them with life energy.
Speaker A: Yeah.
Speaker B: Right. So if you walk that thought experiment through, what happens when we touch another person, when we hug them, when we hold them. And the reason this ties into my answer for your question is that if there is such a thing, if we were to hypothesize hypotheses, such a thing, it could be that the purpose of our lives is to imbue as many things with that love as possible.
Speaker A: That's a beautiful answer and a beautiful way to end it. Peter, you're an incredible person.
Speaker B: Thank you.
Speaker A: Spending so much in the space of engineering and in the space of philosophy. I'm really proud to be living in the same city as, and I'm really grateful that you would spend your valuable time with me today. Thanks.
Speaker B: Well, thank you. I appreciate the opportunity to speak with you.
Speaker A: Thanks for listening to this conversation with Peter Wang. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Peter Wang himself. We tend to think of people as either malicious or incompetent. But in a world filled with corruptible and unchecked institutions, there exists a third thing, malicious incompetence. It's a social cancer. And it only appears once human organizations scale beyond personal accountability. Thank you for listening and hope to see you next time.
