Transcription for Jim Keller： The Future of Computing, AI, Life, and Consciousness ｜ Lex Fridman Podcast #162.mp3:
Full transcript: The following is a conversation with Jim Keller, his second time in the podcast. Jim is a legendary microprocessor architect and is widely seen as one of the greatest engineering minds of the computing age. In a peculiar twist of spacetime in our simulation, Jim is also a brother in law of Jordan Peterson. We talk about this and about computing, artificial intelligence, consciousness and life. Quick mention of our sponsors athletic greens all in one nutrition drink, brook linen sheets, ExpressVPN and Belcampo grass fed meat. Click the sponsor links to get a discount and to support this podcast. As a side note, let me say that Jim is someone who on a personal level inspired me to be myself. There was something in his words on and off the mic, or perhaps that he even paid attention to me at all that almost told me youre alright kid. A kind of pat on the back that can make the difference between a mind that flourishes and a mind that is broken down by the cynicism of the world. So I guess thats just my brief few words of thank you to Jim and in general, gratitude for the people who have given me a chance on this podcast, in my work and in life. If you enjoy this thing, subscribe on YouTube, review it on Apple Podcast, follow on Spotify, support it on Patreon, or connect with me on Twitter alexfriedman. And now here's my conversation with Jim Keller. What's the value and effectiveness of theory versus engineering this dichotomy in building good software or hardware systems? Well, it's good designs both, I guess. That's pretty obvious. By engineering, do you mean reduction of practice of known methods? And then science is the pursuit of discovering things that people don't understand or solving unknown problems. Definitions are interesting here, but I was thinking more in theory, constructing models that kind of generalize about how things work. And engineering is actually building stuff. The pragmatic like okay, we have these nice models, but how do we actually get things to work? Maybe economics is a nice example. Like economists have all these models of how the economy works and how different policies will have an effect. But then there's the actual, okay, let's call it engineering of like actually deploying the policies. So computer design is almost all engineering and reduction of practice of known methods. Now because of the complexity of the computers, we built a, you could think, well, we'll just go write some code and then we'll verify it, and then we'll put it together. And then you find out that the combination of all that stuff is complicated, and then you have to be inventive to figure out how to do it. So that's definitely happens a lot. And then every so often, some big idea happens, but it might be one. Person, and that idea is in the space of engineering or is in the space of. Well, I'll give you an example. So, one of the limits of computer performance is branch predictions. So, and there's a whole bunch of ideas about how good you could predict a branch. And people said, there's a limit to it. It's an aspen taught a curve, and somebody came up with a better way to do branch prediction. It was a lot better, and he published a paper on it, and every computer in the world now uses it. And it was one idea. So the engineers who build branch prediction hardware were happy to drop the one kind of training array and put it in another one. So it was a real idea. And branch prediction is one of the key problems underlying all of sort of the lowest level of software. It boils down to branch prediction, boils down to uncertainty. Computers are limited by, you know, single thread computers, limited by two things, the predictability of the path of the branches and the predictability of the locality of data. So we have predictors that now predict both of those pretty well. So memory is a couple hundred cycles away. Local cache is a couple cycles away. When you're executing fast, virtually all the data has to be in the local cache. So a simple program says, add one to every element in an array. It's really easy to see what the stream of data will be. But you might have a more complicated program that says, get an element of this array, look at something, make a decision, go get another element. It's random, and you can think that's really unpredictable. And then you make this big predictor that looks at this kind of pattern, and you realize, well, if you get this data and this data, then you probably want that one. And if you get this one and this one and this one, you probably want that one. And is that theory, or is that engineering? Like the paper that was written? Was it asymptotic kind of, kind of discussion? Or is it more like, here's a hack that works? Well, it's a little bit of both. Like, there's information theory in it, I think, somewhere. So it's actually trying to prove. But once, once you know the method, implementing it is an engineering problem. Now, there's a flip side of this, which is, in a big design team, what percentage of people think their plan or their life's work is engineering versus design, inventing things. So lots of companies will reward you for filing patents. Some, many big companies get stuck because to get promoted, you have to come up with something new. And then what happens is everybody's trying to do some random new thing, 99% of which doesn't matter, and the basics get neglected. And. Or they get to. There's a dichotomy, they think, like the cell library and the basic CAD tools or basic software validation methods. That's simple stuff. You know, they want to work on the exciting stuff, and then they spend lots of time trying to figure out how to patent something, and that's mostly useless. But the breakthroughs are on the simple stuff. No, no, you. No, you have to do the simple stuff really well. If you're building a building out of bricks, you want great bricks. So you go to two places to sell bricks. So one guy says, yeah, they're over there in an ugly pile. And the other guy is like, lovingly tells you about the 50 kinds of bricks and how hard they are and how beautiful they are, square they are, and you know which one you can buy bricks from, which is going to make a better house. So you're talking about the craftsman, the person who understands bricks, who loves bricks, who loves the variety. That's a good word. You know, good engineering is great craftsmanship. And when you start thinking engineering is about invention and set up a system that rewards invention, the craftsmanship gets neglected. Okay, so maybe one perspective is the theory. The science overemphasizes invention, and engineering emphasizes craftsmanship, and therefore, like, so if you. It doesn't matter what you do, theory. Well, everybody does, like, read the tech racks. They're always talking about some breakthrough or innovation, and everybody thinks that's the most important thing. But the number of innovative ideas is actually relatively low. We need them, right? And innovation creates a whole new opportunity. Like when some guy invented the Internet, right? Like, that was a big thing. The million people that wrote software against that were mostly doing engineering software writing. The elaboration of that idea was huge. I don't know if you know, Brendan Ike. He wrote JavaScript in ten days. And that's an interesting story. It makes me wonder. And it was, you know, famously, for many years considered to be a pretty crappy programming language. Still is, perhaps. It's been improving sort of consistently. But the interesting thing about that guy is, you know, he doesn't get any awards. You don't get a Nobel Prize or a Fields medal or. A crappy piece of, you know, that software code that. Is currently the number one programming language in the world and runs now is increasingly running the back end of the Internet. Does he know why everybody uses it? That would be an interesting thing. Was it the right thing at the right time? Because when stuff like JavaScript came out, there was a move from writing C programs in C to let's what they call managed code frameworks, where you write simple code, it might be interpreted, it has lots of libraries, productivity is high and you don't have to be an expert. So, you know, Java was supposed to solve all the world's problems. It was complicated. JavaScript came out after a bunch of other scripting languages. I'm not an expert on it, but was it the right thing at the right time or was there something clever because he wasn't the only one? There's a few elements. Maybe if he figured out what it was, then he'd get a prize. Constructive theory. Maybe this problem doesn't define this, or he just needs a good promoter. Well I think there was a bunch of blog posts written about it, which is like wrong is right, which is like doing the crappy thing fast, just like hacking together the thing that answers some of the needs and then iterating over time. Listening to developers, like listening to people who actually use the thing, this is something you can do more in software, but the right time, you have to sense, you have to have a good instinct of when is the right time for the right tool and make it super simple and just get it out there. The problem is, this is true with hardware, this is less true with software, is there's backward compatibility that just drags behind you as you know, as you try to fix all the mistakes of the past. But the timing was good, there's something about that, and it wasn't accidental. You have to give yourself over to the, you have to have this like broad sense of what's needed now, both scientifically and like the community. And just like this, it was obvious that there was no. The interesting thing about JavaScript is everything that ran in the browser at the time, like Java and, and I think other like scheme, other programming languages, they were all in a separate external container. And then JavaScript was literally just injected into the web page. It was the dumbest possible thing running in the same thread as everything else, and it was inserted as a comment. So JavaScript code is inserted as a comment in the HTML code. I mean it's either genius or super dumb, but it's like it has no. Apparatus for a virtual machine and container, it just executed in the framework the program is already running. That's cool. And then because something about that accessibility, the ease of its use, resulted in then developers innovating of how to actually use it. I mean, I don't even know what to make of that, but it does seem to echo across different software, like stories of different software. PHP has the same story, really crappy language, they just took over the world. Always have a joke that the random length instructions, variable length instruction sets, always one, even though they're obviously worse. Like nobody knows why. X 86 is arguably the worst architecture on the planet, is one of the most popular ones. Well, I mean, isn't that also the story of risk versus cis? I mean, is that simplicity? There's something about simplicity that us in this evolutionary process is valued. If it's simple, it gets, it spreads faster, it seems like. Or is that not always true? That's not always true. Yeah, it could be simple is good, but too simple is bad. So why did risk win, you think so far? Did risk win in the long arc of history? We don't know. So who's going to win? What's risk, what's Cisc? And who's going to win in that space? In these instruction sets, a ice offer. Is going to win, but there'll be little computers that run little programs like normal all over the place. But we're going through another transformation. But you think instruction sets underneath it all will change? Yeah, they evolve slowly. They don't matter very much. They don't matter very much. Okay. I mean, the limits of performance are predictability of instructions and data. I mean, that's the big thing. And then the usability of it is some, you know, quality of design, quality of tools, availability. Like right now, X 86 is proprietary with intel and AMD, but they can change it any way they want independently. Arm is proprietary to arm and they won't let anybody else change it. So it's like a sole point. And RISC V is open source, so anybody can change it, which is super cool. But that also might mean it gets changed in too many random ways, that there's no common subset of it that people can use. Do you like open or do you like closed? Like if you were to bet all your money on one or the other risk, five versus it? No idea. It's case dependent. Well, X 86, oddly enough, when intel first started developing it, they licensed it like seven people. So it was the open architecture, and then they moved faster than others and also bought one or two of them. But there were seven different people making x 86 because at the time there was a 6502 and z, you could argue. Everybody thought z 80 was the better instruction set, but that was proprietary to one place. Oh, and the 6800. So there's like four or five different microprocessors. Intel went open, got the market share, because people felt like they had multiple sources from it. And then over time, it narrowed down to two players. So why you, as a historian, why did intel win for so long with their processors? I mean, they were great. Their process development was great. So it's just looking back to JavaScript and Brandon is Microsoft and Netscape and all these Internet browsers. Microsoft won the browser game because they aggressively stole other people's ideas. Like right after they did it. You know, I don't know if intel was stealing other people's ideas. They started making a good way stealing, just to clarify. They started making rams, random access memories. And then at the time when the japanese manufacturers came up, you know, they were getting out, competed on that, and they pivoted the microprocessors, and they made the first, you know, integrated microprocessor programs, uh, 4004 or something. Who was behind that pivot? That's a hell of a pivot. Andy Grove, and he was great. That's a hell of a pivot. And then they led semiconductor industry. Like they were just a little company. IBM, all kinds of big companies had boatloads of money, and they out innovated. Everybody out of innovated. Okay. Yeah, yeah. So it's not like marketing. It's not. And their processor designs were pretty good. I think the core two was probably the first one I thought was great. It was a really fast processor. And then Haswell was great. What makes a great processor in that? Oh, if you just look at its performance versus everybody else, it's the size of it, the usability of it. So it's not specific, some kind of element that makes it beautiful. It's just literally just raw performance. Is that how you think of bioprocessors? It's just like raw performance? Of course, it's like a horse race. The fastest one wins. Now, you don't care how. Well there's the fastest. In an environment. Like, for years, you made the fastest one you could, and then people started to have power limits, so then you made the fastest at the right power point. And then when we started doing multiprocessors, if you could scale your processors more than the other guy, you could be 10% faster on a single thread, but you have more threads, so there's lots of variability. And then arm really explored. They have the A series and the r series and the m series, like a family of processors for all these different design points from unbelievably small and simple. And so then when you're doing the design, it's like this big palette of cpu's. Like they're the only ones with a credible top to bottom pallet. And what do you mean incredible top to bottom? Well, there's people who make microcontrollers that are small, but they don't have a fast one. There's people who make fast processors but don't have a little, a medium one or a small one. Is it hard to do that full palette? That seems like a. It's a lot of different. So what's the difference in the arm folks and intel in terms of the way they're approaching this problem? Well, intel, almost all their processor designs were very custom, high end for the last 1520 years. The fastest horse possible in one horse range. Yeah, architecturally they're really good, but the company itself was fairly insular to what's going on in the industry with CAD tools and stuff. There's this debate about custom design versus synthesis and how do you approach that? I'd say intel was slow on the getting to synthesize processors. ARm came in from the bottom and they generated IP, which went to all kinds of customers, so they had very little say on how the customer implemented their IP. So ARm is super friendly to the synthesis IP environment, whereas intel said, we're going to make this great client chip, server chip, with our own CAD tools, with our own process, with our own other supporting IP, and everything only works with our stuff. So is that, is Arm winning the mobile platform space in terms of process? And so in that what you're describing is why they're winning. Well, they had lots of people doing lots of different experiments, so they controlled the processor architecture and IP, but they let people put in lots of different chips and there was a lot of variability in what happened there. Whereas intel, when they made their mobile, their foray into mobile, they had one team doing one part, so it wasn't ten experiments. And then their mindset was PC mindset, Microsoft software mindset, and that brought a whole bunch of things along that the mobile world, the embedded world, don't do. Do you think it was possible for intel to pivot hard and win the mobile market? That's a hell of a difficult thing to do, right, for a huge company to just pivot. I mean, so interesting to. Because we'll talk about your current work. It's like, it's clear that PCs were dominating for several decades, like desktop computers and then mobile. It's unclear. It's a leadership question. Like Apple under Steve Jobs, when he came back, they pivoted multiple times. They built iPads and itunes and phones and tablets and great Macs. Who knew computers should be made out of aluminum? Nobody knew that. That they're great. It's super fun. That was Steve? Yeah, Steve Jobs. Like, they pivoted multiple times. And, you know, the old intel, they did that multiple times. They made drams and processors and processes. And I gotta ask this. What was it like working with Steve jobs? I didn't work with him. Did you interact with him? Twice. I said hi to him twice in the cafe. What did he say? Hi. He said, hey, fellas. He was friendly. He was wandering around and with somebody. He couldn't find a table because the cafeteria was packed, and I gave my table. But I worked for Mike Colbert, who talked to, like, Mike was the unofficial CTO of apple and a brilliant guy, and he worked for Steve for 25 years, maybe more. And he talked to Steve multiple times a day. And he was one of the people who could put up with Steve's, let's say, brilliance and intensity. And Steve really liked him. And Steve trusted Mike to translate the shit he thought up into engineering products at work. And then Mike ran a group called Platform Architecture. And I was in that group so many times. I'd be sitting with Mike and the phone would ring. It'd be Steve. And Mike would hold the phone like this because Steve would be yelling about. Something or other, and then he would. Translate and he translated, and then he would say, steve wants us to do this. So was Steve a good engineer, or. No. I don't know. He was a great idea guy, idea person. And he's a really good selector for talent. Yeah. That seems to be one of the key elements of leadership. Right. And then he was a really good first principles guy. Like, somebody say something couldn't be done, and he would just think, that's obviously wrong. Right. But, you know, maybe it's hard to do. Maybe it's expensive to do. Maybe we need different people. You know, there's like a whole bunch of, like, if you want to do something hard, you know, maybe it takes time. Maybe you have to iterate. There's a whole bunch of things you could think about. But saying it can't be done is stupid. How would you compare? So it seems like Elon Musk is more engineering centric, but is also, I think, he considered himself a designer, too. He has a design mind. Steve Jobs feels like he is much more idea space, design. Space versus engineering. Just make it happen. Like, the world should be this way. Just figure it out. But he used computers. He had computer people talk to him all the time. Mike was a really good computer guy. He knew computers could do computer, meaning computer hardware. Hardware, software, all the pieces. And then he would have an idea about what could we do with this next? That was grounded in reality. It wasn't like he was, you know, just finger painting on the wall and wishing somebody would interpret it, like. So. He had this interesting connection, because now he wasn't a computer architect or designer, but he had an intuition from the computers we had to what could happen. And it's interesting you say intuition because it seems like he was pissing off a lot of engineers in his intuition about what can and can't be done. Those, like the. What is all these stories about, like, floppy disks and all that kind of stuff like that. Yeah. So in Steve, the first round, like, he'd go into a lab and look at what's going on and hate it and fire people or ask somebody in the elevator what they're doing for apple and not be happy when he came back, my impression was, is he surrounded himself with a relatively small group of people. Yes. And didn't really interact outside of that as much. And then the joke was you'd see, like, a little somebody moving a prototype through the quad with a black blanket over it. And that was because it was secret, you know, partly from Steve, because they didn't want Steve to see it until it was ready. Yeah. The dynamic with Jony Ive and Steve is interesting. Like, you don't want to. He ruins as many ideas as he generates. Yeah, yeah. It's a dangerous kind of line to. Walk if you have a lot of ideas. Like, Gordon Bell was famous for ideas. Right. And it wasn't that the percentage of good ideas was way higher than anybody else. It was. He had so many ideas, and he was also good at talking to people about it and getting the filters right and, you know, seeing through stuff, whereas Elon was like, hey, I want to build rockets. So Steve would hire a bunch of rocket guys, and Elon would go read rocket manuals. So Elon is a better engineer, a sense, like. Or, like, more like a love and passion for the manuals and the details. The details. The craftsmanship, too, right? Well, I guess you had craftsmanship, too, but of a different kind. What do you make of the. Just to stand in for just a little longer. What do you make of, like, the anger and the passion and all that? The. The firing and the mood swings and the madness, the, you know, being emotional and all that? That's Steve and I guess Elon, too. So what is that, a set, a bug or a feature? It's a feature. So there's a graph, which is y axis productivity. Yeah. X axis at zero is chaos and infinity. It's complete order. Yeah. Right. So as you go from the, you know, the origin, as you improve order, you improve productivity. Yeah. And at some point, productivity peaks and then it goes back down again. Too much order, nothing can happen. Yes, but the question is, how close to the chaos is that? No, no. Here's the thing is, once you start moving, a direction or the force vector to drive you towards order is unstoppable. Oh. Every organization will move to the place where their productivity is stymied by order. So you need. So the question is, who's the counterforce? Because it also feels really good. As you get more organized and productivity goes up, the organization feels it. They orient towards it. They hired more people. They got more guys who can run process. You get bigger, inevitably, the organization gets captured by the bureaucracy that manages all the processes. And then humans really like that. And so if you just walk into a room and say, guys, love what you're doing, but I need you to have less order. If you don't have some force behind that, nothing will happen. I can't tell you on how many levels. That's profound. That's why I say it's a feature. Now, could you be nicer about it? I don't know. I don't know any good examples of being nicer about it. Well, the funny thing is, to get stuff done, you need people who can manage stuff and manage people, because humans are complicated. They need lots of care and feeding that. You need to tell them they look nice and they're doing good stuff and pat them on the back. Right. I don't know. You tell me, is that needed? Humans need that. I had a friend, he started a magic roof, said, I figured it out. You have to praise them before they do anything. I was waiting till they were done, and they were always mad at me. Now I tell them what a great job they're doing while they're doing it, but then you get stuck in that trap, because then when they're not doing something, how do you confront these people? I think a lot of people that had trauma in their childhood would disagree with you. Successful people that you need to first do the rough stuff and then be nice later. I don't know. Okay, but engineering companies are full of adults who had all kinds of range of childhoods. You know, most people had okay childhoods. Well, I don't know if. And lots of people only work for praise, which is weird. You mean, like everybody? I'm not that interested in it, but. Well, you're probably looking for somebody's approval, even still. Yeah, maybe I should think about that. Maybe somebody who's no longer with this kind of thing. I don't know. I used to call my dad and tell him what I was doing. He was. He was very excited about engineering and stuff. You got his approval? Yeah, a lot. I was lucky. Like, he decided I was smart and unusual as a kid, and that was okay when I was really young. So when I did poorly in school, I was dyslexic. I didn't read until I was third or fourth grade, and they didn't care. My parents were like, oh, he'll be fine. So I was lucky. That was cool. Is he still with us? You miss him? Sure. Yeah. He had Parkinson's and then cancer. His last ten years were tough, and I killed him. Killing a man like that's hard. The mind, well, it's pretty good. Parkinson's causes slow dementia, and the chemotherapy, I think, accelerated it, but it was like hallucinogenic dementia. So he was clever and funny and interesting and was pretty unusual. Do you remember conversations from that time? Like what? Do you have fond memories of the guy? Yeah. Oh, yeah? Anything come to mind? A friend told me one time I could draw a computer on the whiteboard faster than anybody you'd ever met. And I said, you should meet my dad. Like, when I was a kid, he'd come home and say, I was driving by this bridge, and I was thinking about it, and he pulled out a piece of paper, and he'd draw the whole bridge. He was a mechanical engineer, and he would just draw the whole thing, and then he would tell me about it and tell me how he would have changed it. And he had this idea that he could understand and conceive anything. And I just grew up with that, so that was natural. So when I interview people, I ask them to draw a picture of something they did on a whiteboard, and it's really interesting. Some people draw a little box, you know, and then they'll say, and this talks to this, and I'll be like, that's just frustrating. And I had this other guy come in one time. He says, well, I designed a floating point in this chip, but I'd really like to tell you how the whole thing works and then tell you how the floating point works inside of it. Do you mind if I do that? He covered two whiteboards in like 30 minutes, and I hired him like he was great. There's craftsman. I mean, that's the craftsmanship to that. Yeah, but also the mental agility to understand the whole thing. Put the pieces in context, real view of the balance of how the design worked, because if you don't understand it properly when you start to draw it, you'll fill up half the whiteboard with a little piece of it. Your ability to lay it out an understandable way takes a lot of understanding. And be able to zoom into the detail and then zoom out in the picture really fast. What about the impossible thing? See, your dad believe that you can do anything. That's a weird feature for a craftsman. Yeah, it seems that that echoes in your own behavior. Like that's, that's the, well, it's not. That anybody can do anything right now. Right. It's that if you work at it, you can get better at it, and there might not be a limit. And they did funny things like, like he always wanted to play piano, so at the end of his life he started playing the piano when he had Parkinson's, and he was terrible, but he thought if he really worked out it in this life, maybe the next life, he'd be better at it. He might be onto something. Yeah, he enjoyed doing it. Yeah. So that's pretty funny. Do you think the perfect is the enemy of the good in hardware and software engineering? It's like we were talking about JavaScript a little bit. And the messiness of the ten day building process. Yeah. You know, creative tension. Right. So creative tension is you have two different ideas that you can't do both. Right. And then, but the fact that you want to do both causes you to go try to solve that problem. That's the creative part. So if you're building computers, like some people say, we have the schedule, and anything that doesn't fit in the schedule, we can't do. So they throw out the perfect because they have a schedule. I hate that. Then there's other people who say, we need to get this perfectly right, and no matter what, more people, more money, and there's a really clear idea about what you want. And some people are really good at articulating it. Let's call that the perfect. But that's also terrible because they never ship anything. They never hit any goals. So now you have the. Now you have your framework. Yes. You can't throw out stuff. Cause you can't get it done today. Cause maybe you get it done tomorrow or the next project. Right? You can't. So you have to. I work with a guy that I really like working with, but he over filters his ideas. Over filters. He'd start thinking about something, and as soon as he figured out what's wrong with it, he'd throw it out. And then I start thinking about it. And you come up with an idea, and then you find out what's wrong with it, and then you give it a little time to set because sometimes you figure out how to tweak it, or maybe that idea helps some other idea. So idea generation is really funny. So you have to give your ideas space. Spaciousness of mind is key, but you also have to execute programs and get shit done. And then it turns out computer engineering is fun because it takes 100 people to build a computer, 200 to 300, whatever the number is. And people are so variable about, you know, temperament and, you know, skill sets and stuff that in a big organization, you find that the people who love the perfect ideas and the people that want to get stuff done yesterday, and people like to come up with ideas, and people like to, let's say, shoot down ideas. And it takes the whole, it takes a large group of people. Some are good at generating ideas, some are good at filtering ideas, and then they're all in that giant mess. You're somehow, I guess the goal is for that giant mess of people to find the perfect path through the tension, the creative tension. But how do you know when you said there's some people good at articulating what perfect looks like, what a good design is? If you're sitting in a room and you have a set of ideas about how to design a better processor, how do you know this is something special here? This is a good idea. Let's try this. Have you ever brainstormed idea with a couple people that were really smart, and you kind of go into it and you don't quite understand it, and you're working on it, and then you start talking about it, putting it on the whiteboard. Maybe it takes days or weeks, and then your brain start to kind of synchronize. It's really weird. Like, you start to see what each other is thinking, and it starts to work. Like, you can see work. Like, my talent in computer design is. I can see how computers work in my head, like, really well. And I know other people can do that, too. And when you're working with people that can do that, it is kind of an amazing experience. And then, and every once in a while, you get to that place and then you find the flaw, which is kind of funny because you can fool yourself, but the two of you kind. Of drifted along into a direction that was useless. Yeah, that happens, too. Like, you have to, because, you know, the nice thing about computer design, there's always reduction in practice. Like, you come up with your good ideas, and I've known some architects who really love ideas, and then they work on them and then they put it on the shelf, then go work on the next idea and put it on the shelf. They never reduce it to practice, so they find out what's good and bad. Because almost every time I've done something really new, by the time it's done, like, the good parts are good, but I know all the flaws. Like. Yeah. Would you say your career, just your own experience, is your career defined by mostly by flaws or by successes? Like, if, again, there's great tension between those. If you haven't tried hard. Yeah. Right. And done something new. Right. Then you're not going to be facing the challenges when you build it. Then you find out all the problems with it and. But when you look back, do you see problems? Okay. Oh, when I look back, what do you. I think earlier in my career. Yeah. Like, Ev five was the second alpha chip. I was so embarrassed about the mistakes, I could barely talk about it. And it was in the Guinness Book of Worlds Records, and it was the fastest processor on the planet. Yeah, so it was. And at some point I realized that was really a bad mental framework to deal with, like doing something new. We did a bunch of new things, and some worked out great and some were bad, and we learned a lot from it. And then the next one, we learned a lot that also Ev six also had some really cool things in it. I think the proportion of good stuff went up, but it had a couple of fatal flaws in it that were painful. And then. Yeah, you learned to channel the pain into, like, pride. Not pride, really, just realization about how the world works or how that kind of idea set works. Life is suffering. That's the reality. What? No, it's nothing. Well, you know, the Buddha said that and a couple other people are stuck on it. No, it's, you know, there's this kind of weird combination of good and bad, you know, light and darkness that you have to tolerate and, you know, deal with. Yeah, there's definitely lots of suffering in. The world depends on the perspective. It seems like there's way more darkness, but that makes the light part really nice. What computing hardware, or just any kind of even software design do you find beautiful from your own work, from other people's work that you're just, we were just talking about the battleground of flaws and mistakes and errors, but things that were just beautifully done. Is there something that pops to mind? Well, when things are beautifully done, usually there's a well set, thought out set of abstraction layers. So the whole thing works in unison nicely. Yes. And when I say abstraction layer, that means two different components. When they work together, they work independently. They don't have to know what the other one is doing. So that decoupling. Yeah. So the famous one was the network stack. There's a seven layer network stack, data transport protocol and all the layers. And the innovation was when they really got that right, because networks before that didn't define those very well. The layers could innovate independently. And occasionally the layer boundary would, you know, the interface would be upgraded and that let you know the design space breathe. You could do something new in layer seven without having to worry about how layer four worked. And so good design does that, and you see it in processor designs. When we did the Zen design at AMD, we made several components very modular. And my insistence at the top was I wanted all the interfaces defined before we wrote the RTL for the pieces one of the verification leads had. If we do this right, I can test the pieces so well independently, when we put it together, we won't find all these interaction bugs because the floating point knows how the cache works. And I was a little skeptical, but he was mostly right that the modularity of the design greatly improved the quality. Is that universally true in general, would you say about good designs, the modularity is like, usually, well, we talked about this before. Humans are only so smart and we're not getting any smarter. Right. But the complexity of things is going up. So, you know, a beautiful design can't be bigger than the person doing it. It's just, you know, their piece of it. Like the odds of you doing a really beautiful design of something that's way too hard for you is low, right? If it's way too simple for you, it's not that interesting. It's like, well, anybody could do that. But when you get the right match of your expertise and mental power to the right design size, that's cool, but that's not big enough to make a meaningful impact on the world. So now you have to have some framework to design the pieces so that the whole thing is big and harmonious. But when you put it together, it's sufficiently interesting to be used. So that's like a beautiful design is. Matching the limits of that human cognitive capacity to the module that you can create and creating a nice interface between those modules, and thereby, do you think there's a limit to the kind of beautiful, complex systems we can build with this kind of modular design? It's like if we build increasingly more complicated, you can think of the Internet. Okay, let's scale it down. You can think of social network like Twitter as one computing system, but those are little modules, but it's built on. So many components, nobody at Twitter even understands. So if an alien showed up and looked at Twitter, he wouldn't just see Twitter as a beautiful, simple thing that everybody uses, which is really big. You would see the network it runs on, the fiber optics, the data is transported, the computers. The whole thing is so bloody complicated, nobody at Twitter understands it. And so I think that's what the alien would see. So, yeah, if an alien showed up and looked at Twitter or looked at the various different networked systems that you can see on Earth. So imagine they were really smart that could comprehend the whole thing, and then they sort of, you know, evaluated the human and thought, this is really interesting. No human on this planet comprehends the system they built. No individual, or would they even see individual humans like we? Humans are very human centric, entity centric. And so we think of us as the organ, as the central organism, and the networks as just the connection of organisms. But from a perspective of an alien, from an outside perspective, it seems like. Yeah, I get it. We're the ants, and they'd see the ant colony. The ant colony, yeah. Or the result of production of the ant colony, which is like cities, and. Yeah, it's. It's a. In that sense, humans are pretty impressive. The modularity that we're able to and the. And how robust we are to noise and mutation, all that kind of stuff. Well, that's because it's stress tested all the time. Yeah. You know, you build all these cities with buildings, and you get earthquakes occasionally and wars, you know, some, you know, wars, earthquakes, viruses. Every once in a while, you know. Changes in business plans for, you know, like shipping or something like. Like, as long as it's all stress tested, then it keeps adapting to the situation. That's a curious phenomenon. Well, let's talk about Moore's law a little bit at the broad view of Moore's law, where it's just exponential improvement of computing capability. Like OpenAI, for example, recently published this kind of papers looking at the exponential improvement in the training efficiency of neural networks for like imagenet and all that kind of stuff. We just got better on this is purely software side, just figuring out better tricks and algorithms for training neural networks. And that seems to be improving significantly faster than the Moore's law prediction. So that's in the software space. What do you think if Moore's law continues, or if the general version of Moore's law continues? Do you think that comes mostly from the hardware, from the software? Some mix of the two, some interesting, totally. So not the reduction of the size of the transistor kind of thing, but more in the. In the totally interesting kinds of innovations in the hardware space, all that kind of stuff? Well, there's like a half a dozen things going on in that graph. So one is there's initial innovations that had a lot of headroom to be exploited. So, you know, the efficiency of the networks has improved dramatically. And then the decomposability of those and the use, you know, they started running on one computer, then multiple computers, then multiple GPU's, and then arrays of GPU's, and they're up to thousands and at some point. So it's sort of like they were going from like a single computer application to 1000 computer application. So that's not really a Moore's law thing, that's an independent vector. How many computers can I put on this problem? Because the computers themselves are getting better on like a Moore's law rate, but their ability to go from one to ten to 100 to 1000 was something, and then multiplied by the amount of computes it took to resolve, like Alexnet to Resnet, the transformers been quite steady improvements. But those are like s curves, aren't they? That's the exactly kind of s curves that are underlying Moore's law from the very beginning. So what's the biggest, what's the most productive, rich source of s curves in the future, do you think? Is it hardware, is it software, or is it. So hardware is going to move along relatively slowly, like double performance every two years. There's still. I like how you call that slow. Yeah, that's the slow version. The snail's pace of Moore's law. Maybe we should trademark that one. Whereas the scaling by number of computers can go much faster. I'm sure at some point Google had their initial search engine was running on a laptop, and at some point they really worked on scaling that, and then they factored the indexer from this piece and this piece and this piece, and they spread the data on more and more things, and they did a dozen innovations. But as they scaled up the number of computers on that, it kept breaking, finding new bottlenecks in their software and their schedulers and made them rethink. It seems insane to do a scheduler across 1000 computers who schedule parts of it and then send the results to one computer. But if you want to schedule a million searches, that makes perfect sense. So the scaling by just quantity is probably the richest thing. But then as you scale quantity, like, a network that was great on 100 computers may be completely the wrong one. You may pick a network that's ten times slower on 10,000 computers, like per computer. But if you go from 100 to 10,000, it's 100 times. So that's one of the things that happened when we did Internet scaling, is the efficiency went down, not up. The future of computing is inefficiency. Not efficiency, but scales. Inefficient scale. It's scaling faster than inefficiency bites you. And as long as there's dollar value there, like, scaling costs lots of money. But Google showed, Facebook showed, everybody showed that the scale was where the money was at. So it's worth it financially. Do you think? Is it possible that, like, basically the entirety of earth will be, like, a computing surface? Like, this table will be doing computing, this hedgehog will be doing computing? Like, everything really inefficient, dumb computing will be science fiction? Books, they call it computronium. Computronium. We turn everything into computing. Well, most of the elements aren't very good for anything. Like, you're not gonna make a computer out of iron. Like, you know, silicon and carbon have, like, nice structures. You know, we'll see what you can do with the rest of it. People talk about, well, maybe we can turn the sun into computer, but it's hydrogen and a little bit of helium. So what I mean is more like actually just adding computers to everything. Oh, okay, so you're just converting all the mass of the universe into computer. No. No. So not using, to be ironic from. The simulation point of view, is like the simulator build mass to simulate a. Like. Yeah, I mean, yeah, so, I mean, ultimately, this is all heading towards a simulation. Yeah. Well, I think I might have told you this story. A Tesla. They were deciding, so they want to measure the current coming out of the battery, and they decide between putting a resistor in there and putting a computer with a sensor in there, and the computer was faster than the computer I worked on in 1982. And we chose the computer because it was cheaper than the resistor. So, sure, this hedgehog cost $13, and we can put an AI that's as smart as you in there for $5. It'll have one. So computers will be everywhere. I was hoping it wouldn't be smarter than me because, well, everything's going to. Be smarter than you. But you were saying it's inefficient. I thought it was better to have a lot of dumps. Well, Moore's law will slowly compact that. Stuff, so even the dumb things will be smarter than us. The dump things are going to be smart. Are they going to be smart enough to talk to something that's really smart? You know, it's like. Well, just remember, like a big computer chip. Yeah. You know, it's like an inch by an inch and, you know, 40 microns thick. It doesn't take very much, very many atoms to make a high power computer, and 10,000 of them can fit in the shoebox. But, you know, you have the cooling and power problems, but, you know, people. Are working on that, but they still can't write compelling poetry or music or understand what love is, or have a fear of mortality. So we're still winning. Neither can most of humanity, so, well. They can write books about it, so. But speaking about this, walk along the path of innovation towards the dumb things being smarter than humans. You are now the CTO of ten storent. As of two months ago. They build hardware for deep learning. How do you build scalable and efficient deep learning? This is such a fascinating space. Yeah, yeah. So it's interesting. So up until recently, I thought there was two kinds of computers. There are serial computers that run, like, C programs, and then there's parallel computers. So the way I think about it is, parallel computers have given parallelism, like GPU's are great because you have a million pixels, and modern gpu's run a program on every pixel. They call it a shader program, or finite element analysis. You build something, you make this into little tiny chunks. You give each chunk to a computer, so you're given all these chunks. You have parallels, and like that. But most C programs, you write this linear narrative, and you have to make a go fast to make it go fast. You predict all the branches, all the data fetches, and you run that more in parallel. But that's found parallelism. AI is. I'm still trying to decide how fundamental this is. It's a given parallelism problem. But the way people describe the neural networks and then how they write them in Pytorch, it makes graphs. Yeah, that might be fundamentally different than the GPU kind of parallelism. Yeah, it might be because when you run the GPU program on all the pixels you're running depends. This group of pixels say it's background blue and it runs a really simple program. This pixel is some patch of your face, so you have some really interesting shader program to give you the impression of translucency. But the pixels themselves don't talk to each other. There's no graph, right? So you do the image and then you do the next image and you do the next image and you run 8 million pixels, 8 million programs every time. And modern GPU's have like 6000 thread engines in them. So you know, to get 8 million pixels, each one runs a program on, you know, ten or 20 pixels. And that's how, that's how they work. There's no graph, but you think graph might be a totally new way to think about hardware. So Raja Guduri and I have been having this conversation about given versus found parallelism and then the kind of walk as we got more transistors like computers way back when did stuff on scalar data, then we did it on vector data, famous vector machines. Now we're making computers that operate on matrices. And then the category we said that was next was spatial like. Imagine you have so much data that you want to do the compute on this data, and then when it's done, it says send the result to this pile of data on some software on that. And it's better to think about it spatially than to move all the data to a central processor and do all the work. So spatially you mean moving in the space of data as opposed to moving the data. You have a petabyte data space spread across some huge array of computers. And when you do a computation somewhere, you send the result of that computation, or maybe a pointer to the next program, to some other piece of data and do it. But I think a better word might be graph. And all the AI neural networks are graphs. Do some computations, send the result here, do another computation, do a data transformation, do emerging, do a pooling, do another computation. Is it possible to compress and say how we make this thing efficient, this whole process efficient? There's different. So first, the fundamental elements in the graphs are things like matrix multiplies, convolutions, data manipulations and data movements. So GPU's emulate those things with their little singles, basically running a single threaded program. And then there's an invita calls it a warp, where they group a bunch of programs that are similar together for efficiency and instruction use. Then at a higher level, you take this graph and you say, this part of the graph is a matrix multiplier, which runs on these 32 threads, but the model at the bottom was built for running programs on pixels, not executing graphs. So it's emulation ultimately. So is it possible to build something that natively runs graphs? Yes. So that's what ten storm did. So where are we on that? How, like in the history of that effort, are we in the early days? Yeah, I think so. Ten storrants started by a friend of mine, Labija Bajak, and I was his first investor. So I've been kind of following him and talking to him about it for years. And in the fall, when I was considering things to do, I decided we held a conference last year with a friend, organized it, and we wanted to bring in thinkers, and two of the people were Andre Karpasi and Chris Ladner. And Andre gave this talk, it's on YouTube called Software 2.0, which I think is great, which is we went from programmed computers where you write programs, to data program computers, like the future of software as data programs, the networks, and I think that's true. And then Chris has been working, he worked on LLVM, the low level virtual machine, which became the intermediate representation for all compilers. And now he's working on another project called MLiR, which is mid level intermediate representation, which is essentially under the graph about how do you represent that kind of computation, and then coordinate large numbers of potentially heterogeneous computers? I would say technically tends torrents. Two pillars of those two ideas, software 2.0 and mid level representation. But it's in service of executing graph programs. The hardware is designed to do that. So it's including the hardware piece. Then the other cool thing is, for a relatively small amount of money, they did a test chip and two production chips. It's a super effective team, unlike some AI startups, where if you don't build the hardware to run the software that they really want to do, then you have to fix it by writing lots more software. So the hardware naturally does matrix multiply, convolution, the data manipulations, and the data movement between processing elements that you can see in the graph, which I think is all pretty clever, and that's what I'm working on now. So I think it's called the grace call processor. Introduced last year. There's a bunch of measures of performance. We're talking about horses. It seems to outperform 368 trillion operations per second, seems to outperform Nvidia's Tesla T four system. So these are just numbers. What do they actually mean in real world performance? What are the metrics for you that you're chasing in your horse race? What do you care about? Well, first, the native language of people who write AI network programs is Pytorch. Now, Pytorch, tensorflow, there's a couple others. The pytorch is one over tensorflow. Is it just. I'm not an expert on that. I know many people who have switched from Tensorflow to Pytorch. Yeah. And there's technical reasons for it. And I use. Both are still awesome. Both are still awesome. But the deepest love is for Pytorch currently. Yeah, there's more love for that, and that may change. So the first thing is, when they write their programs, can the hardware execute it pretty much as it was written. So Pytorch turns into a graph. We have a graph compiler that makes that graph. Then it fractions the graph down. So if you have big matrix multiply, we turn it into right size chunks to run on the processing elements. It hooks all the graph up, it lays out all the data. There's a couple of mid level representations of it that are also simulatable, so that if you are writing the code, you can see how it's going to go through the machine, which is pretty cool. And then at the bottom, it schedules kernels like math, data manipulation, data movement kernels, which do this stuff so we don't have to run, write a little program to do matrix multiply, because we have a big matrix multiplier. Like there's no SIMD program for that, but there is scheduling for that. Right? So one of the goals is if you write a piece of Pytorch code that looks pretty reasonable, you should be able to compile it, run it on the hardware without having to tweak it and do all kinds of crazy things to get performance. There's not a lot of intermediate steps. It's running directly as written, like on a GPU. If you write a large matrix multiply, naively, you'll get five to 10% of the peak performance of the GPU. Then there's a bunch of people published papers on this, and I read them about what steps do you have to do? And it goes from pretty reasonable. Well, transpose one of the matrices so you do row ordered, not column ordered, you know, block it so that you can put a block of the matrix on different sms, you know, groups of threads. But some of it gets into little details, like you have to schedule it just so, so you don't have register conflicts. So the, they call them cuda ninjas. Cuda ninjas. I love it. To get to the optimal point, you either write a pre use a pre written library, which is a good strategy for some things, or you have to be an expert in microarchitecture to program it. Right. So the optimization step is way more complicated with the GPU. So our, our goal is if you write Pytorch, that's good, Pytorch, you can do it. Now there's, as the networks are evolving, you know, they've changed from convolutional to matrix multiply. People are talking about conditional graphs, they're talking about very large matrices, they're talking about sparsity, they're talking about problems that scale across many, many chips. So the native data item is a packet. You send the packet to a processor, it gets processed, it does a bunch of work, and then it may send packets to other processors and they execute in a data flow graph methodology. Got it. We have a big network on chip, and then second chip has 16 Ethernet ports to hook lots of them together. It's the same graph compiler across multiple chips. That's where the scale comes in. It's built to scale naturally. My experience with scaling is as you scale, you run into lots of interesting problems. So scaling is a mountain to climb. So the hardware is built to do this, and we're in the process of. Is there a software part to this with Ethernet and all that? Well, the protocol at the bottom we send, it's an Ethernet fi, but the protocol basically says send a packet from here to there. It's all point to point. The header bit says which processor to send it to, and we basically take a packet off our on chip network, put an Ethernet header on it, send it to the other end, strip the header off and send it to the local thing. It's pretty straightforward. Human to human interaction is pretty straightforward too. But when you get a million of us, we do some crazy stuff together. Yeah, it can be fun. So is that the goal is scale. So like for example, I've been recently doing a bunch of robots at home for my own personal pleasure. Am I going to ever use ten storing or is this more for. There's all kinds of problems, like there's small inference problems or small training problems. There's big training problems. What's the big goal? Is it the big training problems or the small training problems? One of the goals is to scale from 100 milliwatts to a megawatt. So really have some range on the problems. And the same kind of AI programs work at all different levels. So that's the goal, since the natural data item is a packet that we can move around. It's built to scale, but so many people have small problems, but inside that. Phone is a small problem to solve. So do you see thunderstorm potentially being inside a phone? Well, the power efficiency of local memory, local computation, and the way we built it is pretty good. And then there's a lot of efficiency on being able to do conditional graphs and sparsity. I think for complicated networks that want to go into small factor, it's quite good, but we have to prove that's a fun problem. And that's the early days of the company. Right? It's a couple of years, you said, but you think you invested, you think they're legit once you join. Well, it's also, it's a really interesting place to be. Like the AI world is exploding. I looked at some other opportunities, like build a faster processor, which people want, but that's more on an incremental path than what's going to happen in AI in the next ten years. So this is kind of an exciting place to be. Part of the revolutions will be happening in the very space, and then lots. Of people are working on it. But there's lots of technical reasons why some of them aren't going to work out that well. And that's, that's interesting. And there's also the same problem about getting the basics right. Like, we've talked to customers about exciting features, and at some point we realized that each year, realizing they want to hear first about memory bandwidth, local bandwidth, compute intensity, programmability, they want to know the basics, power management, how the network ports work, what are the basics? Do all the basics work? Because it's easy to say, we've got this great idea that, you know, the crack GPT-3 but the people we talk to want to say, if I buy the. So we have a piece of express card with our chip on it. If you buy the card, you plug it in your machine, you download the driver. How long does it take me to get my network to run? Right? No, that's a real question. It's a very basic question. So, yeah. Is there an answer to that yet, or is it trying to our goal. Is, like, an hour. Okay. When can I buy a Tesla? Pretty soon. For my. For the small case training. Yeah, pretty soon. Months. Good. I love the idea of you inside a room with Karpathy. Andre Karpathy and Chris Ladner. Very, very interesting, very brilliant people. Very out of the box thinkers, but also, like, first principles thinkers. Well, they both get stuff done. They only get stuff done to get their own projects done. They talk about it clearly. They educate large numbers of people, and they've created platforms for other people to go do their stuff on. Yeah, the. The clear thinking that's able to be communicated is kind of impressive. It's kind of remarkable to. Yeah, I'm a fan. Well, let me ask, because I talked to Chris, actually a lot these days. He's been one of the cool. Just to give him a shout out in. He's been so supportive as a human being. So everybody's quite different. Like, great engineers are different, but he's been, like, sensitive to the human element in a way that's been fascinating. Like, he was one of the early people on this stupid podcast that I do to say, like, don't quit this thing. And also talk to whoever the hell you want to talk to that kind of from a legit engineer to get, like, props and be like, you can do this. That was. I mean, that's what a good leader does, right? It's just kind of let a little kid do his thing. Like, go, go do it. Let's see, let's see. See what turns out that's a, that's a pretty powerful thing. But what do you. What's your sense about. He used to be. He now, I think, stepped away from Google. Right. He said sci-fi. I think what, what's really impressive to you about the things that Chris has worked on, because it's that we mentioned the optimization, the compiler design stuff, the LLVM. Then there's. He's also at Google work that TPU stuff. He's obviously worked on Swift. So the programming language side, talking about people that work in the entirety of the stack. From your time, interacting with Chris and knowing the guy, what's really impressive to you that just inspires you? Well. Well, LLVM became the de facto platform for compilers. It's amazing. And it was good code quality, good design choices. He hit the right level of abstraction. There's a little bit of the right time, the right place. Then he built a new programming language called Swift, which after, let's say, some adoption resistance, became very successful. I don't know that much about his work at Google, although I know that that was a typical. They started Tensorflow stuff and it was new. They wrote a lot of code, and then at some point it needed to be refactored to be, because its development slowed down. Why Pytorch started a little later and then passed it. So he did a lot of work on that. And then his idea about MliR, which is what people started to realize, is the complexity of the software stack above the low level. Ir was getting so high that forcing the features of that into low level was putting too much of a burden on it. So he's splitting that into multiple pieces. That was one of the inspirations for our software stack, where we have several intermediate representations that are all executable and you can look at them and do transformations on them before you lower the level. So that was, I think we started before Mlir really got far enough along to use, but we're interested in that. He's really excited about Mlir. That's his little baby. And there seems to be some profound ideas on that that are really useful. So each one of those things has been, as the world of software gets more and more complicated, how do we create the right abstraction levels to simplify it in a way that people can now work independently on different levels of it? So I would say all three of those projects, LLVM, Swift and Mlir, did that successfully. So I'm interested was what he's going to do next in the same kind of way? Yes. So on the either the TPU or maybe the Nvidia GPU side, how does ten store, you think? Or the ideas underlying it doesn't have to be test, or just this kind of graph focused, graph centric hardware. Deep learning centric hardware beat Nvidias. Do you think it's possible for it to basically overtake Nvidia? Sure. What's that process look like? What's that journey look like, you think? Well, GPU's were built to run shader programs on millions of pixels, not to run graphs. Yes. So there's a hypothesis that says the way the graphs are built is going to be really interesting to be inefficient on computing this. And then the primitives is not a SIMD program, it's matrix multiply convolution. And then the data manipulations are fairly extensive about how do you do a fast transpose with a program? I don't know if you've ever written a transpose program. They're ugly and slow, but in hardware you can do really well. I'll give you an example. When GPU accelerators started doing triangles like so, you have a triangle which maps on the set of pixels. So you build, it's very easy, straightforward to build a hardware engine that'll find all those pixels. And it's kind of weird because you walk along the triangle to get to the edge, and then you have to go back down to the next row and walk along. And then you have to decide on the edge. If the line of the triangle is like half on the pixel, what's the pixel color? Because it's half of this pixel and half the next one. That's called rasterization. You're saying that could be done in hardware? No, just that's an example of that operation as a software program is really bad. I've written a program that did rasterization. The hardware that does it is actually less code than the software program that does it, and it's way faster. So there are certain times when the abstraction you have rasterize a triangle, execute a graph, components of a graph. The right thing to do in the hardware software boundary is for the hardware to naturally do it. So the GPU is really optimized for the rasterization of triangles. Well, no, that's just, well, like in a modern, you know, that's a small piece of modern GPU's. What they did is that they still rasterize triangles when you're running a game. But for the most part, most of the computation in the area, the GPU is running shader programs, but they're single threaded programs on pixels, not graphs, to be honest. And say, I don't actually know the math behind shader shading and lighting and all that kind of stuff, I don't. Know what they look like. Little simple floating point programs or complicated ones. You can have 8000 instructions in a. Shader program, but I don't have a good intuition why it could be parallelized so easily. No, it's because you have 8 million pixels in every single. So when you have a light, right, that comes down the angle, you know the amount of light, like, say, this is a line of pixels across this table, right? The amount of light on each pixel is subtly different, and each pixel is. Responsible for figuring out what, figuring it out. So that pixel says, I'm this pixel. I know the angle of the light, I know the occlusion, I know the color. I am like, every single pixel here is a different color. Every single pixel gets a different amount of light. Every single pixel has a subtly different translucency. So to make it look realistic, the solution was you run a separate program on every pixel. See? But I thought there's like reflection from all over the place is every pixel. Yeah, but there is. So you build a reflection map, which also has some pixelated thing, and then when the pixel is looking at the reflection map, has to calculate what the normal of the surface is, and it does it per pixel, by the way, there's boatloads of hacks on that. You're like, you may have a lower resolution light map, reflection map. There's all these hacks. They do. But at the end of the day, it's per pixel computation. And it so happened that you can map graph like computation onto this pixel centric computation. You could do floating point programs on convolutions and matrices. And Nvidia invested for years in Cuda, first for HPC, and then they got lucky with the AI trend. But do you think they're going to essentially not be able to hardcore pivot out of their yemenite? We'll see. That's always interesting. How often do big companies hardcore pivot? Occasionally. How much do you know about Nvidia, folks? Some. Some. I'm curious as well, who's ultimately as a. Well, they've, they've innovated several times, but they've also worked really hard on mobile, they worked really hard on radios, you know, you know, they're fundamentally a GPU company. Well, they tried to pivot. There's an interesting little game and play in autonomous vehicles, right, with, or a semi autonomous, like playing with Tesla and so on, and seeing that's a dipping a toe into that kind of pivot. They came out with this platform, which was interesting technically, but it was like a 3000 watt, you know, thousand watt, $3,000 GPU platform. I don't know if it's interesting technically. It's interesting philosophically. I did. Technically. I don't know if it's the execution that craftsmanship is there. I'm not sure, but I didn't get. A sense they were repurposing GPU's for an automotive solution. Right. It's not a real pivot. They didn't, they didn't build a ground up solution. Right. Like, the chips inside Tesla are pretty cheap. Like, Mobileye has been doing this. They're, they're doing the classic work from the simplest thing. Yeah. You know, they were building 40 square millimeter chips. And Nvidia, their solution had 2800 millimeter chips and 2200 millimeter chips. And I like boatloads are really expensive drams, and it's a really different approach. The Mobileye fit the, let's say, automotive cost and form factor, and then they added features as it was economically viable. And Nvidia said, take the biggest thing and we're going to go make it work. And that's also influenced, like Waymo. There's a whole bunch of autonomous startups where they have a 5000 watt server in their trunk, but that's because they think, well, 5000 watts and $10,000 is okay because it's replacing a driver. Elon's approach was that port has to be cheap enough to put it in every single Tesla, whether they turn on autonomous driving or not, which. And Mobileye was like, we need to fit in the bomb and cost structure that car companies do. So they may sell you a gps for $1,500, but the bomb for that's like $25. Well, and for Mobile eye, it seems like neural networks were not first class citizens. Like the computation, they didn't start out. As a. Yeah, it was a cv problem. They did classic cv and found stop lights and lines and they were really good at it. Yeah. And they never, I mean, I don't know what's happening now, but they never fully pivoted. I mean, it's like, it's the Nvidia thing then, as opposed to. So if you look at the new Tesla work, it's like neural networks from the ground up, right? Yeah. And even Tesla started with a lot of CV stuff in it, and Andre has basically been eliminating it, move, move everything into the network. So without, this isn't like confidential stuff, but you sitting on a porch looking over the world, looking at the work that Andre is doing, that Elon's doing with Tesla autopilot. Do you like the trajectory of where things are going on, the hardware? They're making serious progress. I like the videos of people driving the beta stuff. Like, it's taken some pretty complicated intersections and all that, but it's still an intervention per drive. I mean, I have the current autopilot, my Tesla, I use it every day. Do you have full self driving beta or no. So you like where this is going? They're making progress. It's taken longer than anybody thought. You know, my wonder was, is hardware three? Is it enough computing? Off by two, off by five, off by ten, off by 100? Yeah. And I thought it probably wasn't enough, but they're doing pretty well with it now. And one thing is the dataset gets bigger, the training gets better, and then there's this interesting thing is you sort of train and build an arbitrary size network that solves the problem, and then you refactor the network down to the thing that you can afford to ship. So the goal isn't to build a network that fits in the phone, it's to build something that actually works. And then how do you make that most effective on the hardware you have? They seem to be doing that much better than a couple years ago. Well, the one really important thing is also what they're doing well is how to iterate that quickly. Which means, like, it's not just about one time deployment, one building, it's constantly iterating the network and trying to automate as many steps as possible. Right. And that's actually the principles of the software 2.0, like you mentioned with Andre, is it's not just. I mean, I don't know what the actual, his description of software 2.0 is, if it's just high level philosophical or their specifics. But the interesting thing about what that actually looks in the real world is it's that what I think Andre calls the data engine. It's the iterative improvement of the thing. You have a neural network that does stuff, fails on a bunch of things, and learns from it over and over and over. So you're constantly discovering edge cases. So it's very much about data engineering, figuring out. It's kind of what you were talking about with ten storm is you have the data landscape. You have to walk along that data landscape in a way that's constantly improving the neural network, and that feels like that's the central piece that's. And there's two pieces of it. You find edge cases that don't work, and then you define something that goes, get your data for that. But then the other constraint is whether you have to label it or not. Like, the amazing thing about the GPT-3 stuff is it's unsupervised. So there's essentially infinite amount of data. Now, there's obviously infinite amount of data available from cars, of people successfully driving. But the current pipelines are mostly running on labeled data, which is human limited. So when that becomes unsupervised, it'll create unlimited amount of data, which then they'll scale. Now, the networks that may use that data might be way too big for cars, but then there'll be the transformation from, now we have unlimited data. I know exactly what I want. Now can I turn that into something that fits in the car? And that process is going to happen all over the place every time you get to the place where you have unlimited data. And that's what software 2.0 is about, unlimited data training networks, to do stuff without humans writing code to do it. And ultimately also trying to discover, like you're saying, the self supervised formulation of the problem. So the unsupervised formulation of the problem. Like, you know, in driving, there's this really interesting thing, which is you look at a scene that's before you, and you have data about what a successful human driver did in that scene, you know, 1 second later, it's a little piece of data that you can use, just like with GPT-3 as training currently, even though Tesla says they're using that, it's an open question to me. How much, how far can you, can you solve all of the driving with just that self supervised piece of data? And, like, I think that's what common AI is doing. That's what common AI is doing. But the question is how. How much data? So what Kamei doesn't have is as good of a data engine, for example, as Tesla does. That's where the, like, the organization of the data. I mean, as far as I know, I haven't talked to George, but they do have the data. The question is how much data is needed, because we say infinite very loosely here. And then the other question, which you said, I don't know if you think it's still an open question, is, are we in the right order of magnitude for the compute necessary? That is this is it like what Elon said, this chip that's in there now is enough to do full self driving or doing another order of magnitude? I think nobody actually knows the answer to that question. I like the confidence that Elon has. But, yeah, we'll see. There's another funny thing, is you don't learn to drive with infinite amounts of data. You learn to drive with an intellectual framework that understands physics and color and horizontal surfaces and laws and roads, and all your experience from manipulating your environment. There's so many factors go into that. So then, when you learn to drive, driving is a subset of this conceptual framework that you have. Self driving cars right now, we're teaching them to drive with driving data. You never teach a human to do that. You teach a human all kinds of interesting things, like language, like, don't do that. You know, watch out, you know, there's all kinds of stuff going on. Well, this is where you, I think previous time we talked about where you poetically disagreed with my naive notion about humans. I just think that humans will make this whole driving thing really difficult. Yeah, all right. I said humans don't move that slow. It's a ballistics problem. It's a ballistic. Humans are a ballistics problem, which is like poetry to me. It's very, it's very possible that in driving there, indeed, purely a ballistics problem. I, and I think that's probably the right way to think about it. But I still, they still continue to surprise me. Those damn pedestrians, the cyclists, other humans and other cars. And. Yeah, but it's going to be one of these compensating things. So when you're driving, you have an intuition about what humans are going to do, but you don't have 360 cameras and radars, and you have an attention problem. So the self driving car comes in with no attention problem, 360 cameras, a bunch of other features. So they'll wipe out a whole class of accidents. And emergency braking with radar, and especially as it gets AI enhanced, will eliminate collisions. Yeah, right. But then you have the other problems of these unexpected things where, you know, you think your human intuition is helping. But then the cars also have, you know, a set of hardware features that you're not even close to. And the key thing, of course, is if you wipe out a huge number of kind of accidents, then it might be just way safer than a human driver. Even though. Even if humans are still a problem, that's hard to figure out. Yeah, that's probably what will happen, is autonomous cars will have a small number of accidents humans would have avoided, but they'll wipe. They'll get rid of the bulk of them. What do you think about Tesla's dojo efforts? Or it can be bigger than Tesla in general. It's kind of like the tense torrent trying to innovate. This is the dichotomy. Should a company try to, from scratch, build its own neural network training hardware? Well, first, I think it's great. So we need lots of experiments, right? And there's lots of startups working on this, and they're pursuing different things. I was there when we started dojo, and it was sort of like, what's the unconstrained computer solution to go do very large training problems? And then there's fun stuff like, you know, we said, well, we have this 10,000 watt board to cool. Well, you go talk to guys at SpaceX, and they think 10,000 watts is a really small number, not a big number. Yeah. And there's brilliant people working on it. I'm curious to see how it'll come out. I couldn't tell you. I know. It pivoted a few times since I left. The cooling doesn't seem to be a big problem. I do like what Elon said about it, which is like, we don't want to do the thing unless it's way better than the alternative, whatever the alternative is. So it has to be way better than, like, racks or GPU's. Yeah. And the other thing is, just like the Tesla autonomous driving hardware, it was only serving one software stack, and the hardware team and the software team were tightly coupled. If you're building a general purpose AI solution, and there's so many different customers with so many different needs now, something Andre said is, I think this is amazing. Ten years ago, vision, recommendation language, were completely different disciplines. He said, the people literally couldn't talk to each other. And three years ago, it was all neural networks. But they're very different neural networks. And recently, it's converging on one set of networks. They vary a lot in size, obviously, they vary in data, vary in outputs, but the technology has converged a good bit. Yeah. These transformers behind GPT-3 it seems like they could be applied to video, they could be applied to a lot of. And they're all really. It was like to literally replace letters with pixels. It does vision. It's amazing. And then size actually improves the thing. So the bigger it gets, the more compute you throw at it, the better it gets. And the more data you have, the better it gets. So then you start to wonder, well, is that a fundamental thing, or is this just another step to some fundamental understanding about this kind of computation? Which is really interesting. Us humans don't want to believe that that kind of thing will achieve conceptual understandings. You were saying, like, you'll figure out physics, but maybe it will. Maybe. Probably will. Well, it's worse than that. It'll understand physics in ways that we can't understand. I like your Stephen Wolfram talk where he said, there's three generations of physics. There was physics by reasoning. Well, big things should fall faster than small things, right? That's reasoning. And then there's physics by equations, like, you know. But the number of programs in the world that are solved with the single equation is relatively low. Almost all programs have, you know, more than one line of code, maybe 100 million lines of code. So he said then, now we're going to physics by equation, which is his project, which is cool. I might point out that there was two generations of physics before reasoning habit. Like all animals, you know? No things fall and birds fly and, you know, predators know how to, you know, solve a differential equation to cut off a accelerating, you know, curving animal path. And then there was, you know, the gods did it, right? So. Yeah, right, so there was, you know, there's five generations now. Software 2.0 says programming things is not the last step data. So there's going to be a physics bass Stevens Wolfram's compensation that's not explainable to us humans. And actually, there's no reason that I can see, well, that even that's the limit. Like, there's something beyond that. I mean, they're usually like, usually when you have this hierarchy, it's not like, well, if you have this step and this step and this step, and they're all qualitatively different and conceptually different, it's not obvious why, you know, six is the right number of hierarchy steps and not seven or eight or. Well, then it's probably impossible for us to, to comprehend something that's beyond the thing that's not explainable. Yeah, but the thing. But the thing that, you know, understands the thing that's not explainable to us will conceive the next one. And, like, I'm not sure why there's a limit to it. Click. Your brain hurts. That's a sad story. If we look at our own brain, which is an interesting, illustrative example. In your work with testorrent and trying to design deep learning architectures, do you think about the brain at all? Maybe from a hardware designer perspective, if you could change something about the brain, what would you change or do? Funny question. How would you do? So, your brain is really weird. Like your cerebral cortex, where we think we do most of our thinking, is what, like six or seven neurons thick? Yeah, like, that's weird. Like, all the big networks are way bigger than that. Like, way deeper. So that seems odd. And then, you know, when you're thinking, if it's. If the input generates a result, you can lose, it goes really fast, but if it can't, that generates an output that's interesting, which turns into an input and then your brain to the point where you mold things over for days and how many trips through your brain is that? Right? Like it's 300 milliseconds or something to get through seven levels of neurons. I forget the number. Exactly. But then it does it over and over and over as it searches. And the brain clearly looks like some kind of graph because you have a neuron with connections and it talks to other ones and it's locally very computationally intense, but it also does sparse computations across a pretty big area. There's a lot of messy biological type of things, and it's. It's meaning, like, first of all, there's mechanical, chemical, and electrical signals. That's all that's going on. Then there's the asynchronicity of signals, and there's, like, there's just a lot of variability that seems continuous and messy and just a mess of biology. And it's unclear whether that's a good thing or it's a bad thing, because if it's a good thing, then we need to run the entirety of the evolution. Well, we're gonna have to start with basic bacteria to create something. Imagine we could control. You could build a brain with ten layers. Would that be better or worse or more more connections or less connections? Or, you know, we don't know to what level our brains are optimized. But if I was changing things, like, yeah, like, you know, you can only hold, like, seven numbers in your head? Yeah, like, why not 100 or a million? Never thought of that. And why can't, like, why can't we have, like, a floating point processor that can compute anything we want, like, and see it all properly? That would be kind of fun. And why can't we see in four or eight dimensions? 3d is kind of a drag. Like, all the hard mass transforms are up in multiple dimensions. So you could imagine a rain architecture that you could enhance with a whole bunch of features that would be really useful for thinking about things. It's possible that the limitations you're describing are actually essential for, like, the constraints are essential for creating, like, the depth of intelligence, like that, the ability to reason, you know? Yeah, it's hard to say because, like, your brain is clearly a parallel processor, you know? Yeah. You know, 10 billion neurons talking to each other at a relatively low clock rate, but it produces something that looks like a serial thought process. It's a serial narrative in your head. I. That's true. But then there are people, famously, who are visual thinkers. Like, I think I'm a relatively visual thinker. I can imagine any object and rotate it in my head and look at it, and there are people who say they don't think that way at all. And recently I read an article about people who say they don't have a voice in their head. They can talk, but when they, you know, it's like, well, what are you thinking? They'll describe something that's visual. So that's curious. Now, if you're saying if we dedicated more hardware to holding information, like ten numbers or a million numbers, would that distract us from our ability to form this kind of singular identity? Like it dissipates somehow. Right, but maybe future humans will have many identities that have some higher level organization, but can actually do lots more things in parallel. Yeah, there's no reason, if we're thinking modularly, there's no reason we can't have multiple consciousnesses in one brain. Yeah, and maybe there's some way to make it faster so that the area of the computation could still have a unified feel to it while still having way more ability to do parallel stuff the same time. Could definitely be improved. Could be improved. Yeah. Well, it's pretty good right now, actually. People don't give it enough credit. The thing is pretty nice. The fact that the ride ends seemed to be given nice spark of beauty to the whole experience. I don't know. I don't know if it can be improved easily. It could be more beautiful. I don't know how I. Yeah. What do you mean, how? All the ways you can't imagine. No, but that's the whole point. I wouldn't be able to. The fact that I can imagine ways in which it could be more beautiful. Means, you know, Ian Banks, his stories. So the super smart AI's there live, mostly live in the world of what they call infinite fun, because they can create arbitrary worlds, so they interact, and, you know, the story has it, they interact in the normal world, and they're very smart, and they can do all kinds of stuff. And, you know, a given mind can, you know, talk to a million humans at the same time. Because we're very slow and for reasons, you know, artificial, they're interested in people and doing stuff, but they mostly live in this, this other land of thinking. My inclination is to think that the ability to create infinite fun will will not be so fun. That's sad. Why? There's so many things to do. Imagine being able to make a star move planets around. Yeah, yeah, but because we can imagine. That is why life is fun. If we can, if we actually were able to do it, it'd be a slippery slope where fun wouldn't even have a meaning, because we just consistently desensitize ourselves by the infinite amounts of fun we're having. The sadness, the dark stuff, is what makes it fun. I think that could be the russian. Could be the fun makes it fun, and the sadness makes it bittersweet. Yeah, that's true. Fun could be the thing that makes it fun. So what do you think about the expansion not through the biology side, but through the BCI, the brain computer interfaces. Yeah, you got a chance to check out the neuralink stuff. It's super interesting. Like, like humans, like, like our thoughts to manifest as action, you know, like, like, as a kid, you know, like, shooting a rifle was super fun, driving a mini bike, doing things. And then computer games, I think for a lot of kids became the thing where they, you know, they can do what they want, they can fly a plane, they can do this, they can do this. Right. But you have to have this physical interaction. Now imagine, you know, you could just imagine stuff and it happens, right? Like really richly and interestingly, like, we kind of do that when we dream. Like, dreams are funny because, like, if you have some control or awareness in your dreams, like, it's very realistic looking or not realistically, depends on the dream, but you can also manipulate that. And what's possible there is odd. And the fact that nobody understands it's hilarious. But do you think it's possible to expand that capability through computing? Sure. Is there some interesting. So from a hardware designer perspective, is there, do you think it'll present totally new challenges in the kind of hardware required that, like. So this hardware isn't standalone computing. Well, this is not working with the brain. So today computer games are rendered by GPU's and, but you've seen the gans stuff where trained neural networks render realistic images, but there's no pixels, no triangles, no shaders, no lightmaps, no nothing. So the future of graphics is probably AI. Yes. Now that AI is heavily trained by lots of real data. So if you have an interface with AI renderer. So if you say render a cat, it won't say, well, how tall is the cat and how big it, you know, it'll render a cat. And you might say, well, a little bigger, a little smaller, you know, make it a tabby shorter hair. Like, you could tweak it. Like, the amount of data you'll have to send to interact with a very powerful AI renderer could be low. But the question is, brain computer interfaces would need to render not onto a screen, but render onto the brain. And like directly. So there's a bandwidth. Well, it could do it both ways. I mean, our eyes are really good sensors. It could render onto a screen, and we could feel like we're participating in it. You know, they're gonna, they're gonna have, you know, like the oculus kind of stuff. It's gonna be so good. When a projection to your eyes, you think it's real. You know, they're slowly solving those problems. And I suspect when the renderer of that information into your head is also AI mediated, they'll be able to give you the cues that you know you really want for depth and all kinds of stuff. Like your brain is partly faking your visual field. Right. Like, your eyes are twitching around, but you don't notice that occasionally they blank. You don't notice that. You know, there's all kinds of things, like you think you see over here, but you don't really see there. It's all fabricated. Yeah. So peripheral vision is fascinating. So if you have an AI renderer that's trained to understand exactly how you see and the kind of things that enhance the realism of that experience could be super real, actually. So I don't know what the limits to that are, but obviously, if we have a brain interface that goes in, inside your, you know, visual cortex in a better way than your eyes do, which is possible, it's a lot of neurons. Yeah, maybe that'll be even cooler. But the really cool thing is it has to do with the. The infinite fun that you're referring to, which is our brains seem to be very limited, and like you said, computations. So. Very plastic. Very plastic, yeah. Yeah. So it's a. It's a interesting combination. The interesting open question is the limits of that neuroplasticity. Like, how flexible is that thing? Because we haven't really tested it. We know about that. The experiments where they put a pressure pad on somebody's head and had a visual transducer pressurize it, and somebody slowly learned to see. Yep. Especially at a young age, if you throw a lot at it, like, what? What can it. Can it completely? So can you arbitrarily expand it with computing power so connected to the Internet directly somehow? Yeah, the answer is probably yes. So the problem with biology and ethics is, like, there's a mess there. Like us, humans are perhaps unwilling to take risks into directions that are full of uncertainty. So it's like 90% of the population is unwilling to take risks. The other 10% is rushing into the risks unaided by any infrastructure whatsoever. And that's where all the fun happens in society. There's been huge transformations in the last couple thousand years. Yeah. It's funny. I gotten the chance to interact with this Matthew Johnson from Johns Hopkins. He's doing this large scale study of psychedelics. It's becoming more and more I've gotten a chance to interact with that community of scientists working on psychedelics. But because of that, that opened the door to me to all these, what do they call it? Psychonauts. The people who, like you said, the 10% who are like, I don't care. I don't know if there's a science behind this. I'm taking the spaceship. If I'm be the first on Mars, I'll be psychedelics. Interesting in the sense that in another dimension, like you said, it's a way to explore the. With the limits of the human mind. Like, what is this thing capable of doing? Because you kind of, like, when you dream, you detach it. I don't know exactly the neuroscience of it, but you detach your, like, reality from what your mind, the images your mind is able to conjure up, and your mind goes into weird places and, like, entities appear somehow. Freudian type of, like, trauma is probably connected in there somehow, but you start to have, like, these weird, vivid worlds that, like. So do you actively dream? Do you? Why not? I have, like, six, 6 hours of dreams, and I. It's like, really useful time. I know. I don't, I haven't, I don't. For some reason, I just knock out and I have sometimes, like, anxiety inducing, kind of, like, very pragmatic, like, nightmare type of dreams, but not. Nothing fun. Nothing. Nothing fun. Nothing fun. I try. I unfortunately have mostly have fun in the waking world, which is very limited in the amount of fun you can have. It's not that limited either. Yeah. That's why we'll have to talk. Yeah, I need instructions. Yeah, there's like a manual for that. You might want to. I'll look it up. I'll ask Elon, what would you dream. Of, you know, years ago? And I read about, you know, like, you know, a book about how to have, you know, become aware in your dreams. I worked on it for a while. Like, there's this trick about, you know, imagine you can see your hands and look out and. And I got somewhat good at it. Like, but my, mostly when I'm thinking about things or working on problems, I prep myself before I go to sleep. It's like I pull into my mind all the things I want to work on or think about, and then that, let's say, greatly improves the chances that I'll work on that while I'm sleeping. And then I also basically asked to remember it. And I often remember very detailed within. The dream or outside the dream to. Bring it up in, in my dreaming and then to remember it when I wake up. It's just, it's more of a meditative practice to say, you know, to prepare yourself to do that. Like, if you go to, you know, to sleep still gnashing your teeth about some random thing that happened that you're not that really interested in, you'll dream about it. That's really interesting. Maybe, but. But you can direct your dreams somewhat by prepping. Yeah, I'm gonna have to try that. It's really interesting. Like the most important, the interesting. Not like, what, did this guy send an email? Kind of like stupid worry stuff, but like fundamental problems. You're actually concerned about prepping and interesting. Things you're worried about or books you're reading or some great conversation you had or some adventure you want to have. There's a lot of space there, and it seems to work that my percentage of interesting dreams and memories went up. Is that the source of, if you were able to deconstruct where some of your best ideas came from, is there a process that's at the core of that? Some people walk and think, some people in the shower, the best ideas hit them. If you talk about like, Newton Apple hitting them on the head. No, I found out a long time ago. I process things somewhat slowly. So, like, in college, I had friends that could study at the last minute, get an a next day. I can't do that at all. So I always front loaded all the work, like, I do all the problems early, you know, for finals, like the last three days, I wouldn't look at a book because I want, you know. Cause like a new fact day before finals may screw up my understanding of what I thought I knew. So my goal was to always get it in and give it time to soak. And I used to, you know, I remember when we were doing like, 3d calculus, I would have these amazing dreams of 3d surfaces with normal, you know, calculating the gradient. And this is like, all come up. So it was really fun, like, very visual. And, and if I got cycles of that, that was useful. And the other is just don't over filter your ideas. Like, I like that process of brainstorming where lots of ideas can happen. I like people who have lots of ideas and they sit, then there's a. Yeah, I let them sit and let it breathe a little bit and then reduce it to practice. Like, at some point you really have to. Does it really work? Like, is this real or not? Right, but you have to do both. There's creative tension there. Like, how do you be both open and, you know, precise? Have you had ideas that you just, that sit in your mind for like, years before the. Sure, that's, it's an interesting way to generate ideas and just let them sit. Let them sit there for a while. I think I have a few of those ideas. Yeah, that was so funny. Yeah, I think that's, you know, creativity. Discipline or something for the slow thinkers in the, in the room, I suppose, as I. Some people, like you said, are just like, like the. Yeah, it's really interesting. There's so much diversity in how people think, you know, how fast or slow they are, how well they remember or don't look. You know, I'm not super good at remembering facts, but processes and methods, like in our engineering. I went to Penn State and almost all our engineering tests were open book. I could remember the page and not the formula, but as soon as I saw the formula, I could remember the whole method if I learned it. So it's a funny where some people could swatch friends flipping through the book, trying to find the formula, even knowing that they'd done just as much work. And I would just open the book. It's on page 27, bottom half. I could see the whole thing visually. Yeah. And you have to learn that about yourself and figure out what function optimally. I had a friend who was always concerned. He didn't know how he came up with ideas. He had lots of ideas, but he said they just sort of popped up. Like you'd be working on something, having this idea, like, where does it come from? But you can have more awareness of it. Like how your brain works is a little murky as you go down from the voice in your head or the obvious visualizations. Like when you visualize something, how does that happen? Yeah, you know, if I say, you know, visualize volcano, it's easy to do. Right. And what does it actually look like when you visualize it? I can visualize to the point where I don't see very much out of my eyes and I see the colors of the thing I'm visualizing. Yeah, but there's like, there's a shape, there's a texture, there's a color, but there's also conceptual visualization. Like, what are you actually visualizing when you're visualizing volcano? Just like with peripheral vision, you think you see the whole thing. Yeah, yeah, that's a good way to say it. You know, you have this kind of almost peripheral vision of your visualizations. They're like these ghosts. But if, you know, if you, if you work on it, you can get a pretty high level of detail and. Somehow you can walk along those visualizations and come up with an idea, which. Is weird, but when you're thinking about solving problems, like, you're putting information in, you're exercising the stuff you do know. You're sort of teasing the area that's you don't understand and don't know, but you can almost, you know, feel, you know, that process happening. You know, that's, that's how I like, like, I know sometimes when I'm working really hard on something, like, like, I get really hot when I'm sleeping, and, you know, it's like, we got the blankets roll. I wake up, all the blankets are on the floor, and, and, you know, every time it's. Well, I wake up and think, wow, that was great. You know? Are you able to reverse engineer what the hell happened there? Oh, sometimes it's vivid dreams, and sometimes it's just kind of, like you say, like, shadow thinking that you sort of have this feeling you're, you're going through this stuff, but it's, it's not that obvious. Isn't that so amazing at the mind just does all these little experiments. I never, you know, I thought, I always thought it's like a river that you can't, you're just there for the ride. But you're right. If you prep it. No, it's all understandable. Meditation really helps. You got to start figuring out, you need to learn the language of your own mind. And there's multiple levels of it. But the abstractions again, right. It's somewhat comprehensible and observable and feelable, or whatever the right word is. Yeah. You're not along for the ride. You are the ride. I have to ask you, hardware engineer working on neural networks now, what's consciousness? What the hell is that thing? Is that just some little weird quirk of our particular computing device? Or is it something fundamental that we really need to crack open if we're to build good computers? Do you ever think about consciousness? Like, why it feels like something to be. I know, it's really weird. So, yeah, I mean, everything about it is weird. First, it's a half a second behind reality, right? It's a post hoc narrative about what happened. You've already done stuff by the time you're conscious of it, and your consciousness generally is a single threaded thing, but we know your brain is 10 billion neurons running some crazy parallel thing, and there's a really big sorting thing going on there. It also seems to be really reflective in the sense that you create a space in your head. We don't really see anything? Photons hit your eyes. It gets turned into signals. It goes through multiple layers, the neurons. I'm so curious. That looks glassy. And that looks not glassy, how the resolution of your vision is so high, you have to go through all this processing where for most of it, it looks nothing like vision. Like there's no theater in your mind, right? So we have a world in our heads. We're literally just isolated behind our sensors, but we can look at it, speculate about it, speculate about alternatives, problem solve. What if, you know, there's so many things going on, and that process is. Lagging reality, and it's single threaded, even though the underlying thing is massively parallel. So it's so curious. So imagine you're building an AI computer. If you wanted to replicate humans, well, you'd have huge arrays of neural networks and apparently only six or seven deep, which, hilarious, they don't even remember seven numbers, but I think we can upgrade that a lot. And then somewhere in there, you would train the network to create basically the world you live in. Right? So, like, tell stories to itself about the world that it's perceiving. Well, create this. Create the world, tell stories in the world, and then have many dimensions of, you know, like, sideshows to it. Like, we have an emotional structure, like we have a biological structure, and that seems hierarchical too. Like, if you're hungry, it dominates your thinking. If you're mad, it dominates your thinking. And we don't know if that's important to consciousness or not, but it certainly disrupts intrudes in the consciousness. So there's lots of structure to that. And we like to dwell on the past. We like to think about the future. We like to imagine, we like to fantasize. And the somewhat circular observation of that is the thing we call consciousness. Now, if you created a computer system that did all things, create worldviews, created future alternate histories, you know, dwelled on past events, you know, accurately or semi accurately, you know, it's. It's. Will consciousness just spring up like natural? Well, would that feel, look and feel conscious to you? Like, you seem conscious to me, but I observer sense. Do you think a thing that looks conscious is conscious? Like, do you? Again, this is like an engineering kind of question, I think, because, like, if we want to engineer consciousness, is it okay to engineer something that just looks conscious, or is it, is there a difference between. Well, we evolve consciousness because it's a super effective way to manage our affairs. Yeah, right. Social element. Yeah. Well, it gives us a planning system, you know, we have a huge amount of stuff. Like, when we're talking, like, the reason we can talk really fast is we're modeling each other a really high level. Of detail, and consciousness is required for that. Well, all those components together manifest consciousness. Right. So if we make intelligent beings that we want to interact with, that we're like, you know, wondering what they're thinking, you know? You know, looking forward to seeing them, you know, when they interact with them, they. They're interesting, surprising, you know, fascinating. You know, they will probably. We feel conscious like we do, and we'll. We'll perceive them as conscious. I don't know why not, but you never know. Another fun question on this, because from a computing perspective, we're trying to create something that's human like or superhuman like. Let me ask you about aliens. Aliens. Do you think there's intelligent alien civilizations out there? And do you think there technology, their computing, their AI bots, their chips are of the same nature as ours? I have no idea. I mean, if there's lots of aliens out there, they've been awfully quiet. There's speculation about why there seems to be more than enough planets out there. There's a lot. Yeah. There's intelligent life on this planet that seems quite different. You know, like, you know, dolphins seem like plausibly understandable. Octopuses don't seem understandable at all. If they live longer than a year, maybe they would be running the planet. They seem really smart, and their neural architecture is completely different than ours. Now, who knows how they perceive things? I mean, that's the question is for us intelligent beings, we might not be able to perceive other kinds of intelligence if they become sufficiently different than us. Yeah. We live in the current constrained world. You know, it's three dimensional geometry, and the geometry defines a certain amount of physics. And, you know, there's like, how time work seems to work. Like, there's so many things that seem like a whole bunch of the input parameters to the, you know, another conscious being are the same. Yes. Like, if it's biological, biological things seem to be in a relatively narrow temperature range, right? Because, you know, organics don't. Aren't stable, too cold or too hot. So if you specify the list of things that input to that. But as soon as we make really smart beings and they go solve about how to think about a billion numbers at the same time and how to think in n dimensions, there's a funny science fiction book where all the society had uploaded into this matrix. And at some point, some of the beings in the matrix thought, I wonder if there's intelligent life out there. So they had to do a whole bunch of work to figure out how to make a physical thing because their matrix was self sustaining, and they made a little spaceship and they traveled to another planet. When they got there, there was life running around, but there was no intelligent life. And then they figured out that there was these huge organic matrix all over the planet inside there, where intelligent beings had uploaded themselves into that matrix. So everywhere intelligent life was, soon as it got smart, it up leveled itself into something way more interesting than 3d geometry. Yeah, it escaped whatever this upload was better. The essence of what we think of as an intelligent being. I tend to like the thought experiment of the organism. Like humans aren't the organisms. I like the notion of Richard Dawkins and memes that ideas themselves are the organisms that are just using our minds to evolve. So we're just meat receptacles for ideas to breed and multiply and so on. And maybe those are the aliens. So Jordan Peterson has lined, says, you think you have ideas, but ideas have you? Yeah. Right. And then we know about the phenomenon of groupthink, and there's so many things that constrain us. But I think you can examine all that and not be completely owned by the ideas and completely sucked into groupthink. And part of your responsibility as a human is to escape that kind of phenomena, which isn't a, you know, it's, you know, it's, it's one of the creative tension things. Again, you're constructed by it, but you can still observe it and you can think about it, and you can make choices about, to some level how constrained you are by it. And, you know, it's useful to do that. And, but, but they're at the same time, and it could be by doing that, you know, the group and society you're part of becomes collectively even more interesting. So, you know, so the outside observer will think, wow, you know, all these Lexus running around with all these really independent ideas have created something even more interesting in the aggregate. So. So I don't know, I'm, those are lenses to look at the situation, but give you some inspiration. But I don't think they're constraints. Right. As a small little quirk of history, it seems like you're related to Jordan Peterson. Like you mentioned, he's going through some rough stuff. Now. Is there some comment you can make about the roughness of the human journey, the ups and downs? Well, I became an expert in Benzod withdrawal, like, which is you took benzodiazepines, and at some point, they interact with Gaba circuits, you know, to reduce anxiety and do a hundred other things. Like, there's actually no known list of everything they do because they interact with so many parts of your body. And then once you're on them, you habituate to them, and you're, you're. You have a dependency. It's not like you're a drug dependency where you're trying to get high. It's a yemenite, it's a metabolic dependency. And then if you discontinue them, there's a funny thing called kindling, which is if you stop them and then go, you know, you'll have a horrible thrall symptoms, and if you go back on them at the same level, you won't be stable. And that, unfortunately, happened to him, because. It'S so deeply integrated into all the kinds of systems in the body, it. Literally changes the size and numbers of neurotransmitter sites in your brain. Yeah. So there's a, there's a process called the Ashton protocol, where you taper it down slowly. Over two years, the people go through that, go through unbelievable hell. And what Jordan went through seemed to be worse, because on advice of doctors, you know, well, stop taking these and take this. It was a disaster. And he got some. Yeah, it was pretty tough. Um, he seems to be doing quite a bit better intellectually. You can see his brain clicking back together. I spent a lot of time with, I've never seen anybody suffer so much. Well, his brain is also, like this powerhouse. Right? So I wonder, does a brain that's able to think deeply about the world suffer more through these kinds of withdrawals? Like, I don't know, I've watched videos of people going through withdrawal. They, they all seem to suffer unbelievably. And, you know, my heart goes out to everybody. And there's some funny math about this. Some doctor said, as best he can tell, there's the standard recommendations, don't take them for more than a month and then taper over a couple of weeks. Many doctors prescribe them endlessly, which is against the protocol, but it's common. And then something like 75% of people, when they taper, it's. Half the people have difficulty, but 75% get off okay, 20% have severe difficulty, and 5% have life threatening difficulty. And if you're one of those, it's really bad. And the stories that people have on this is heartbreaking and tough. So you put some of the fault at the doctors they just not know what the hell they're doing. Oh, no. It's hard to say. It's one of those commonly prescribed things. Like one doctor said, what happens is, if you're prescribed them for a reason, and then you have a hard time getting off the protocol basically says you're either crazy or dependent, and you get kind of pushed into a different treatment regime. You're a drug addict or a psychiatric patient. And so, like one doctor said, you know, I prescribed them for ten years, thinking I was helping my patients, and I realized I was really harming them. And, you know, the awareness of that is slowly coming up. The fact that they're casually prescribed to people is horrible, and it's bloody scary. And some people are stable on them, but they're on them for life. Like, once you know it's another one of those drugs. But benzos, long range, have real impacts on your personality. People talk about the benzo bubble, where you get disassociated from reality and your friends a little bit. It's really terrible. The mind is terrifying. We're talking about how the infinite possibility of fun, but, like, it's the infinite possibility of suffering, too, which is one of the dangers of, like, expansion of the human mind. It's like, I wonder if all the possible human experiences that an intelligent computer can have, is it mostly fun or is it mostly suffering? So, like, if you. If you brute force expand the set of possibilities, like, are you going to run into some trouble in terms of torture and suffering and so on? Maybe our human brain is just protecting us from much more possible pain and suffering. Maybe the space of pain is much larger than we could possibly imagine. The world's in a balance. All the literature on religion and stuff, the struggle between good and evil is balanced, very finely tuned for reasons that are complicated. But that's a long philosophical conversation. Speaking of balance, that's complicated, I wonder, because we're living through one of the more important moments in human history with this particular virus. It seems like pandemics have at least the ability to kill off most of the human population at their worst. And there's just fascinating, because there's so many viruses in this world. There's so many. I mean, viruses basically around the world in the sense that they've been around very long time. They're everywhere. They seem to be extremely powerful in a distributed kind of way, but at the same time, they're not intelligent and they're not even living. Do you have high level thoughts about this virus that, like, in terms of, you being fascinated or terrified or somewhere in between. So I believe in frameworks, right? So, like, one of them is evolution. Like, we're evolved creatures, right? Yes. And one of the things about evolution is it's hyper competitive. And it's not competitive out of a sense of evil. It's competitive in a sense of there's endless variation and variations that work better when. And then over time, there's so many levels of that competition. You know, like multicellular life partly exists because of the competition between different kinds of life forms. And we know sex partly exists to scramble our genes so that we have genetic variation against the invasion of the bacteria and the viruses, and it's endless. I read some funny statistic. The density of viruses and bacteria in the ocean is really high, and one third of the bacteria die every day because the viruses invading them, like, one third of them. Wow. Like, I don't know if that number is true, but it was like, there's like, the amount of competition and what's going on is stunning. And there's a theory as we age, we slowly accumulate bacterias and viruses. And as our immune system kind of goes down, you know, that's what slowly kills us. And it just feels so peaceful from a human perspective when we sit back and are able to have a relaxed conversation and there's wars going on out there. Like right now, you're harboring how many bacteria? The ones. Many of them are parasites on you, and some of them are helpful, and some of them are modifying your behavior, and some of them are. It's really wild. But this particular manifestation is unusual in the demographic how it hit and the political response that it engendered and the healthcare response it engendered. Technology. It's gendered. It's kind of wild. Yeah. The communication on Twitter that it led every level, all that kind of stuff at every. Every single level. Yeah. But what usually kills life? The big extinctions are caused by meteors and volcanoes. That's the one you're worried about as opposed to human created bombs that we. Solar flares are another good one. You know, occasionally solar flares hit the planet. So it's nature. Yeah, it's all pretty wild. Another historic moment. This is perhaps outside, but perhaps within your space of frameworks that you think about. That just happened, I guess, a couple weeks ago, is, I don't know if you're paying attention at all, is the GameStop and Wall street bets. So it's really fascinating. There's kind of a theme to this conversation today because it's like neural networks. It's cool how there's a large number of people in a distributed way almost having a kind of fun. We're able to take on the powerful elites, elite hedge funds, centralized powers and overpower them. Do you have thoughts on this whole saga? I don't know enough about finance, but it was like the Elon Robinhood guy. When they talked, what did you think about that? Well, the Robinhood guy didn't know how the finance system worked. That was clear. He was treating the people who settled the transactions as a black box. And suddenly somebody called him up and said, hey, black box calling you, your transaction volume means you need to put up $3 billion right now. And he's like, I don't have $3 billion. Like, I don't even make any money on these trades. Why do I owe $3 billion while you're sponsoring a trade? So there was a set of abstractions that I don't think either. Now you understand it. This happens in chip design. You buy wafers from TSMC or Samsung or intel, and they say it works like this, and you do your design based on that, and then chip comes back and doesn't work, and then suddenly you start having to open the black boxes. Transistors really work. Like they said, what's the real issue? So there's a whole set of things that created this opportunity, and somebody spotted it. Now, people spot these kinds of opportunities all the time. There's been flash crashes, there's been short squeezes are fairly regular. Every CEO I know hates the shorts because they're manipulating. Theyre trying to manipulate their stock in a way that they make money and deprive value from both the company and the investors. So the fact that some of these stocks were so short, its hilarious that this hasnt happened before. I dont know why. And I dont actually know why some serious hedge funds didnt do it to other hedge funds. And some of the hedge funds actually made a lot of money on this. Yes. So my guess is we know 5% of what really happened, and that a lot of the players don't know what happened. And people who probably made the most money aren't the people that they're talking about. Yeah, that's. Do you think there was something, I mean, this is the cool kind of Elon, you're the same kind of conversationalist, which is like, first principles, questions of, like, what the hell happened? Just very basic questions of, like, was there something shady going on? What, you know, who are the parties involved? This is the basic questions that everybody wants to know about. Yeah. So, like, we're in a very competitive, hyper competitive world, right. But transactions like buying and selling stock is a trust event. You know, I trust the company representing themselves properly. You know, I bought the stock because I think it's going to go up. I trust that the regulations are solid. Now, inside of that, there's all kinds of places where humans over trust and this exposed, let's say, some weak points in the system. I don't know if it's going to get corrected. I don't know if we have close to the real story. My suspicion is we don't. And listen to that guy. He was a little wide eyed about, and then he did this and then they did that. And I was like, I think you should know more about your business than that. But again, there's many businesses when like, this layer is really stable, you stop paying attention to it. You pay attention to the stuff that's bugging you or new. You don't pay attention to the stuff that just seems to work all the time. You just, you know, sky's blue every day. California. And every once in a while it rains and everybody's like, what do we do? Somebody go bring in the lawn furniture, you know, like, it's getting wet. We don't know why it's getting wet. Yeah, it doesn't. I was blue for like 100 days and now it's, you know, so. But part of the problem here with Vlad, this, the CEO of Robinhood, is the scaling, is that what they've been talking about is there's a lot of unexpected things that happen with the scaling, and you have to be. I think the scaling forces you to then return to the fundamentals. Well, it's interesting because when you buy and sell stocks, the scaling is the stocks to only move in a certain range. And if you buy a stock, you can only lose that amount of money on the short market, you can lose a lot more than you can benefit. It has a weird cost function or whatever the right word for that is. He was trading in a market where he wasn't actually capitalized for the downside if it got outside a certain range. Now, whether something nefarious has happened, I have no idea. But at some point, the financial risk to both him and his customers was way outside of his financial capacity. And his understanding how the system work was clearly weak or he didn't represent himself. I don't know. The person, when I listened to him, it could have been the surprise question was like. And then these guys called and you know, it sounded like he was treating stuff as a black box. Maybe he shouldn't have, but maybe as a whole pilot expert somewhere else that knew what's going on. I don't, I don't know. Yep. I mean, this is, uh, this is one of the qualities of a good leader is under fire. You have to perform, and that means to think clearly and to speak clearly. And he dropped the ball on those things because, and understand the problem quickly. Learn and understand the problem at, like, at the, like, basic level, like, what the hell happened? And my guess is, you know, at some level, it was amateurs trading against, you know, experts slash insiders slash people with, you know, special information. Outsiders VerSus insiders. Yeah. And the Insiders, you know, my guess is the next time this happens, we'll make money on it. The insiders always win. Well, they have more tools and more incentive. I mean, this always happens. Like, the outsiders are doing this for fun. The Insiders are doing this 24/7 but. There'S numbers in the Outsiders. This is the interesting thing. Well, there's numbers on the Insiders, too. Like different kind of numbers. Different kind of numbers. But this could be a new era because I don't know, at least I didn't expect that a bunch of Redditors could, you know, there's, you know, millions of people get together. The next one won't be a surprise. But don't you think the crowd, the people are planning the next attack? We'll see, but it has to be a surprise. Can't be the same game. As to the like. It could be there's a very large number of games to play and they can be agile about it. I don't know. I'm not an expert. Right. That's a good question. The space of games, how restricted is it? Yeah. And the system is so complicated, it could be relatively unrestricted. And also, like, you know, during the last couple of financial crashes, you know, what set it off was sets of derivative events where Nassim Talib's thing is they're trying to lower volatility in the short run by creating tail events. And systems always evolve towards that, and then they always crash. The gas curve is the star low ramp plateau crash. It's 100% effective in the long run. Let me ask you some advice to put on your profound hat. There's a bunch of young folks who listen to this thing for no good reason whatsoever. Undergraduate students, maybe high school students, maybe just young folks, young at heart, looking for the next steps to take in life. What advice would you give to a young person today about life, maybe career, but also life in general. Get good at some stuff. Well, get to know yourself. Right. I get good at something that you're actually interested in. You have to love what you're doing to get good at it. You really got to find that. Don't waste all your time doing stuff that's just boring or bland or numbing. Right. Don't let old people screw you. Well, people get talked into doing all kinds of shit and racking up huge student, you know, student debts, and, like, there's so much crap going on, you. Know, and it drains your time and. Drains. Yeah, the Eric Weinstein, you know, thesis that, you know, the older generation won't let go. Yeah. They're trapping all the young people. I think there's some truth to that. Yeah, sure. Just because you're old doesn't mean you stop thinking. I know lots of really original old people. I'm an old person, so. But you have to be conscious about it. You can fall into the ruts and then do that. I mean, when I hear young people spouting opinions that sounds like they come from Fox News or CNN, I think they've been captured by groupthink and memes. And as opposed to think on their own, you know? So if you find yourself repeating what everybody else is saying, you're not gonna have a good life. Like. Like, that's not how the world works. It may be it seems safe, but it puts you at a great jeopardy for, well, being boring or unhappy or. How long did it take you to find the thing that you have fun with? I don't know. I've been a fun person since I. Was pretty little, so everything. I've gone through a couple periods of depression in my life. For good reason or for the reason doesn't make any sense. Yeah, like, some things are hard. Like, you go through mental transitions. In high school, I was really depressed for a year, and I think I had my first midlife crisis at 26. I kind of thought, is this all there is? Like, I was working at a job that I loved, but I was going to work, and all my time was consumed. What's the escape out of that depression? What's the answer to? Is this all there is? Well, a friend of mine, I asked him because he was working his ass off. I said, what's your work life balance like? Like, there's, you know, work, friends, family, personal time. Are you bouncing in that? And you said, work 80%, family 20%. And I try to. I try to find some time to sleep. Like, there's no personal time. There's no passionate time, I guess, you know, young people are often passionate about work, so. And I was certainly like that. But you need to. You need to have some space in your life for different things, and. That makes you resistant to the whole. The deep dips into depression kind of thing. Yeah, well, you have to get to know yourself, too. Meditation helps some physical. Something physically intense helps, like, the weird. Places your mind goes kind of thing. And why does it happen? Why do you do what you do? Like, triggers, like, the things that cause your mind to go to different places kind of thing, or events, like your. Upbringing, for better or worse, whether your parents are great people or not, you. You come into adulthood with all kinds of emotional burdens. Yeah. And you can see some people are so bloody stiff and restrained, and they think, you know, the world's fundamentally negative. Like you maybe, that you have unexplored territory. Yeah. Or you're afraid of something. Definitely afraid of quite a few things. Then you got to go face them. Like, what's the worst thing that happened? You're going to die, right? Like, that's inevitable. You might as well get over that, like, 100% death rate. People are worried about the virus, but, you know, the human condition is pretty deadly. There's something about embarrassment that I've competed a lot in my life, and I think the. If I'm to introspect it, the thing I'm most afraid of is being, like, humiliated. I think nobody cares about that. Look, you're the only person on the planet who cares about you being humiliated. Exactly. So it's a really useless thought. It is. It's like you're all humiliated. Something happened in a room full of people, and they walk out and they didn't think about it one more second. Or maybe somebody told a funny story. To somebody else and then throughout. Yeah, yeah, no, I know it, too. I mean, I've been really embarrassed about shit that nobody cared about myself. Yeah, it's a funny thing. So the worst thing, ultimately, is just, uh. Yeah, but that's a cage, and then you have to get out of it. Yeah. Like, once you. Here's the thing. Once you find something like that, you have to be determined to break it, because otherwise you'll just, you know, so you accumulate that kind of junk, and then you die as a, you know, a mess. So the goal, I guess it's like a cage within a cage. I guess the goal is to die in the biggest possible cage. Well, ideally, you'd have no cage. People do get enlightened. I've met a few. It's great you found a few. There's a few out there. I don't know, of course there, either that or they have, you know, it's a great sales pitch. There's like, enlighten people, write books and doing all kinds of stuff. It's a good way to sell a book, I'll give you that. You've never met somebody, you just thought, they just kill me. Like, they just like mental clarity, humor. No, 100%. But I just feel like they're living in a bigger cage. They have their own. You still think there's a cage? There's still a cage. You secretly suspect there's always a cage. There's nothing outside the universe. There's nothing outside the cage. You were, you worked at a bunch of companies, you led a lot of amazing teams. I don't, I'm not sure if you've ever been like, at the early stages of a startup, but do you have advice for somebody that wants to do a startup or build a company? Like build a strong team of engineers that are passionate, just want to solve a big problem? Like, is there more specifically on that point? You have to be really good at stuff. If you're going to lead and build a team, you better be really interested in how people work and think. The people or the solution to the problem. So there's two things, right? One is how people work, and the. Other is actually, there's quite a few successful startups. It's pretty clear the founders don't know anything about people. People like, the idea was so powerful that it propelled them. But I suspect somewhere early they hired some people who understood people, because people really need a lot of care and feeding to collaborate and work together and feel engaged and work hard. Startups are all about out producing other people. You're nimble because you don't have any legacy. You don't have a bunch of people who are depressed about life just showing up. So startups have a lot of advantages that way. Do you like the Steve Jobs talked about this idea of a players and b players? I don't know if you know this formulation. Yeah, no. Organizations that get taken over by b player leaders often really underperform their hires. You players. That said, in big organizations there's so much work to do and there's so many people who are happy to do what the leadership or the big idea. People who consider menial jobs and you need a place for them, but you need an organization that both values and rewards them, but doesn't let them take over the leadership of it. Got it. So you need to have an organization that's resistant to that. But in the early days, the notion with. With Steve was that, like, one B player in a room of a players will be, like, destructive to the whole. I've seen that happen. I don't know if it's, like, always true. Like, you know, you run into people who clearly be players, but they think they're a players, and so they have a loud voice at the table and they make lots of demands for that. But there's other people who are like, I know who I am. I just want to work with, you know, cool people on cool shit and just tell me what to do and I'll go get it done. Yeah. You know, so you have to. Again, this is, like, people skills. Like, what kind of person is it? You know, I've met some really great people. I love working with that weren't the biggest it people, the most productive ever, but they show up, they get it done. You know, they create connection and community that people value. It's pretty diverse. I don't think there's a recipe for that. I gotta ask you about love. I heard you're into this now, into this love thing. Yeah. Is this. Do you think this is your solution to your depression? No, I'm just trying to, like you said, the enlighten people on occasion, trying to sell a book. I'm writing a book about love. You're writing a book about love? No, I'm not. I'm not. A friend of mine said you should really write a book about your management philosophy. He said it'd be a short book. Well, that one was solved pretty well. What role do you think love, family, friendship, all that kind of human stuff play in a successful life? You've been exceptionally successful in the space of, like, running teams, building cool shit in this world, creating some amazing things. What, did love get in the way? Did love help the family get in the way? Did family help friendship? You want the engineer's answer? Please. So, like, first, love is functional, right? It's functional in what way? So we habituate ourselves to the environment. And actually, Jordan told me, Jordan Peterson told me this line. So you go through life and you just get used to everything except for the things you love. They remain new. Like, this is really useful for, you know, like. Like other people's children and dogs and, you know, trees. You just don't pay that much attention to them. Your old kids, you're monitoring them really closely, like. And if they go off a little bit because you love them, if you're smart, if you're gonna be a successful parent, you notice it right away. You don't habituate just things you love. And if you want to be successful at work, if you don't love it, you're not going to put the time in somebody else as somebody else that loves it, like because it's new and interesting and that lets you go to the next level. So it's a function that generates newness and novelty and surprises you and all those kinds of things. It's really interesting. People figured out lots of frameworks for this. Humans seem to go in partnership, go through interest. Suddenly somebody's interesting, and then you're infatuated with them and then you're in love with them. And then different people have ideas about parental love or mature love. You go through a cycle of that which keeps us together. And it's super functional for creating families and creating communities and making you support somebody despite the fact that you don't love them. And it can be really enriching. Now in the work life balance scheme, if all you do is work, you think you may be optimizing your work potential. But if you don't love your work or you don't have family and friends and things you care about, your brain isn't well balanced. It's like everybody knows the experience of you works on something. All week you went home and took two days off and you came back in. The odds of you working on the thing picking up right where you left off is zero. Your brain refactored it. But being in love is great. It's like. Changes the color of the light in the room. It creates a spaciousness that's different. It helps you think, it makes you strong. Bukowski had this line about love being a fog that dissipates with the first light of reality in the morning. That's depressing. I think it's the other way around. It lasts. Well, like you said, it's a function, it's a thing that generates. You can be the light that actually enlivens your world and creates the interest and the power and the strength to go do something. Well, it's like, like that sounds like, you know, there's like physical love, emotional love, intellectual love, spiritual. Yeah, right. Isn't it all the same thing? Kind of. Nope. You should differentiate that. Maybe that's your problem in your book. You should refine that a little bit. Different chapters. Yeah, there's different chapters. What's that? What's these? Aren't these just different layers of the same thing or the stack? Physical people. People. Some people are addicted to physical love and they have no idea about emotional or intellectual love. I don't know if they're the same things. I think they're different. That's true. They could be different. I guess the ultimate goal is for it to be the same. Well, if you want something to be bigger and interesting, you should find all its components and differentiate them, not climb it together. People do this all the time. They, yeah, the modularity. Get your abstraction layers right and then you can, you have room to breathe. Well, maybe you can write the forward. To my book about love or the afterwards. You really tried. I feel like Lex has made a lot of progress in this book. Well, you have things in your life that you love. Yeah, yeah. You know, so, and they are, you're right, they're modular. It's quite. Well, they're, and you can have multiple things with the same person or the same thing and, but yeah, depending on. The moment of the day. Yeah. There's like what Bukoski described as that moment. You go from being in love to having a different kind of love. Yeah. Right. And that's a transition. But when it happens, if you'd read the owner's manual and you believed it, you would have said, oh, this happened. It doesn't mean it's not love. It's a different kind of love. But, but maybe there's something better about that. As you grow old, if all you do is regret how you used to be, it sat. Right. You should have learned a lot of things because, like, who you can be in your future self is actually more interesting and possibly delightful than, you know, being a mad kid in love with the next person, like, that's super fun when it happens, but that's, you know, 5% of the possibility. Yeah, that's right. That there's a lot more fun to be had in the long lasting stuff. Yeah. Or meaning, you know, if that's a. Good thing, which is a kind of fun, it's a deeper kind of fun. And it's surprising, you know, that's like, like the thing I like is surprises, you know? And you just never know what's gonna happen. But you have to look carefully and you have to work at it. You have to think about it. You know, it's, yeah. You have to see the surprises when they happen. Right. You have to be looking for it. From the branching perspective, you mentioned regrets. Do you have regrets about your own trajectory? Oh, yeah, of course. Yeah. Some of it's painful, but you want to hear the painful stuff. I'd say, like, in terms of working with people, when people did say stuff I didn't like, especially if it was a bit nefarious, I took it personally, and I also felt it was personal about them. But a lot of times, like, humans are, you know, most humans are a mess. Right. And then they act out and they do stuff. And this psychologist I heard a long time ago said, you tend to think somebody does something to you, but really what they're doing is they're doing what they're doing while they're in front of you. It's not that much about you. Yeah. Right. And as I got more interested in, you know, when I work with people, I think about them and probably analyze them and understand them a little bit. And then when they do stuff, I'm way less surprised and I'm way, you know, and if it's bad, I'm way less hurt and I react way less. Like I sort of expect. Everybody's got their shit. Yeah. And it's not about you as a. About me that much. It's like, you know, you do something and you think you're embarrassed, but nobody cares. Like, and somebody's really mad at you. The odds of it being about you. No, they're getting mad the way they're doing that because of some pattern they learned. And, you know, and maybe you can help them if you care enough about it, but. Or you could step. You could see it coming and step out of the way, like, like, I wish I was way better at that. I'm a bit of a hothead. And you read that, you said with Steve, that was a feature, not a bug. Yeah, well, he was using it as the counter force orderliness that would. Well, you were doing the same. Maybe. I don't think my vision was big enough. It was more like I just got pissed off and did stuff. I'm sure that's what. Yeah. You're telling. I don't know if it had the, it didn't have the amazing effect of creating a trillion dollar company. It was more like I just got pissed off and left and. Or made enemies that I shouldn't have. Yeah, it's hard. Like, I didn't really understand politics until I worked at Apple, where Steve was a master player of politics and his staff had to be or they wouldn't survive him. And it was definitely part of the culture. And then I've been in companies where they say it's political, but it's all fun and games compared to Apple. And it's not that the people at Apple are bad people. It's just they operate politically at a higher level. You know, it's not like, oh, somebody said something bad about somebody, somebody else, which is most politics. It's, you know, they had strategies about accomplishing their goals sometimes, you know, over the dead bodies of their enemies, you know, with Game of Thrones. Yeah, more Game of Thrones sophistication and, like, a big time factor rather than. A, you know, that requires a lot of control over your emotions, I think, to have a bigger strategy in the way you behave. Yeah. And it's effective in the sense that coordinating thousands of people to do really hard things where many of the people in there don't understand themselves, much less how they're participating, creates all kinds of drama and problems that our solution is political in nature. Like, how do you convince people? How do you leverage them? How do you motivate them? How do you get rid of them? You know, like, there's. There's so many layers of that that are interesting. And even though some. Some of it, let's say, may be tough, it's not evil unless, you know, you use that skill to evil purposes, which some people obviously do. But. But it's a skill set that operates, you know, and I wish I'd, you know, I was interested in it, but I, you know, it was sort of like, I'm an engineer. I do my thing, and there's times when I could have had way bigger impact if I knew how to. If I paid more attention and knew more about that. About the human layer of the stack. Yeah, the human political power expression layer of the stack, which is complicated, and there's lots to know about it. I mean, people are good at it. They're just amazing. And when they're good at it and let's say, relatively kind and oriented, a good direction, you can really feel it, can get lots of stuff done and coordinate things that you never thought possible. But all people like that also have some pretty hard edges because, you know, it's a heavy lift. And I wish I spent more time at that when I was younger, but maybe I wasn't ready. You know, I was a wide eyed kid for 30 years. Still a bit of a kid. What do you hope your legacy is? When there's a. When there's a book like a Hitchhiker's guide to the Galaxy, and there's, like a one sentence entry. Bob Jim Miller from like, that guy lived at some point. There's not many, you know, not many people would be remembered. You're one of the sparkling little human creatures that had a big impact on the world. How do you hold. You'll be remembered? My daughter was trying to get. She edited my Wikipedia page to say that I was a legend and a guru, but they took it out, so she put it back in. She's 15. I think that was probably the best part of my legacy. She got her sister. They were all excited. They were like trying to put it in the references because there's articles in. That and it's calling you that. So in the eyes of your kids, your legend, well, they're pretty skeptical because. They'Ll be better than that. They're like, dad. So, yeah, that's. That's super. That kind of stuff is super fun. In terms of the big legend stuff. I don't care. I don't care. Legacy, I don't. I don't really care. You're just an engineer. Yeah. They've been thinking about building a big pyramid. So I had a debate with a friend about whether pyramids are or craters are cooler. And you realize that there's craters everywhere. But, you know, they built a couple pyramids 5000 years ago and they remember. You for a while. They're still talking about it. I think that would be cool. Those aren't easy to build. Oh, I know. And they don't actually know how they built them, which is great. It's either AGI or aliens could be involved. So I think you're gonna have to figure out quite a few more things than just the basics of civil engineering. So I guess you hope your legacy is pyramids. That would. That would be cool. And my Wikipedia page, you know, getting updated by my daughter periodically, like those two things would pretty much make it. Jim, it's a huge honor talking to you again. I hope we talk many more times in the future. I can't wait to see what you do with tennis torrent. I can't wait to use it. I can't wait for you to revolutionize yet another space in computing. It's a huge honor to talk to you. Thanks for talking today. This was fun. Thanks for listening to this conversation with Jim Keller. And thank you to our sponsors. Athletic greens all in one nutrition drink, Brooklinen sheets, ExpressVPN and bell Campo grass fed meat. Click the sponsor links to get a discount and to support this podcast. And now let me leave you with some words from Alan Turing. Those who can imagine anything can create the impossible. Thank you for listening and hope to see you next time.

Utterances:
Speaker A: The following is a conversation with Jim Keller, his second time in the podcast. Jim is a legendary microprocessor architect and is widely seen as one of the greatest engineering minds of the computing age. In a peculiar twist of spacetime in our simulation, Jim is also a brother in law of Jordan Peterson. We talk about this and about computing, artificial intelligence, consciousness and life. Quick mention of our sponsors athletic greens all in one nutrition drink, brook linen sheets, ExpressVPN and Belcampo grass fed meat. Click the sponsor links to get a discount and to support this podcast. As a side note, let me say that Jim is someone who on a personal level inspired me to be myself. There was something in his words on and off the mic, or perhaps that he even paid attention to me at all that almost told me youre alright kid. A kind of pat on the back that can make the difference between a mind that flourishes and a mind that is broken down by the cynicism of the world. So I guess thats just my brief few words of thank you to Jim and in general, gratitude for the people who have given me a chance on this podcast, in my work and in life. If you enjoy this thing, subscribe on YouTube, review it on Apple Podcast, follow on Spotify, support it on Patreon, or connect with me on Twitter alexfriedman. And now here's my conversation with Jim Keller. What's the value and effectiveness of theory versus engineering this dichotomy in building good software or hardware systems?
Speaker B: Well, it's good designs both, I guess. That's pretty obvious. By engineering, do you mean reduction of practice of known methods? And then science is the pursuit of discovering things that people don't understand or solving unknown problems.
Speaker A: Definitions are interesting here, but I was thinking more in theory, constructing models that kind of generalize about how things work. And engineering is actually building stuff. The pragmatic like okay, we have these nice models, but how do we actually get things to work? Maybe economics is a nice example. Like economists have all these models of how the economy works and how different policies will have an effect. But then there's the actual, okay, let's call it engineering of like actually deploying the policies.
Speaker B: So computer design is almost all engineering and reduction of practice of known methods. Now because of the complexity of the computers, we built a, you could think, well, we'll just go write some code and then we'll verify it, and then we'll put it together. And then you find out that the combination of all that stuff is complicated, and then you have to be inventive to figure out how to do it. So that's definitely happens a lot. And then every so often, some big idea happens, but it might be one.
Speaker A: Person, and that idea is in the space of engineering or is in the space of.
Speaker B: Well, I'll give you an example. So, one of the limits of computer performance is branch predictions. So, and there's a whole bunch of ideas about how good you could predict a branch. And people said, there's a limit to it. It's an aspen taught a curve, and somebody came up with a better way to do branch prediction. It was a lot better, and he published a paper on it, and every computer in the world now uses it. And it was one idea. So the engineers who build branch prediction hardware were happy to drop the one kind of training array and put it in another one. So it was a real idea.
Speaker A: And branch prediction is one of the key problems underlying all of sort of the lowest level of software. It boils down to branch prediction, boils down to uncertainty.
Speaker B: Computers are limited by, you know, single thread computers, limited by two things, the predictability of the path of the branches and the predictability of the locality of data. So we have predictors that now predict both of those pretty well. So memory is a couple hundred cycles away. Local cache is a couple cycles away. When you're executing fast, virtually all the data has to be in the local cache. So a simple program says, add one to every element in an array. It's really easy to see what the stream of data will be. But you might have a more complicated program that says, get an element of this array, look at something, make a decision, go get another element. It's random, and you can think that's really unpredictable. And then you make this big predictor that looks at this kind of pattern, and you realize, well, if you get this data and this data, then you probably want that one. And if you get this one and this one and this one, you probably want that one.
Speaker A: And is that theory, or is that engineering? Like the paper that was written? Was it asymptotic kind of, kind of discussion? Or is it more like, here's a hack that works?
Speaker B: Well, it's a little bit of both. Like, there's information theory in it, I think, somewhere.
Speaker A: So it's actually trying to prove.
Speaker B: But once, once you know the method, implementing it is an engineering problem. Now, there's a flip side of this, which is, in a big design team, what percentage of people think their plan or their life's work is engineering versus design, inventing things. So lots of companies will reward you for filing patents. Some, many big companies get stuck because to get promoted, you have to come up with something new. And then what happens is everybody's trying to do some random new thing, 99% of which doesn't matter, and the basics get neglected. And. Or they get to. There's a dichotomy, they think, like the cell library and the basic CAD tools or basic software validation methods. That's simple stuff. You know, they want to work on the exciting stuff, and then they spend lots of time trying to figure out how to patent something, and that's mostly useless.
Speaker A: But the breakthroughs are on the simple stuff.
Speaker B: No, no, you. No, you have to do the simple stuff really well. If you're building a building out of bricks, you want great bricks. So you go to two places to sell bricks. So one guy says, yeah, they're over there in an ugly pile. And the other guy is like, lovingly tells you about the 50 kinds of bricks and how hard they are and how beautiful they are, square they are, and you know which one you can buy bricks from, which is going to make a better house.
Speaker A: So you're talking about the craftsman, the person who understands bricks, who loves bricks, who loves the variety.
Speaker B: That's a good word. You know, good engineering is great craftsmanship. And when you start thinking engineering is about invention and set up a system that rewards invention, the craftsmanship gets neglected.
Speaker A: Okay, so maybe one perspective is the theory. The science overemphasizes invention, and engineering emphasizes craftsmanship, and therefore, like, so if you. It doesn't matter what you do, theory.
Speaker B: Well, everybody does, like, read the tech racks. They're always talking about some breakthrough or innovation, and everybody thinks that's the most important thing. But the number of innovative ideas is actually relatively low. We need them, right? And innovation creates a whole new opportunity. Like when some guy invented the Internet, right? Like, that was a big thing. The million people that wrote software against that were mostly doing engineering software writing. The elaboration of that idea was huge.
Speaker A: I don't know if you know, Brendan Ike. He wrote JavaScript in ten days. And that's an interesting story. It makes me wonder. And it was, you know, famously, for many years considered to be a pretty crappy programming language. Still is, perhaps. It's been improving sort of consistently. But the interesting thing about that guy is, you know, he doesn't get any awards. You don't get a Nobel Prize or a Fields medal or.
Speaker B: A crappy piece of, you know, that software code that.
Speaker A: Is currently the number one programming language in the world and runs now is increasingly running the back end of the Internet.
Speaker B: Does he know why everybody uses it? That would be an interesting thing. Was it the right thing at the right time? Because when stuff like JavaScript came out, there was a move from writing C programs in C to let's what they call managed code frameworks, where you write simple code, it might be interpreted, it has lots of libraries, productivity is high and you don't have to be an expert. So, you know, Java was supposed to solve all the world's problems. It was complicated. JavaScript came out after a bunch of other scripting languages. I'm not an expert on it, but was it the right thing at the right time or was there something clever because he wasn't the only one?
Speaker A: There's a few elements.
Speaker B: Maybe if he figured out what it was, then he'd get a prize. Constructive theory. Maybe this problem doesn't define this, or he just needs a good promoter.
Speaker A: Well I think there was a bunch of blog posts written about it, which is like wrong is right, which is like doing the crappy thing fast, just like hacking together the thing that answers some of the needs and then iterating over time. Listening to developers, like listening to people who actually use the thing, this is something you can do more in software, but the right time, you have to sense, you have to have a good instinct of when is the right time for the right tool and make it super simple and just get it out there. The problem is, this is true with hardware, this is less true with software, is there's backward compatibility that just drags behind you as you know, as you try to fix all the mistakes of the past. But the timing was good, there's something about that, and it wasn't accidental. You have to give yourself over to the, you have to have this like broad sense of what's needed now, both scientifically and like the community. And just like this, it was obvious that there was no. The interesting thing about JavaScript is everything that ran in the browser at the time, like Java and, and I think other like scheme, other programming languages, they were all in a separate external container. And then JavaScript was literally just injected into the web page. It was the dumbest possible thing running in the same thread as everything else, and it was inserted as a comment. So JavaScript code is inserted as a comment in the HTML code. I mean it's either genius or super dumb, but it's like it has no.
Speaker B: Apparatus for a virtual machine and container, it just executed in the framework the program is already running. That's cool.
Speaker A: And then because something about that accessibility, the ease of its use, resulted in then developers innovating of how to actually use it. I mean, I don't even know what to make of that, but it does seem to echo across different software, like stories of different software. PHP has the same story, really crappy language, they just took over the world.
Speaker B: Always have a joke that the random length instructions, variable length instruction sets, always one, even though they're obviously worse. Like nobody knows why. X 86 is arguably the worst architecture on the planet, is one of the most popular ones.
Speaker A: Well, I mean, isn't that also the story of risk versus cis? I mean, is that simplicity? There's something about simplicity that us in this evolutionary process is valued. If it's simple, it gets, it spreads faster, it seems like. Or is that not always true?
Speaker B: That's not always true. Yeah, it could be simple is good, but too simple is bad.
Speaker A: So why did risk win, you think so far? Did risk win in the long arc of history?
Speaker B: We don't know.
Speaker A: So who's going to win? What's risk, what's Cisc? And who's going to win in that space? In these instruction sets, a ice offer.
Speaker B: Is going to win, but there'll be little computers that run little programs like normal all over the place. But we're going through another transformation.
Speaker A: But you think instruction sets underneath it all will change?
Speaker B: Yeah, they evolve slowly. They don't matter very much.
Speaker A: They don't matter very much. Okay.
Speaker B: I mean, the limits of performance are predictability of instructions and data. I mean, that's the big thing. And then the usability of it is some, you know, quality of design, quality of tools, availability. Like right now, X 86 is proprietary with intel and AMD, but they can change it any way they want independently. Arm is proprietary to arm and they won't let anybody else change it. So it's like a sole point. And RISC V is open source, so anybody can change it, which is super cool. But that also might mean it gets changed in too many random ways, that there's no common subset of it that people can use.
Speaker A: Do you like open or do you like closed? Like if you were to bet all your money on one or the other risk, five versus it?
Speaker B: No idea.
Speaker A: It's case dependent.
Speaker B: Well, X 86, oddly enough, when intel first started developing it, they licensed it like seven people. So it was the open architecture, and then they moved faster than others and also bought one or two of them. But there were seven different people making x 86 because at the time there was a 6502 and z, you could argue. Everybody thought z 80 was the better instruction set, but that was proprietary to one place. Oh, and the 6800. So there's like four or five different microprocessors. Intel went open, got the market share, because people felt like they had multiple sources from it. And then over time, it narrowed down to two players.
Speaker A: So why you, as a historian, why did intel win for so long with their processors? I mean, they were great.
Speaker B: Their process development was great.
Speaker A: So it's just looking back to JavaScript and Brandon is Microsoft and Netscape and all these Internet browsers. Microsoft won the browser game because they aggressively stole other people's ideas. Like right after they did it.
Speaker B: You know, I don't know if intel was stealing other people's ideas.
Speaker A: They started making a good way stealing, just to clarify.
Speaker B: They started making rams, random access memories. And then at the time when the japanese manufacturers came up, you know, they were getting out, competed on that, and they pivoted the microprocessors, and they made the first, you know, integrated microprocessor programs, uh, 4004 or something.
Speaker A: Who was behind that pivot? That's a hell of a pivot.
Speaker B: Andy Grove, and he was great.
Speaker A: That's a hell of a pivot.
Speaker B: And then they led semiconductor industry. Like they were just a little company. IBM, all kinds of big companies had boatloads of money, and they out innovated.
Speaker A: Everybody out of innovated.
Speaker B: Okay. Yeah, yeah.
Speaker A: So it's not like marketing. It's not.
Speaker B: And their processor designs were pretty good. I think the core two was probably the first one I thought was great. It was a really fast processor. And then Haswell was great.
Speaker A: What makes a great processor in that?
Speaker B: Oh, if you just look at its performance versus everybody else, it's the size of it, the usability of it.
Speaker A: So it's not specific, some kind of element that makes it beautiful. It's just literally just raw performance. Is that how you think of bioprocessors? It's just like raw performance?
Speaker B: Of course, it's like a horse race. The fastest one wins.
Speaker A: Now, you don't care how.
Speaker B: Well there's the fastest. In an environment. Like, for years, you made the fastest one you could, and then people started to have power limits, so then you made the fastest at the right power point. And then when we started doing multiprocessors, if you could scale your processors more than the other guy, you could be 10% faster on a single thread, but you have more threads, so there's lots of variability. And then arm really explored. They have the A series and the r series and the m series, like a family of processors for all these different design points from unbelievably small and simple. And so then when you're doing the design, it's like this big palette of cpu's. Like they're the only ones with a credible top to bottom pallet.
Speaker A: And what do you mean incredible top to bottom?
Speaker B: Well, there's people who make microcontrollers that are small, but they don't have a fast one. There's people who make fast processors but don't have a little, a medium one or a small one.
Speaker A: Is it hard to do that full palette? That seems like a.
Speaker B: It's a lot of different.
Speaker A: So what's the difference in the arm folks and intel in terms of the way they're approaching this problem?
Speaker B: Well, intel, almost all their processor designs were very custom, high end for the last 1520 years.
Speaker A: The fastest horse possible in one horse range.
Speaker B: Yeah, architecturally they're really good, but the company itself was fairly insular to what's going on in the industry with CAD tools and stuff. There's this debate about custom design versus synthesis and how do you approach that? I'd say intel was slow on the getting to synthesize processors. ARm came in from the bottom and they generated IP, which went to all kinds of customers, so they had very little say on how the customer implemented their IP. So ARm is super friendly to the synthesis IP environment, whereas intel said, we're going to make this great client chip, server chip, with our own CAD tools, with our own process, with our own other supporting IP, and everything only works with our stuff.
Speaker A: So is that, is Arm winning the mobile platform space in terms of process? And so in that what you're describing is why they're winning.
Speaker B: Well, they had lots of people doing lots of different experiments, so they controlled the processor architecture and IP, but they let people put in lots of different chips and there was a lot of variability in what happened there. Whereas intel, when they made their mobile, their foray into mobile, they had one team doing one part, so it wasn't ten experiments. And then their mindset was PC mindset, Microsoft software mindset, and that brought a whole bunch of things along that the mobile world, the embedded world, don't do.
Speaker A: Do you think it was possible for intel to pivot hard and win the mobile market? That's a hell of a difficult thing to do, right, for a huge company to just pivot. I mean, so interesting to. Because we'll talk about your current work. It's like, it's clear that PCs were dominating for several decades, like desktop computers and then mobile. It's unclear.
Speaker B: It's a leadership question. Like Apple under Steve Jobs, when he came back, they pivoted multiple times. They built iPads and itunes and phones and tablets and great Macs. Who knew computers should be made out of aluminum? Nobody knew that. That they're great. It's super fun.
Speaker A: That was Steve?
Speaker B: Yeah, Steve Jobs. Like, they pivoted multiple times. And, you know, the old intel, they did that multiple times. They made drams and processors and processes.
Speaker A: And I gotta ask this. What was it like working with Steve jobs?
Speaker B: I didn't work with him.
Speaker A: Did you interact with him?
Speaker B: Twice. I said hi to him twice in the cafe.
Speaker A: What did he say? Hi.
Speaker B: He said, hey, fellas. He was friendly. He was wandering around and with somebody. He couldn't find a table because the cafeteria was packed, and I gave my table. But I worked for Mike Colbert, who talked to, like, Mike was the unofficial CTO of apple and a brilliant guy, and he worked for Steve for 25 years, maybe more. And he talked to Steve multiple times a day. And he was one of the people who could put up with Steve's, let's say, brilliance and intensity. And Steve really liked him. And Steve trusted Mike to translate the shit he thought up into engineering products at work. And then Mike ran a group called Platform Architecture. And I was in that group so many times. I'd be sitting with Mike and the phone would ring. It'd be Steve. And Mike would hold the phone like this because Steve would be yelling about.
Speaker A: Something or other, and then he would.
Speaker B: Translate and he translated, and then he would say, steve wants us to do this.
Speaker A: So was Steve a good engineer, or. No.
Speaker B: I don't know. He was a great idea guy, idea person. And he's a really good selector for talent.
Speaker A: Yeah. That seems to be one of the key elements of leadership. Right.
Speaker B: And then he was a really good first principles guy. Like, somebody say something couldn't be done, and he would just think, that's obviously wrong. Right. But, you know, maybe it's hard to do. Maybe it's expensive to do. Maybe we need different people. You know, there's like a whole bunch of, like, if you want to do something hard, you know, maybe it takes time. Maybe you have to iterate. There's a whole bunch of things you could think about. But saying it can't be done is stupid.
Speaker A: How would you compare? So it seems like Elon Musk is more engineering centric, but is also, I think, he considered himself a designer, too. He has a design mind. Steve Jobs feels like he is much more idea space, design. Space versus engineering. Just make it happen. Like, the world should be this way. Just figure it out.
Speaker B: But he used computers. He had computer people talk to him all the time. Mike was a really good computer guy.
Speaker A: He knew computers could do computer, meaning computer hardware.
Speaker B: Hardware, software, all the pieces. And then he would have an idea about what could we do with this next? That was grounded in reality. It wasn't like he was, you know, just finger painting on the wall and wishing somebody would interpret it, like. So. He had this interesting connection, because now he wasn't a computer architect or designer, but he had an intuition from the computers we had to what could happen.
Speaker A: And it's interesting you say intuition because it seems like he was pissing off a lot of engineers in his intuition about what can and can't be done. Those, like the. What is all these stories about, like, floppy disks and all that kind of stuff like that.
Speaker B: Yeah. So in Steve, the first round, like, he'd go into a lab and look at what's going on and hate it and fire people or ask somebody in the elevator what they're doing for apple and not be happy when he came back, my impression was, is he surrounded himself with a relatively small group of people.
Speaker A: Yes.
Speaker B: And didn't really interact outside of that as much. And then the joke was you'd see, like, a little somebody moving a prototype through the quad with a black blanket over it. And that was because it was secret, you know, partly from Steve, because they didn't want Steve to see it until it was ready.
Speaker A: Yeah. The dynamic with Jony Ive and Steve is interesting. Like, you don't want to. He ruins as many ideas as he generates.
Speaker B: Yeah, yeah.
Speaker A: It's a dangerous kind of line to.
Speaker B: Walk if you have a lot of ideas. Like, Gordon Bell was famous for ideas. Right. And it wasn't that the percentage of good ideas was way higher than anybody else. It was. He had so many ideas, and he was also good at talking to people about it and getting the filters right and, you know, seeing through stuff, whereas Elon was like, hey, I want to build rockets. So Steve would hire a bunch of rocket guys, and Elon would go read rocket manuals.
Speaker A: So Elon is a better engineer, a sense, like. Or, like, more like a love and passion for the manuals and the details. The details. The craftsmanship, too, right? Well, I guess you had craftsmanship, too, but of a different kind. What do you make of the. Just to stand in for just a little longer. What do you make of, like, the anger and the passion and all that? The. The firing and the mood swings and the madness, the, you know, being emotional and all that? That's Steve and I guess Elon, too. So what is that, a set, a bug or a feature?
Speaker B: It's a feature. So there's a graph, which is y axis productivity.
Speaker A: Yeah.
Speaker B: X axis at zero is chaos and infinity. It's complete order.
Speaker A: Yeah.
Speaker B: Right. So as you go from the, you know, the origin, as you improve order, you improve productivity.
Speaker A: Yeah.
Speaker B: And at some point, productivity peaks and then it goes back down again. Too much order, nothing can happen.
Speaker A: Yes, but the question is, how close to the chaos is that?
Speaker B: No, no. Here's the thing is, once you start moving, a direction or the force vector to drive you towards order is unstoppable.
Speaker A: Oh.
Speaker B: Every organization will move to the place where their productivity is stymied by order.
Speaker A: So you need.
Speaker B: So the question is, who's the counterforce? Because it also feels really good. As you get more organized and productivity goes up, the organization feels it. They orient towards it. They hired more people. They got more guys who can run process. You get bigger, inevitably, the organization gets captured by the bureaucracy that manages all the processes. And then humans really like that. And so if you just walk into a room and say, guys, love what you're doing, but I need you to have less order. If you don't have some force behind that, nothing will happen.
Speaker A: I can't tell you on how many levels. That's profound.
Speaker B: That's why I say it's a feature. Now, could you be nicer about it? I don't know. I don't know any good examples of being nicer about it. Well, the funny thing is, to get stuff done, you need people who can manage stuff and manage people, because humans are complicated. They need lots of care and feeding that. You need to tell them they look nice and they're doing good stuff and pat them on the back. Right.
Speaker A: I don't know. You tell me, is that needed? Humans need that.
Speaker B: I had a friend, he started a magic roof, said, I figured it out. You have to praise them before they do anything. I was waiting till they were done, and they were always mad at me. Now I tell them what a great job they're doing while they're doing it, but then you get stuck in that trap, because then when they're not doing something, how do you confront these people?
Speaker A: I think a lot of people that had trauma in their childhood would disagree with you. Successful people that you need to first do the rough stuff and then be nice later. I don't know.
Speaker B: Okay, but engineering companies are full of adults who had all kinds of range of childhoods. You know, most people had okay childhoods.
Speaker A: Well, I don't know if.
Speaker B: And lots of people only work for praise, which is weird.
Speaker A: You mean, like everybody?
Speaker B: I'm not that interested in it, but.
Speaker A: Well, you're probably looking for somebody's approval, even still.
Speaker B: Yeah, maybe I should think about that.
Speaker A: Maybe somebody who's no longer with this kind of thing. I don't know.
Speaker B: I used to call my dad and tell him what I was doing. He was. He was very excited about engineering and stuff.
Speaker A: You got his approval?
Speaker B: Yeah, a lot. I was lucky. Like, he decided I was smart and unusual as a kid, and that was okay when I was really young. So when I did poorly in school, I was dyslexic. I didn't read until I was third or fourth grade, and they didn't care. My parents were like, oh, he'll be fine. So I was lucky. That was cool.
Speaker A: Is he still with us? You miss him?
Speaker B: Sure. Yeah. He had Parkinson's and then cancer. His last ten years were tough, and I killed him. Killing a man like that's hard. The mind, well, it's pretty good. Parkinson's causes slow dementia, and the chemotherapy, I think, accelerated it, but it was like hallucinogenic dementia. So he was clever and funny and interesting and was pretty unusual.
Speaker A: Do you remember conversations from that time? Like what? Do you have fond memories of the guy?
Speaker B: Yeah. Oh, yeah?
Speaker A: Anything come to mind?
Speaker B: A friend told me one time I could draw a computer on the whiteboard faster than anybody you'd ever met. And I said, you should meet my dad. Like, when I was a kid, he'd come home and say, I was driving by this bridge, and I was thinking about it, and he pulled out a piece of paper, and he'd draw the whole bridge. He was a mechanical engineer, and he would just draw the whole thing, and then he would tell me about it and tell me how he would have changed it. And he had this idea that he could understand and conceive anything. And I just grew up with that, so that was natural. So when I interview people, I ask them to draw a picture of something they did on a whiteboard, and it's really interesting. Some people draw a little box, you know, and then they'll say, and this talks to this, and I'll be like, that's just frustrating. And I had this other guy come in one time. He says, well, I designed a floating point in this chip, but I'd really like to tell you how the whole thing works and then tell you how the floating point works inside of it. Do you mind if I do that? He covered two whiteboards in like 30 minutes, and I hired him like he was great.
Speaker A: There's craftsman. I mean, that's the craftsmanship to that.
Speaker B: Yeah, but also the mental agility to understand the whole thing. Put the pieces in context, real view of the balance of how the design worked, because if you don't understand it properly when you start to draw it, you'll fill up half the whiteboard with a little piece of it. Your ability to lay it out an understandable way takes a lot of understanding.
Speaker A: And be able to zoom into the detail and then zoom out in the picture really fast. What about the impossible thing? See, your dad believe that you can do anything. That's a weird feature for a craftsman. Yeah, it seems that that echoes in your own behavior. Like that's, that's the, well, it's not.
Speaker B: That anybody can do anything right now. Right. It's that if you work at it, you can get better at it, and there might not be a limit. And they did funny things like, like he always wanted to play piano, so at the end of his life he started playing the piano when he had Parkinson's, and he was terrible, but he thought if he really worked out it in this life, maybe the next life, he'd be better at it.
Speaker A: He might be onto something.
Speaker B: Yeah, he enjoyed doing it.
Speaker A: Yeah.
Speaker B: So that's pretty funny.
Speaker A: Do you think the perfect is the enemy of the good in hardware and software engineering? It's like we were talking about JavaScript a little bit. And the messiness of the ten day building process.
Speaker B: Yeah. You know, creative tension. Right. So creative tension is you have two different ideas that you can't do both. Right. And then, but the fact that you want to do both causes you to go try to solve that problem. That's the creative part. So if you're building computers, like some people say, we have the schedule, and anything that doesn't fit in the schedule, we can't do. So they throw out the perfect because they have a schedule. I hate that. Then there's other people who say, we need to get this perfectly right, and no matter what, more people, more money, and there's a really clear idea about what you want. And some people are really good at articulating it. Let's call that the perfect. But that's also terrible because they never ship anything. They never hit any goals. So now you have the. Now you have your framework.
Speaker A: Yes.
Speaker B: You can't throw out stuff. Cause you can't get it done today. Cause maybe you get it done tomorrow or the next project. Right? You can't. So you have to. I work with a guy that I really like working with, but he over filters his ideas.
Speaker A: Over filters.
Speaker B: He'd start thinking about something, and as soon as he figured out what's wrong with it, he'd throw it out. And then I start thinking about it. And you come up with an idea, and then you find out what's wrong with it, and then you give it a little time to set because sometimes you figure out how to tweak it, or maybe that idea helps some other idea. So idea generation is really funny. So you have to give your ideas space. Spaciousness of mind is key, but you also have to execute programs and get shit done. And then it turns out computer engineering is fun because it takes 100 people to build a computer, 200 to 300, whatever the number is. And people are so variable about, you know, temperament and, you know, skill sets and stuff that in a big organization, you find that the people who love the perfect ideas and the people that want to get stuff done yesterday, and people like to come up with ideas, and people like to, let's say, shoot down ideas. And it takes the whole, it takes a large group of people.
Speaker A: Some are good at generating ideas, some are good at filtering ideas, and then they're all in that giant mess. You're somehow, I guess the goal is for that giant mess of people to find the perfect path through the tension, the creative tension. But how do you know when you said there's some people good at articulating what perfect looks like, what a good design is? If you're sitting in a room and you have a set of ideas about how to design a better processor, how do you know this is something special here? This is a good idea. Let's try this.
Speaker B: Have you ever brainstormed idea with a couple people that were really smart, and you kind of go into it and you don't quite understand it, and you're working on it, and then you start talking about it, putting it on the whiteboard. Maybe it takes days or weeks, and then your brain start to kind of synchronize. It's really weird. Like, you start to see what each other is thinking, and it starts to work. Like, you can see work. Like, my talent in computer design is. I can see how computers work in my head, like, really well. And I know other people can do that, too. And when you're working with people that can do that, it is kind of an amazing experience. And then, and every once in a while, you get to that place and then you find the flaw, which is kind of funny because you can fool yourself, but the two of you kind.
Speaker A: Of drifted along into a direction that was useless.
Speaker B: Yeah, that happens, too. Like, you have to, because, you know, the nice thing about computer design, there's always reduction in practice. Like, you come up with your good ideas, and I've known some architects who really love ideas, and then they work on them and then they put it on the shelf, then go work on the next idea and put it on the shelf. They never reduce it to practice, so they find out what's good and bad. Because almost every time I've done something really new, by the time it's done, like, the good parts are good, but I know all the flaws. Like.
Speaker A: Yeah. Would you say your career, just your own experience, is your career defined by mostly by flaws or by successes?
Speaker B: Like, if, again, there's great tension between those. If you haven't tried hard.
Speaker A: Yeah.
Speaker B: Right. And done something new. Right. Then you're not going to be facing the challenges when you build it. Then you find out all the problems with it and.
Speaker A: But when you look back, do you see problems? Okay.
Speaker B: Oh, when I look back, what do you. I think earlier in my career.
Speaker A: Yeah.
Speaker B: Like, Ev five was the second alpha chip. I was so embarrassed about the mistakes, I could barely talk about it. And it was in the Guinness Book of Worlds Records, and it was the fastest processor on the planet. Yeah, so it was. And at some point I realized that was really a bad mental framework to deal with, like doing something new. We did a bunch of new things, and some worked out great and some were bad, and we learned a lot from it. And then the next one, we learned a lot that also Ev six also had some really cool things in it. I think the proportion of good stuff went up, but it had a couple of fatal flaws in it that were painful. And then.
Speaker A: Yeah, you learned to channel the pain into, like, pride.
Speaker B: Not pride, really, just realization about how the world works or how that kind of idea set works.
Speaker A: Life is suffering. That's the reality. What?
Speaker B: No, it's nothing. Well, you know, the Buddha said that and a couple other people are stuck on it. No, it's, you know, there's this kind of weird combination of good and bad, you know, light and darkness that you have to tolerate and, you know, deal with. Yeah, there's definitely lots of suffering in.
Speaker A: The world depends on the perspective. It seems like there's way more darkness, but that makes the light part really nice. What computing hardware, or just any kind of even software design do you find beautiful from your own work, from other people's work that you're just, we were just talking about the battleground of flaws and mistakes and errors, but things that were just beautifully done. Is there something that pops to mind?
Speaker B: Well, when things are beautifully done, usually there's a well set, thought out set of abstraction layers.
Speaker A: So the whole thing works in unison nicely.
Speaker B: Yes. And when I say abstraction layer, that means two different components. When they work together, they work independently. They don't have to know what the other one is doing.
Speaker A: So that decoupling.
Speaker B: Yeah. So the famous one was the network stack. There's a seven layer network stack, data transport protocol and all the layers. And the innovation was when they really got that right, because networks before that didn't define those very well. The layers could innovate independently. And occasionally the layer boundary would, you know, the interface would be upgraded and that let you know the design space breathe. You could do something new in layer seven without having to worry about how layer four worked. And so good design does that, and you see it in processor designs. When we did the Zen design at AMD, we made several components very modular. And my insistence at the top was I wanted all the interfaces defined before we wrote the RTL for the pieces one of the verification leads had. If we do this right, I can test the pieces so well independently, when we put it together, we won't find all these interaction bugs because the floating point knows how the cache works. And I was a little skeptical, but he was mostly right that the modularity of the design greatly improved the quality.
Speaker A: Is that universally true in general, would you say about good designs, the modularity is like, usually, well, we talked about this before.
Speaker B: Humans are only so smart and we're not getting any smarter. Right. But the complexity of things is going up. So, you know, a beautiful design can't be bigger than the person doing it. It's just, you know, their piece of it. Like the odds of you doing a really beautiful design of something that's way too hard for you is low, right? If it's way too simple for you, it's not that interesting. It's like, well, anybody could do that. But when you get the right match of your expertise and mental power to the right design size, that's cool, but that's not big enough to make a meaningful impact on the world. So now you have to have some framework to design the pieces so that the whole thing is big and harmonious. But when you put it together, it's sufficiently interesting to be used. So that's like a beautiful design is.
Speaker A: Matching the limits of that human cognitive capacity to the module that you can create and creating a nice interface between those modules, and thereby, do you think there's a limit to the kind of beautiful, complex systems we can build with this kind of modular design? It's like if we build increasingly more complicated, you can think of the Internet. Okay, let's scale it down. You can think of social network like Twitter as one computing system, but those are little modules, but it's built on.
Speaker B: So many components, nobody at Twitter even understands. So if an alien showed up and looked at Twitter, he wouldn't just see Twitter as a beautiful, simple thing that everybody uses, which is really big. You would see the network it runs on, the fiber optics, the data is transported, the computers. The whole thing is so bloody complicated, nobody at Twitter understands it.
Speaker A: And so I think that's what the alien would see. So, yeah, if an alien showed up and looked at Twitter or looked at the various different networked systems that you can see on Earth.
Speaker B: So imagine they were really smart that could comprehend the whole thing, and then they sort of, you know, evaluated the human and thought, this is really interesting. No human on this planet comprehends the system they built.
Speaker A: No individual, or would they even see individual humans like we? Humans are very human centric, entity centric. And so we think of us as the organ, as the central organism, and the networks as just the connection of organisms. But from a perspective of an alien, from an outside perspective, it seems like.
Speaker B: Yeah, I get it. We're the ants, and they'd see the ant colony.
Speaker A: The ant colony, yeah. Or the result of production of the ant colony, which is like cities, and.
Speaker B: Yeah, it's.
Speaker A: It's a. In that sense, humans are pretty impressive. The modularity that we're able to and the. And how robust we are to noise and mutation, all that kind of stuff.
Speaker B: Well, that's because it's stress tested all the time.
Speaker A: Yeah.
Speaker B: You know, you build all these cities with buildings, and you get earthquakes occasionally and wars, you know, some, you know, wars, earthquakes, viruses.
Speaker A: Every once in a while, you know.
Speaker B: Changes in business plans for, you know, like shipping or something like. Like, as long as it's all stress tested, then it keeps adapting to the situation. That's a curious phenomenon.
Speaker A: Well, let's talk about Moore's law a little bit at the broad view of Moore's law, where it's just exponential improvement of computing capability. Like OpenAI, for example, recently published this kind of papers looking at the exponential improvement in the training efficiency of neural networks for like imagenet and all that kind of stuff. We just got better on this is purely software side, just figuring out better tricks and algorithms for training neural networks. And that seems to be improving significantly faster than the Moore's law prediction. So that's in the software space. What do you think if Moore's law continues, or if the general version of Moore's law continues? Do you think that comes mostly from the hardware, from the software? Some mix of the two, some interesting, totally. So not the reduction of the size of the transistor kind of thing, but more in the. In the totally interesting kinds of innovations in the hardware space, all that kind of stuff?
Speaker B: Well, there's like a half a dozen things going on in that graph. So one is there's initial innovations that had a lot of headroom to be exploited. So, you know, the efficiency of the networks has improved dramatically. And then the decomposability of those and the use, you know, they started running on one computer, then multiple computers, then multiple GPU's, and then arrays of GPU's, and they're up to thousands and at some point. So it's sort of like they were going from like a single computer application to 1000 computer application. So that's not really a Moore's law thing, that's an independent vector. How many computers can I put on this problem? Because the computers themselves are getting better on like a Moore's law rate, but their ability to go from one to ten to 100 to 1000 was something, and then multiplied by the amount of computes it took to resolve, like Alexnet to Resnet, the transformers been quite steady improvements.
Speaker A: But those are like s curves, aren't they? That's the exactly kind of s curves that are underlying Moore's law from the very beginning. So what's the biggest, what's the most productive, rich source of s curves in the future, do you think? Is it hardware, is it software, or is it.
Speaker B: So hardware is going to move along relatively slowly, like double performance every two years. There's still.
Speaker A: I like how you call that slow.
Speaker B: Yeah, that's the slow version. The snail's pace of Moore's law. Maybe we should trademark that one. Whereas the scaling by number of computers can go much faster. I'm sure at some point Google had their initial search engine was running on a laptop, and at some point they really worked on scaling that, and then they factored the indexer from this piece and this piece and this piece, and they spread the data on more and more things, and they did a dozen innovations. But as they scaled up the number of computers on that, it kept breaking, finding new bottlenecks in their software and their schedulers and made them rethink. It seems insane to do a scheduler across 1000 computers who schedule parts of it and then send the results to one computer. But if you want to schedule a million searches, that makes perfect sense. So the scaling by just quantity is probably the richest thing. But then as you scale quantity, like, a network that was great on 100 computers may be completely the wrong one. You may pick a network that's ten times slower on 10,000 computers, like per computer. But if you go from 100 to 10,000, it's 100 times. So that's one of the things that happened when we did Internet scaling, is the efficiency went down, not up. The future of computing is inefficiency. Not efficiency, but scales.
Speaker A: Inefficient scale.
Speaker B: It's scaling faster than inefficiency bites you. And as long as there's dollar value there, like, scaling costs lots of money. But Google showed, Facebook showed, everybody showed that the scale was where the money was at.
Speaker A: So it's worth it financially. Do you think? Is it possible that, like, basically the entirety of earth will be, like, a computing surface? Like, this table will be doing computing, this hedgehog will be doing computing? Like, everything really inefficient, dumb computing will be science fiction?
Speaker B: Books, they call it computronium.
Speaker A: Computronium.
Speaker B: We turn everything into computing. Well, most of the elements aren't very good for anything. Like, you're not gonna make a computer out of iron. Like, you know, silicon and carbon have, like, nice structures. You know, we'll see what you can do with the rest of it. People talk about, well, maybe we can turn the sun into computer, but it's hydrogen and a little bit of helium.
Speaker A: So what I mean is more like actually just adding computers to everything.
Speaker B: Oh, okay, so you're just converting all the mass of the universe into computer.
Speaker A: No.
Speaker B: No.
Speaker A: So not using, to be ironic from.
Speaker B: The simulation point of view, is like the simulator build mass to simulate a. Like.
Speaker A: Yeah, I mean, yeah, so, I mean, ultimately, this is all heading towards a simulation.
Speaker B: Yeah. Well, I think I might have told you this story. A Tesla. They were deciding, so they want to measure the current coming out of the battery, and they decide between putting a resistor in there and putting a computer with a sensor in there, and the computer was faster than the computer I worked on in 1982. And we chose the computer because it was cheaper than the resistor. So, sure, this hedgehog cost $13, and we can put an AI that's as smart as you in there for $5. It'll have one. So computers will be everywhere.
Speaker A: I was hoping it wouldn't be smarter than me because, well, everything's going to.
Speaker B: Be smarter than you.
Speaker A: But you were saying it's inefficient. I thought it was better to have a lot of dumps.
Speaker B: Well, Moore's law will slowly compact that.
Speaker A: Stuff, so even the dumb things will be smarter than us.
Speaker B: The dump things are going to be smart. Are they going to be smart enough to talk to something that's really smart? You know, it's like. Well, just remember, like a big computer chip.
Speaker A: Yeah.
Speaker B: You know, it's like an inch by an inch and, you know, 40 microns thick. It doesn't take very much, very many atoms to make a high power computer, and 10,000 of them can fit in the shoebox. But, you know, you have the cooling and power problems, but, you know, people.
Speaker A: Are working on that, but they still can't write compelling poetry or music or understand what love is, or have a fear of mortality. So we're still winning.
Speaker B: Neither can most of humanity, so, well.
Speaker A: They can write books about it, so. But speaking about this, walk along the path of innovation towards the dumb things being smarter than humans. You are now the CTO of ten storent. As of two months ago. They build hardware for deep learning. How do you build scalable and efficient deep learning? This is such a fascinating space.
Speaker B: Yeah, yeah. So it's interesting. So up until recently, I thought there was two kinds of computers. There are serial computers that run, like, C programs, and then there's parallel computers. So the way I think about it is, parallel computers have given parallelism, like GPU's are great because you have a million pixels, and modern gpu's run a program on every pixel. They call it a shader program, or finite element analysis. You build something, you make this into little tiny chunks. You give each chunk to a computer, so you're given all these chunks. You have parallels, and like that. But most C programs, you write this linear narrative, and you have to make a go fast to make it go fast. You predict all the branches, all the data fetches, and you run that more in parallel. But that's found parallelism. AI is. I'm still trying to decide how fundamental this is. It's a given parallelism problem. But the way people describe the neural networks and then how they write them in Pytorch, it makes graphs.
Speaker A: Yeah, that might be fundamentally different than the GPU kind of parallelism.
Speaker B: Yeah, it might be because when you run the GPU program on all the pixels you're running depends. This group of pixels say it's background blue and it runs a really simple program. This pixel is some patch of your face, so you have some really interesting shader program to give you the impression of translucency. But the pixels themselves don't talk to each other. There's no graph, right? So you do the image and then you do the next image and you do the next image and you run 8 million pixels, 8 million programs every time. And modern GPU's have like 6000 thread engines in them. So you know, to get 8 million pixels, each one runs a program on, you know, ten or 20 pixels. And that's how, that's how they work.
Speaker A: There's no graph, but you think graph might be a totally new way to think about hardware.
Speaker B: So Raja Guduri and I have been having this conversation about given versus found parallelism and then the kind of walk as we got more transistors like computers way back when did stuff on scalar data, then we did it on vector data, famous vector machines. Now we're making computers that operate on matrices. And then the category we said that was next was spatial like. Imagine you have so much data that you want to do the compute on this data, and then when it's done, it says send the result to this pile of data on some software on that. And it's better to think about it spatially than to move all the data to a central processor and do all the work.
Speaker A: So spatially you mean moving in the space of data as opposed to moving the data.
Speaker B: You have a petabyte data space spread across some huge array of computers. And when you do a computation somewhere, you send the result of that computation, or maybe a pointer to the next program, to some other piece of data and do it. But I think a better word might be graph. And all the AI neural networks are graphs. Do some computations, send the result here, do another computation, do a data transformation, do emerging, do a pooling, do another computation.
Speaker A: Is it possible to compress and say how we make this thing efficient, this whole process efficient? There's different.
Speaker B: So first, the fundamental elements in the graphs are things like matrix multiplies, convolutions, data manipulations and data movements. So GPU's emulate those things with their little singles, basically running a single threaded program. And then there's an invita calls it a warp, where they group a bunch of programs that are similar together for efficiency and instruction use. Then at a higher level, you take this graph and you say, this part of the graph is a matrix multiplier, which runs on these 32 threads, but the model at the bottom was built for running programs on pixels, not executing graphs.
Speaker A: So it's emulation ultimately. So is it possible to build something that natively runs graphs?
Speaker B: Yes. So that's what ten storm did.
Speaker A: So where are we on that? How, like in the history of that effort, are we in the early days?
Speaker B: Yeah, I think so. Ten storrants started by a friend of mine, Labija Bajak, and I was his first investor. So I've been kind of following him and talking to him about it for years. And in the fall, when I was considering things to do, I decided we held a conference last year with a friend, organized it, and we wanted to bring in thinkers, and two of the people were Andre Karpasi and Chris Ladner. And Andre gave this talk, it's on YouTube called Software 2.0, which I think is great, which is we went from programmed computers where you write programs, to data program computers, like the future of software as data programs, the networks, and I think that's true. And then Chris has been working, he worked on LLVM, the low level virtual machine, which became the intermediate representation for all compilers. And now he's working on another project called MLiR, which is mid level intermediate representation, which is essentially under the graph about how do you represent that kind of computation, and then coordinate large numbers of potentially heterogeneous computers? I would say technically tends torrents. Two pillars of those two ideas, software 2.0 and mid level representation. But it's in service of executing graph programs. The hardware is designed to do that.
Speaker A: So it's including the hardware piece.
Speaker B: Then the other cool thing is, for a relatively small amount of money, they did a test chip and two production chips. It's a super effective team, unlike some AI startups, where if you don't build the hardware to run the software that they really want to do, then you have to fix it by writing lots more software. So the hardware naturally does matrix multiply, convolution, the data manipulations, and the data movement between processing elements that you can see in the graph, which I think is all pretty clever, and that's what I'm working on now.
Speaker A: So I think it's called the grace call processor. Introduced last year. There's a bunch of measures of performance. We're talking about horses. It seems to outperform 368 trillion operations per second, seems to outperform Nvidia's Tesla T four system. So these are just numbers. What do they actually mean in real world performance? What are the metrics for you that you're chasing in your horse race? What do you care about?
Speaker B: Well, first, the native language of people who write AI network programs is Pytorch. Now, Pytorch, tensorflow, there's a couple others.
Speaker A: The pytorch is one over tensorflow. Is it just.
Speaker B: I'm not an expert on that. I know many people who have switched from Tensorflow to Pytorch.
Speaker A: Yeah.
Speaker B: And there's technical reasons for it. And I use.
Speaker A: Both are still awesome.
Speaker B: Both are still awesome.
Speaker A: But the deepest love is for Pytorch currently.
Speaker B: Yeah, there's more love for that, and that may change. So the first thing is, when they write their programs, can the hardware execute it pretty much as it was written. So Pytorch turns into a graph. We have a graph compiler that makes that graph. Then it fractions the graph down. So if you have big matrix multiply, we turn it into right size chunks to run on the processing elements. It hooks all the graph up, it lays out all the data. There's a couple of mid level representations of it that are also simulatable, so that if you are writing the code, you can see how it's going to go through the machine, which is pretty cool. And then at the bottom, it schedules kernels like math, data manipulation, data movement kernels, which do this stuff so we don't have to run, write a little program to do matrix multiply, because we have a big matrix multiplier. Like there's no SIMD program for that, but there is scheduling for that. Right? So one of the goals is if you write a piece of Pytorch code that looks pretty reasonable, you should be able to compile it, run it on the hardware without having to tweak it and do all kinds of crazy things to get performance.
Speaker A: There's not a lot of intermediate steps. It's running directly as written, like on a GPU.
Speaker B: If you write a large matrix multiply, naively, you'll get five to 10% of the peak performance of the GPU. Then there's a bunch of people published papers on this, and I read them about what steps do you have to do? And it goes from pretty reasonable. Well, transpose one of the matrices so you do row ordered, not column ordered, you know, block it so that you can put a block of the matrix on different sms, you know, groups of threads. But some of it gets into little details, like you have to schedule it just so, so you don't have register conflicts. So the, they call them cuda ninjas.
Speaker A: Cuda ninjas. I love it.
Speaker B: To get to the optimal point, you either write a pre use a pre written library, which is a good strategy for some things, or you have to be an expert in microarchitecture to program it.
Speaker A: Right. So the optimization step is way more complicated with the GPU.
Speaker B: So our, our goal is if you write Pytorch, that's good, Pytorch, you can do it. Now there's, as the networks are evolving, you know, they've changed from convolutional to matrix multiply. People are talking about conditional graphs, they're talking about very large matrices, they're talking about sparsity, they're talking about problems that scale across many, many chips. So the native data item is a packet. You send the packet to a processor, it gets processed, it does a bunch of work, and then it may send packets to other processors and they execute in a data flow graph methodology.
Speaker A: Got it.
Speaker B: We have a big network on chip, and then second chip has 16 Ethernet ports to hook lots of them together. It's the same graph compiler across multiple chips.
Speaker A: That's where the scale comes in.
Speaker B: It's built to scale naturally. My experience with scaling is as you scale, you run into lots of interesting problems. So scaling is a mountain to climb. So the hardware is built to do this, and we're in the process of.
Speaker A: Is there a software part to this with Ethernet and all that?
Speaker B: Well, the protocol at the bottom we send, it's an Ethernet fi, but the protocol basically says send a packet from here to there. It's all point to point. The header bit says which processor to send it to, and we basically take a packet off our on chip network, put an Ethernet header on it, send it to the other end, strip the header off and send it to the local thing. It's pretty straightforward.
Speaker A: Human to human interaction is pretty straightforward too. But when you get a million of us, we do some crazy stuff together.
Speaker B: Yeah, it can be fun.
Speaker A: So is that the goal is scale. So like for example, I've been recently doing a bunch of robots at home for my own personal pleasure. Am I going to ever use ten storing or is this more for.
Speaker B: There's all kinds of problems, like there's small inference problems or small training problems. There's big training problems.
Speaker A: What's the big goal? Is it the big training problems or the small training problems?
Speaker B: One of the goals is to scale from 100 milliwatts to a megawatt. So really have some range on the problems. And the same kind of AI programs work at all different levels. So that's the goal, since the natural data item is a packet that we can move around. It's built to scale, but so many people have small problems, but inside that.
Speaker A: Phone is a small problem to solve. So do you see thunderstorm potentially being inside a phone?
Speaker B: Well, the power efficiency of local memory, local computation, and the way we built it is pretty good. And then there's a lot of efficiency on being able to do conditional graphs and sparsity. I think for complicated networks that want to go into small factor, it's quite good, but we have to prove that's a fun problem.
Speaker A: And that's the early days of the company. Right? It's a couple of years, you said, but you think you invested, you think they're legit once you join.
Speaker B: Well, it's also, it's a really interesting place to be. Like the AI world is exploding. I looked at some other opportunities, like build a faster processor, which people want, but that's more on an incremental path than what's going to happen in AI in the next ten years. So this is kind of an exciting place to be.
Speaker A: Part of the revolutions will be happening in the very space, and then lots.
Speaker B: Of people are working on it. But there's lots of technical reasons why some of them aren't going to work out that well. And that's, that's interesting. And there's also the same problem about getting the basics right. Like, we've talked to customers about exciting features, and at some point we realized that each year, realizing they want to hear first about memory bandwidth, local bandwidth, compute intensity, programmability, they want to know the basics, power management, how the network ports work, what are the basics? Do all the basics work? Because it's easy to say, we've got this great idea that, you know, the crack GPT-3 but the people we talk to want to say, if I buy the. So we have a piece of express card with our chip on it. If you buy the card, you plug it in your machine, you download the driver. How long does it take me to get my network to run? Right? No, that's a real question.
Speaker A: It's a very basic question.
Speaker B: So, yeah.
Speaker A: Is there an answer to that yet, or is it trying to our goal.
Speaker B: Is, like, an hour.
Speaker A: Okay. When can I buy a Tesla?
Speaker B: Pretty soon.
Speaker A: For my. For the small case training.
Speaker B: Yeah, pretty soon. Months.
Speaker A: Good. I love the idea of you inside a room with Karpathy. Andre Karpathy and Chris Ladner. Very, very interesting, very brilliant people. Very out of the box thinkers, but also, like, first principles thinkers.
Speaker B: Well, they both get stuff done. They only get stuff done to get their own projects done. They talk about it clearly. They educate large numbers of people, and they've created platforms for other people to go do their stuff on.
Speaker A: Yeah, the. The clear thinking that's able to be communicated is kind of impressive.
Speaker B: It's kind of remarkable to. Yeah, I'm a fan.
Speaker A: Well, let me ask, because I talked to Chris, actually a lot these days. He's been one of the cool. Just to give him a shout out in. He's been so supportive as a human being. So everybody's quite different. Like, great engineers are different, but he's been, like, sensitive to the human element in a way that's been fascinating. Like, he was one of the early people on this stupid podcast that I do to say, like, don't quit this thing. And also talk to whoever the hell you want to talk to that kind of from a legit engineer to get, like, props and be like, you can do this. That was. I mean, that's what a good leader does, right? It's just kind of let a little kid do his thing. Like, go, go do it. Let's see, let's see. See what turns out that's a, that's a pretty powerful thing. But what do you. What's your sense about. He used to be. He now, I think, stepped away from Google. Right. He said sci-fi. I think what, what's really impressive to you about the things that Chris has worked on, because it's that we mentioned the optimization, the compiler design stuff, the LLVM. Then there's. He's also at Google work that TPU stuff. He's obviously worked on Swift. So the programming language side, talking about people that work in the entirety of the stack. From your time, interacting with Chris and knowing the guy, what's really impressive to you that just inspires you?
Speaker B: Well. Well, LLVM became the de facto platform for compilers. It's amazing. And it was good code quality, good design choices. He hit the right level of abstraction. There's a little bit of the right time, the right place. Then he built a new programming language called Swift, which after, let's say, some adoption resistance, became very successful. I don't know that much about his work at Google, although I know that that was a typical. They started Tensorflow stuff and it was new. They wrote a lot of code, and then at some point it needed to be refactored to be, because its development slowed down. Why Pytorch started a little later and then passed it. So he did a lot of work on that. And then his idea about MliR, which is what people started to realize, is the complexity of the software stack above the low level. Ir was getting so high that forcing the features of that into low level was putting too much of a burden on it. So he's splitting that into multiple pieces. That was one of the inspirations for our software stack, where we have several intermediate representations that are all executable and you can look at them and do transformations on them before you lower the level. So that was, I think we started before Mlir really got far enough along to use, but we're interested in that.
Speaker A: He's really excited about Mlir. That's his little baby. And there seems to be some profound ideas on that that are really useful.
Speaker B: So each one of those things has been, as the world of software gets more and more complicated, how do we create the right abstraction levels to simplify it in a way that people can now work independently on different levels of it? So I would say all three of those projects, LLVM, Swift and Mlir, did that successfully. So I'm interested was what he's going to do next in the same kind of way?
Speaker A: Yes. So on the either the TPU or maybe the Nvidia GPU side, how does ten store, you think? Or the ideas underlying it doesn't have to be test, or just this kind of graph focused, graph centric hardware. Deep learning centric hardware beat Nvidias. Do you think it's possible for it to basically overtake Nvidia?
Speaker B: Sure.
Speaker A: What's that process look like? What's that journey look like, you think?
Speaker B: Well, GPU's were built to run shader programs on millions of pixels, not to run graphs.
Speaker A: Yes.
Speaker B: So there's a hypothesis that says the way the graphs are built is going to be really interesting to be inefficient on computing this. And then the primitives is not a SIMD program, it's matrix multiply convolution. And then the data manipulations are fairly extensive about how do you do a fast transpose with a program? I don't know if you've ever written a transpose program. They're ugly and slow, but in hardware you can do really well. I'll give you an example. When GPU accelerators started doing triangles like so, you have a triangle which maps on the set of pixels. So you build, it's very easy, straightforward to build a hardware engine that'll find all those pixels. And it's kind of weird because you walk along the triangle to get to the edge, and then you have to go back down to the next row and walk along. And then you have to decide on the edge. If the line of the triangle is like half on the pixel, what's the pixel color? Because it's half of this pixel and half the next one. That's called rasterization.
Speaker A: You're saying that could be done in hardware?
Speaker B: No, just that's an example of that operation as a software program is really bad. I've written a program that did rasterization. The hardware that does it is actually less code than the software program that does it, and it's way faster. So there are certain times when the abstraction you have rasterize a triangle, execute a graph, components of a graph. The right thing to do in the hardware software boundary is for the hardware to naturally do it.
Speaker A: So the GPU is really optimized for the rasterization of triangles.
Speaker B: Well, no, that's just, well, like in a modern, you know, that's a small piece of modern GPU's. What they did is that they still rasterize triangles when you're running a game. But for the most part, most of the computation in the area, the GPU is running shader programs, but they're single threaded programs on pixels, not graphs, to be honest.
Speaker A: And say, I don't actually know the math behind shader shading and lighting and all that kind of stuff, I don't.
Speaker B: Know what they look like. Little simple floating point programs or complicated ones. You can have 8000 instructions in a.
Speaker A: Shader program, but I don't have a good intuition why it could be parallelized so easily.
Speaker B: No, it's because you have 8 million pixels in every single. So when you have a light, right, that comes down the angle, you know the amount of light, like, say, this is a line of pixels across this table, right? The amount of light on each pixel is subtly different, and each pixel is.
Speaker A: Responsible for figuring out what, figuring it out.
Speaker B: So that pixel says, I'm this pixel. I know the angle of the light, I know the occlusion, I know the color. I am like, every single pixel here is a different color. Every single pixel gets a different amount of light. Every single pixel has a subtly different translucency. So to make it look realistic, the solution was you run a separate program on every pixel.
Speaker A: See? But I thought there's like reflection from all over the place is every pixel.
Speaker B: Yeah, but there is. So you build a reflection map, which also has some pixelated thing, and then when the pixel is looking at the reflection map, has to calculate what the normal of the surface is, and it does it per pixel, by the way, there's boatloads of hacks on that. You're like, you may have a lower resolution light map, reflection map. There's all these hacks. They do. But at the end of the day, it's per pixel computation.
Speaker A: And it so happened that you can map graph like computation onto this pixel centric computation.
Speaker B: You could do floating point programs on convolutions and matrices. And Nvidia invested for years in Cuda, first for HPC, and then they got lucky with the AI trend.
Speaker A: But do you think they're going to essentially not be able to hardcore pivot out of their yemenite?
Speaker B: We'll see. That's always interesting. How often do big companies hardcore pivot? Occasionally.
Speaker A: How much do you know about Nvidia, folks?
Speaker B: Some.
Speaker A: Some. I'm curious as well, who's ultimately as a.
Speaker B: Well, they've, they've innovated several times, but they've also worked really hard on mobile, they worked really hard on radios, you know, you know, they're fundamentally a GPU company.
Speaker A: Well, they tried to pivot. There's an interesting little game and play in autonomous vehicles, right, with, or a semi autonomous, like playing with Tesla and so on, and seeing that's a dipping a toe into that kind of pivot.
Speaker B: They came out with this platform, which was interesting technically, but it was like a 3000 watt, you know, thousand watt, $3,000 GPU platform.
Speaker A: I don't know if it's interesting technically. It's interesting philosophically. I did. Technically. I don't know if it's the execution that craftsmanship is there. I'm not sure, but I didn't get.
Speaker B: A sense they were repurposing GPU's for an automotive solution.
Speaker A: Right. It's not a real pivot.
Speaker B: They didn't, they didn't build a ground up solution.
Speaker A: Right.
Speaker B: Like, the chips inside Tesla are pretty cheap. Like, Mobileye has been doing this. They're, they're doing the classic work from the simplest thing.
Speaker A: Yeah.
Speaker B: You know, they were building 40 square millimeter chips. And Nvidia, their solution had 2800 millimeter chips and 2200 millimeter chips. And I like boatloads are really expensive drams, and it's a really different approach. The Mobileye fit the, let's say, automotive cost and form factor, and then they added features as it was economically viable. And Nvidia said, take the biggest thing and we're going to go make it work. And that's also influenced, like Waymo. There's a whole bunch of autonomous startups where they have a 5000 watt server in their trunk, but that's because they think, well, 5000 watts and $10,000 is okay because it's replacing a driver. Elon's approach was that port has to be cheap enough to put it in every single Tesla, whether they turn on autonomous driving or not, which. And Mobileye was like, we need to fit in the bomb and cost structure that car companies do. So they may sell you a gps for $1,500, but the bomb for that's like $25.
Speaker A: Well, and for Mobile eye, it seems like neural networks were not first class citizens. Like the computation, they didn't start out.
Speaker B: As a. Yeah, it was a cv problem. They did classic cv and found stop lights and lines and they were really good at it.
Speaker A: Yeah. And they never, I mean, I don't know what's happening now, but they never fully pivoted. I mean, it's like, it's the Nvidia thing then, as opposed to. So if you look at the new Tesla work, it's like neural networks from the ground up, right?
Speaker B: Yeah. And even Tesla started with a lot of CV stuff in it, and Andre has basically been eliminating it, move, move everything into the network.
Speaker A: So without, this isn't like confidential stuff, but you sitting on a porch looking over the world, looking at the work that Andre is doing, that Elon's doing with Tesla autopilot. Do you like the trajectory of where things are going on, the hardware?
Speaker B: They're making serious progress. I like the videos of people driving the beta stuff. Like, it's taken some pretty complicated intersections and all that, but it's still an intervention per drive. I mean, I have the current autopilot, my Tesla, I use it every day.
Speaker A: Do you have full self driving beta or no. So you like where this is going?
Speaker B: They're making progress. It's taken longer than anybody thought. You know, my wonder was, is hardware three? Is it enough computing? Off by two, off by five, off by ten, off by 100?
Speaker A: Yeah.
Speaker B: And I thought it probably wasn't enough, but they're doing pretty well with it now. And one thing is the dataset gets bigger, the training gets better, and then there's this interesting thing is you sort of train and build an arbitrary size network that solves the problem, and then you refactor the network down to the thing that you can afford to ship. So the goal isn't to build a network that fits in the phone, it's to build something that actually works. And then how do you make that most effective on the hardware you have? They seem to be doing that much better than a couple years ago.
Speaker A: Well, the one really important thing is also what they're doing well is how to iterate that quickly. Which means, like, it's not just about one time deployment, one building, it's constantly iterating the network and trying to automate as many steps as possible.
Speaker B: Right.
Speaker A: And that's actually the principles of the software 2.0, like you mentioned with Andre, is it's not just. I mean, I don't know what the actual, his description of software 2.0 is, if it's just high level philosophical or their specifics. But the interesting thing about what that actually looks in the real world is it's that what I think Andre calls the data engine. It's the iterative improvement of the thing. You have a neural network that does stuff, fails on a bunch of things, and learns from it over and over and over. So you're constantly discovering edge cases. So it's very much about data engineering, figuring out. It's kind of what you were talking about with ten storm is you have the data landscape. You have to walk along that data landscape in a way that's constantly improving the neural network, and that feels like that's the central piece that's.
Speaker B: And there's two pieces of it. You find edge cases that don't work, and then you define something that goes, get your data for that. But then the other constraint is whether you have to label it or not. Like, the amazing thing about the GPT-3 stuff is it's unsupervised. So there's essentially infinite amount of data. Now, there's obviously infinite amount of data available from cars, of people successfully driving. But the current pipelines are mostly running on labeled data, which is human limited. So when that becomes unsupervised, it'll create unlimited amount of data, which then they'll scale. Now, the networks that may use that data might be way too big for cars, but then there'll be the transformation from, now we have unlimited data. I know exactly what I want. Now can I turn that into something that fits in the car? And that process is going to happen all over the place every time you get to the place where you have unlimited data. And that's what software 2.0 is about, unlimited data training networks, to do stuff without humans writing code to do it.
Speaker A: And ultimately also trying to discover, like you're saying, the self supervised formulation of the problem. So the unsupervised formulation of the problem. Like, you know, in driving, there's this really interesting thing, which is you look at a scene that's before you, and you have data about what a successful human driver did in that scene, you know, 1 second later, it's a little piece of data that you can use, just like with GPT-3 as training currently, even though Tesla says they're using that, it's an open question to me. How much, how far can you, can you solve all of the driving with just that self supervised piece of data? And, like, I think that's what common AI is doing. That's what common AI is doing. But the question is how. How much data? So what Kamei doesn't have is as good of a data engine, for example, as Tesla does. That's where the, like, the organization of the data. I mean, as far as I know, I haven't talked to George, but they do have the data. The question is how much data is needed, because we say infinite very loosely here. And then the other question, which you said, I don't know if you think it's still an open question, is, are we in the right order of magnitude for the compute necessary? That is this is it like what Elon said, this chip that's in there now is enough to do full self driving or doing another order of magnitude? I think nobody actually knows the answer to that question. I like the confidence that Elon has.
Speaker B: But, yeah, we'll see. There's another funny thing, is you don't learn to drive with infinite amounts of data. You learn to drive with an intellectual framework that understands physics and color and horizontal surfaces and laws and roads, and all your experience from manipulating your environment. There's so many factors go into that. So then, when you learn to drive, driving is a subset of this conceptual framework that you have. Self driving cars right now, we're teaching them to drive with driving data. You never teach a human to do that. You teach a human all kinds of interesting things, like language, like, don't do that. You know, watch out, you know, there's all kinds of stuff going on.
Speaker A: Well, this is where you, I think previous time we talked about where you poetically disagreed with my naive notion about humans. I just think that humans will make this whole driving thing really difficult.
Speaker B: Yeah, all right. I said humans don't move that slow. It's a ballistics problem.
Speaker A: It's a ballistic. Humans are a ballistics problem, which is like poetry to me. It's very, it's very possible that in driving there, indeed, purely a ballistics problem. I, and I think that's probably the right way to think about it. But I still, they still continue to surprise me. Those damn pedestrians, the cyclists, other humans and other cars. And.
Speaker B: Yeah, but it's going to be one of these compensating things. So when you're driving, you have an intuition about what humans are going to do, but you don't have 360 cameras and radars, and you have an attention problem. So the self driving car comes in with no attention problem, 360 cameras, a bunch of other features. So they'll wipe out a whole class of accidents. And emergency braking with radar, and especially as it gets AI enhanced, will eliminate collisions. Yeah, right. But then you have the other problems of these unexpected things where, you know, you think your human intuition is helping. But then the cars also have, you know, a set of hardware features that you're not even close to.
Speaker A: And the key thing, of course, is if you wipe out a huge number of kind of accidents, then it might be just way safer than a human driver. Even though. Even if humans are still a problem, that's hard to figure out.
Speaker B: Yeah, that's probably what will happen, is autonomous cars will have a small number of accidents humans would have avoided, but they'll wipe. They'll get rid of the bulk of them.
Speaker A: What do you think about Tesla's dojo efforts? Or it can be bigger than Tesla in general. It's kind of like the tense torrent trying to innovate. This is the dichotomy. Should a company try to, from scratch, build its own neural network training hardware?
Speaker B: Well, first, I think it's great. So we need lots of experiments, right? And there's lots of startups working on this, and they're pursuing different things. I was there when we started dojo, and it was sort of like, what's the unconstrained computer solution to go do very large training problems? And then there's fun stuff like, you know, we said, well, we have this 10,000 watt board to cool. Well, you go talk to guys at SpaceX, and they think 10,000 watts is a really small number, not a big number.
Speaker A: Yeah.
Speaker B: And there's brilliant people working on it. I'm curious to see how it'll come out. I couldn't tell you. I know. It pivoted a few times since I left.
Speaker A: The cooling doesn't seem to be a big problem. I do like what Elon said about it, which is like, we don't want to do the thing unless it's way better than the alternative, whatever the alternative is. So it has to be way better than, like, racks or GPU's.
Speaker B: Yeah. And the other thing is, just like the Tesla autonomous driving hardware, it was only serving one software stack, and the hardware team and the software team were tightly coupled. If you're building a general purpose AI solution, and there's so many different customers with so many different needs now, something Andre said is, I think this is amazing. Ten years ago, vision, recommendation language, were completely different disciplines. He said, the people literally couldn't talk to each other. And three years ago, it was all neural networks. But they're very different neural networks. And recently, it's converging on one set of networks. They vary a lot in size, obviously, they vary in data, vary in outputs, but the technology has converged a good bit.
Speaker A: Yeah. These transformers behind GPT-3 it seems like they could be applied to video, they could be applied to a lot of. And they're all really.
Speaker B: It was like to literally replace letters with pixels. It does vision. It's amazing.
Speaker A: And then size actually improves the thing. So the bigger it gets, the more compute you throw at it, the better it gets.
Speaker B: And the more data you have, the better it gets. So then you start to wonder, well, is that a fundamental thing, or is this just another step to some fundamental understanding about this kind of computation? Which is really interesting.
Speaker A: Us humans don't want to believe that that kind of thing will achieve conceptual understandings. You were saying, like, you'll figure out physics, but maybe it will. Maybe.
Speaker B: Probably will. Well, it's worse than that. It'll understand physics in ways that we can't understand. I like your Stephen Wolfram talk where he said, there's three generations of physics. There was physics by reasoning. Well, big things should fall faster than small things, right? That's reasoning. And then there's physics by equations, like, you know. But the number of programs in the world that are solved with the single equation is relatively low. Almost all programs have, you know, more than one line of code, maybe 100 million lines of code. So he said then, now we're going to physics by equation, which is his project, which is cool. I might point out that there was two generations of physics before reasoning habit. Like all animals, you know? No things fall and birds fly and, you know, predators know how to, you know, solve a differential equation to cut off a accelerating, you know, curving animal path. And then there was, you know, the gods did it, right? So. Yeah, right, so there was, you know, there's five generations now. Software 2.0 says programming things is not the last step data. So there's going to be a physics bass Stevens Wolfram's compensation that's not explainable to us humans. And actually, there's no reason that I can see, well, that even that's the limit. Like, there's something beyond that. I mean, they're usually like, usually when you have this hierarchy, it's not like, well, if you have this step and this step and this step, and they're all qualitatively different and conceptually different, it's not obvious why, you know, six is the right number of hierarchy steps and not seven or eight or.
Speaker A: Well, then it's probably impossible for us to, to comprehend something that's beyond the thing that's not explainable.
Speaker B: Yeah, but the thing. But the thing that, you know, understands the thing that's not explainable to us will conceive the next one. And, like, I'm not sure why there's a limit to it. Click. Your brain hurts. That's a sad story.
Speaker A: If we look at our own brain, which is an interesting, illustrative example. In your work with testorrent and trying to design deep learning architectures, do you think about the brain at all? Maybe from a hardware designer perspective, if you could change something about the brain, what would you change or do?
Speaker B: Funny question.
Speaker A: How would you do?
Speaker B: So, your brain is really weird. Like your cerebral cortex, where we think we do most of our thinking, is what, like six or seven neurons thick? Yeah, like, that's weird. Like, all the big networks are way bigger than that. Like, way deeper. So that seems odd. And then, you know, when you're thinking, if it's. If the input generates a result, you can lose, it goes really fast, but if it can't, that generates an output that's interesting, which turns into an input and then your brain to the point where you mold things over for days and how many trips through your brain is that? Right? Like it's 300 milliseconds or something to get through seven levels of neurons. I forget the number. Exactly. But then it does it over and over and over as it searches. And the brain clearly looks like some kind of graph because you have a neuron with connections and it talks to other ones and it's locally very computationally intense, but it also does sparse computations across a pretty big area.
Speaker A: There's a lot of messy biological type of things, and it's. It's meaning, like, first of all, there's mechanical, chemical, and electrical signals. That's all that's going on. Then there's the asynchronicity of signals, and there's, like, there's just a lot of variability that seems continuous and messy and just a mess of biology. And it's unclear whether that's a good thing or it's a bad thing, because if it's a good thing, then we need to run the entirety of the evolution. Well, we're gonna have to start with basic bacteria to create something.
Speaker B: Imagine we could control. You could build a brain with ten layers. Would that be better or worse or more more connections or less connections? Or, you know, we don't know to what level our brains are optimized. But if I was changing things, like, yeah, like, you know, you can only hold, like, seven numbers in your head? Yeah, like, why not 100 or a million?
Speaker A: Never thought of that.
Speaker B: And why can't, like, why can't we have, like, a floating point processor that can compute anything we want, like, and see it all properly? That would be kind of fun. And why can't we see in four or eight dimensions? 3d is kind of a drag. Like, all the hard mass transforms are up in multiple dimensions. So you could imagine a rain architecture that you could enhance with a whole bunch of features that would be really useful for thinking about things.
Speaker A: It's possible that the limitations you're describing are actually essential for, like, the constraints are essential for creating, like, the depth of intelligence, like that, the ability to reason, you know?
Speaker B: Yeah, it's hard to say because, like, your brain is clearly a parallel processor, you know?
Speaker A: Yeah.
Speaker B: You know, 10 billion neurons talking to each other at a relatively low clock rate, but it produces something that looks like a serial thought process. It's a serial narrative in your head. I. That's true. But then there are people, famously, who are visual thinkers. Like, I think I'm a relatively visual thinker. I can imagine any object and rotate it in my head and look at it, and there are people who say they don't think that way at all. And recently I read an article about people who say they don't have a voice in their head. They can talk, but when they, you know, it's like, well, what are you thinking? They'll describe something that's visual. So that's curious. Now, if you're saying if we dedicated more hardware to holding information, like ten numbers or a million numbers, would that distract us from our ability to form this kind of singular identity?
Speaker A: Like it dissipates somehow.
Speaker B: Right, but maybe future humans will have many identities that have some higher level organization, but can actually do lots more things in parallel.
Speaker A: Yeah, there's no reason, if we're thinking modularly, there's no reason we can't have multiple consciousnesses in one brain.
Speaker B: Yeah, and maybe there's some way to make it faster so that the area of the computation could still have a unified feel to it while still having way more ability to do parallel stuff the same time. Could definitely be improved.
Speaker A: Could be improved. Yeah. Well, it's pretty good right now, actually. People don't give it enough credit. The thing is pretty nice. The fact that the ride ends seemed to be given nice spark of beauty to the whole experience. I don't know. I don't know if it can be improved easily.
Speaker B: It could be more beautiful.
Speaker A: I don't know how I. Yeah.
Speaker B: What do you mean, how? All the ways you can't imagine.
Speaker A: No, but that's the whole point. I wouldn't be able to. The fact that I can imagine ways in which it could be more beautiful.
Speaker B: Means, you know, Ian Banks, his stories. So the super smart AI's there live, mostly live in the world of what they call infinite fun, because they can create arbitrary worlds, so they interact, and, you know, the story has it, they interact in the normal world, and they're very smart, and they can do all kinds of stuff. And, you know, a given mind can, you know, talk to a million humans at the same time. Because we're very slow and for reasons, you know, artificial, they're interested in people and doing stuff, but they mostly live in this, this other land of thinking.
Speaker A: My inclination is to think that the ability to create infinite fun will will not be so fun.
Speaker B: That's sad. Why? There's so many things to do. Imagine being able to make a star move planets around.
Speaker A: Yeah, yeah, but because we can imagine. That is why life is fun. If we can, if we actually were able to do it, it'd be a slippery slope where fun wouldn't even have a meaning, because we just consistently desensitize ourselves by the infinite amounts of fun we're having. The sadness, the dark stuff, is what makes it fun. I think that could be the russian.
Speaker B: Could be the fun makes it fun, and the sadness makes it bittersweet.
Speaker A: Yeah, that's true. Fun could be the thing that makes it fun. So what do you think about the expansion not through the biology side, but through the BCI, the brain computer interfaces. Yeah, you got a chance to check out the neuralink stuff.
Speaker B: It's super interesting. Like, like humans, like, like our thoughts to manifest as action, you know, like, like, as a kid, you know, like, shooting a rifle was super fun, driving a mini bike, doing things. And then computer games, I think for a lot of kids became the thing where they, you know, they can do what they want, they can fly a plane, they can do this, they can do this. Right. But you have to have this physical interaction. Now imagine, you know, you could just imagine stuff and it happens, right? Like really richly and interestingly, like, we kind of do that when we dream. Like, dreams are funny because, like, if you have some control or awareness in your dreams, like, it's very realistic looking or not realistically, depends on the dream, but you can also manipulate that. And what's possible there is odd. And the fact that nobody understands it's hilarious.
Speaker A: But do you think it's possible to expand that capability through computing?
Speaker B: Sure.
Speaker A: Is there some interesting. So from a hardware designer perspective, is there, do you think it'll present totally new challenges in the kind of hardware required that, like. So this hardware isn't standalone computing. Well, this is not working with the brain.
Speaker B: So today computer games are rendered by GPU's and, but you've seen the gans stuff where trained neural networks render realistic images, but there's no pixels, no triangles, no shaders, no lightmaps, no nothing. So the future of graphics is probably AI.
Speaker A: Yes.
Speaker B: Now that AI is heavily trained by lots of real data. So if you have an interface with AI renderer. So if you say render a cat, it won't say, well, how tall is the cat and how big it, you know, it'll render a cat. And you might say, well, a little bigger, a little smaller, you know, make it a tabby shorter hair. Like, you could tweak it. Like, the amount of data you'll have to send to interact with a very powerful AI renderer could be low.
Speaker A: But the question is, brain computer interfaces would need to render not onto a screen, but render onto the brain. And like directly. So there's a bandwidth.
Speaker B: Well, it could do it both ways. I mean, our eyes are really good sensors. It could render onto a screen, and we could feel like we're participating in it. You know, they're gonna, they're gonna have, you know, like the oculus kind of stuff. It's gonna be so good. When a projection to your eyes, you think it's real. You know, they're slowly solving those problems. And I suspect when the renderer of that information into your head is also AI mediated, they'll be able to give you the cues that you know you really want for depth and all kinds of stuff. Like your brain is partly faking your visual field. Right. Like, your eyes are twitching around, but you don't notice that occasionally they blank. You don't notice that. You know, there's all kinds of things, like you think you see over here, but you don't really see there. It's all fabricated.
Speaker A: Yeah. So peripheral vision is fascinating.
Speaker B: So if you have an AI renderer that's trained to understand exactly how you see and the kind of things that enhance the realism of that experience could be super real, actually. So I don't know what the limits to that are, but obviously, if we have a brain interface that goes in, inside your, you know, visual cortex in a better way than your eyes do, which is possible, it's a lot of neurons. Yeah, maybe that'll be even cooler.
Speaker A: But the really cool thing is it has to do with the. The infinite fun that you're referring to, which is our brains seem to be very limited, and like you said, computations.
Speaker B: So. Very plastic.
Speaker A: Very plastic, yeah.
Speaker B: Yeah. So it's a. It's a interesting combination.
Speaker A: The interesting open question is the limits of that neuroplasticity. Like, how flexible is that thing? Because we haven't really tested it.
Speaker B: We know about that. The experiments where they put a pressure pad on somebody's head and had a visual transducer pressurize it, and somebody slowly learned to see.
Speaker A: Yep. Especially at a young age, if you throw a lot at it, like, what? What can it. Can it completely? So can you arbitrarily expand it with computing power so connected to the Internet directly somehow?
Speaker B: Yeah, the answer is probably yes.
Speaker A: So the problem with biology and ethics is, like, there's a mess there. Like us, humans are perhaps unwilling to take risks into directions that are full of uncertainty.
Speaker B: So it's like 90% of the population is unwilling to take risks. The other 10% is rushing into the risks unaided by any infrastructure whatsoever. And that's where all the fun happens in society. There's been huge transformations in the last couple thousand years.
Speaker A: Yeah. It's funny. I gotten the chance to interact with this Matthew Johnson from Johns Hopkins. He's doing this large scale study of psychedelics. It's becoming more and more I've gotten a chance to interact with that community of scientists working on psychedelics. But because of that, that opened the door to me to all these, what do they call it? Psychonauts. The people who, like you said, the 10% who are like, I don't care. I don't know if there's a science behind this. I'm taking the spaceship. If I'm be the first on Mars, I'll be psychedelics. Interesting in the sense that in another dimension, like you said, it's a way to explore the. With the limits of the human mind. Like, what is this thing capable of doing? Because you kind of, like, when you dream, you detach it. I don't know exactly the neuroscience of it, but you detach your, like, reality from what your mind, the images your mind is able to conjure up, and your mind goes into weird places and, like, entities appear somehow. Freudian type of, like, trauma is probably connected in there somehow, but you start to have, like, these weird, vivid worlds that, like.
Speaker B: So do you actively dream? Do you? Why not? I have, like, six, 6 hours of dreams, and I. It's like, really useful time.
Speaker A: I know. I don't, I haven't, I don't. For some reason, I just knock out and I have sometimes, like, anxiety inducing, kind of, like, very pragmatic, like, nightmare type of dreams, but not. Nothing fun. Nothing.
Speaker B: Nothing fun.
Speaker A: Nothing fun. I try. I unfortunately have mostly have fun in the waking world, which is very limited in the amount of fun you can have.
Speaker B: It's not that limited either.
Speaker A: Yeah.
Speaker B: That's why we'll have to talk.
Speaker A: Yeah, I need instructions.
Speaker B: Yeah, there's like a manual for that. You might want to.
Speaker A: I'll look it up. I'll ask Elon, what would you dream.
Speaker B: Of, you know, years ago? And I read about, you know, like, you know, a book about how to have, you know, become aware in your dreams. I worked on it for a while. Like, there's this trick about, you know, imagine you can see your hands and look out and. And I got somewhat good at it. Like, but my, mostly when I'm thinking about things or working on problems, I prep myself before I go to sleep. It's like I pull into my mind all the things I want to work on or think about, and then that, let's say, greatly improves the chances that I'll work on that while I'm sleeping. And then I also basically asked to remember it. And I often remember very detailed within.
Speaker A: The dream or outside the dream to.
Speaker B: Bring it up in, in my dreaming and then to remember it when I wake up. It's just, it's more of a meditative practice to say, you know, to prepare yourself to do that. Like, if you go to, you know, to sleep still gnashing your teeth about some random thing that happened that you're not that really interested in, you'll dream about it.
Speaker A: That's really interesting. Maybe, but.
Speaker B: But you can direct your dreams somewhat by prepping.
Speaker A: Yeah, I'm gonna have to try that. It's really interesting. Like the most important, the interesting. Not like, what, did this guy send an email? Kind of like stupid worry stuff, but like fundamental problems. You're actually concerned about prepping and interesting.
Speaker B: Things you're worried about or books you're reading or some great conversation you had or some adventure you want to have. There's a lot of space there, and it seems to work that my percentage of interesting dreams and memories went up.
Speaker A: Is that the source of, if you were able to deconstruct where some of your best ideas came from, is there a process that's at the core of that? Some people walk and think, some people in the shower, the best ideas hit them. If you talk about like, Newton Apple hitting them on the head.
Speaker B: No, I found out a long time ago. I process things somewhat slowly. So, like, in college, I had friends that could study at the last minute, get an a next day. I can't do that at all. So I always front loaded all the work, like, I do all the problems early, you know, for finals, like the last three days, I wouldn't look at a book because I want, you know. Cause like a new fact day before finals may screw up my understanding of what I thought I knew. So my goal was to always get it in and give it time to soak. And I used to, you know, I remember when we were doing like, 3d calculus, I would have these amazing dreams of 3d surfaces with normal, you know, calculating the gradient. And this is like, all come up. So it was really fun, like, very visual. And, and if I got cycles of that, that was useful. And the other is just don't over filter your ideas. Like, I like that process of brainstorming where lots of ideas can happen. I like people who have lots of ideas and they sit, then there's a. Yeah, I let them sit and let it breathe a little bit and then reduce it to practice. Like, at some point you really have to. Does it really work? Like, is this real or not? Right, but you have to do both. There's creative tension there. Like, how do you be both open and, you know, precise?
Speaker A: Have you had ideas that you just, that sit in your mind for like, years before the. Sure, that's, it's an interesting way to generate ideas and just let them sit. Let them sit there for a while. I think I have a few of those ideas.
Speaker B: Yeah, that was so funny. Yeah, I think that's, you know, creativity.
Speaker A: Discipline or something for the slow thinkers in the, in the room, I suppose, as I. Some people, like you said, are just like, like the.
Speaker B: Yeah, it's really interesting. There's so much diversity in how people think, you know, how fast or slow they are, how well they remember or don't look. You know, I'm not super good at remembering facts, but processes and methods, like in our engineering. I went to Penn State and almost all our engineering tests were open book. I could remember the page and not the formula, but as soon as I saw the formula, I could remember the whole method if I learned it. So it's a funny where some people could swatch friends flipping through the book, trying to find the formula, even knowing that they'd done just as much work. And I would just open the book. It's on page 27, bottom half. I could see the whole thing visually.
Speaker A: Yeah. And you have to learn that about yourself and figure out what function optimally.
Speaker B: I had a friend who was always concerned. He didn't know how he came up with ideas. He had lots of ideas, but he said they just sort of popped up. Like you'd be working on something, having this idea, like, where does it come from? But you can have more awareness of it. Like how your brain works is a little murky as you go down from the voice in your head or the obvious visualizations. Like when you visualize something, how does that happen? Yeah, you know, if I say, you know, visualize volcano, it's easy to do. Right.
Speaker A: And what does it actually look like when you visualize it?
Speaker B: I can visualize to the point where I don't see very much out of my eyes and I see the colors of the thing I'm visualizing.
Speaker A: Yeah, but there's like, there's a shape, there's a texture, there's a color, but there's also conceptual visualization. Like, what are you actually visualizing when you're visualizing volcano? Just like with peripheral vision, you think you see the whole thing.
Speaker B: Yeah, yeah, that's a good way to say it. You know, you have this kind of almost peripheral vision of your visualizations. They're like these ghosts. But if, you know, if you, if you work on it, you can get a pretty high level of detail and.
Speaker A: Somehow you can walk along those visualizations and come up with an idea, which.
Speaker B: Is weird, but when you're thinking about solving problems, like, you're putting information in, you're exercising the stuff you do know. You're sort of teasing the area that's you don't understand and don't know, but you can almost, you know, feel, you know, that process happening. You know, that's, that's how I like, like, I know sometimes when I'm working really hard on something, like, like, I get really hot when I'm sleeping, and, you know, it's like, we got the blankets roll. I wake up, all the blankets are on the floor, and, and, you know, every time it's. Well, I wake up and think, wow, that was great. You know?
Speaker A: Are you able to reverse engineer what the hell happened there?
Speaker B: Oh, sometimes it's vivid dreams, and sometimes it's just kind of, like you say, like, shadow thinking that you sort of have this feeling you're, you're going through this stuff, but it's, it's not that obvious.
Speaker A: Isn't that so amazing at the mind just does all these little experiments. I never, you know, I thought, I always thought it's like a river that you can't, you're just there for the ride. But you're right. If you prep it.
Speaker B: No, it's all understandable. Meditation really helps. You got to start figuring out, you need to learn the language of your own mind. And there's multiple levels of it.
Speaker A: But the abstractions again, right.
Speaker B: It's somewhat comprehensible and observable and feelable, or whatever the right word is. Yeah. You're not along for the ride. You are the ride.
Speaker A: I have to ask you, hardware engineer working on neural networks now, what's consciousness? What the hell is that thing? Is that just some little weird quirk of our particular computing device? Or is it something fundamental that we really need to crack open if we're to build good computers? Do you ever think about consciousness? Like, why it feels like something to be.
Speaker B: I know, it's really weird. So, yeah, I mean, everything about it is weird. First, it's a half a second behind reality, right? It's a post hoc narrative about what happened. You've already done stuff by the time you're conscious of it, and your consciousness generally is a single threaded thing, but we know your brain is 10 billion neurons running some crazy parallel thing, and there's a really big sorting thing going on there. It also seems to be really reflective in the sense that you create a space in your head. We don't really see anything? Photons hit your eyes. It gets turned into signals. It goes through multiple layers, the neurons. I'm so curious. That looks glassy. And that looks not glassy, how the resolution of your vision is so high, you have to go through all this processing where for most of it, it looks nothing like vision. Like there's no theater in your mind, right? So we have a world in our heads. We're literally just isolated behind our sensors, but we can look at it, speculate about it, speculate about alternatives, problem solve. What if, you know, there's so many things going on, and that process is.
Speaker A: Lagging reality, and it's single threaded, even though the underlying thing is massively parallel.
Speaker B: So it's so curious. So imagine you're building an AI computer. If you wanted to replicate humans, well, you'd have huge arrays of neural networks and apparently only six or seven deep, which, hilarious, they don't even remember seven numbers, but I think we can upgrade that a lot. And then somewhere in there, you would train the network to create basically the world you live in. Right?
Speaker A: So, like, tell stories to itself about the world that it's perceiving.
Speaker B: Well, create this. Create the world, tell stories in the world, and then have many dimensions of, you know, like, sideshows to it. Like, we have an emotional structure, like we have a biological structure, and that seems hierarchical too. Like, if you're hungry, it dominates your thinking. If you're mad, it dominates your thinking. And we don't know if that's important to consciousness or not, but it certainly disrupts intrudes in the consciousness. So there's lots of structure to that. And we like to dwell on the past. We like to think about the future. We like to imagine, we like to fantasize. And the somewhat circular observation of that is the thing we call consciousness. Now, if you created a computer system that did all things, create worldviews, created future alternate histories, you know, dwelled on past events, you know, accurately or semi accurately, you know, it's. It's.
Speaker A: Will consciousness just spring up like natural?
Speaker B: Well, would that feel, look and feel conscious to you? Like, you seem conscious to me, but I observer sense.
Speaker A: Do you think a thing that looks conscious is conscious? Like, do you? Again, this is like an engineering kind of question, I think, because, like, if we want to engineer consciousness, is it okay to engineer something that just looks conscious, or is it, is there a difference between.
Speaker B: Well, we evolve consciousness because it's a super effective way to manage our affairs.
Speaker A: Yeah, right. Social element. Yeah.
Speaker B: Well, it gives us a planning system, you know, we have a huge amount of stuff. Like, when we're talking, like, the reason we can talk really fast is we're modeling each other a really high level.
Speaker A: Of detail, and consciousness is required for that.
Speaker B: Well, all those components together manifest consciousness. Right. So if we make intelligent beings that we want to interact with, that we're like, you know, wondering what they're thinking, you know? You know, looking forward to seeing them, you know, when they interact with them, they. They're interesting, surprising, you know, fascinating. You know, they will probably. We feel conscious like we do, and we'll. We'll perceive them as conscious. I don't know why not, but you never know.
Speaker A: Another fun question on this, because from a computing perspective, we're trying to create something that's human like or superhuman like. Let me ask you about aliens.
Speaker B: Aliens.
Speaker A: Do you think there's intelligent alien civilizations out there? And do you think there technology, their computing, their AI bots, their chips are of the same nature as ours?
Speaker B: I have no idea. I mean, if there's lots of aliens out there, they've been awfully quiet. There's speculation about why there seems to be more than enough planets out there.
Speaker A: There's a lot.
Speaker B: Yeah. There's intelligent life on this planet that seems quite different. You know, like, you know, dolphins seem like plausibly understandable. Octopuses don't seem understandable at all. If they live longer than a year, maybe they would be running the planet. They seem really smart, and their neural architecture is completely different than ours. Now, who knows how they perceive things?
Speaker A: I mean, that's the question is for us intelligent beings, we might not be able to perceive other kinds of intelligence if they become sufficiently different than us.
Speaker B: Yeah. We live in the current constrained world. You know, it's three dimensional geometry, and the geometry defines a certain amount of physics. And, you know, there's like, how time work seems to work. Like, there's so many things that seem like a whole bunch of the input parameters to the, you know, another conscious being are the same. Yes. Like, if it's biological, biological things seem to be in a relatively narrow temperature range, right? Because, you know, organics don't. Aren't stable, too cold or too hot. So if you specify the list of things that input to that. But as soon as we make really smart beings and they go solve about how to think about a billion numbers at the same time and how to think in n dimensions, there's a funny science fiction book where all the society had uploaded into this matrix. And at some point, some of the beings in the matrix thought, I wonder if there's intelligent life out there. So they had to do a whole bunch of work to figure out how to make a physical thing because their matrix was self sustaining, and they made a little spaceship and they traveled to another planet. When they got there, there was life running around, but there was no intelligent life. And then they figured out that there was these huge organic matrix all over the planet inside there, where intelligent beings had uploaded themselves into that matrix. So everywhere intelligent life was, soon as it got smart, it up leveled itself into something way more interesting than 3d geometry.
Speaker A: Yeah, it escaped whatever this upload was better. The essence of what we think of as an intelligent being. I tend to like the thought experiment of the organism. Like humans aren't the organisms. I like the notion of Richard Dawkins and memes that ideas themselves are the organisms that are just using our minds to evolve. So we're just meat receptacles for ideas to breed and multiply and so on. And maybe those are the aliens.
Speaker B: So Jordan Peterson has lined, says, you think you have ideas, but ideas have you?
Speaker A: Yeah.
Speaker B: Right. And then we know about the phenomenon of groupthink, and there's so many things that constrain us. But I think you can examine all that and not be completely owned by the ideas and completely sucked into groupthink. And part of your responsibility as a human is to escape that kind of phenomena, which isn't a, you know, it's, you know, it's, it's one of the creative tension things. Again, you're constructed by it, but you can still observe it and you can think about it, and you can make choices about, to some level how constrained you are by it. And, you know, it's useful to do that. And, but, but they're at the same time, and it could be by doing that, you know, the group and society you're part of becomes collectively even more interesting. So, you know, so the outside observer will think, wow, you know, all these Lexus running around with all these really independent ideas have created something even more interesting in the aggregate. So. So I don't know, I'm, those are lenses to look at the situation, but give you some inspiration. But I don't think they're constraints. Right.
Speaker A: As a small little quirk of history, it seems like you're related to Jordan Peterson. Like you mentioned, he's going through some rough stuff. Now. Is there some comment you can make about the roughness of the human journey, the ups and downs?
Speaker B: Well, I became an expert in Benzod withdrawal, like, which is you took benzodiazepines, and at some point, they interact with Gaba circuits, you know, to reduce anxiety and do a hundred other things. Like, there's actually no known list of everything they do because they interact with so many parts of your body. And then once you're on them, you habituate to them, and you're, you're. You have a dependency. It's not like you're a drug dependency where you're trying to get high. It's a yemenite, it's a metabolic dependency. And then if you discontinue them, there's a funny thing called kindling, which is if you stop them and then go, you know, you'll have a horrible thrall symptoms, and if you go back on them at the same level, you won't be stable. And that, unfortunately, happened to him, because.
Speaker A: It'S so deeply integrated into all the kinds of systems in the body, it.
Speaker B: Literally changes the size and numbers of neurotransmitter sites in your brain.
Speaker A: Yeah.
Speaker B: So there's a, there's a process called the Ashton protocol, where you taper it down slowly. Over two years, the people go through that, go through unbelievable hell. And what Jordan went through seemed to be worse, because on advice of doctors, you know, well, stop taking these and take this. It was a disaster. And he got some. Yeah, it was pretty tough. Um, he seems to be doing quite a bit better intellectually. You can see his brain clicking back together. I spent a lot of time with, I've never seen anybody suffer so much.
Speaker A: Well, his brain is also, like this powerhouse. Right? So I wonder, does a brain that's able to think deeply about the world suffer more through these kinds of withdrawals?
Speaker B: Like, I don't know, I've watched videos of people going through withdrawal. They, they all seem to suffer unbelievably. And, you know, my heart goes out to everybody. And there's some funny math about this. Some doctor said, as best he can tell, there's the standard recommendations, don't take them for more than a month and then taper over a couple of weeks. Many doctors prescribe them endlessly, which is against the protocol, but it's common. And then something like 75% of people, when they taper, it's. Half the people have difficulty, but 75% get off okay, 20% have severe difficulty, and 5% have life threatening difficulty. And if you're one of those, it's really bad. And the stories that people have on this is heartbreaking and tough.
Speaker A: So you put some of the fault at the doctors they just not know what the hell they're doing.
Speaker B: Oh, no. It's hard to say. It's one of those commonly prescribed things. Like one doctor said, what happens is, if you're prescribed them for a reason, and then you have a hard time getting off the protocol basically says you're either crazy or dependent, and you get kind of pushed into a different treatment regime. You're a drug addict or a psychiatric patient. And so, like one doctor said, you know, I prescribed them for ten years, thinking I was helping my patients, and I realized I was really harming them. And, you know, the awareness of that is slowly coming up. The fact that they're casually prescribed to people is horrible, and it's bloody scary. And some people are stable on them, but they're on them for life. Like, once you know it's another one of those drugs. But benzos, long range, have real impacts on your personality. People talk about the benzo bubble, where you get disassociated from reality and your friends a little bit. It's really terrible.
Speaker A: The mind is terrifying. We're talking about how the infinite possibility of fun, but, like, it's the infinite possibility of suffering, too, which is one of the dangers of, like, expansion of the human mind. It's like, I wonder if all the possible human experiences that an intelligent computer can have, is it mostly fun or is it mostly suffering? So, like, if you. If you brute force expand the set of possibilities, like, are you going to run into some trouble in terms of torture and suffering and so on? Maybe our human brain is just protecting us from much more possible pain and suffering. Maybe the space of pain is much larger than we could possibly imagine.
Speaker B: The world's in a balance. All the literature on religion and stuff, the struggle between good and evil is balanced, very finely tuned for reasons that are complicated. But that's a long philosophical conversation.
Speaker A: Speaking of balance, that's complicated, I wonder, because we're living through one of the more important moments in human history with this particular virus. It seems like pandemics have at least the ability to kill off most of the human population at their worst. And there's just fascinating, because there's so many viruses in this world. There's so many. I mean, viruses basically around the world in the sense that they've been around very long time. They're everywhere. They seem to be extremely powerful in a distributed kind of way, but at the same time, they're not intelligent and they're not even living. Do you have high level thoughts about this virus that, like, in terms of, you being fascinated or terrified or somewhere in between.
Speaker B: So I believe in frameworks, right? So, like, one of them is evolution. Like, we're evolved creatures, right?
Speaker A: Yes.
Speaker B: And one of the things about evolution is it's hyper competitive. And it's not competitive out of a sense of evil. It's competitive in a sense of there's endless variation and variations that work better when. And then over time, there's so many levels of that competition. You know, like multicellular life partly exists because of the competition between different kinds of life forms. And we know sex partly exists to scramble our genes so that we have genetic variation against the invasion of the bacteria and the viruses, and it's endless. I read some funny statistic. The density of viruses and bacteria in the ocean is really high, and one third of the bacteria die every day because the viruses invading them, like, one third of them.
Speaker A: Wow.
Speaker B: Like, I don't know if that number is true, but it was like, there's like, the amount of competition and what's going on is stunning. And there's a theory as we age, we slowly accumulate bacterias and viruses. And as our immune system kind of goes down, you know, that's what slowly kills us.
Speaker A: And it just feels so peaceful from a human perspective when we sit back and are able to have a relaxed conversation and there's wars going on out there.
Speaker B: Like right now, you're harboring how many bacteria? The ones. Many of them are parasites on you, and some of them are helpful, and some of them are modifying your behavior, and some of them are. It's really wild. But this particular manifestation is unusual in the demographic how it hit and the political response that it engendered and the healthcare response it engendered. Technology. It's gendered. It's kind of wild.
Speaker A: Yeah. The communication on Twitter that it led every level, all that kind of stuff at every. Every single level. Yeah.
Speaker B: But what usually kills life? The big extinctions are caused by meteors and volcanoes.
Speaker A: That's the one you're worried about as opposed to human created bombs that we.
Speaker B: Solar flares are another good one. You know, occasionally solar flares hit the planet.
Speaker A: So it's nature.
Speaker B: Yeah, it's all pretty wild.
Speaker A: Another historic moment. This is perhaps outside, but perhaps within your space of frameworks that you think about. That just happened, I guess, a couple weeks ago, is, I don't know if you're paying attention at all, is the GameStop and Wall street bets. So it's really fascinating. There's kind of a theme to this conversation today because it's like neural networks. It's cool how there's a large number of people in a distributed way almost having a kind of fun. We're able to take on the powerful elites, elite hedge funds, centralized powers and overpower them. Do you have thoughts on this whole saga?
Speaker B: I don't know enough about finance, but it was like the Elon Robinhood guy.
Speaker A: When they talked, what did you think about that?
Speaker B: Well, the Robinhood guy didn't know how the finance system worked. That was clear. He was treating the people who settled the transactions as a black box. And suddenly somebody called him up and said, hey, black box calling you, your transaction volume means you need to put up $3 billion right now. And he's like, I don't have $3 billion. Like, I don't even make any money on these trades. Why do I owe $3 billion while you're sponsoring a trade? So there was a set of abstractions that I don't think either. Now you understand it. This happens in chip design. You buy wafers from TSMC or Samsung or intel, and they say it works like this, and you do your design based on that, and then chip comes back and doesn't work, and then suddenly you start having to open the black boxes. Transistors really work. Like they said, what's the real issue? So there's a whole set of things that created this opportunity, and somebody spotted it. Now, people spot these kinds of opportunities all the time. There's been flash crashes, there's been short squeezes are fairly regular. Every CEO I know hates the shorts because they're manipulating. Theyre trying to manipulate their stock in a way that they make money and deprive value from both the company and the investors. So the fact that some of these stocks were so short, its hilarious that this hasnt happened before. I dont know why. And I dont actually know why some serious hedge funds didnt do it to other hedge funds. And some of the hedge funds actually made a lot of money on this.
Speaker A: Yes.
Speaker B: So my guess is we know 5% of what really happened, and that a lot of the players don't know what happened. And people who probably made the most money aren't the people that they're talking about. Yeah, that's.
Speaker A: Do you think there was something, I mean, this is the cool kind of Elon, you're the same kind of conversationalist, which is like, first principles, questions of, like, what the hell happened? Just very basic questions of, like, was there something shady going on? What, you know, who are the parties involved? This is the basic questions that everybody wants to know about.
Speaker B: Yeah. So, like, we're in a very competitive, hyper competitive world, right. But transactions like buying and selling stock is a trust event. You know, I trust the company representing themselves properly. You know, I bought the stock because I think it's going to go up. I trust that the regulations are solid. Now, inside of that, there's all kinds of places where humans over trust and this exposed, let's say, some weak points in the system. I don't know if it's going to get corrected. I don't know if we have close to the real story. My suspicion is we don't. And listen to that guy. He was a little wide eyed about, and then he did this and then they did that. And I was like, I think you should know more about your business than that. But again, there's many businesses when like, this layer is really stable, you stop paying attention to it. You pay attention to the stuff that's bugging you or new. You don't pay attention to the stuff that just seems to work all the time. You just, you know, sky's blue every day. California. And every once in a while it rains and everybody's like, what do we do? Somebody go bring in the lawn furniture, you know, like, it's getting wet. We don't know why it's getting wet.
Speaker A: Yeah, it doesn't.
Speaker B: I was blue for like 100 days and now it's, you know, so.
Speaker A: But part of the problem here with Vlad, this, the CEO of Robinhood, is the scaling, is that what they've been talking about is there's a lot of unexpected things that happen with the scaling, and you have to be. I think the scaling forces you to then return to the fundamentals.
Speaker B: Well, it's interesting because when you buy and sell stocks, the scaling is the stocks to only move in a certain range. And if you buy a stock, you can only lose that amount of money on the short market, you can lose a lot more than you can benefit. It has a weird cost function or whatever the right word for that is. He was trading in a market where he wasn't actually capitalized for the downside if it got outside a certain range. Now, whether something nefarious has happened, I have no idea. But at some point, the financial risk to both him and his customers was way outside of his financial capacity. And his understanding how the system work was clearly weak or he didn't represent himself. I don't know. The person, when I listened to him, it could have been the surprise question was like. And then these guys called and you know, it sounded like he was treating stuff as a black box. Maybe he shouldn't have, but maybe as a whole pilot expert somewhere else that knew what's going on. I don't, I don't know.
Speaker A: Yep. I mean, this is, uh, this is one of the qualities of a good leader is under fire. You have to perform, and that means to think clearly and to speak clearly. And he dropped the ball on those things because, and understand the problem quickly. Learn and understand the problem at, like, at the, like, basic level, like, what the hell happened?
Speaker B: And my guess is, you know, at some level, it was amateurs trading against, you know, experts slash insiders slash people with, you know, special information.
Speaker A: Outsiders VerSus insiders.
Speaker B: Yeah. And the Insiders, you know, my guess is the next time this happens, we'll make money on it.
Speaker A: The insiders always win.
Speaker B: Well, they have more tools and more incentive. I mean, this always happens. Like, the outsiders are doing this for fun. The Insiders are doing this 24/7 but.
Speaker A: There'S numbers in the Outsiders. This is the interesting thing.
Speaker B: Well, there's numbers on the Insiders, too.
Speaker A: Like different kind of numbers.
Speaker B: Different kind of numbers.
Speaker A: But this could be a new era because I don't know, at least I didn't expect that a bunch of Redditors could, you know, there's, you know, millions of people get together.
Speaker B: The next one won't be a surprise.
Speaker A: But don't you think the crowd, the people are planning the next attack?
Speaker B: We'll see, but it has to be a surprise. Can't be the same game.
Speaker A: As to the like.
Speaker B: It could be there's a very large number of games to play and they can be agile about it. I don't know. I'm not an expert.
Speaker A: Right. That's a good question. The space of games, how restricted is it?
Speaker B: Yeah. And the system is so complicated, it could be relatively unrestricted. And also, like, you know, during the last couple of financial crashes, you know, what set it off was sets of derivative events where Nassim Talib's thing is they're trying to lower volatility in the short run by creating tail events. And systems always evolve towards that, and then they always crash. The gas curve is the star low ramp plateau crash. It's 100% effective in the long run.
Speaker A: Let me ask you some advice to put on your profound hat. There's a bunch of young folks who listen to this thing for no good reason whatsoever. Undergraduate students, maybe high school students, maybe just young folks, young at heart, looking for the next steps to take in life. What advice would you give to a young person today about life, maybe career, but also life in general.
Speaker B: Get good at some stuff. Well, get to know yourself. Right. I get good at something that you're actually interested in. You have to love what you're doing to get good at it. You really got to find that. Don't waste all your time doing stuff that's just boring or bland or numbing. Right. Don't let old people screw you. Well, people get talked into doing all kinds of shit and racking up huge student, you know, student debts, and, like, there's so much crap going on, you.
Speaker A: Know, and it drains your time and. Drains.
Speaker B: Yeah, the Eric Weinstein, you know, thesis that, you know, the older generation won't let go.
Speaker A: Yeah.
Speaker B: They're trapping all the young people.
Speaker A: I think there's some truth to that.
Speaker B: Yeah, sure. Just because you're old doesn't mean you stop thinking. I know lots of really original old people. I'm an old person, so. But you have to be conscious about it. You can fall into the ruts and then do that. I mean, when I hear young people spouting opinions that sounds like they come from Fox News or CNN, I think they've been captured by groupthink and memes.
Speaker A: And as opposed to think on their own, you know?
Speaker B: So if you find yourself repeating what everybody else is saying, you're not gonna have a good life. Like. Like, that's not how the world works. It may be it seems safe, but it puts you at a great jeopardy for, well, being boring or unhappy or.
Speaker A: How long did it take you to find the thing that you have fun with?
Speaker B: I don't know. I've been a fun person since I.
Speaker A: Was pretty little, so everything.
Speaker B: I've gone through a couple periods of depression in my life.
Speaker A: For good reason or for the reason doesn't make any sense.
Speaker B: Yeah, like, some things are hard. Like, you go through mental transitions. In high school, I was really depressed for a year, and I think I had my first midlife crisis at 26. I kind of thought, is this all there is? Like, I was working at a job that I loved, but I was going to work, and all my time was consumed.
Speaker A: What's the escape out of that depression? What's the answer to? Is this all there is?
Speaker B: Well, a friend of mine, I asked him because he was working his ass off. I said, what's your work life balance like? Like, there's, you know, work, friends, family, personal time. Are you bouncing in that? And you said, work 80%, family 20%. And I try to. I try to find some time to sleep. Like, there's no personal time. There's no passionate time, I guess, you know, young people are often passionate about work, so. And I was certainly like that. But you need to. You need to have some space in your life for different things, and.
Speaker A: That makes you resistant to the whole. The deep dips into depression kind of thing.
Speaker B: Yeah, well, you have to get to know yourself, too. Meditation helps some physical. Something physically intense helps, like, the weird.
Speaker A: Places your mind goes kind of thing.
Speaker B: And why does it happen? Why do you do what you do?
Speaker A: Like, triggers, like, the things that cause your mind to go to different places kind of thing, or events, like your.
Speaker B: Upbringing, for better or worse, whether your parents are great people or not, you. You come into adulthood with all kinds of emotional burdens.
Speaker A: Yeah.
Speaker B: And you can see some people are so bloody stiff and restrained, and they think, you know, the world's fundamentally negative. Like you maybe, that you have unexplored territory.
Speaker A: Yeah.
Speaker B: Or you're afraid of something.
Speaker A: Definitely afraid of quite a few things.
Speaker B: Then you got to go face them. Like, what's the worst thing that happened? You're going to die, right? Like, that's inevitable. You might as well get over that, like, 100% death rate. People are worried about the virus, but, you know, the human condition is pretty deadly.
Speaker A: There's something about embarrassment that I've competed a lot in my life, and I think the. If I'm to introspect it, the thing I'm most afraid of is being, like, humiliated.
Speaker B: I think nobody cares about that. Look, you're the only person on the planet who cares about you being humiliated.
Speaker A: Exactly.
Speaker B: So it's a really useless thought. It is. It's like you're all humiliated. Something happened in a room full of people, and they walk out and they didn't think about it one more second. Or maybe somebody told a funny story.
Speaker A: To somebody else and then throughout.
Speaker B: Yeah, yeah, no, I know it, too. I mean, I've been really embarrassed about shit that nobody cared about myself. Yeah, it's a funny thing.
Speaker A: So the worst thing, ultimately, is just, uh.
Speaker B: Yeah, but that's a cage, and then you have to get out of it.
Speaker A: Yeah.
Speaker B: Like, once you. Here's the thing. Once you find something like that, you have to be determined to break it, because otherwise you'll just, you know, so you accumulate that kind of junk, and then you die as a, you know, a mess.
Speaker A: So the goal, I guess it's like a cage within a cage. I guess the goal is to die in the biggest possible cage.
Speaker B: Well, ideally, you'd have no cage. People do get enlightened. I've met a few.
Speaker A: It's great you found a few. There's a few out there.
Speaker B: I don't know, of course there, either that or they have, you know, it's a great sales pitch. There's like, enlighten people, write books and doing all kinds of stuff.
Speaker A: It's a good way to sell a book, I'll give you that.
Speaker B: You've never met somebody, you just thought, they just kill me. Like, they just like mental clarity, humor.
Speaker A: No, 100%. But I just feel like they're living in a bigger cage. They have their own.
Speaker B: You still think there's a cage?
Speaker A: There's still a cage.
Speaker B: You secretly suspect there's always a cage.
Speaker A: There's nothing outside the universe.
Speaker B: There's nothing outside the cage.
Speaker A: You were, you worked at a bunch of companies, you led a lot of amazing teams. I don't, I'm not sure if you've ever been like, at the early stages of a startup, but do you have advice for somebody that wants to do a startup or build a company? Like build a strong team of engineers that are passionate, just want to solve a big problem? Like, is there more specifically on that point?
Speaker B: You have to be really good at stuff. If you're going to lead and build a team, you better be really interested in how people work and think.
Speaker A: The people or the solution to the problem. So there's two things, right? One is how people work, and the.
Speaker B: Other is actually, there's quite a few successful startups. It's pretty clear the founders don't know anything about people. People like, the idea was so powerful that it propelled them. But I suspect somewhere early they hired some people who understood people, because people really need a lot of care and feeding to collaborate and work together and feel engaged and work hard. Startups are all about out producing other people. You're nimble because you don't have any legacy. You don't have a bunch of people who are depressed about life just showing up. So startups have a lot of advantages that way.
Speaker A: Do you like the Steve Jobs talked about this idea of a players and b players? I don't know if you know this formulation.
Speaker B: Yeah, no. Organizations that get taken over by b player leaders often really underperform their hires. You players. That said, in big organizations there's so much work to do and there's so many people who are happy to do what the leadership or the big idea. People who consider menial jobs and you need a place for them, but you need an organization that both values and rewards them, but doesn't let them take over the leadership of it.
Speaker A: Got it. So you need to have an organization that's resistant to that. But in the early days, the notion with. With Steve was that, like, one B player in a room of a players will be, like, destructive to the whole.
Speaker B: I've seen that happen. I don't know if it's, like, always true. Like, you know, you run into people who clearly be players, but they think they're a players, and so they have a loud voice at the table and they make lots of demands for that. But there's other people who are like, I know who I am. I just want to work with, you know, cool people on cool shit and just tell me what to do and I'll go get it done.
Speaker A: Yeah.
Speaker B: You know, so you have to. Again, this is, like, people skills. Like, what kind of person is it? You know, I've met some really great people. I love working with that weren't the biggest it people, the most productive ever, but they show up, they get it done. You know, they create connection and community that people value. It's pretty diverse. I don't think there's a recipe for that.
Speaker A: I gotta ask you about love.
Speaker B: I heard you're into this now, into this love thing. Yeah. Is this. Do you think this is your solution to your depression?
Speaker A: No, I'm just trying to, like you said, the enlighten people on occasion, trying to sell a book. I'm writing a book about love.
Speaker B: You're writing a book about love?
Speaker A: No, I'm not. I'm not.
Speaker B: A friend of mine said you should really write a book about your management philosophy. He said it'd be a short book.
Speaker A: Well, that one was solved pretty well. What role do you think love, family, friendship, all that kind of human stuff play in a successful life? You've been exceptionally successful in the space of, like, running teams, building cool shit in this world, creating some amazing things. What, did love get in the way? Did love help the family get in the way? Did family help friendship?
Speaker B: You want the engineer's answer? Please. So, like, first, love is functional, right?
Speaker A: It's functional in what way?
Speaker B: So we habituate ourselves to the environment. And actually, Jordan told me, Jordan Peterson told me this line. So you go through life and you just get used to everything except for the things you love. They remain new. Like, this is really useful for, you know, like. Like other people's children and dogs and, you know, trees. You just don't pay that much attention to them. Your old kids, you're monitoring them really closely, like. And if they go off a little bit because you love them, if you're smart, if you're gonna be a successful parent, you notice it right away. You don't habituate just things you love. And if you want to be successful at work, if you don't love it, you're not going to put the time in somebody else as somebody else that loves it, like because it's new and interesting and that lets you go to the next level.
Speaker A: So it's a function that generates newness and novelty and surprises you and all those kinds of things.
Speaker B: It's really interesting. People figured out lots of frameworks for this. Humans seem to go in partnership, go through interest. Suddenly somebody's interesting, and then you're infatuated with them and then you're in love with them. And then different people have ideas about parental love or mature love. You go through a cycle of that which keeps us together. And it's super functional for creating families and creating communities and making you support somebody despite the fact that you don't love them. And it can be really enriching. Now in the work life balance scheme, if all you do is work, you think you may be optimizing your work potential. But if you don't love your work or you don't have family and friends and things you care about, your brain isn't well balanced. It's like everybody knows the experience of you works on something. All week you went home and took two days off and you came back in. The odds of you working on the thing picking up right where you left off is zero. Your brain refactored it. But being in love is great. It's like. Changes the color of the light in the room. It creates a spaciousness that's different. It helps you think, it makes you strong.
Speaker A: Bukowski had this line about love being a fog that dissipates with the first light of reality in the morning.
Speaker B: That's depressing. I think it's the other way around.
Speaker A: It lasts. Well, like you said, it's a function, it's a thing that generates.
Speaker B: You can be the light that actually enlivens your world and creates the interest and the power and the strength to go do something. Well, it's like, like that sounds like, you know, there's like physical love, emotional love, intellectual love, spiritual. Yeah, right.
Speaker A: Isn't it all the same thing? Kind of.
Speaker B: Nope. You should differentiate that. Maybe that's your problem in your book. You should refine that a little bit.
Speaker A: Different chapters.
Speaker B: Yeah, there's different chapters.
Speaker A: What's that? What's these? Aren't these just different layers of the same thing or the stack? Physical people.
Speaker B: People. Some people are addicted to physical love and they have no idea about emotional or intellectual love. I don't know if they're the same things. I think they're different.
Speaker A: That's true. They could be different. I guess the ultimate goal is for it to be the same.
Speaker B: Well, if you want something to be bigger and interesting, you should find all its components and differentiate them, not climb it together. People do this all the time. They, yeah, the modularity. Get your abstraction layers right and then you can, you have room to breathe.
Speaker A: Well, maybe you can write the forward.
Speaker B: To my book about love or the afterwards. You really tried. I feel like Lex has made a lot of progress in this book. Well, you have things in your life that you love.
Speaker A: Yeah, yeah. You know, so, and they are, you're right, they're modular. It's quite.
Speaker B: Well, they're, and you can have multiple things with the same person or the same thing and, but yeah, depending on.
Speaker A: The moment of the day.
Speaker B: Yeah. There's like what Bukoski described as that moment. You go from being in love to having a different kind of love.
Speaker A: Yeah.
Speaker B: Right. And that's a transition. But when it happens, if you'd read the owner's manual and you believed it, you would have said, oh, this happened. It doesn't mean it's not love. It's a different kind of love. But, but maybe there's something better about that. As you grow old, if all you do is regret how you used to be, it sat. Right. You should have learned a lot of things because, like, who you can be in your future self is actually more interesting and possibly delightful than, you know, being a mad kid in love with the next person, like, that's super fun when it happens, but that's, you know, 5% of the possibility.
Speaker A: Yeah, that's right. That there's a lot more fun to be had in the long lasting stuff.
Speaker B: Yeah. Or meaning, you know, if that's a.
Speaker A: Good thing, which is a kind of fun, it's a deeper kind of fun.
Speaker B: And it's surprising, you know, that's like, like the thing I like is surprises, you know? And you just never know what's gonna happen. But you have to look carefully and you have to work at it. You have to think about it. You know, it's, yeah.
Speaker A: You have to see the surprises when they happen. Right. You have to be looking for it. From the branching perspective, you mentioned regrets. Do you have regrets about your own trajectory?
Speaker B: Oh, yeah, of course. Yeah. Some of it's painful, but you want to hear the painful stuff. I'd say, like, in terms of working with people, when people did say stuff I didn't like, especially if it was a bit nefarious, I took it personally, and I also felt it was personal about them. But a lot of times, like, humans are, you know, most humans are a mess. Right. And then they act out and they do stuff. And this psychologist I heard a long time ago said, you tend to think somebody does something to you, but really what they're doing is they're doing what they're doing while they're in front of you. It's not that much about you.
Speaker A: Yeah.
Speaker B: Right. And as I got more interested in, you know, when I work with people, I think about them and probably analyze them and understand them a little bit. And then when they do stuff, I'm way less surprised and I'm way, you know, and if it's bad, I'm way less hurt and I react way less. Like I sort of expect. Everybody's got their shit.
Speaker A: Yeah. And it's not about you as a.
Speaker B: About me that much. It's like, you know, you do something and you think you're embarrassed, but nobody cares. Like, and somebody's really mad at you. The odds of it being about you. No, they're getting mad the way they're doing that because of some pattern they learned. And, you know, and maybe you can help them if you care enough about it, but. Or you could step. You could see it coming and step out of the way, like, like, I wish I was way better at that. I'm a bit of a hothead.
Speaker A: And you read that, you said with Steve, that was a feature, not a bug.
Speaker B: Yeah, well, he was using it as the counter force orderliness that would.
Speaker A: Well, you were doing the same.
Speaker B: Maybe. I don't think my vision was big enough. It was more like I just got pissed off and did stuff.
Speaker A: I'm sure that's what. Yeah.
Speaker B: You're telling. I don't know if it had the, it didn't have the amazing effect of creating a trillion dollar company. It was more like I just got pissed off and left and. Or made enemies that I shouldn't have. Yeah, it's hard. Like, I didn't really understand politics until I worked at Apple, where Steve was a master player of politics and his staff had to be or they wouldn't survive him. And it was definitely part of the culture. And then I've been in companies where they say it's political, but it's all fun and games compared to Apple. And it's not that the people at Apple are bad people. It's just they operate politically at a higher level. You know, it's not like, oh, somebody said something bad about somebody, somebody else, which is most politics. It's, you know, they had strategies about accomplishing their goals sometimes, you know, over the dead bodies of their enemies, you know, with Game of Thrones. Yeah, more Game of Thrones sophistication and, like, a big time factor rather than.
Speaker A: A, you know, that requires a lot of control over your emotions, I think, to have a bigger strategy in the way you behave.
Speaker B: Yeah. And it's effective in the sense that coordinating thousands of people to do really hard things where many of the people in there don't understand themselves, much less how they're participating, creates all kinds of drama and problems that our solution is political in nature. Like, how do you convince people? How do you leverage them? How do you motivate them? How do you get rid of them? You know, like, there's. There's so many layers of that that are interesting. And even though some. Some of it, let's say, may be tough, it's not evil unless, you know, you use that skill to evil purposes, which some people obviously do. But. But it's a skill set that operates, you know, and I wish I'd, you know, I was interested in it, but I, you know, it was sort of like, I'm an engineer. I do my thing, and there's times when I could have had way bigger impact if I knew how to. If I paid more attention and knew more about that.
Speaker A: About the human layer of the stack.
Speaker B: Yeah, the human political power expression layer of the stack, which is complicated, and there's lots to know about it. I mean, people are good at it. They're just amazing. And when they're good at it and let's say, relatively kind and oriented, a good direction, you can really feel it, can get lots of stuff done and coordinate things that you never thought possible. But all people like that also have some pretty hard edges because, you know, it's a heavy lift. And I wish I spent more time at that when I was younger, but maybe I wasn't ready. You know, I was a wide eyed kid for 30 years.
Speaker A: Still a bit of a kid. What do you hope your legacy is? When there's a. When there's a book like a Hitchhiker's guide to the Galaxy, and there's, like a one sentence entry. Bob Jim Miller from like, that guy lived at some point. There's not many, you know, not many people would be remembered. You're one of the sparkling little human creatures that had a big impact on the world. How do you hold. You'll be remembered?
Speaker B: My daughter was trying to get. She edited my Wikipedia page to say that I was a legend and a guru, but they took it out, so she put it back in. She's 15. I think that was probably the best part of my legacy. She got her sister. They were all excited. They were like trying to put it in the references because there's articles in.
Speaker A: That and it's calling you that. So in the eyes of your kids, your legend, well, they're pretty skeptical because.
Speaker B: They'Ll be better than that. They're like, dad. So, yeah, that's. That's super. That kind of stuff is super fun. In terms of the big legend stuff. I don't care.
Speaker A: I don't care.
Speaker B: Legacy, I don't. I don't really care.
Speaker A: You're just an engineer.
Speaker B: Yeah. They've been thinking about building a big pyramid. So I had a debate with a friend about whether pyramids are or craters are cooler. And you realize that there's craters everywhere. But, you know, they built a couple pyramids 5000 years ago and they remember.
Speaker A: You for a while.
Speaker B: They're still talking about it. I think that would be cool.
Speaker A: Those aren't easy to build.
Speaker B: Oh, I know. And they don't actually know how they built them, which is great.
Speaker A: It's either AGI or aliens could be involved. So I think you're gonna have to figure out quite a few more things than just the basics of civil engineering. So I guess you hope your legacy is pyramids.
Speaker B: That would. That would be cool. And my Wikipedia page, you know, getting updated by my daughter periodically, like those two things would pretty much make it.
Speaker A: Jim, it's a huge honor talking to you again. I hope we talk many more times in the future. I can't wait to see what you do with tennis torrent. I can't wait to use it. I can't wait for you to revolutionize yet another space in computing. It's a huge honor to talk to you. Thanks for talking today.
Speaker B: This was fun.
Speaker A: Thanks for listening to this conversation with Jim Keller. And thank you to our sponsors. Athletic greens all in one nutrition drink, Brooklinen sheets, ExpressVPN and bell Campo grass fed meat. Click the sponsor links to get a discount and to support this podcast. And now let me leave you with some words from Alan Turing. Those who can imagine anything can create the impossible. Thank you for listening and hope to see you next time.
