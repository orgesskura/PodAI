Transcription for Lee Cronin： Controversial Nature Paper on Evolution of Life and Universe ｜ Lex Fridman Podcast #404.mp3:
Full transcript: Every star in the sky probably has planets, and life is probably emerging on these planets. But I think the commentarial space associated with these planets is so different, our causal cones are never going to overlap or not easily. And this is the thing that makes me sad about alien life, why it's why we have to create alien life in the lab as quickly as possible, because I don't know if we are going to be able to be able to build architectures that will intersect with alien intelligence. Architectures intersect. You don't mean in time or space? Time and the ability to communicate. The ability to communicate, yeah. My biggest fear, in a way, is that life is everywhere, but we become infinitely more lonely because of our scaffolding in that commentarial space. The following is a conversation with Lee Cronin, his third time on this podcast. He is a chemist from University of Glasgow who is one of the most fascinating, brilliant, and fun to talk to scientists I've ever had the pleasure of getting to know. This is a Lex Friedman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Lee Cronin. So your big assembly theory paper was published in Nature. Congratulations. Thanks. It created, I think it's fair to say, a lot of controversy, but also a lot of interesting discussion. So maybe I can try to summarize assembly theory and you tell me if I'm wrong. Go for it. So, assembly theory says that if we look at any object in the universe, any object, that we can quantify how complex it is by trying to find the number of steps it took to create it, and also we can determine if it was built by a process akin to evolution by looking at how many copies of the object there are. Yep. That's spot on. Yeah, spot on. I was not expecting that. Okay, so let's go through definitions. So there's a central equation I'd love to talk about, but definition wise, what is an object? Yeah, an object. So, from. So if I'm going to try to be as meticulous as possible, objects need to be finite, and they need to be decomposable into subunits. All human made artifacts are objects. Is a planet an object? Probably, yes, if you scale out. So an object is finite and countable and decomposable, I suppose, mathematically, but, yeah, I still wake up some days and go think to myself, what is an object? Because it's a non trivial question, persists over time. I'm quoting from the paper here. An object is finite, is distinguishable. That's a weird adjective. Distinguishable. We've had so many people help offering to rewrite the paper after it came out. You wouldn't believe it's so funny. Persists over time and is breakable. Such that the set of constraints to construct it from elementary building blocks is quantifiable. Such that the set of constraints to construct it from elementary building blocks is quantifiable. The history is in the objects. It's kind of cool, right? So, okay, so what defines the object is it's history or memory, whichever is the sexier word. I'm happy with both, depending on the day. Okay, so the set of steps it took to create the object. So there's a sense in which every object in the universe has a history. Yeah. And that is part of the thing that is used to describe its complexity, how complicated it is. Okay, what is an assembly index? So the assembly index, if you're to take the object apart and be super lazy about it, or minimal, say what it might, you know, it's like you've got a really short term memory. So what you do is you lay all the parts on the path, and you find the minimum number of steps you take on the path to add the parts together to reproduce the object. And that minimum number is the assembly index. There's a minimum bounden. And it was always my intuition the minimum bound in assembly theory was really important. And I only worked out why a few weeks ago, which is kind of funny, because I was just like, no, this is sacrosanct. I don't know why it will come to me one day. And then when I was pushed by a bunch of mathematicians, we came up with the correct physical explanation, which I can get to, but it's the minimum, and it's really important. It's the minimum. And the reason I knew the minimum was right is because we could measure it. So almost before this paper came out, with published papers, explain how you can measure the assembly index of molecules. Okay, so that's not so trivial to figure out. So when you look at an object, we can say molecule, we can say object more generally, to figure out the minimum number of steps it takes to create that object. That doesn't seem like a trivial thing to do. So with molecules it is. It's not trivial, but it is possible, because what you can do, and because I'm a chemist, so I'm kind of like, I see the lens of the world through just chemistry. I break the molecule apart and break bonds. And if you take a molecule and you break it all apart, you have a bunch of atoms, and then you say, okay, I'm going to then take the atoms and form bonds and go up the chain of events to make the molecule. And that's what made me realize, take a toy example, literally, toy example. Take a Lego object, which is broken up of Lego blocks. So you could do exactly the same thing. In this case, the lego blocks are naturally the smallest. They're the atoms in the actual composite Lego architecture. But then if you maybe take a couple of blocks and put them together in a certain way, maybe they're offset in some way. That offset is on the memory. You can use that offset again with only a penalty of one, and you can then make a square triangle and keep going. And you remember those motifs on the chain. So you can then leap from the start with all the lego blocks or atoms just laid out in front of you and say, right, I'll take you, you connect and do the least amount of work. So it's really like the smallest steps you can take on the graph to make the object. And so for molecules, it came relatively intuitively, and then we started to apply it to language. We've even started to apply it to mathematical theorems. But I'm so well out of my depth. But it looks like you can take minimum set of axioms and then start to build up kind of mathematical architectures in the same way. And then the shortest path to get there is something interesting that I don't yet understand. So what's the computational complexity of figuring out the shortest path with molecules, with language, with mathematical theorems? It seems like once you have the fully constructed Lego castle, or whatever your favorite Lego world is, figuring out how to get there from the building, basic building blocks isn't like a. Is that an empty, hard problem? It's a hard problem. It's a hard problem. But actually, if you look at it. So the best way to look at it, let's take a molecule. So if the molecule has 13 bonds, first of all, take 13 copies of the molecule and just cut all the bonds. So take, cut twelve bonds, and then you just put them in order. Yeah. And then that's how it works. So you keep looking for symmetry or copies, so you can then shorten it as you go down. And that becomes commentarily quite hard for some natural product molecules. It becomes very hard. It's not impossible, but we're looking at the bounds on that at the moment. But as the object gets bigger, it becomes really hard. And. But that's the bad news. But the good news is there are shortcuts, and we might even be able to physically measure the complexity without computationally calculating it, which is kind of insane. Wait, how would you do that? Well, in the case of molecule. So, if you shine light on a molecule, let's take an infrared. The molecule has each of the bonds, absorbs the infrared differently in what we call the fingerprint region. And so it's a bit like. And because it's quantized as well, you have all these discrete kind of absorbances. And my intuition, after we realized we could cut molecules up in mass spec, that was the first go at this. We did it with using infrared, and the infrared gave us an even better correlation assembly index. And we used another technique as well, in addition to infrared, called NMR, nuclear magnetic resonance, which tells you about the number of different magnetic environments in a molecule. And that also worked out. So we have three techniques, which each of them independently gives us the same, or tending towards the same assembly index for a molecule that we can calculate mathematically. Okay, so these are all methods of mass spectrometry. Mass spec. You scan a molecule, it gives you data in the form of a mass spectrum. And you're saying that the data correlates to the assembly index. Yeah. How generalizable is that shortcut, first of all, to chemistry, and second of all, beyond that, because that seems like a nice hack, and you're extremely knowledgeable about various aspects of chemistry, so you can say, okay, it kind of correlates. But, you know, the whole idea behind assembly theory paper, and perhaps why it's so controversial, is that it reaches bigger. It reaches for the bigger general theory of objects in the universe. Yeah, I'd say so. I'd agree. So, I've started assembly theory of emoticons with my lab, believe it or not. So we take emojis, pixelate them, and work out the assembly index for the emoji, and then work out how many emojis you can make on the path of emojis. So there's the uber emoji, from which all other emojis emerge. Yeah. And then you can. So you can then take a photograph, and by looking at the shortest path, by reproducing the pixels to make the image you want, you can measure that. So then you start to be able to take spatial data. Now, there's some problems there. What is then the definition of the object? How many pixels? How do you break it down? And so we're just learning all this right now. So how do you compute this? How would you begin to compute the assembly index of a graphical, like a set of pixels on a 2d plane that form a thing. So you would first of all determine the resolution. So then what is your XY and what number on the X and Y plane? And then look at the surface area. And then you take all your emojis and make sure they're all looked at the same resolution. Yes. And then we will basically then do the, exactly the same thing we would do for cutting bonds. You'd cut bits out of the emoji and look at, you'd have a bag of pixels and you would then add those pixels together to make the overall emoji. Wait a minute. But first of all, not every pixels. I mean this is at the core sort of machine learning and computer vision. Not every pixel is that important. And there's like macro features, there's micro features and all that kind of stuff. Exactly like, you know, the eyes appear in a lot of them, the smile appears in a lot of them. So in the same way in chemistry, we assume the bond is fundamental. What we do in here is we assume the resolution at the scale at which we do it is fundamental. And we're just working that out. And that. You're right, that will change. Right. Because as you take your lens out a bit, it will change dramatically. But it's just a new way of looking at, not just compression. What we do right now in computer science and data, one big kind of misunderstanding is assembly theory is telling you about how compressed the object is. That's not right. It's a how much information is required on a chain of events. Because the nice thing is if, when you do compression in computer science, we're wandering a bit here, but it's kind of worth wandering, I think. You assume you have instantaneous access to all the information in the memory. In assembly theory, you say no, you don't get access to that memory until you've done the work. And then when you don't access that memory, you can have access, but not to the next one. And this is how in assembly theory we talk about the four universes, the assembly universe, the assembly possible and the assembly contingent. And then the assembly observed. And they're all scales in this combinatorial universe. Yeah. Can you explain each one of them? Yep. So the assembly universe is like anything goes just this, just combinatorial kind of explosion in everything. So that's the biggest one? That's the biggest one. It's massive assembly universe. Assembly possible assembly contingent assembly observed. And on the y axis is assembly steps in time. Yeah. And you know, in the x axis, as the thing expands through time, more and more unique objects appear. So, yeah. So assembly universe, everything goes, yep. Assembly possible laws of physics come in. In this case, in chemistry, bonds in assembly. So that means those are actually constraints, I guess. Yes, and they're the only constraints. They're the constraints at the base. The way to look at it is you've got all your atoms, they're quantized, and you can just bung them together. So then you can become a kind of. So in the way in computer science speak, I suppose the assembly universe is just like no laws of physics. Things can fly through mountains beyond the speed of light. In the assembly possible, you have to apply the laws of physics, but you can get access to all the motifs instantaneously with no effort. So that means you could make anything. Then the assembly contingent says, no, you can't have access to the highly assembled object in the future until you've done the work in the past on the causal chain. And that's really the really interesting shift where you go from assembly possible to assembly contingent. That is really the key thing in assembly theory that says you cannot just have instantaneous access to all those memories. You have to have done the work somehow. The universe has to have somehow built a system that allows you to select that path rather than other paths. And then the final thing the assembly observed is basically us saying, oh, these are the things we actually see. We can go backwards now and understand that they have been created by this causal process. Wait a minute. So when you say the universe has to construct the system that does the work, is that like the environment that allows for, like, selection? Yeah, yeah, yeah. That's the thing that does the selection. You could think about in terms of a von Neumann constructor versus the selection, a ribosome Tesla plant assembling Teslas. You know, the difference between the assembly universe in Teslaland and the Cesar factory is everyone says, no, Teslas are just easy. They just spring out. You know how to make them all a Tesla factory? You have to put things in sequence and out comes a Tesla. So you're talking about the factory. Yes. This is really nice. Super important point is that when I talk about the universe having a memory or there's some magic, it's not that. It's that tells you that there must be a process encoded somewhere in physical reality, be it a cell, a Tesla factory, or something else that is making that object. I'm not saying there's some kind of woo woo memory in the universe, morphic resonance or something. I'm saying that there is an actual causal process that is being directed, constrained in some way. So it's not kind of just making everything. Yeah, but Lee, what's the factory that made the factory? So what is the. So, first of all, you assume the laws of physics has just sprung to existence at the beginning. Those are constraints. But what makes the factory the environment that does the selection? This is the question of. Well, it's the first interesting question that I want to answer out of four. I think the factory emerges in the environment, the interplay between the environment and the objects that are being built. And I'll have a go at explaining to you the shortest path. So why is the shortest path important? Imagine you've got. I'm going to have to go chemistry for a moment, then abstract it. So imagine you've got a given environment that you have a budget of atoms you're just flinging together. And the objective of those atoms that being flung together in, say, molecule a, have to make. They decompose. So molecules decompose over time. So the molecules in this environment, in this magic environment, have to not die. But they do die, they have a half life. So the only way the molecules can get through that environment out the other side. Let's pretend the environment is a box and go in and out without dying, and there's just an infinite supply of atoms coming, or, well, a large supply. The molecule gets built, but the molecule that is able to template itself, being built and survives in the environment will. Will basically reign supreme. Now, let's say that molecule takes ten steps now, and it's using a finite set of atoms, right? Or now let's say another molecule, smart arse molecule, we'll call it, comes in and can survive in that environment and can copy itself, but it only needs five steps. The molecule that only needs five steps, because both molecules have been destroyed, but they're creating themselves faster. They can be destroyed. You can see that the shortest path reigns supreme. So the shortest path tells us something super interesting about the minimal amount of information required to propagate that motif in time and space. And it's just like a kind of. It seems to be like some kind of conservation law. So one of the intuitions you have is the propagation of motifs in time will be done by the things that can construct themselves in the shortest path. Yeah. So, like, you can assume that most objects in the universe are built in the shortest, in the most efficient way. So, big leap I just took there. Yeah. Yes and no, because there are other things. So in the limit. Yes, because you want to tell the difference between things that have required a factory to build them and just random processes. But you can find instances where the shortest path isn't taken for an individual object, an individual function, and people go, ah, that means the shortest path isn't right. And then I say, well, I don't know. I think it's right still, because. So of course, because there are other driving forces. It's not just one molecule. Now when you start to, now you start to consider two objects. You have a joint assembly space. And now it's a compromise between not just making a and b in the shortest path, you want to make a and b in the shortest path, which might mean that a is slightly longer, you have a compromise. So when you see slightly more nesting in the construction, when you take a given object that can look longer, but that's because the overall function is the object is still trying to be efficient. Yeah, and this is still very hand wavy and maybe have no leg to stand on, but we think we're getting somewhere with that. And there's probably some parallelization. Yeah, right. So this is all, this is not sequential. The building is, I guess. No, you're right. When you're talking about complex objects, you don't have to work sequentially. You can work in parallel, you can get your friends together and they can. Yeah. And the thing we're working on right now is how to understand these parallel processes. Now there's a new thing we've introduced called assembly depth. And assembly depth can be lower than the assembly index for a molecule when they're cooperating together, because exactly this parallel processing is going on. And my team have been working this out in the last few weeks because we're looking at what compromises does nature need to make when it's making molecules in a cell? And I wonder if maybe like, well, I'm always leaping out of my competence, but in economics, I'm just wondering if you could apply this in economic process. It seems like capitalism is very good at finding the shortest path every time, but there are ludicrous things that happen because actually the cost function has been minimized. And so I keep seeing parallels everywhere where they're complex nested systems, where if you give it enough time and you introduce a bit of heterogeneity, the system readjusts and finds a new shortest path. But the shortest path isn't fixed on just one model molecule. Now it's in the actual existence of the object over time. And that object could be a city it could be a cell, it could be a factory. But I think we're going way beyond molecules, and my competence probably should go back to molecules. But, hey, all right, before we get too far, let's talk about the assembly equation. Okay, how should we do this? Now, let me just even read that part of the paper. We define assembly as the total amount of selection necessary to produce an ensemble of observed objects quantified using equation one. The equation basically has a on one side, which is the assembly of the ensemble, and then a sum from one to n, where n is the total number of unique objects. And then there is a few variables in there that include the assembly index, the copy number, which we'll talk about. That's an interesting. I don't remember you talking about that. That's an interesting addition. And I think a powerful one has to do with what, that you can create pretty complex objects randomly. And in order to know that they're not random, that there's a factory involved, you need to see a bunch of them. Yeah, that's the intuition there. It's an interesting intuition and then some normalization. What else is it in minus one? Just to make sure that more than one object could be a one off and random, and then you have more than one identical object. That's interesting. When there's two of a thing, two. Of a thing is super important, especially if the index, assembly index is high. So we could say several questions here. One, let's talk about selection. What is this term, selection, what is this term evolution that we're referring to? Which aspect of darwinian evolution that we're referring to? That's interesting here? So, yeah, so this is probably what, you know, the paper. We should talk about the paper a second. The paper, what it did, is it kind of annoyed? We didn't know? I mean, it got intention and obviously angry people. The angry people were annoyed. There's angry people in the world. That's good. So what happened is the evolutionary biologists got angry. We were not expecting that because we thought evolutionary biologists would be cool. I knew that some, not many computational complexity people would get angry because I'd kind of been poking them and maybe I deserved it, but I was trying to poke them in a productive way. And then the physicists kind of got grumpy because the initial conditions tell everything. The prebiotic chemist got slightly grumpy because there's not enough chemistry in there. Then finally, when the creationist said it wasn't creationist enough, I was like, no, I've done my job you say in. The physics, they say, because you're basically saying that physics is not enough to tell the story of how biology emerges. I think so, cassie. And then they said a few. Physics is the beginning and the end of the story. Yeah. So what happened is the reason why people put the phone down on the call of the paper. If you view reading the paper like a phone call, they got to the abstract. Yep. And in the abstract, the first sentence is pretty. The first two sentences caused everybody. Scientists have grappled with reconciling biological evolution with the immutable laws of the universe defined by physics. True. Right. There's nothing wrong with that statement. Totally true. Yeah. These laws underpin life's origin, evolution, and the development of human culture and technology, yet they do not predict the emergence of these phenomena. Wow. First of all, we should say the title of the paper. This paper was accepted and published in nature. The title is assembly theory explains and quantifies selection and evolution. Very humble title. And the entirety of the paper, I think, presents interesting ideas but reaches high. I am not. I would do it all again. This paper was actually on the preprint server for over a year. You regret nothing. Yeah, I think, yeah, I don't regret anything. You and Frank Sinatra did it your way. What I love about being a scientist is kind of sometimes because I'm a bit dim, I'm like. And I don't understand what people telling me. I want to get to the point. This paper says, hey, laws of physics are really cool. The universe is great, but they don't really. It's not intuitive that you just run the standard model and get life out. I think most physicists might go, yeah, there's this, you know, it's not just, we can't just go back and say, that's what happened. Because physics can't explain the origin of life yet. It doesn't mean it won't or can't. Okay, just to be clear. Sorry, intelligent designers, we are going to get there. Second point, we say that evolution works, but we don't know how evolution got going. So biological evolution and biological selection. So for me, this seems like a simple continuum. So when I mentioned selection and evolution in the title, I think, and in the abstract, we should have maybe prefaced that and said non biological selection and non biological evolution, and then that might have made it even more crystal clear. But I didn't think that biology, evolutionary biology should be so bold to claim ownership of selection and evolution. And secondly, a lot of evolutionary biologists seem to dismiss the origin of life questions to say it's obvious. And that causes a real problem scientifically, because when two different, when the physicists are like, we own the universe, the universe is good, we explain all of it. Look at us. And biologists say we can explain biology, and the poor chemist in the middle going, but hang on. And this paper kind of says, hey, there is an interesting disconnect between physics and biology, and that's at the point at which memories get made in chemistry through bonds. And, hey, let's look at this close and see if we can quantify it. So, yeah, I mean, I never expected the paper to kind of get that much interest. And still, I mean, it's only been published just over a month ago now. Just linger on the selection. What is the broader sense of what selection means? Yeah, that's a really good for selection. Selection. So I think for selection, you need. So this is where, for me, the concept of an object is something that can persist in time and not die, but basically can be broken up. So if I was going to kind of bolster the definition of an object, so if something can form and persist for a long period of time under an existing environment that could destroy other, and I'm going to use anthropomorphic terms, I apologize that weaker objects or less robust, then the environment could have selected that. So good chemistry examples. If you took some carbon and you made a chain of carbon atoms, whereas if you took some, I don't know, some carbon, nitrogen and oxygen, and made chains from those, you'd start to get different reactions and rearrangements. So a chain of carbon atoms might be more resistant to falling apart under acidic or basic conditions versus another set of molecules. So it survives in that environment. So the acid pond, the molecule, the resistant molecule can get through, and then that molecule goes into another environment. So that environment, now, maybe being an acid bond is a basic pond, or maybe it's an oxidizing pond. And so if you've got carbon and it goes in an oxidizing pond, maybe the carbon starts to oxidize and break apart. So you go through all these kind of obstacle courses, if you like, given by reality. So selection is the ability happens when an object survives in an environment for some time. But, and this is the thing that's super subtle, the object has to be continually being destroyed and made by process. So it's not just about the process. The object, now, it's about the process and time that makes it. Because a rock could just stand on the mountainside for 4 billion years and nothing happened to it. And that's not necessarily really advanced selection. So for selection to get really interesting, you need to have a turnover in time. You need to be continually creating objects, producing them, what we call discovery time. So there's a discovery time for an object when that object is discovered. If it's, say, a molecule that can then act on itself, or the chain of events that caused itself to bolster its formation, then you go from discovery time to production time, and suddenly you have more of it in the universe. So it could be a self replicating molecule, and the interaction of the molecule in the environment, in the warm little pond or in the sea or wherever in the bubble, could then start to build a proto factory, the environment. So really, to answer your question, what the factory is, the factory is the environment, but it's not very autonomous, it's not very redundant. There's lots of things that could go wrong. So once you get high enough up the hierarchy of networks of interactions, something needs to happen that needs to be compressed into a smaller volume and made resistant, robust, because in biology, selection and evolution is robust, that you have error correction built in, you have really, you know, there's good ways of basically making sure propagation goes on. So really the difference between inorganic abiotic selection, evolution and evolution and stuff in biology is robustness. The ability to kind of propagate, overdose over in the ability to survive in lots of different environments, whereas our poor little inorganic salt molecule, whatever, just dies in lots of different environments. So there's something super special that happens from the inorganic molecule in the environment that kills it to where you've got evolution, and cells can survive everywhere. How special is that? How do you know those kinds of evolution factors aren't everywhere in the universe? I don't. And I'm excited because I think selection isn't special at all. I think what is special is the history of the environments on earth that gave rise to the first cell, that now has taken all those environments and is now more autonomous. And I would like to think that, you know, this paper could be very wrong, but I don't think it's very wrong. It means certainly wrong, but it's less wrong than some other ideas, I hope. Right? And if this allow inspires us to go and look for selection in the universe, because we now have an equation where we can say, we can look for selection going on and say, oh, that's interesting. We seem to have a process that's giving, giving us high copy number objects that also are highly complex, but that doesn't look like life as we know it. And we use that and say, oh, there's a hydrothermal vent. Oh, there's a process going on. There's molecular networks, because the assembly equation is not only meant to identify at the higher end, advanced selection. What you get, I would call in biology, super advanced selection. And even, I mean, you could use the assembly equation to look for technology. And I, God forbid we could talk about consciousness and abstraction, but let's keep it primitive molecules and biology. So I think the real power of the assembly equation is to say how much selection is going on in this space. And there's a really simple thought experiment I could do is you have a little petri dish, and on that petri dish you put some simple food. So the assembly index of all the sugars and everything is quite low. So then you put a single cell of E. Coli cell. Yeah. And then you say, I'm gonna, I'm gonna measure the assembly in this amount of assembly in the box. So it's quite low. But the rate of change of assembly, da dt, will go, voom, sigmoidal as it eats all the food. And the number of coli cells will replicate because they take all the food they can copy themselves. The assembly index of all the molecules goes up, up and up until the food is exhausted in the box. So now the, now the E. Coli has stopped. I mean, die is probably a strong word. They stop respiring because all the food is gone. But suddenly the amount of assembly in the box has gone up gigantically because of that. One E. Coli factory has just eaten through milled. Lots of other E. Coli factory has run out of food and stopped. And so looking at that. So in the initial box, although the amount of assembly was really small, it was able to replicate and use all the food and go up. And that's what we're trying to do in the lab, actually, is kind of make those kind of experiments and see if we can spot the emergence of molecular networks that are producing complexity as we feed in raw materials. And we feed a challenge, an environment, you know, we try and kill the molecules. And really that's the main kind of idea for the entire paper. Yeah. And see if you can measure the changes in the assembly index throughout the whole system. Yeah. Okay. What about if I show up to a new planet, we go to Mars or some other planet from a different solar system? And how do we use assembly index there to discover alien life? Very simply, actually, if we, let's say we'll go to Mars with a mass spectrometer with a sufficiently high resolution. So what you have to be able to do. So a good thing about mass spec is that you can select a molecule from the mass, and then if it's high enough resolution, you can be more and more sure that you're just seeing identical copies. You can count them and then you fragment them, and you count the number of fragments and look at the molecular weight, and the higher the molecular weight and the higher the number of the fragments, the higher the assembly index. So if you go to Mars and you take a mass spec or high enough resolution, and you can find molecules, and I'll give a guide on earth, if you could find molecules, say greater than 350 molecular weight, were more than 15 fragments, you have found artifacts that can only be produced, at least on earth, by life. Now, you would say, oh, maybe the geological process, I would argue very vehemently that that is not the case. But we can say, look, if you don't like the cut off on earth, go up higher, 3100, right? Because there's going to be a point where you find a molecule with so many different parts. The chances of you getting a molecule that has 100 different parts and finding a million identical copies, that's just impossible. That could never happen in an infinite set of universes. Can you just linger on this copy number thing? A million different copies? What do you mean by copies? And why is the number of copies important? Yeah, that was so interesting. And I always understood the copy number is really important, but I never explained it properly for ages. And I kept having this. It goes back to this. If I give you, I don't know, a really complicated molecule, and I say it's complicated, you could say, hey, that's really complicated, but is it just really random? And so I realized that ultimate randomness and ultimate complexity are indistinguishable until you can, you can see a structure in the randomness, so you can see copies. So copies implies structure. Yeah, the factory. I mean, there's a deep, profound thing in there, because if you just have a random, random process, you're going to get a lot of complex, beautiful, sophisticated things. What makes them complex in the way we think life is complex? Or. Yeah, something like a factory that's operating under a selection process, there should be copies. Is there some looseness about copies? What does it mean for two objects to be equal? It's all to do with the telescope or the microscope you're using. And so at the maximum resolution. So in the nice thing about, the nice thing about chemists, is they have this concept of the molecule, and they are all familiar with the molecule and molecules you can hold on your hand, and lots of them, identical copies. A molecule is actually a super important thing in chemistry to say, look, you can have a mole of a molecule and Avogadro's number of molecules, and they're identical. What does that mean? That means that the molecular composition, the bonding and so on, the configuration is indistinguishable. You can hold them together, you can overlay them. So the way I do it is if I say, here's a bag of ten identical molecules, let's prove they're identical. You pick one out of the bag, and you basically observe it using some technique, and then you put it, you take it away, and then you take another one out. If you observe it using technique, you see no differences. They're identical. It's really interesting to get right, because if you take, say, two molecules, molecules can be in different vibrational rotational states. They're moving all the time. So with this respect, identical molecules have identical bonding. In this case, we don't even talk about chirality because we don't have a chirality detector. So two identical molecules in one conception. Assembly theory basically considers both hands as being the same, but of course, they're not. They're different. As soon as you have a chiral distinguisher detect the left and the right hand, they become different. And so it's to do with the detection system that you have and the resolution. So I wonder if there's an art and science to the which detection system is used when you show up to a new planet. Yeah, yeah, yeah. So, like, you're talking about chemistry a lot today we have kind of standardized detection systems. Right, of how to compare molecules. So, you know, when you start to talk about emojis and language and mathematical theorems and, I don't know, more sophisticated things, a different scale at a smaller scale than molecules. At a larger scale than molecules. Like what detection. If we look at the difference between you and me lexingly, are we the same? Are we different? Sure. I mean, of course we're different close up, but if you zoom out a little bit, morphologically, look the same. Yeah. You know, high in characteristics, hair length, stuff like that. Also like the species and. Yeah, yeah, yeah. And, and also there's a sense why we're both from earth. Yeah, I agree. I mean, this is the power of assembly theory in that regard, that you. If, if you so, if everything, so the way to look at it, if you have a box of objects, if they're all, if they're all indistinguishable, then using your technique, what you then do is you then look at the assembly index. Now, if the assembly index of them is really low and they're all indistinguishable, then it's telling you that you have to go to another resolution. It's a sliding scale. It's kind of nice. Those two are attention with each other. The number of copies and the assembly index. That's really, really interesting. So, okay, so you show up to a new planet, you'll be doing what. I would do mass spec. I would bring on a sample of what? Like, first of all, like, how big of a scoop do you take? Did you just take a scoop? Like what? Like, uh. So we're looking for primitive life. I would, I would look, yeah. So if we're just going to Mars or Titan or Enceladus or somewhere. So a number of ways of doing it. So you could take a large scoop or you go for the atmosphere and detect stuff, you could make a life meter. So one of Sarah's colleagues at ASU, Paul Davies, keeps calling it a life meter, which is quite a nice idea because you think about it, if you've got a living system that's producing these highly complex molecules and they drift away and they're in a highly kind of demanding environment, they could be burnt, right? So they could just be falling apart. So you want to sniff a little bit of complexity and say, warmer, warmer, warmer. Oh, we've found life. We found the alien. We've found, we found the alien, Elon musk smoking a joint in the bottom of the cave on Mars, or Elon himself, whatever, right? You say, okay, found it. So what you can do is the mass spectrometer, you could just look for things in the gas phase, or you go on the surface, drill down, because you want to find molecules that are. You've either got to find the source living system, because the problem with just looking for complexity is it gets burned away. So in a harsh environment on the surface of Mars, there's a very low probability that you're going to find really complex molecules because of all the radiation and so on. If you drill down a little bit, you could drill down a bit into soil that's billions of years old. Then I would put in some solvent, water, alcohol or something, or take a scoop, make it volatile, put it into the mass spectrometer and just try and detect high complexity, high abundant molecules. And if you get them, hey, presto, you can have evidence of life. Wouldn't that then be great if you could say, okay, we've found evidence of life. Now we want to keep, keep the life meter keeps searching for more and more complexity until you actually find living cells. You can get those new living cells and then, and then you could bring them back to earth, or you could try and sequence them. You could see that they have different DNA and proteins, go along the gradient. Of the life meter. How would you build a life meter? Let's say we're together, starting new company. Launching a life meter mass spectrometer would be the first way of doing it. No, no, but that's, that's a, that's one of the major components of it. But I'm talking about, like, what if it's a device, we got a branding logo we got to talk about. That's later. But what's the input? Like, how do you get to the metered output? So I would take a. So my life meter, our life meter. There you go. Thank you. Yeah, you're welcome. Would have both infrared and aspect, so it would have two ports so we could shine a light. And so what it would do is you would have a vacuum chamber and you would have an electrostatic analyzer and you'd have a monochromator. To producing infrared, you'd add the sump, so you'd take a scoop of the sample, put it in the life meter. It would then add a solvent or heat up the sample so some volatiles come off. The volatiles would then be put into the, into the mass spectrometer, into electrostatic trap, and you'd weigh the molecules and fragment them. Alternatively, you'd shine infrared light on them. You'd count the number of bands, but you'd have to, in that case, do some separation because you want to separate. And so in mass spec, it's really nice and convenient because you can separate electrostatically, but you need to have that. Can you do it in real time? Yeah, pretty much. Pretty much, yeah. So let's go all the way back. So let's. Okay, we're really going to get this Lexus life, me, Lex and Lee's life. It's a good, good, good ring to it. All right, so you have a, you have a vacuum chamber. You have a little nose. The nose would have some. A packing material. So you would take your sample, add it onto the nose, add a solvent or a gas. It would then be sucked up the nose and that would be separated using chrome, what we call chromatography. And then as each band comes off the nose. We would then do mass spec and infrared. And in the case of the infrared, count the number of bands. In the case of the mass spec, count the number of fragments and weigh it. And then the further up in molecular weight range for the mass spec and the number of bands, you go up and up and up from the dead. Interesting, interesting. Over the threshold. Oh, my gosh. Earth life. And then right up to the batshit crazy. This is definitely alien intelligence that's made this life. Right? You could almost go all the way there, same in the infrared. And it's pretty simple. The thing that is really problematical is that for many years, decades, what people have done, and I can't blame them, is they've rather, they've been obsessing about small biomarkers on that we find on earth, amino acids, like single amino acids or evidence of small molecules and these things and looking for those rather than looking for complexity. Well, the beautiful thing about this is you can look for complexity without earth chemistry bias or earth biology bias. So assembly theory is just a way of saying, hey, complexity and abundance is evidence of selection. That's how our universal life meter will work. Complexity in abundance is evidence of selection. Okay, so let's apply our life meter to earth. So what, you know, if we were just to apply assembly index measurements to earth, what kind of stuff are going to be get. Are going to get what's impressive about some of the complexity on earth. So we did this a few years ago when I was trying to convince NASA and colleagues that this technique could work. And honestly, it's so funny because everyone's like, no, it ain't going to work. And I was just like. Because the chemist was saying, of course there are complicated molecules out there. You can detect that just form randomly, really. That's like, that was like, you know, as a bit like a. I don't know, someone saying, of course, Darwin textbook was just written randomly by some monkeys and a typewriter. I was just. For me, it was like, really? And I pushed a lot on the chemists now, and I think most of them are on board, but not totally. It really had some big arguments. But the copy number caught there because I think I confused the chemist by saying one off. And then when I made clear about the copy number, I think that made it a little bit easier. Just to clarify, chemists might say that, of course, out there, outside of earth, there's complex molecules. Yes. Okay. And then you're saying, wait a minute, that's like saying, of course, there's aliens out there. Yeah, exactly that. Okay. Exactly. You say you clarify that. Thats actually a very interesting question. And we should be looking for complex molecules of which the copy number is two or greater. Yeah, exactly. So on earth. So coming back to earth, what we did is we took a whole bunch of samples and we were running prebiotic chemistry experiments in the lab. We took various inorganic minerals and extracted them. Look at the volatile, because theres a special way of treating minerals and polymers and assembly theory in our life machine, we're looking at molecules. We don't care about polymers because they don't. They're not volatile. You can't hold them. How can you make. If you can't assert that they're identical, then it's very difficult for you to work out if there's undergone selection or they're just a random mess. Same with some minerals, but we can come back to that. So basically what you do, we got a whole load of samples, inorganic ones. We got a load of. We got scotch whiskey and also got took ard Berg, which is one of my favorite whiskies, which is very peaty. And another whisk. What does peaty mean? Is like. So the way that on, in Scotland, in Islay, which is little island, the scotch, the whisky is led to mature in barrels. And it said that the peat, the complex molecules in the peat might find their way through into the whiskey. And that's what gives it this intense brown color and really complex flavor. It's literally molecular complexity that does that. And so vodka is the complete opposite. It's just pure, right? The better the whiskey, the higher the assembly index. The higher the assembly index, the better the whiskey. I mean, I really love deep, peaty scottish whiskies. Near my house, there is one of the lowland distilleries called glengoyne. Still beautiful whisky, but not as complex. So for fun, I took some glencoin whiskey in our bag and put them into the mass spec and measure the assembly index. I also got e coli. So the way we do it, take the E. Coli, break the cell apart, take it all apart, and also got some beer. And people were ridiculing us, saying, oh, beer is evidence of complexity. One of the computational complexity people was just throwing. Yeah, kind of. He's very vigorous in his disagreement of assembly theory, was just saying, you know, you don't know what you're doing. Even beer is more complicated than human. What he didn't realize is that it's not beer per se. It is taking the yeast extract, taking the extract, breaking the cells extracting the molecules and just looking at the profile of the molecules, see if there's anything over the threshold. And we also put in a really complex molecule, taxol. So we took all of these, but also NASA gave us, I think, five samples and they wouldn't tell us what they are. They said, no, we don't believe you can get this to work. And they really gave us some super complex samples and they gave us two fossils, one that was a million years old and one was at 10,000 years old, something from Antarctica seabed. They gave us immersious and meteorite and a few others put them through the system. So we took all the samples, treat them all identically, put them into mass spec, fragmented them, counted, and in this case, implicit in the measurement was in mass spec. You only detect peaks when you've got more than say, let's say, 10,000 identical molecules. So the copy number is already baked in but wasn't quantified, which is super important there. This is in the first paper because I was like, it's abundant, of course. And when you then took it all out, we found that the biological samples gave you molecules that had an assembly index greater than 15 and all the abiotic samples were less than 15. And then we took the NASA samples and we looked at the ones that were more than 15, less than 15, and we gave them back to NASA and they're like, oh, gosh, I. Yep. Dead living. Dead living. You got it. And that's what we found on earth. That's a success. Yeah. Oh, yeah. Resounding success. Can you just go back to the beer and the E. Coli? So what's the assembly index on those? So what you were able to do is like the assembly index of. We found high assembly index molecules originating from the beer sample and the E. Coli sample. The east. And the beauty, I mean, I didn't know which one was higher. We didn't really do any detail there because now we are doing that because one of the things we've done, it's a secret, but I can tell you. Nobody'S listening. Well, is that we've just mapped the tree of life using assembly theory because everyone said, oh, that you can't do infant biology. And what we're able to do is. So you. I think there's three way. Well, two ways of doing tree of life traffic. Well, three ways, actually. What's the tree of life? So the tree of life is basically tracing back the history of life on earth for all the different species going back who evolved from what? And it all goes all the way back to the first kind of life forms, and they branch off and like, you have plant kingdom, the animal kingdom, the Fungi kingdom, and different branches all the way up and the way this was classically done. And I'm no evolutionary biologist. The evolutionary biologists are very tell me every day, at least ten times. I want to be one, though. I kind of like biology. It's kind of cool. Yeah, it's very cool. But basically, what Darwin and Mendeleev and all these people do is just, they draw pictures, right? And they tax her. They just con, they were able to draw pictures and say, oh, these look like common classes. Then. There are artists, really. They're just, you know. But they were able to find out a lot, right, in looking at Verber inverts Cameron explosion and all this stuff. And then came the genomic revolution, and suddenly everyone used gene sequencing. And Craig Venter is a good example. I think he's gone around the world in his yacht, just picking up samples, looking for new species where he's just found new species of life just from sequencing. It's amazing. So you have taxonomy, you have sequencing, and then you can also do a little bit of kind of molecular kind of archaeology, like measure the samples and kind of form some inference. What we did is we were able to fingerprint, we took a load of random samples from all of biology, and we used mass spectrometry. And what we did now is not just look for individual molecules, but we looked for coexisting molecules where they had to look at their joint assembly space, and where we were able to cut them apart and undergo recursion in the mass spec and infer some relationships. And we're able to recapitulate the tree of life using mass spectroscopy. No sequencing and no drawing. All right, can you try to say that again with a little more detail? So, recreating, what does it take to recreate the tree of life? What does the reverse engineering process look like here? So what you do is you take an unknown sample, you pung it into the mass spec you get, because this comes from what you ask, like, what do you see in E. Coli? And so in E. Coli, you don't just see, it's nothing. It's not that the most sophisticated cells on earth make the most sophisticated molecules. It is the coexistence of lots of complex molecules above a threshold. And so what we realize is you could fingerprint different life forms. So fungi make really complicated molecules. Why? Because they can't move. They have to make everything on site. Whereas some animals are like lazy, they can just go eat the fungi, they don't need to make very much. And so what you do is you look at the, so you take, I don't know, the fingerprint, maybe the top number of high molecular weight molecules you find in the sample. You fragment them to get their assembly indices. And then what you can do is you can infer common origins of molecules. You can do a kind of molecular, when the reverse engineering of the assembly space, you can infer common roots and look at what's called the joint assembly space. But let's translate that into the experiment. Take a sample, bung it the mass spec, take the top, say ten molecules, fragment them, and that gives you one fingerprint. Then you do it for another sample, you get another fingerprint. Now the question is, you say, hey, are these samples the same or different? And that's what we've been able to do. And by basically looking at the assembly space that these molecules create without any knowledge of assembly theory, you are unable to do it. With a knowledge of assembly theory, you can reconstruct the tree. How does knowing if they're the same or different give you the tree? Let's go to two leaves on different branches on the tree. Right. What you can do, by counting the number of differences, you can estimate how far away their origin was. And that's all we do. And it just works. But when we realized you could even use assembly theory to recapitulate the tree of life with no gene sequencing, we were like, huh? So this is looking at samples that exist today in the world. What about, like, things that are no longer exist? I mean, the tree contains information about the past. I would. Some of it is gone. Yeah, absolutely. I would love to get old fossil samples and apply assembly theory, mass spec and see if we can find new forms of life that have, that are no longer amenable to gene sequencing because the DNA is all gone. Because DNA in RNA is quite unstable, but some of the more complex molecules might be there that might give you a hint of something new. Or wouldn't it be great if you, if you find a sample that's worth really persevering and doing, you know, doing the proper extraction to, you know, PCR and so on, and then sequence it and then put it together so when. A thing dies, you can still get some information about its complexity. Yeah, and we can, and it appears that you can do some dating. Now. There are really good techniques. There's radiocarbon dating, there is longer dating go and looking at radioactive minerals and so on. And you can also, in bone, you can look at the, what happens after something dies is you get what's called racemization, where the chirality in the polymers basically changes and you get decomposition and the deviation from the pure enantiomer to the mixture. It gives you a time scale on it, half life, so you can date when it died. I want to use assembly theory, see if I can use it, date death and things, and trace the tree of life and also decomposition of molecules. You think it's possible? Oh, yeah, without a doubt. It may not be better than what? Because, like, I was just at a conference where some brilliant people were looking at isotope enrichment and looking at how life enriches isotopes, and they're really sophisticated stuff that they're doing, but I think there's some fun to be had there, because it gives you another dimension of dating. How old is this molecule in terms of, or more importantly, how long ago was this molecule produced by life? The more complex a molecule, the more prospect for decomposition, oxidation, reorganization, loss of chirality and all that jazz. But what life also does is it enriches. As you get older, the amount of carbon 13 in you goes up because of the way the bonding is in carbon 13. So it has a slightly different strength bond. Strengthen you is called a kinetic isotope effect. So you can literally date how old you are, or when you stop metabolizing, so you could date someone's debt how old they are. I think I'm making this up. This might be right, but I think it's roughly right. The amount of carbon 13 you have in you, you can kind of estimate how old you are. How old living organ. Humans are living. Yeah, yeah. Like you could say, oh, this person is ten years old and this person 30 years old, because they've been metabolizing more carbon and they've accumulated it. That's the basic idea. It's probably completely wrong. Time scale signatures of chemistry are fascinating. So you've been saying a lot of chemistry examples for assembly theory. What if we zoom out and look at a bigger scale of an object, like really complex objects like humans or living organisms that are made up of millions or billions of other organisms. How do you try to apply assembly theory to that? At the moment, we should be able to do this to morphology in cells. So we're looking at cell surfaces, and really I'm trying to extend further. It's just that we work so hard to get this paper out and people to start discussing the ideas, but it's kind of funny because I think the penny is falling on this. What does it mean for a penny? The pennies dropped, right? Because a lot of people were like, it's rubbish, it's rubbish. You've insulted me, it's wrong. And I'm. And then, you know, I mean, the paper got published on the 4 October, it had 2.3 million engagements on Twitter, right? And it's been downloaded over a few hundred thousand times. And someone actually said to me, wrote to me and said, this is an example of really bad writing and what not to do. And I was like, if all of my papers got read this much, because that's the objective of, I have a publishing paper on people to read it. I want to write that badly again. Yeah. I don't know what's the deep insight here about the negativity in the space? I think it's probably the immune system of the scientific community making sure that there's no bullshit that gets published and it can over fire, it can do a lot of damage, it can shut down conversations in a way that's not productive. We go back, I mean, I'll answer your question about the hierarchy and assembly, but let's go back to the perception, people saying the paper was badly written. I mean, of course we could improve it. We could always improve the clarity. Let's go there. Before we go to the hierarchy, you know, it has been criticized quite a bit, the paper. What has been some criticism that you found most powerful, like that you can understand and can you explain it? Yes. The most exciting criticism came from the evolutionary biologist telling me that they thought that origin of life was a solved problem. And I was like, whoa, we're really onto something, because it's clearly not. And when you poked them on that, they just said, no, you don't understand evolution. And I said, no, no, I don't think you understand that evolution had to occur before biology. And we need, there's a gap. That was really, for me, that misunderstanding, and that did cause an immune response, which was really interesting. The second thing was the fact that physicists, the physicists were actually really polite, right, really nice about it, but they just said, huh, we're not really sure about the initial conditions thing, but this is a really big debate that we should certainly get into, because the emergence of life was not encoded in the initial conditions of the universe, and it can't. And I think assembly theory shows why it can't be. Sure. If you could say that again, the emergence of life was not and cannot in principle be encoded in the initial conditions of the universe. Just to clarify, what we mean by life is like, what, high assembly index objects. Yeah. And this goes back to your favorite subject, what's that? Time. Right. So why, so why, what does time have to do with it? I mean, probably we can come back to it later, but I think it might be if we have time. But I think that. I think I now understand how to explain how lots of people got angry with the assembly paper. But also the ramifications of this is how time is fundamental in the universe and this notion of commentarial spaces. And there are so many layers on this, but you have to become an intuition, I think you have to become an intuitionist mathematician, and you have to abandon platonic mathematics. And also platonic mathematics has left physics astray. But there's a lot to unpack there so we can go to the platonic mathematics. Okay. It's okay. The evolutionary biologists criticize because the origin of life is understood and not, it doesn't require an explanation that involves physics. Yeah. That's their statement. Well, I mean, it was, I think they said lots of confusing statements. Basically, I realized the evolutionary biology community that were vocal and some of them really rude, really spiteful and needlessly so. Right. Because, like, you know, I didn't. People misunderstand publication as well. Some of the people have said, how dare this be published in nature? This is, you know, how. What a terrible journal. And it really, and I want to set the people look, this is a brand new idea that's not only potentially going to change the way we look at biology, it's going to change the way we look at the universe. And everyone's like saying, how dare you? How dare you be so grandiose? I'm like, no, no, no, this is not hype. We're not like saying we've invented some, I don't know, we've discovered an alien in a closet somewhere just for hype. We genuinely mean this to genuinely have the impact or ask the question. And the way people jumped on that was a really bad precedent for young people who want to actually do something new, because this makes a bold claim, and the chances are that it's not correct. But what I wanted to do is a couple of things, is I want to make a bold claim that was precise and testable and correctable, not a woolly, another woolly information in biology argument information, turing machine, blah, blah, blah, blah, blah. A concrete series of statements that can be falsified and explored and either the theory could be destroyed or built upon. Well, what about the criticism of you're just putting a bunch of sexy names on something that's already obvious? Yeah, that's really good. So the assembly index of a molecule is not obvious. No one had measured it before, and no one has thought to quantify selection, complexity and copy number before in such a primitive, quantifiable way. I think the nice thing about this paper, this paper is a tribute to all the people that understand that biology does something very interesting. Some people call it neg entropy. Some people call it, think about organizational principles, that. Lots of people were not shocked by the paper because they'd done it before. A lot of, the lot of the arguments we got, some people said, oh, it's rubbish. Oh, by the way, I had this idea 20 years before. I was like, which one is it the rubbish part or the really revolutionary part? So this kind of plucked two strings at once. It plucked the. There is something interesting that biology does. We can see around this, but we haven't quantified yet. And what, this is the first stab at quantifying that. So the fact that people said, this is obvious, but it's also, if it's obvious, why have you not done it? Sure. But there's a few things to say there. One is, this is in part of a philosophical framework, because it's not like you can apply this generally to any object in the universe. It's very chemistry focused. Yeah. Well, I think you will be able to. We just haven't got there robustly. We can say, how can we? Let's go up a level. So if we go up from level, we go up. Let's go up from molecules to cells, because you would jump to people and I jumped for motor cons, and both are good. And they will be assembled sickle cells. Yeah. So if we go from molecules to assemblies and let's take a cellular assembly. A nice thing about a cell is you can tell the difference between a eukaryote and a prokaryote, right. The organelles are specialized differently. We then look at the cell surface, and the cell surface has different glycosylation patterns, and these cells will stick together. Now let's go up a level. In multicellular creatures, you have cellular differentiation. Now, if you think about how embryos develop, you go all the way back, those cells undergo a differentiation in a causal way. That's biomechanically a feedback between the genetics and biomechanics. I think we can use assembly theory to apply to tissue types. We can even apply it to different cell disease types. So that's what we're doing next. But we're trying to walk. You know, the thing is, I'm trying to leap ahead. I want to leap ahead to go, whoa. We apply it to culture, but clearly you can apply it to memes and culture. And we've also applied assembly theory to cas and not, as you think, cellular automata, but yeah, yeah, to cellular automata, not just as you think. Different CA rules were invented by different people at different times. And one of my, one of my co workers, very talented chap, basically was like, oh, I can realize that different people had different ideas with different rules and they copied each other and made slightly different bit, but different cellular automata rules. And they. And looked at them online. And so he was able to affirm assembly index and copy number of rule, whatever, doing this thing. But I digress. But it does show you can apply it at higher scale. So what do we need to do to apply assembly theory? Two things we need to agree. There's a common set of building blocks. So in a cell, well, in a. In a multicellular creature, you need to look back in time. So there is the initial cell, which the creature is fertilized and then starts to grow, and then there is cell differentiation. And you have to then make that causal chain both on those that requires development of the organism in time. Or if you look at the cell surfaces and the cell types, they've got different features on the cell walls and inside the cell. So we're building up. But obviously, I want a leap to things like emoticons, language, mathematical theory. That's a very large number of steps to get from a molecule to the human brain. Yeah. And I think they are related, but in hierarchies of emergence. Right. So you shouldn't compare them. I mean, the assembly index of a human brain, what does that even mean? Well, maybe we can look at the morphology of the human brain. Say all human brains have these number of features in common. If they have those number. And then let's look at a brain in a whale or a dolphin or a chimpanzee or a bird and say, okay, let's look at the assembly indices, number of features in these. And now the copy number is just a number of how many birds are there, how many chimpanzees are there, how many humans are there. Then you have to discover for that the features that you would be looking for. Yeah. And that means you need to have a, you need to have some idea of the anatomy. But is there an automated way to. Discover features, I guess so. I mean, and I think this is a good way to apply machine learning and image recognition just to basically characterize. Things, apply compression to it to see what emerges, and then use the thing, the features used as part of the compression, as the measurement of, as the thing that is searched for when you're measuring assembly index and copy number one. And the compression has to be, remember the assembly universe, which is you have to go from assembly possible to assembly contingent, and that jump from, because assembly possible, all possible brains, all possible features all the time. But we know that on the tree of life and also on the lineage of life going back to Luca, the human brain just didn't spring into existence yesterday. It is a long lineage of brains going all the way back. And so if we could do assembly theory to understand the development, not just in evolutionary history, but in biological development, as you grow, we are going to learn something more. What would be amazing is if you can use assembly theory, this framework, to show the increase in the assembly index, associate with, I don't know, cultures or pieces of text like language or images and so on, and illustrate without knowing the data ahead of time, just kind of like you did with NASA, that you're able to demonstrate that it applies in those other contexts, I mean, and that, you know, probably wouldn't at first. And you have to evolve the theory somehow. You have to change it, you have to expand it, you know? I think so. But like that, I guess this is, as a paper, a first step in saying, okay, can we create a general framework for measuring complexity of objects, for measuring life, the complexity of living organisms? Yeah, that's what this is reaching for. That is the first step. And also to say, look, we have a way of quantifying selection and evolution in a fairly. In a fairly. Not mundane, but a fairly mechanical way, because before now, it wasn't very. The ground truth for it was very subjective, whereas here we're talking about clean observables and there's going to be layers on that. I mean, with collaborators right now, we already think we can do assembly theory on language. And not only that, wouldn't it be great if we can? So if we can figure out how under pressure, language is going to evolve and be more efficient, because you're going to want to transmit things. And again, it's not just about compression. It is about understanding how you can make the most of the. In the architecture you've already built. And I think this is something beautiful that evolution does. We're reusing those architectures, we can't just abandon our evolutionary history. And if you don't want to abandon your evolutionary history and you know that evolution has been happening, then assembly theory works. And I think that's a key comment I want to make, is that assembly theory is great for understanding where evolution has been used. The next jump is when we go to technology. Because of course if you take the M three processor, I want to buy, I haven't bought one yet, I can't justify it, but I want to at some point. The M three processor, arguably there's quite a lot of features, a quite large number. The M two came before it, then the m one all the way back. You can apply assembly theory to microprocessor architecture. It doesn't take a huge leap to see that. I'm a Linux guy, by the way. So your examples go way over. Yeah, well whatever. Is that like, is that a fruit company of some sort? I don't even know. Yeah, there's a lot of interesting stuff to ask about language. Like you could look at. How would that work? You could look at GPT one, GPT-2 GPT 3354, and try to analyze the kind of language it produces. I mean that's almost trying to look at assembly index of intelligent systems. Yeah, I mean, I think the thing about large language models, and this is a whole hobby horse I have at the moment, is that obviously they're all about the, the evidence of evolution in the large language model comes from all the people that produced all the language. And that's really interesting. And all the corrections in the mechanical Turk, right? Sure. That's part of the history, part of the memory of the system. Exactly. So it would be really interesting to basically use an assembly based approach to making language in a hierarchy. Right. I think my guess is that you could, we might be able to build a new type of large language model that uses assembly theory, that it has more understanding of the past and how things were created. Basically the thing with LLMs is they're like everything everywhere, all at once, splat and make the user happy. So there's not much intelligence in the model. The model is how the human interacts with the model. But wouldn't it be great if we could understand how to embed more intelligence in the system? What do you mean by intelligence there? Like you seem to associate intelligence with history. Yeah, memory. I think selection produces intelligence. You're almost implying that selection is intelligence. No, kind of. I would go out on a limb and say that, but I think it's a little bit more. Human beings have the ability to abstract and they can break beyond selection. And this is what darwinian selection, because a human being doesn't have to basically do trial and error. They can think about. They say, oh, that's a bad idea, won't do that. And then technologies and so on. So we escaped darwinian evolution and now we're onto some other kind of evolution. I guess higher levels. And assembly theory will measure that as well. Right, because it's all a lineage. Okay. Another piece of criticism, or by way of question, is how is assembly theory, or maybe assembly index, different from Kolmogorov complexity? So for people who don't know, Kolmogorov complexity of an object is the length of a shortest computer program that produces the object as output. Yeah. There seems to be a disconnect between the computational approach to common goller off measure requires a Turing machine, requires a computer, and that's one thing. And the other thing is assembly theory is supposed to trace the process by which life evolution emerged. There's a main thing there. There are lots of other layers. So common Golorov complexity, you can approximate common go off complexity, but it's not really telling you very much about the actual, it's really telling you about your data set, compression of your data set. And so that doesn't really help you identify the turtle in this case is the computer. And so what assembly theory does is, I'm going to say, trigger warning for anyone listening who loves complexity theory. I think that we're going to show that AIT is a very important subset of assembly theory, because here's what happens. I think that assembly theory allows us to build, understand when selection is occurring. Selection produces factories and things. Factories, in the end produce computers, and you can get algorithmic information theory comes out of that. The frustration I've had with looking at life through this kind of information theory is it doesn't take into account causation. So the main difference between assembly theory and all these complexity measures is there's no causal chain. Yeah. And I think that's the main, that's. The causal chain is at the, at the core of assembly theory. Exactly. And if you've got your data in a computer memory, all the data is the same. You can access it in the same way. You don't care, you just compress it. And you either look at the program runtime or the shortest program. And that, for me, is absolutely not capturing what it is, what its selection does. But assembly theory looks at objects. It doesn't have information about the object history. It's going to try to infer that history by looking for the shortest history. Right. The object doesn't like, have a Wikipedia page that goes with it about its history. I would say it does in a way, and it is fascinating. Look, so you've just got the object and you have no other information about the object. What assembly theory allows you to do just with the object is to. And the word infer is correct. I agree with infer. You say, well, that's not the history, but something really interesting comes from this. The shortest path is inferred from the object. That is the worst case scenario if you have no machine to make it. So that tells you about the depth of that object in time. And so what assembly theory allows you to do is without considering any other circumstances, to say from this object, how deep is this object in time, if we just treat the object as itself without any other, any other constraints. And that's super powerful because the shortest path then says, allows you to say, oh, this object wasn't just created randomly, there was a process. And so assembly theory is not meant to, you know, one up ait or to ignore the factory is just to say, it's just to say, hey, there was a factory and how big was that factory and how deep in time is it? But it's still computationally very difficult to compute that history. Right? For complex objects it is, it becomes harder. But one of the things that's super nice is that it constrains your initial conditions, right? It constrains where you're going to be. So if you take, say, imagine. So one of the things we're doing right now is applying assembly theory to drug discovery. Now what everyone's doing right now is taking all the proteins and looking at the proteins and looking at molecules, doctor, proteins. Why not instead take the look at the molecules that are involved in interacting with the receptors over time, rather thinking about and use the molecules that evolve over time as a proxy for how the proteins evolved over time, and then use that to constrain your drug discovery process. You flip the problem 180 and focus on the molecule evolution rather than the protein, and so you can guess in the future what might happen. So rather than having to consider all possible molecules, you know where to focus. And that's the same thing. If you're looking at an assembly spaces for an object where you don't know the entire history, but you know that in the history of this object, it's not going to have some other motif there that it doesn't apply. It doesn't appear in the past. But just even for the drug discovery point you made, don't you have to simulate all of chemistry to figure out how to come up with constraints? No. The molecules? No, I don't know enough about protein. Well, this is another thing that I think causes, because this paper goes across so many boundaries. So chemists have looked at this and said, this is not correct reaction. It's like. No, it's a graph. Sure. There's assembly index and shortest path examples here on chemistry. Yeah. And what you do is you look at the minimal constraints on that graph. Of course, it has some mapping to the synthesis, but actually, you don't have to know all of chemistry. You just have to understand you can build up the constraint space rather nicely. But this is just at the beginning, right? There are so many directions this could go in. And as I said, it could all be wrong, but hopefully it's less wrong. What about the little criticism I saw of, by way of question, do you consider the different probabilities of each reaction in the chain so that there could be different? When you look at a chain of events that led up to the creation of an object, doesn't it matter that some parts in the chain are less likely than others? No, it doesn't matter. No. No. Well, let's go back. So, no, not less likely, but react. So, no. So let's go back to what we're looking at here. So the assembly index is the minimal path that could have created that object probabilistically. So imagine you have all your atoms in a plasma. You got enough energy, you've got enough. There's collisions. What is the quickest way you could zip out that molecule with no reaction constraints? How do you define quickest there, then? It's just basically a walk on a random graph. So we make an assumption that basically the time scale for forming the bonds. I don't want to say that, because it's going to have people getting obsessing about this point. And your criticism is a really good one. What we're trying to say is this puts a lower bound on something. Of course, some reactions are less possible than others, but actually, I don't think chemical reactions exist. Oh, boy. What does that mean? Why don't chemical reactions exist? I'm writing a paper right now that I keep being told I have to finish, and it's called the origin of chemical reactions, and it merely says that reactivity exists as controlled by the laws of quantum mechanics and reactions. Chemists put names on reactions. So you could have like, I don't know, the wittic reaction, which is by wittic, you could have the Suzuki reaction, which is by Suzuki. Now, what are these reactions? So these reactions are constrained by the following. They're constrained by the fact they're on planet Earth, one G 298 kelvin, 1 bar. So these are constraints. They're also constrained by the chemical composition of Earth, oxygen availability, all this stuff. And that then allows us to focus in our chemistry. So when a chemist does a reaction, that's a really nice compressed shorthand for constraint application. Glass flask, pure reagent, temperature, pressure, bomb, bomb, bomb bomb, bomb control. Control. So of course we have bond energies. So the bond energies are kind of intrinsic in a vacuum, if you say that. So the bond energy, you have to have a bond. And so for assembly theory to work, you have to have a bond, which means that bond has to give the molecule certainly a half life. So you're probably going to find later on that some bonds are weaker and that you are going to miss in mass spectrum. When you look at the assembly of some molecules, you're going to miscount the assembly of the molecule because it falls apart too quickly because the bonds just form. But you can solve that with looking infrared. So when people think about the probability, they're kind of misunderstanding. Assembly theory says nothing about the chemistry because chemistry is chemistry and the constraints are put in by biology. There was no chemist on the origin of life, bacon, unless you believe in the chemist in the sky. And they were, you know, it's like Santa Claus, they had a lot of work to do. But chemical reactions do not exist in the constraints that allow chemical transformations to occur do exist. Okay. Okay. So it's constraint application. So there's no chemical reactions. It's all constraint application. Yeah. Which enables the emergence of react. Of, what's a different word for chemical reaction? Transformation. Transformation, yeah, like a function. It's a function, but no, but I love chemical reactions as a shorthand and. Yeah, and so the chemists don't all go mad. I mean, of course chemical reactions exist on earth. It's a shorthand. It's a shorthand for all these constraints. Right. So assuming all these constraints that we've been using for so long that we just assume that that's what was the case in natural language conversation. Exactly. The grammar of chemistry, of course, emerges in reactions and we can use them reliably, but I do not think the wittic reaction is accessible on Venus. Right. And this is useful to remember, you know, to frame it as constraint application is useful for when you zoom out to the bigger picture of the universe and looking at the chemistry of the universe and then starting to apply assembly theory. Yeah, that's interesting. That's really interesting. But we've also pissed off the chemists now. Oh, that's pretty happy, but. Well, most of them. No, everybody. Everybody deep down is happy. I think they're just sometimes feisty. That's how they show. That's how they have fun. Everyone is grumpy on some days when they. When you challenge. The problem with this paper is you. Why is like, it's almost like I went to a park. It's like you. I used to do this occasionally when I was younger. Go to a meeting and just find a way to offend everyone at the meeting simultaneously. Even the factions that don't like each other, they're all unified in their hatred of you, just offending them. This paper, it feels like the person that went to the party and offended everyone simultaneously, so stopped fighting with themselves and just focused on this paper. Maybe just a little insider interesting information. What were the editors of nature, the reviews and so on? How difficult was that process? Because this is a pretty, like, big paper. Yeah, I mean, the. So when we originally sent the paper, we sent the paper and the editor said that, you know, this was like, this was quite a long process. We sent the paper and the editor gave us some feedback and said, you know, I don't think it's that interesting. It's not, you know, or it's hard. It's a hard concept. And we asked and the editor gave us some feedback, and we, and Sarah and I took a year to rewrite the paper. Was the nature of the feedback very specific on, like, this part? This part? Or was it like, like, what are you guys smoking? What kind of. Yeah, it was kind of the latter. What you smoking? Okay. And, you know. But polite and there's promise. Yeah, well, the thing is, there was, the edit was really critical, but in a really professional way. And, I mean, for me, this was the way science should happen. So when it came back, you know, we had too many equations in the paper. If you look at the preprint, they're just equations everywhere. Like 23 equations. And when I said to Abhishek, who was the first author, we've got to remove all the equations. But my assembly equation, staying in Abhishek, was like, you know, no, we can't. I said, well, look, if we want to explain this to people, there's a real challenge. And so Sarah and I went through the I think it was actually 160 versions of the paper, but we basically, we got to version 40 or something. We said, right, zero. Let's start again. So we wrote the whole paper again. We knew the entire amazing. And we just went bit by bit by bit and said, what is it we want to say? And then we send the paper in, and we expected it to be rejected and not even go to review. And then we got notification back it had gone to review, and we were like, oh, my God, it's so going to get rejected. How's it going to get rejected? Because first assembly paper on the mass spec we sent to nature went through six rounds of review and rejected, right? And by a chemist just said, I don't believe you. You must be committing fraud. Long story, probably a boring story, but in this case, it went out to review. The comments came back, and the comments were incredibly. No, they were very. They were very deep comments from all the reviewers there were. And. But the nice thing was, the reviewers were kind of very critical but not dismissive. They were like, oh, really? Explain this. Explain this. Explain this. Explain this. Are you sure it's not common golla off? Are you sure it's not this? And we went through, I think, three rounds of review pretty quick, and the editor went, yeah, it's in. But maybe you could just comment on the whole process. You've published some pretty huge papers on all kinds of topics within chemistry and beyond. Some of them have some little spice in them, a little spice of crazy, like Tom Wade says, I like my tom with a little drop of poison. It's not a mundane paper. So what's it like psychologically to go through all this process, to keep getting rejected, to. To get reviews from people that don't get the paper or all that kind of stuff? Just from a question of a scientist, what is that like? I think it's. I mean, this paper, for me, kind of, because this wasn't the first time we tried to publish assembly theory at the highest level. The nature communications paper on the mass spec on the idea went through, went to nature and got rejected. Went through six rounds of review and got rejected. And I just was so confused when the chemist said, this can't be possible. I do not believe you can measure complexity using mass spec. And also, by the way, molecules, complex molecules, can randomly form. And will I put a look at the data, the data says. And they said, no, no, we don't believe you. And we went, and I just wouldn't give up. And the editor, in the end, was just like, different editors, actually. Right. What's behind that? Never giving up. Like, when you're sitting there 10:00 in the evening, there's a melancholy feeling that comes over you. You're like, okay, this is rejection number five. Or it's not rejection, but maybe it feels like a rejection because, you know, the comments are that you totally don't get it. Like, what gives you strength to keep going there? Yeah. I don't know. I don't normally get emotional about papers, but it's not about giving up because we want to get it published, because we want the glory or anything. It's just like, why don't you understand? And so what I did, so what? I would just try to be as. As rational as possible and say, yeah, you didn't like it? Tell me why. And then, sorry. Silly. Any part. Never get emotional about papers normally. But I think what we did, you just compressed, like five years of angst from this. So it's been rough. It's not just rough. It's like it happened, you know, I came up with the assembly equation, you know, remote from Sarah in Arizona and the people SFI. I felt like I was a mad person. Like, you know, the guy in depicted in a beautiful mind who was just like, not, not the actual genius part, but just gibberish. Gibberish. Because I kept writing expanded, and I have no mathematical ability at all. And I was expand. I was making these mathematical expansions where I kept seeing the same motif again. I was like, I think this is a copy number. The same string is carrying again and again. I couldn't do the math. And then I realized the copy number fell out of the equation and everything collapsed down, I was like, oh, that works, kind of. So we submitted the paper, and then when it was almost accepted, right, the mass spec one, and it was, astrobiologists said, great. You know, a mass spectroscopist said, great. And the chemist went, nonsense. Like, biggest pile of nonsense ever. Fraudental. And I was like, but why fraud? And they just said, just because. And I was like, well. And I could not convince the editor in this case. The editor was just so pissed off because they see it as like a kind of, you know, you're wasting my time. And I would not give up. I wrote, I went and dissected all the parts. And I think, although, I mean, I got upset about it, you know, it was kind of embarrassing, actually, but I. But I guess beautiful. But it was just trying to understand why they didn't like it. So they were, part of me was like, really devastated. And a part of me was super excited because I'm like, huh? They can't tell me why I'm wrong. And this kind of goes back to when I was at school. I was in a kind of learning difficulties class, and I kept going to the teacher and say, what do I do today to prove I'm smart? And they were like, nothing. You can't. I was like, give me a job. You know, give me something to do. Give me a job to do. Something to do as we. And I kind of felt like that a bit when I was arguing with the. And not arguing. There was no ad hominem. I wasn't telling the editor they were idiots or anything like this, or the reviewers. I kept it strictly, like, factual. And all I did is I just kept knocking it down bit by bit by bit by bit by bit. It was ultimately rejected, and it got published elsewhere, and then the actual experimental data. So this is kind of in this paper, the experimental justification was already published. So when we did this one, and we went through the versions, and then we sent it in, and in the end, it just got accepted. We were like, well, that's kind of cool, right? This is kind of like some days you had the student, sorry. The first author was like, I can't believe it got accepted. Like, nor am I, but it's great. It's like, it's good. And then when the paper was published, I was not expecting the backlash. I was expecting computational. No, actually, I was just expecting one person who'd been trolling me for a while about it just to carry on trolling, but I didn't expect the backlash. And then I wrote to the editor and apologized, and the editor was like, what are you apologizing for? It was a great paper. Of course it's going to get backlash. You said some controversial stuff, but it's awesome. And so it's. I think it's a beautiful story of perseverance, and the backlash is just a negative word for discourse, which I think is beautiful. I think you, as I said to, you know, when it got accepted and people were saying, we're kind of, like, hacking on it, I was like, papers are not gold medals. The reason I wanted to publish that paper in nature is because it says, hey, there's something before biological evolution. You have to have that. If you're not a creationist, by the way, this is an approach. First time someone has put a concrete mechanism, or, sorry, a concrete quantification, and what comes next you're pushing on is a mechanism, and that's what we need to get to, is an autocaladic set, self replicating molecules, some other features that come in. And the fact that this paper has been so discussed for me is a dream come true. Like, it doesn't get better than that if you can't accept a few people hating it. And the nice thing is, the thing that really makes me happy, is that no one has attacked the actual physical content. Like, you can measure the assembly index, you can measure selection now. So either that's right, or it's, well. Well, either that's helpful or unhelpful. If it's unhelpful, this paper will sink down and no one will use it again. If it's helpful, it'll help people build scaffold on it, and we'll start to converge to a new paradigm. So I think that that's the thing that I wanted to see. My colleagues, authors, collaborators, and people were like, you've just published this paper. You're a chemist. Why have you done this? Who are you to be doing evolutionary theory, Mike? Well, I don't know. I mean. Sorry, did I need to cause anyone to do anything? Well, I'm glad you did. Let me just. Before coming back to origin of life and these kinds of questions, you mentioned learning difficulties. I didn't know about this. So what was it like? I wasn't very good at school. Right, this is when you were very young? Yeah, yeah. But in primary school, my handwriting was really poor, and apparently I couldn't read, and my mathematics was very poor. So they just said, this is a problem. They identified it. My parents kind of, at the time, were confused because I was busy taking things apart, buying electronic junk from the shop, trying to build computers and things. And then once I got out of. When I was. I think about the major transition in my stupidity. Like, you know, everyone thought I wasn't that stupid when I was. Basically, everyone thought I was faking. I like stuff and I was faking wanting to be it. So I always want to be a scientist. So five, six, seven years old, I'd be a scientist, take things apart, and everyone's like, yeah, this guy wants to be a scientist, but he's an idiot. And so everyone was really confused. I think at first that I wasn't smarter than I was claiming to be, and then I just basically didn't do well in the test. I went down and down and down and down, and then. And I was kind of like, huh, this is really embarrassing. I really like maths, and everyone says I can't do it. I really like kind of, you know, physics and chemistry and all that, and science and people say, you're not. You can't. You can't read and write. And so I found myself in a learning difficulties class at the end of primary school and the beginning of secondary school in the UK. Secondary school is like 1112 years old. And I remember being put in the. In the remedial class. And the remedial class was basically full of, well, two types, three types of people. There were people that had quite violent, right? And there were people who couldn't speak English and there were people that really had learning difficulties. So the one thing I can objectively remember was, I mean, I could read. I like reading, I read a lot. But something in me, I'm a bit of a rebel. I refuse to read what I was told to read. And I found it difficult to read individual words in the way they were told. But anyway, I got caught one day teaching someone else to read and they said, okay, we don't understand this. I always knew what to be a scientist, but didn't really know what that meant. And I realized you had to go to university. And I thought, I can just go to university, take curious people, like, no, no, no, you need to have these. You have to be able to enter these exams to get this grade point average. And the fact is, the exams you've been entered into and you're just going to get C, D or E. You can't even get a b or c, right? These are the UK GCSE's. I was like, oh, shit. And I said, can you just put me into the higher exams? I said, no, no, you're going to fail. There's no chance. So my father kind of intervened and said, you know, just let him go on the exams. And they said, he's definitely going to fail. It's a waste of time, waste of money. And he said, well, what have we paid? So they said, well, okay, so you didn't actually have to pay. You didn't have to pay if I failed. So I took the exams and passed them. Fortunately, I didn't get the top grades, but I got into a levels. But then that also kind of limited what I could do at a levels. I wasn't allowed to do a level maths. What do you mean you weren't allowed to? Because I had such a bad math grade from my GCSE. I only had a c, but they wouldn't let me go into the ABC for maths because of some kind of coursework requirement back then. So the top grade I could have got was a c. So C dual ethereum. And then let me do kind of as level maths, which is this half intermediate, but get to go to university. But in the archaeological chemistry, I had a good chemistry teacher. So in the end, I got to university to do chemistry. So through that kind of process, I think for kids in that situation, it's easy to start believing that you're not well, how do I put it? That you're stupid and basically give up, that you're just not good at math, you're not good at school. So this is by way of advice for people, for interesting people, for interesting young kids right now experiencing the same thing. Where was the place? What was the source of you not giving up there? I have no idea, other than I. I was really. I really, like not understanding stuff. For me, when I not understand something I didn't understand, I feel like I don't understand anything, but now. But back then, I was so. I remember when I was like, I don't know, I tried to build a laser when I was like, eight, and I thought, how hard could it be? And I basically, I was going to build a co. Was going to build a CO2 laser, and I was like, right, I think I need some partially coated mirrors. I need some carbon dioxide, and I need a high voltage. So I kind of like, I didn't have a. And I was so stupid, right. I was kind of so embarrassed. I. To make enough CO2, I actually set a fire and tried to filter the flame. Oh, nice. To crap it off, CO2. And I was like, it completely failed. And I bent. Burnt half the garage down. So my parents were not very happy about that. So that was one thing I was like, I really like first principle thinking. And so I remember being super curious and being determined to find answers. And so when people do give advice about this, well, I ask for advice about this. I don't really have that much advice other than don't give up. And one of the things I try to do as a chemistry professor in my group is I hire people that I think that who am I? If they're persistent enough, who am I to deny them the chance? Because people gave me a chance and I was able to do stuff. Do you believe in yourself? Essentially. So I love being around smart people, and I love confusing smart people. And when I'm confusing smart people, not by stealing their wallets and hiding it somewhere, but if I can confuse smart people, that is the one piece of hope that I might be doing something interesting. Wow, that's quite brilliant. Like, as a gradient to optimize. Yeah. Hang out with smart people and confuse them. And the more confusing it is, the more there's something there. And as long as they're not telling you, just a complete idiot. And. And they give you different reasons. Yeah. And I mean, I'm, you know, if everyone. It's like with assembly theory, and people said, oh, it's wrong. And I was like, why? And they're like, and no one could give me a consistent reason. They said, oh, because it's been done before, or it's just komagola, or it's just there. That and the other. So I think the thing that I like to do is. And in academia, it's hard, right. Because people are critical. But I mean, you know, the criticism. I mean, although I got kind of upset about it earlier, which is kind of silly, but not silly, because obviously it's hard work being on your own or with a team spatially separated, like, during lockdown and trying to keep everyone on board and have some faith that. But I've always wanted to have a new idea, and so, you know, I like a new idea, and I want to. I don't want. I want to nurture it as long as possible. And if someone can give me actionable criticism, that's why I think I was trying to say earlier when I was kind of, like, stuck for words. Give me actionable criticism. You know, it's wrong. Okay, why is it wrong? You say, oh, it doesn't. Your equation's incorrect for this, or your method is wrong. And so what I try and do is get enough criticism from people to then triangulate and go back. And I've been very fortunate in my life that I've got great colleagues, great collaborators, funders, mentors, and people that will take the time to say, you're wrong, because. And then what I have to do is integrate the wrongness and go, oh, cool, maybe I can fix that. And I think criticism is really good. People have a go at me because I'm really critical. I'm like, but I'm not criticizing you as a person. I'm just criticizing the idea and trying to make it better and say, well, what about this? And sometimes my filters are truncating in some ways. I'm just like, that's wrong, that's wrong, that's wrong. What do this? And people are like, oh, my God, you just told me you destroyed my life's work. I'm like, relax. No, I'm just like, let's make it better. And I think that we don't do that enough because we're, you know, we're either personally critical, which isn't helpful, or we don't give any criticism at all because we're too scared. Yeah, yeah. I've seen you be pretty aggressively critical, but it's. Every time I've seen it, it's the idea, not the person. I'm sure I make mistakes in that. I mean, I argue lots with, with lots. I mean, I argue lots with Sarah, and she's, like, kind of shocked. I've argued with Yashta in the past, and he's like, you're just making Yasha buck. And you're like, you're just making that up. I'm like, no, not quite, but kind of. You know, I had a big argument with Sarah about time, and she's like, no, time. Time doesn't exist. I'm like, no, no time does exist. And now. And as she realized that her conception of assembly theory and my conception assembly theory, the same thing necessitated us to abandon the fact that time is eternal to actually really fundamentally question how the universe produces combinatorial novelty. So time is fundamental for assembly theory. I'm just trying to figure out where you and Sarah converge. So I think assembly theory is fine in this time right now, but I think it helps us understand that something interesting is going on. So there's. And I'm really inspired by a guy called Nick Gizzen. I'm going to butcher his argument, but I love his argument a lot, so I hope he forgives me if he hears about it. But basically, if you want free will, time has to be fundamental, and we can go. And if you want time to be fundamental, you have to give up on platonic mathematics, and you have to use intuitions. Mathematics, by the. By the way. And again, I'm going to butcher this. But basically Hilbert said that, you know, infinite numbers are allowed. And I think it was Brower said, no, you can't. All numbers are finite, so they're kind of like with. So let's go back a step, because it was like people can say, assembly theory seems to explain that large commentarial space allows you to produce things like life and technology, and that large commentarial space is so big, it's not even accessible to a Sean Carroll David Deutsch multiverse. The physicists saying that all of the universe already exists in time is probably provably. That's a strong word. Not correct that we are going to know that the universe, as it stands, the present, the way the present builds the future so big, the universe can't ever contain the future. And this is a really interesting thing. I think Max Tekmark has this mathematical universe where he says, you know, the universe is kind of like a block universe. I apologize to Max if I'm getting it wrong, but people think you can just move. You'd have the stat, you have the initial conditions, and you can run the universe right to the end and go backwards and forwards in that universe. That is not correct. Let me load that in. The universe is not big enough to contain the future. Yeah, that's why. That's it. That's another. That's a beautiful way of saying that time is fundamental. Yes. And you can have a. And that's what, this is why the law of the excluded middle, something is true or false, only works in the past. Is it going to snow in New York next week or in Austin? You might, in Austin say, probably not. In New York, you might say, yeah, if you go forward to next week and say, did it snow in New York last week? True or false? You can answer that question. The fact that the law of the excluded middle cannot apply to the future explains why time is fundamental. Well, I mean, that's a good example, intuitive example, but it's possible that we might be able to predict, you know, whether it's gonna snow. If we had perfect information. I think we're saying it. Not impossible. Impossible. So here's why. I'll make a really quick argument, and this argument isn't mine. It's. It's Nick's and a few other people. Can you. Can you explain his view on fundamental, on time being fundamental? Yeah. So I'll give my view, which kind of resonates with his. But basically, it's very simple, actually. He would say that free will, that your ability to design and do an experiment is exercising free will. So he used that thought process. I never really thought about it that way. And that you actively make decisions. I used to think that free will was a kind of. Kind of consequence of just selection. But I'm kind of understanding that human free will is something really interesting, and he very much inspired me. But I think that what Sarah Walker said, that inspired me as well. These will converge is that I think that the universe in the universe is very big. Huge. But actually, the place is largest in the universe right now. The largest place in the universe is Earth. Yeah, I've seen you say that. And, boy, does that. That's a that's an interesting one to process. What do you mean by that? Earth is the biggest place in the. Universe because we have this combinatorial scaffolding going all the way back from Luca. So you've, you've got cells that can self replicate, and then you go all the way to terraforming the earth. You've got all these architectures, the amount of selection that's going on, biological selection, just to be clear, biological evolution. And then you have multicellularity, then animals and abstraction. And with abstraction, there was another kick, because you can then build architectures and computers and cultures and language. And these things are the biggest things that exist in the universe because we can just build architectures that couldn't naturally arise anywhere. And the further that distance goes in time and this kind of is just gigantic. And from a complexity perspective. Yeah. Okay, wait a minute. But, I mean, I know you're being poetic, but how do you know there's not other earth? Like, uh, like, how do you know? You're, you're basically saying earth is really special. It's awesome stuff. As far as we look out, there's nothing like it going on. But how do you know there's not nearly infinite number of places where cool stuff like this is going on? I agree. And I would say, I'll say again, that Earth is the most gigantic thing we know in the universe. Commentarily, we know. We know. Now, I guess this is just purely a guess. I have no data, but other than hope. Well, maybe not hope, maybe no. I have some data that every star in the sky probably has planets, and life is probably emerging on these planets. The amount of contingency that is associated with life is that I think the commentarial space associated with these planets is so different, we are never going to, our causal cones are never going to overlap or not easily. And this is the thing that makes me sad about alien life. Why? It's why we have to create alien life in the lab as quickly as possible, because I don't know if we are going to be able to be able to build architectures that will intersect with alien intelligence. Architectures intersect. You don't mean in time or space? Time and the ability to communicate. The ability to communicate, yeah. My biggest fear, in a way, is that life is everywhere, but we become infinitely more lonely because of our scaffolding in that commentarial space because it's so big. So you're saying the, the constraints created by the environment that led to the factory of darwinian evolution are just like, list a little tiny cone in a nearly infinite combinatorial space. So there's other cones like it. And why can't we communicate with other, like, just because we can't create it doesn't mean we can't appreciate the creation. Right. Sorry. Detect the creation. I truly don't know, but I. It's an excuse for me to ask for people to give me money to make a planet simulator. Yeah, right. If I can make with a different kind of, like, another shameless say, it's like, give me money, I need. This was all a long plug for a planet simulator. It's like, you know, hey, I won't be the first in line to do my rick. My Rick garage has run out of room, you know. Yeah, no, this is a planet simulator. You mean like a different kind of planet with different sets of environments and pressures? Exactly. If we could basically recreate the selection before biology as we know it, that gives rise to a different biology. We should be able to put the constraints on where to look in the universe. So here's the thing. Here's my dream. My dream is that by creating life in the lab based upon constraints we understand, like this. Go for Venus type life or Earth type life or something. Again, do Earth 2.0. Screw it. Let's do IRF 2.0. An IRF 2.0 has a different genetic Alphabet. Fine, that's fine. Different protein Alphabet. Fine. We have cells and evolution, all that stuff. We will then be able to say, okay, life is a more general phenomena. Selection is more general than what we think is the chemical constraints on life. And we can point to James Webb and other telescopes at other planets that we are in that zone we are most likely to combinatorially overlap with. Right. So, because, you know, we basically. So there is chemistry. You're looking for some overlap, and then. We can then basically shine light on them, literally, and look at light coming back and apply advanced assembly theory to general theory of language that we will get and say, huh, in that signal, it looks random, but there's a copy number. Oh, this random set of things that shouldn't be. That looks like a true random number generator has structure as a not common golorov ait type structure, but evolutionary structure given by assembly theory. And we start to. But I would say that because I'm a shameless assembly theorist. Yeah. It just feels like the. The cone. I might be misusing the word cone here, but the width of the cone is growing faster, is growing really fast to where eventually all the cones overlap, even in a very very, very large combinatorial space. It just. But then again, if you're saying the universe is also growing very quickly in. Terms of possibilities, that's real. I hope that as we build abstractions, the main. I mean, one idea is that as we go to intelligence, intelligence allows us to look at the regularities around us in the universe, and that gives us some common grounding to discuss with aliens. And you might be right, we will overlap there even though we have completely different chemistry, literally completely different chemistry, that we will be our past information from one another. But it's not a given. And I have to kind of try and divorce hope and emotion away from what I can logically justify. But it's just hard to intuit a world, a universe, where there's nearly infinite complexity, objects, and they somehow can't detect. Each other, but the universe is expanding. But the nice thing is that I would say. I would look. You see, I think Carl Sagan did the wrong thing. Well, not the wrong thing. He flicked the Voyager probe around and pale blue dot said, look how big the universe is. I would have done it the other way around, said, look at the Voyager probe that came from the planet Earth, that came from Luca. Look at how big Earth is. Then it produced that. It produced that. Yeah. And I think is, like, completely amazing. And then that should allow people on Earth to think about, well, probably we should try and get causal chains off Earth onto Mars, onto the moon, wherever. Whether it's human life or martian life that we create, it doesn't matter. But I think this commentorial space tells us something very important about the universe and that I realized in assembly theory that the universe is too big to contain itself. And I think this is coming back. And I want to. I want to kind of change your mind about time, because I'm guessing that your time is just coordinate. Yeah. So I'm going to. I'm going to change one of those. I'm going to change one of those. I'm going to change your mind in real time or at least attempt. Oh, in real time. There you go. I already got the tattoo, so this is going to be embarrassing if you change my mind. But you can just add. You can just add a time onto it, right? Or erase it a bit. So. And the argument that I think that is really most interesting is, like people say, the initial conditions specify the future of the universe. Okay, fine. Let's say that's the case for a moment. Now let's go back to newtonian mechanics. Now, the uncertainty principle in newtonian mechanics is this. If I give you the coordinates of your. Of an object moving in space, and the coordinates of another object, and they collide in space, and you know those initial conditions, you should know exactly what's going to happen. However, you cannot specify these coordinates to infinite precision. Now, everyone said, you know, oh, this is kind of like, you know, the chaos theory argument. No, no, it's deeper than that. Here's a problem with numbers. This is where Hilbert and Brouwer fell out of. To have the coordinates of this object, a given object, colliding, you have to have them to infinite precision. That's what Hilbert says. It says, no problem, infinite precision is fine. Let's just take that for granted. But when the object is finite and it can't store its own coordinates, what do you do? So, in principle, if a finite object cannot be specified to infinite precision, in principle, the initial conditions don't apply. Well, how do you know it can't store its. Well, how do you store an infinitely long number in a finite size? Well, we're using infinity very loosely here. No, no, we use infinite precision. I mean, not loosely, but very precise. So you think infinite precision is required? Well, let's take the object. Let's say the object is a golf ball. Golf ball is a few centimeters in diameter. We can work out how many atoms are on the golf ball. And let's say we can store numbers down to atomic dislocations. So we can work out how many atoms there are in the golf ball, and we can store the coordinates in that golf ball down to that number. But beyond that, we can't. Let's make the golf ball smaller. And this is where I think that we think that we get randomness in quantum mechanics. And some people say you can't get randomness, quantum mechanics, deterministic. But, aha. This is where we realize that classical mechanics and quantum mechanics suffer from the same uncertainty principle, and that is the inability to specify the initial conditions to a precise enough degree to give you determinism. The universe is intrinsically too big, and that's why time exists. It's non deterministic. Looking back into the past, you can look at the. You can use logical arguments because you can say, was it true or false? You really know. But this is the fact we are unable to predict the future with the precision is not evidence of lack of knowledge. It's evidence the universe is generating new things. Okay, so, to you, first of all, quantum mechanics, you can just say statistically, what's going to happen when two golf. Balls hit each other statistically. Sure, I can say statistically what's going to happen. But then when they do happen, and you keep nesting it together, you can't. I mean, it goes almost back to look at, look at, look at. Let's think about entropy in the universe. So how do we understand entropy change? Well, we could do the look at or process. We can use the agordic hypothesis. We can also have, we can also have the counterfactuals where we have all the different states, and we can even put that in the multiverse. Right. But both those are kind of, they're non physical. The multiverse kind of collapses back to the same problem about the precision. So all the what you, if you accept, you don't have to have true and false going forward into the future, the real numbers are real, they're just, they're observables. We're trying to see exactly where time being fundamental, sneaks in, and this difference between the golf ball can't contain its own position perfectly precisely how that leads to time needing to be fundamental. Let me do you believe or do you accept you have free will? Yeah, I think at this moment in time, I believe that I have free will. So then you are. Then you have to believe that time is fundamental. I understand that's the statement you've made. Well, no, that we can logically follows, because if you don't have free will, so, like, if you're in it, if you're in a universe that has no time, the universe is deterministic. If it's deterministic, then you have no free will. I think the space of how much we don't know is so vast that saying the universe is deterministic from that jumping there's no free will is just too difficult of a leap. No, I logically follows. No, no, I don't disagree. I'm not saying any. I mean, it's deep and it's important. All I'm saying, and it's the difference, it's actually different to what I've said before, is that if you don't require platonistic mathematics and accepts that non determinism is how the universe looks, and that gives us our creativity in the way the universe is getting novelty. It's kind of really deeply important in assembly theory, because assembly theory starts to actually give you a mechanism why you go from boring time, which is basically initial conditions specify everything, to a mismatch in creative time. And I hope we'll do experiments. I think it's really important to. I would love to do an experiment that proved that time is fundamental and the universe is generating novelty. I don't know all the features of that experiment yet, but by having these conversations openly and getting people to think about the problems in a new way, better people, more intelligent people with good mathematical backgrounds can say, oh, hey, I've got an idea. I would love to do an experiment that. That shows that the universe. I mean, universe is too big for itself going forward in time. And I really, you know, this is why I really hate the idea of the Boltzmann brain. The Boltzmann brain makes me super kind of like, you know, everyone's having a free lunch. It's like saying. It's like, let's break all the laws of physics. So a Boltzmann brain is this idea that in a long enough universe, the brain will just emerge in the universe as conscious, and that neglects the causal chain of evolution required to produce that brain. And this is where the computational argument really falls down, because the computation is going to say, I can calculate the probability of a Boltzmann brain, and I can, and they'll give you a probability, but I can calculate probability of a Boltzmann brain zero. Just because the space of possibilities is so large. Yeah. It's like when we start fooling ourselves with numbers that we can't actually measure and we can't ever conceive of, I think it doesn't give us a good explanation. And I've become. I want to explain why life is in the universe. I think life is actually novelty minor. I mean, life basically mines novelty almost from the future and makes it actualizes it in the present. Okay. Life is a novelty minor from the future that is actualized in the present. Yep, I think so. Novelty minor. First of all, novelty. What's the origin of novelty? When you go from boring time to creative time? Where is that? Is it as simple as randomness, like you're referring to? I'm really struggling with randomness because I had a really good argument with Yasha Bach about randomness, and he said, randomness doesn't give you free will. That's insane, because you'd just be random. But I think. And I think he's right at that level. Yeah, but I don't think we. I don't think he is right on another level. And it's not about randomness. It's about. It's about constrained. I'm gonna sound like constrained opportunity. I'm making this up as I go along, so making this up. Constrained opportunity. So what I mean is, like, so you have to have. So that the novelty. What is novelty? You know, this is what I think is a funny thing you ever want to discuss, AI? Why I think everyone's kind of gone AI mad is that they're misunderstanding novelty. But let's think about novelty. Ask what is novelty? So I think novelty is a genuinely new configuration that is not predicted by the past. Right. And that you discover in the present. Right. And that is truly different. Right. Now, everyone says that. Some people say that novelty doesn't exist. It's always with precedent. I want to do experiments that show that that is not the case. And it goes back to a question you asked me a few moments ago, which is, where is the factory? Because I think the same mechanism that gives us a factory gives us novelty. And I think that is why I'm so deeply hung up on time. Of course I'm wrong, but how wrong? And I think that life opens up that commentarial space in a way that our current laws of physics as contrived in a deterministic initial condition universe, even with the get out of the multiverse, David Deutsch style, which I love, by the way, but I don't think is correct, but it's. It's really beautiful. Multiverse. David Deutsch's conception of the multiverse is kind of like given. But I think that the problem with wave particle duality and quantum mechanics is not about the multiverse. It's about understanding how determined the past is. Well, I don't just think that. Actually, this is a discussion I was having with Sarah about that, where she was like, oh, I think we've been debating this for a long time now about how do we reconcile novelty, determinism, indeterminism. Just to clarify, both you and Sarah think the universe is not deterministic. I won't speak for Sarah, but roughly, I think that the universe. I think the universe is deterministic looking back in the past, but undetermined going forward in the future. So I'm kind of having my cake and eating it here. This is because I fundamentally don't understand randomness, right? As Yasha told me, or other people told me. But if I adopt a new view now, which the new view is the universe is just non deterministic, but I'd like to refine that and say the universe appears deterministic going back in the past, but it's undetermined going forward in the future. So how can we have a determinist, a universe that has deterministically looking rules? That's non determined going into the future. It's this breakdown in precision in the initial conditions. And we have to just stop using initial conditions and start looking at trajectories and how the commentarial space behaves in expanding universe in time and space and assembly theory helps us quantify the transition to biology. And biology appears to be novelty mining because it's making crazy stuff. You know that we are unique to earth, right? There are objects on earth that are unique to earth that will not be found anywhere else because you can do the combinatorial math. What was that statement you made about life? Is novelty mining from the future? Yeah. What's the little element of time that you introduced in. So what I'm kind of meaning is because the future is bigger than the present in a deterministic universe. How do you go from the, how do the states go from one to another? I mean, there's a mismatch. Right? Yeah. So that must mean that you have a little bit of indeterminism, whether that's randomness or something else I don't understand. I want to do experiments to formulate a theory to refine that as we go forward. That might help us explain that. And I think that's why I'm so determined to try and crack a the non life to life transition, looking at networks and molecules and that might help us think about it, the mechanism. But certainly the future is bigger than the past in my conception of the universe. And some conception of the universe, by. The way, that's not obvious, right? That's what the future being bigger than the past. Well, that's one statement. And the statement that the universe is not big enough to contain the future is another statement. Yeah, yeah, yeah, yeah. That one is a big one. That was a really big one. I think so. I think. But I think it's entirely because, look, we have the second law and right now, I mean, I'm. We don't need the second law. If the future is bigger than the past, it follows naturally. Right. So why are we retrofitting all these, these sticking plasters onto our reality to hold on to a timeless universe? Yeah, but that's because it, it's kind of difficult to imagine the universe that's. That can't contain the future. But isn't that really exciting? It's very exciting, but it's hard. I mean, we're humans on earth and we have a very kind of four dimensional conception of the world of 3d plus time. It's just hard to intuit a world where what does that even mean a universe that can't contain the future? Yeah, it's kind of. It's kind of crazy, but obvious. I mean, I suppose it sounds obvious. Yeah, if it's true. But the nice thing is you can. So what I mean, so the reason why assembly theory turned me onto that was that let's just start in the present and look at all the complex molecules and go backwards in time and understand how evolutionary processes gave rise to them. It's not at all obvious that Taxol, which is one of the most complex natural products produced by biology, was going to be invented by biology. It's an accident. Taxol is unique to earth. There's no taxol elsewhere in the universe. And Taxol was not decided by the initial conditions. It was decided by this kind of, this interplay between the. So the past simply is embedded in the present. It gives some features. But why the past doesn't map to the future one to one is because the universe is too big to contain itself. That gives space for creativity, novelty, and some things which are unpredictable. Okay, so given that you're disrespecting the power of the initial conditions, let me ask you about. So how do you explain that cellular automata are able to produce such incredible complexity given just basic rules and basic initial conditions? I think that this falls into the Brouwer Hilbert trap. So how do you get a cellular automata produced complexity? You have a computer, you generate a display, and you map the change of that in time. There are some cas repeat like functions like, it's fascinating to me that for PI, there is a formula where you can go to the millionth decimal place of PI and read out the number without having to go there. But there are some numbers where you can't do that. You have to just crank through. Whether it's wolframian computational irreducibility or some other thing, it doesn't matter. But these cas that complexity. Is that just complexity or a number that is basically, you're mining that number in time. Is that just a display screen for that number, that function? Well, can you say the same thing about the complexity on earth then? No, because the complexity on earth has a copy number and an assembly index associated with it. That CA is just a number running. You don't think it has a copy number? Wait, wait a minute. Well, it does in the human, where we're looking at humans producing different rules, but then it's nested on selection. So those cas are produced by selection. Yeah, I mean, the CA is such a fascinating pseudo complexity generator. What I would love to do is understand, quantify the degree of surprise in a CA and write it long enough. But what I guess that means is we have to instantiate, we have to have a number of experiments where we're generating different rules and running them time spent steps. But. Oh, got it. Cas are mining novelty in the future by iteration. Right. And you're like, oh, that's great, that's great. You didn't predict it. Some rules you can predict what's going to happen, other rules you can't. So for me, if anything, Cas, are evidence that the universe is too big to contain itself, because otherwise you'd know what the rules are going to do forever more. Right. I guess you were saying that the physicists saying that all you need is the initial conditions and the rules of physics is somehow missing the bigger picture. Yeah. And you know, if you look at cas, all you need is the initial condition and the rules and then run the thing. You need three things. You need the initial conditions, you need the rules, and you need time iteration to mine it out. Without the coordinate, you can't get it out. Sure. And that's that. That to use fundamental. And you can't predict it from the initial conditions. Yeah. If you could, then be fine. That time is a resource foundation of this is the history, the memory of each two things are created. It has to have that memory of all the things that led up to it. I think it's. Yeah, you have to have the resource. Yeah, because time is a fundamental resource. And yeah, I'm becoming, I think I had a major epiphany about randomness, but I keep doing that every two days and then it goes away again. It's random. You're a time fundamentalist. You should be as well. If you believe in free will. The only conclusion is there is time is fundamental. Otherwise you cannot have free will. It logically follows. Well, the foundation of my belief in free will is just observation driven. I think if you use logic, it's like logically it seems like the universe. Is deterministic looking backwards in time. And that's correct, the universe is. And then everything else is a kind of leap. It requires a leap. I mean, I think that it's kind of, this is what I think machine learning is going to provide a big chunk of that. Right. Because it helped us explain this. So the way I'd say if you take, that's interesting. Why? Well, let's, let's just. My favorite one is because I'm the AI doomers are driving me mad. And, in fact, that we don't have any intelligence yet. I call AI autonomous informatics. Just to make people grumpy. Yeah. And you're saying we're quite far away from AGI. I think that we have no conception of intelligence, and I think that we don't understand how the human brain does what it does. I think that we are. Neuroscience is making great advances, but I think that we have no idea about AGI. So I am a technological, I guess, optimist. I believe we should do everything. The whole regulation of AI is nonsensical. I mean, why would you regulate excel, other than the fact that clippy should come back? And I love Excel 97, because we can play, you know, we can do the flight. Flight simulator. I'm sorry, in Excel? Yeah. Have you not played the flight simulator in 1990? In Excel 97, yeah. What does that look like? It's like wireframe, very, very basic, but basically, I think it's x zero, y zero shift, and it opens up and you can play the fight simulator. Oh, wow. Wait, wait. Is he using Excel? Excel. Excel 97. Okay. I resurrected it the other day and saw Clippy again for the first time in a long time. Well, Clippy is definitely coming back. But you're saying we don't have a great understanding of what is intelligence? What is the intelligence? I am very frustrated underpinning the human mind. I'm very frustrated, by the way, that we're AI dooming right now. People were bestowing some kind of magic. Now, let's go back a bit. So you said about AGI. Are we far away from AGI? Yes. I do not think we're going to get to AGI anytime soon. I've seen no evidence of it. And the AI doom scenario is nonsensical in the extreme, and the reason why I think it's nonsensical, but it's not. And I don't think there isn't things we should do and be very worried about. There are things we need to worry about right now. What AI doing, whether it's fake data, fake users. Right. I want authentic people or authentic data. I don't want everything to be faked. And I think it's a really big problem. And I absolutely want to go on the record to say I really worry about that. What I'm not worried about is that some fictitious entity is going to turn us all to paper clips or detonate nuclear bombs. I don't know. Maybe. I don't know. Anything you can't think of. Why is this is. And I'll take a very simple series of logical arguments. And this is the AI dumas have not had the correct. And this had not had the correct. They do not have the correct epistemology. They do not understand what knowledge is. And until we understand what knowledge is, they're not going to get anywhere because they're applying things falsely. So let me give you a very simple argument. People talk about the probability p doom AI. We can work out the probability of an asteroid hitting the planet. Why? Because it's happened before. We know the mechanism. We know that there's a gravity well or that space time is bent and stuff falls in. We don't know the probability of AGI because we have no mechanism. So let me give you another one, which is like, I'm really worried about Agda. What's ag is anti gravity. One day we could wake up in anti gravity. You know, it's discovered we're all going to die. The atmosphere is going to float away. We're going to float away. We're all doomed. What is the probability of ag? We don't know because there's no mechanism for ag. Do we worry about it? No. And I don't understand the current reason for these, for the, for certain people in certain areas to be generating this nonsense. I think they're not doing it maliciously. I think we're observing the emergence of new religions, how religions come, because religions are about kind of some control. So you got the optimists saying AI is going to cure us all and AI is going to kill us all. What's the reality? Well, we don't have AI. We have really powerful machine learning tools and they will allow us to do interesting things and we need to be careful about, about how we use those tools in terms of manipulating human beings and faking stuff. Right, right. Well, let me, let me try just sort of steel, man, the AI doomers argument. Actually, I don't know. Are AI doomers in the Yadkowski camp saying it's definitely gonna kill us because there's a spectrum. 95%, I think is the limit. Yeah, 95% plus. No, not plus. I think. I don't know. I was seeing on Twitter today various things, but I think yudakowski is at 95%. But to belong to the AI Doomer club, is there a threshold? I don't know what the membership is maybe. And what are the fees? I think, well, I saw, I think Scott Aronson, like I was quite surprised, had put two. I saw this online, so it could be wrong. So sorry if it's wrong says 2%. But the thing is, if you were to go, if you, if someone said there's a 2% chance you're gonna die going into the lift, would you go into the lift? In the elevator. For the elevator? American English speaking audience well, no, not for the elevator. So I would say anyone higher than 2%. I mean, like, I. I mean, I think there's a 0% chance of AGI doom. Zero. Just to push back on the argument where the end of zero on the AGI, we can see on Earth that there's increasing levels of intelligence of organisms. We can see what humans with extra intelligence were able to do to the other species. So that is, uh, a lot of samples of data. What a delta in intelligence gives you when you have an increase in intelligence, how you're able to dominate a species on Earth. And so the idea there is that if you have a being that's ten x smarter than humans, we're not going to be able to predict what that's going to, with that being is going to be able to do, especially if it has the power to hurt humans, which you can imagine a lot of trajectories in which the more benefit AI systems give, the more control we give to those AI systems over our power grid, over our nuclear weapons or weapons of any sort. And then it's hard to know what ultra intelligence system would be able to do in that case. You don't find that convincing. I think this is. I would fail that argument 100%. Here's a number of reasons to fail it on. First of all, we don't know where the intention comes from. The problem is that people think they keep watching all the hucksters online with a prompt engineering and all this stuff. When I talk to a typical AI computer scientist, they keep talking about the AI as having some kind of decision making ability. That is a category error. The decision making ability comes from human beings. We have no understanding of how humans make decision. We've just been discussing free will for the last half an hour. Right? We don't even know what that is. So the intention, I totally agree with you. People who intend to do bad things can do bad things, and we should not let that risk go. That's totally here and now. I do not want that to happen. And I'm happy to be regulated to make sure that systems I generate, whether they're like computer systems or, you know, I'm working on a new project called X called Ken Machina. Nice. Well done. Yeah, yeah. Which is basically a. For people who don't understand the point that ex machina is a great film about, I guess, AGI embodied and chemistry, chemistry version of that. And I only know one way to embody intelligence. That's in chemistry and human brainstor. So category error number one is agency. They have agency. Category error number two is saying that assuming that anything we make is going to be more intelligent. Now, you didn't say super intelligent. I'll put the words into our mouths here. Superintelligent. That I think that there is no reason to expect that we are going to make systems that are more intelligent, more capable. You know, when people play chess, computers, they don't expect to win now, right? They just. The chess computer is very good at chess. That doesn't mean it's super intelligent. So I think that super intelligence, I mean, I think even Nick Bostrom is pulling back on this now because he invented this. So I see this a lot. When does this first happen? Eric Drexler, nanotechnology, atomically precise machines. He came up with a world where we had these atom cogs everywhere. They were going to. We're going to make self replicating nanobots. Not possible. Why? Because there's no resources to build these self replicating nanobots. You can't get the precision. It doesn't work. It was a major category error in taking engineering principles down to the molecular level. The only functioning molecular technology we know. Not. Sorry, the only functioning nanomolecular technology we know produced by evolution. There. So now let's go forward to AGI. What is AGI? We don't know. It's super. It can do this or humans can't. Think that. I would argue the only AGIs that exist in the universe are produced by evolution. And sure, we may be able to make our working memory better. We might be able to do more things. The human brain is the most compact computing unit in the universe, uses 20 watts. It uses a ready limited volume. It's not like a chat GPT cluster, which has to have thousands of watts model that's generated and has to be corrected by human beings. You are autonomous and embodied intelligence. So I think that there are so many levels that we're missing out. We've just kind of went, oh, we've discovered fire. Oh, gosh, the planet's just going to burn one day randomly. I mean, I just don't understand that leap. There are bigger problems we need to worry about. So what is the motivation? Why are these people, let's assume they have their earnest, have this conviction? Well, I think it's just it's kind of, they're making leaps that they're trapped in a virtual reality that isn't reality. Well, I mean, I can continue a set of arguments here, but also it is true that ideologies that fear monger are dangerous because you can then use it to control, to regulate in a way that halts progress, to control people and to, to cancel people, all that kind of stuff. So you have to be careful because the reason ultimately wins. Right. But there is a lot of concerns with super intelligent systems, very capable systems. When you, I think when I, when you hear the word super intelligent, you're hearing like, it's smarter than humans in every way that humans are smart. But the paperclip manufacturing system doesn't need to be smart in every way, just needs to be smart in a set of specific ways. And the more capable the AI systems become, the more you could see us giving them control over, like I said, our power grid, a lot of aspects of human life. And then that means they will be able to do more and more damage when there's unintended consequences that come to life. I think that that's right. The unintended consequences we have to think about, and that I fully agree with. But let's go back a bit sentient. I mean, again, I'm far away from my comfort zone and all this stuff, but hey, let's talk about it, because I give myself a qualification. Yeah, we're both qualified and sentience, I think. Yeah. So as much as anyone else, I. Think the paperclip scenario is just such a poor one because, because let's think about how that would happen. And also let's think about we are being so unrealistic about how much of the earth's surface we have commandeered for paper clip manufacturing to really happen. I mean, do the math. It's like, it's not going to happen. There's not enough energy, there's not enough resource. Where is it all going to come from? I think that what happens in evolution is really why is, why has a killer virus not killed out all of, not killed all life on Earth? Well, what happens is, sure, super killer viruses that kill the ribosome have emerged, but you know what happens? They nuke a small space because they can't propagate. They all die. So there's this interplay between evolution and propagation, right, and death. And so in evolution, you don't think. It'S possible to engineer, for example, sorry to interrupt, but like a perfect virus. There'S deadly nothing, no nonsensical okay. I think that just wouldn't, again, it wouldn't work. So it was too deadly. It would just kill the radius and not replicate. Yeah, I mean, you don't think it's possible to get a. I mean, if you were sup. I mean, I if you were it. Kill all of life on earth, but kill all humans. There's not many of us. There's only like 8 billion. There's so much more ants. I mean, I don't, I. So many more ants and they're pretty smart. I think we. The nice thing about where we are, I would love for the AI crowd to take a leaf out of the book of the bio warfare, chemical warfare crowd. I mean, not love, because actually people have been killed with chemical weapons in the first and second world war and people and bioweapons have been made and we can argue about Covid-19 and all this stuff. Let's not go there just now. But I think there is a consensus that some certain things are bad and we shouldn't do them. Right. And sure, it would be possible for a bad actor to engineer something bad, but the damage would be, we would see it coming and we would be able to do something about it. Now, I guess what I'm trying to say is when people talk about doom and they just, when you ask them for the mechanism, they just say, you know, they just make something up. I mean, in this case, I'm with Jan Lecun. I think he put out a very good point about trying to regulate jet engines before we've even invented them. And I think that's what I'm saying. I'm not saying we should. I just don't understand why these guys are going around making, literally making stuff up about us all dying. Yeah. When basically we need to actually really focus on. Now, let's say there's some actors are earnest. Let's say Yudakowski is being earnest. Right. And he really cares, but he loves it. Goes, and then you're all going to die. It's like, you know, why don't we try and do the same thing and say you could do this and then you're going to be happy forever after. Yeah. You know. Well, I think there's several things to say there. One, I think there is a role in society for people that say we're all going to die because I think it filters through as a message, as a viral message that gives us the proper amount of concern. Okay. All right. Meaning not the, it's not 95%, but when you say 95%, and it filters through society, you'll give an average of, like a 0.03% an average. So it's nice to have people that are like, we're all going to die, then we'll have a proper concern. Like, for example, I do believe we're not properly concerned about the threat of nuclear weapons currently, like that. It just seems like people have forgotten that that's a thing. And, you know, there's a war in Ukraine with the nuclear power involved. There's nuclear powers throughout the world. And it just feels like we're on the brink of a potential world war to a percentage that I don't think people are properly calibrating. Like, in their head, we're all thinking it's a twitter battle as opposed to, like, actual threat. So, like, it's nice to have that kind of level of concern. But to me, like, what I, when I hear AI doomers, what I'm imagining is with unintended consequences, a potential situation where, let's say, 5% of the world suffers deeply because of a mistake made of unintended consequences. I don't imagine the entirety of human civilization dying, but there could be a lot of suffering if this is done. I understand that. And I'm, I kind of, I guess, I mean, I'm involved in the whole hype cycle. Like, why I would like us to. I don't want us to. So what's happening right now is there seems to be, so let me, let's say having some people saying AI doom is a worry, fine, let's give them that. But what seems to be happening is there seems to be people who don't think AI is doom, and they're trying to use that to control regulation and to push people to regulate, which stops humans generating knowledge. And I am an advocate for generating as much knowledge as possible when it comes to nuclear weapons. I grew up in the seventies and eighties where the nuclear doom, a lot of adults really had existential threat almost as bad as now with AI doom. They were really worried, right? There was some great, were not great. There were some horrific documentaries. I think there's one called freds that was generated in the UK, which was like, it was terrible. It was like, so scary. And I think that the correct thing to do is obviously get rid of nuclear weapons. But let's think about unintended consequences. We've got rid of. This is such a nonsecretary. We got rid of all the sulfur particles in the atmosphere, right? Or the soot. And what's happened in the last couple of years is global warming has accelerated because we've cleaned up the atmosphere too much. Sure. I mean, the same thing. If you get rid of nuclear weapons, you get. Exactly. That's my point. So what we could do is if we actually started to put the AI in charge, which is. I really like an AI to be in charge of all world politics. And this sounds ridiculous for a second. Hang on. But if we could all agree on the AI. Drummers just woke up. Yeah, yeah, yeah. In that statement. But I really don't like politicians who are basically just looking at local sampling. But if you could say globally. But here's some game theory here. What is the minimum number of nuclear weapons we need to distribute around the world to everybody to basically reduce war to zero? I mean, just this thought experiment of the United States and China and Russia and major nuclear powers get together and say, all right, we're going to distribute nuclear weapons to every single nation on earth. Yep. Oh, boy. I mean, that has a probably greater than 50% chance of eliminating major military conflict. Yeah, yeah. But it's not 100%. But. But I don't think anyone will use them because I think. I think. And look, what you've got to try and do is like, for. To qualify for these nuclear weapons. This is a great idea. The game theorists could do this. Right. I think the question is this. I really buy your question. We have too many nukes of. From just from a feeling point of view that we've got too many of them. So let's reduce the number, but not get rid of them, because we'll have too much conventional warfare. So then what is the minimum number of nuclear weapons we can distribute around to remove humans hurting each other is something we should stop doing. It's not out with our conceptual capability. But right now, what about the nations, certain nations that are being exploited for their natural resources in the future because for a short term gain, because we don't want to generate knowledge. And so if everybody had an equal doomsday switch, I predict the quality of life, average human will go up faster. I am an optimist and I believe that humanity is going to get better and better and better, that we're going to eliminate more problems. But I think. Yeah, let's. But the probability of a bad actor, of one of the nations setting off a nuclear weapon, I mean, you have to. You have to integrate that into the. But we get. We just give you the nukes like population. Right. We give. What we do is we can't. But anyway, let's just go there. So if a small nation with a couple of nukes uses one because they're a bit bored or annoyed, they're gonna. They. The likelihood that they are gonna be pummeled out of existence immediately is 100%. And yet they've only. They've only nuked one other city. I know this is crazy, and I apologize for. Well, no, no, I think it's just to be clear, we're just having a thought experiment. That's interesting. But, you know, there's terrorist organizations that would take. That would take. Would take that trade. Yeah. I mean, we have to ask ourselves a question of how many, which percentage of humans would be suicide bombers, essentially, where they would sacrifice their own life because they hate another group of people. I believe it's a very small fraction. But is it large enough if you give out nuclear weapons? I can predict a future where we take all nuclear material and we burn it for energy because we're getting there. And the other thing you could do is say, look, there's a gap. So if we get all the countries to sign up to the virtual nuclear agreement where we all exist, we have a simulation where we can nuke each other in the simulation, and the. And the economic consequences are catastrophic. Sure. In the simulation. I love it. It's not going to kill all humans. It's just going to have economic consequences. Yeah. I don't know. I just made it up. It seems, like interesting. I mean, but it's interesting whether that would have as much power on human psychology as actual physical nuclear. I think so. It's possible. But people don't take economic consequences as seriously, I think, as actual nuclear weapons. I think they do in Argentina and they do in Somalia, and they do in a lot of these places where. No, I think this is a great idea. I'm a strong advocate now for. So what have we come up with? Burning all the nuclear material to have energy. And before we do that, because mad is good, mutually assured destruction is very powerful. Let's take it into the metaverse and then get people to kind of subscribe to that. And if they actually nuke each other, even for fun, in the metaverse, there are dire consequences. Yeah. Yeah. So it's like a video game. We all had to join this metaverse. Video game. Yeah. I can't believe it's dire economic consequences. I don't know how. And it's all run by AI, as you mentioned. So the AI doomers are really terrifying at this point. No, they're happy to have a job for another 20 years, right? Oh, fear monger. Yeah, yeah, yeah. We got. I'm a believer in equal employment. You've mentioned that. Would you call chem machina? Yeah, yeah. So you've mentioned that a chemical brain is something you're interested in creating, and that's a way to get conscious. AI soon. Can you explain what a chemical brain is? I want to understand the mechanism of intelligence that's gone through evolution, right. Because the way that. The way that intelligence was produced by evolution appears to be the origin of life. Multicellularity, locomotion senses. Once you can start to see things coming towards you and you can remember the past and interrogate the present and imagine the future, you can do something amazing. Right? So. And I think only in recent years did humans become Turing complete, right? Yeah. And so that Turing completeness kind of gave us another kick up. But our ability to process that information is produced in a wet brain. And I think that we are not getting going. We do not have the correct hardware architectures to have the domain flexibility and the. The ability to integrate information. I think intelligence also comes at a massive compromise of data. Right now we're obsessing about getting more and more data, more and more processing, more and more tricks to get dopamine hits. So when we look back on this going, oh, yeah, that was really cool, because when I asked chat GPT, it made me really feel really happy. I got a hit from it, but actually it just exposed how little intelligence I use in every moment because I'm easily fooled. So what I would like to do is to say, well, hey, hang on, what is it about the brain? So the brain has this incredible connectivity and it has the ability to. As I said earlier about my nephew, I went from Bill to Billy and he went, all right, Leroy. How did he make that leap that he was able to? Basically, without any training, I extended his name. He went, gay. That he doesn't like. He wants to be called Bill. He went back and said, you like to be called Lee. I'm going to call you Leroy. So human beings have a brilliant ability, or intelligent beings appear to have a brilliant ability to integrate across all domains all at once and to synthesize something which allows us to generate knowledge and becoming Turing complete on our own, I don't. Although AI's are built in Turing complete things, their thinking is not Turing complete in that they are not able to build universal explanations. And that lack of universal explanation means that they're just inductivists. Inductivism doesn't get you anywhere. It's just basically a party trick. It's like, you know, the, I like the, I think it's in the fabric of reality from David Deutsch, where basically, you know, the farmer is feeding the chicken every day, and the chicken's getting fat and happy, and the chicken's like, I'm really happy every time the farmer comes in and feeds me. And then one day the farmer comes in and doesn't, instead of feeding the chicken, just rings its neck, you know? And that's kind of. And had the chicken had an alternative understanding of why the farmer was feeding it. Mm hmm. It's interesting, though, because we don't know what's special about the human mind that's able to come up with these kind of generalities, uh, this universal theories of things. So that's. And will come up with novelty, I can imagine, because you gave an example, you know, you know, about William and Leroy. I I feel like example like that will be able to see in future versions of large language models, will be really, really, really impressed by the humor, the insights, all of it, because it's fundamentally trained on all the incredible humor and insights that's available out there on the Internet. Right. So we'll be impressed. I think we'll be impressed. Oh, I'm impressed. Right? I'm impressed. Increasingly so. But we're mining the past. Yes. And what the human brain appears to be able to do is mine the future. Yes. So, novelty. It is interesting whether these large language models will ever be able to come up with something truly novel. I can show on the back of a piece of paper why that's impossible. And it's like, the problem is that, and again, these are domain experts kind of bullshitting each other. The term generative. Yes. Right. Average person. Oh, it's generous. No, no, no. Look, if I take the numbers between zero and 1000, and I train a model to pick out the prime numbers by giving them all the prime numbers between zero and 1000, it doesn't know what prime number is. Occasionally, if I can cheat a bit, it will start to guess. It never will produce anything out with the data set because you mine the past. The thing that I'm getting to is I think that actually current machine learning technologies might actually help reveal why time is fundamental. It's like, kind of insane because they tell you about what's happened in the past, but they can never help you understand what's happening in the future without training examples. Sure. If that thing happens again, it's like, so I think. So let's think about what large language models are doing. We have all the Internet as we know it, language, but also they're doing something else. We're having human beings correcting it all the time. Those models are being corrected. Steered. Corrected. Modified. Tweaked. Yeah, but I mean, cheating. Well, you could say that training on human data in the first place is cheating. Well, let me. Human is in the loop. Sorry to interrupt. Yes, a human is definitely in the loop, but it's not just human is in the loop. A very large collection of humans is in the car. And that could be, I mean, to me, it's not intuitive that you said prime numbers, that the system can generate an algorithm, right? That. The algorithm that can generate prime numbers or the algorithm that can tell you if a number is prime and so on, and generate algorithms that generate algorithms that generate algorithms that, that start to look a lot like human reasoning. You know, I don't think, I think, again, we can show that on the piece of paper that. Sure. I think there has to. You have to have. So this is the failure in epistemology. Like, I'm glad I even can say that word. Let me know what it means. I said it multiple times. I know, it's like three times now. Quit while you're ahead. Just don't say it again. You did really well. Thanks. So, but I think the. So what is reasoning? So, coming back to the chemical brain, if I could basically, if I could show that in a. Because, I mean, I'm never going to make an intelligence in Cam machina because we don't have brain cells, they don't have glial cells, they don't have neurons. But if I can make, if I can take a gel and engineer the gel to have it be a hybrid hardware for reprogramming, which I think I know how to do, I will be, I process a lot more information and train models billions of times cheaper and use cross domain knowledge. And there are certain techniques I think we can do, but it's still missing, though. The abilities of human beings have had to become true and complete. And so I guess the question to give back is, like, how do you tell the difference between trial and error and the generation of new knowledge? I think the way you can do it is this, is that you come up with a theory, an explanation. Inspiration comes from out. Yeah. And then you then test that, and then you see that's going towards the truth. And human beings are very good at doing that in the transition between philosophy, mathematics, physics and natural sciences. And I think that we can see that where I get confused is why people misappropriate the term artificial intelligence to say, hey, there's something else going on here. Because I think you and I both agree machine learning is really good. It's only going to get better. We can get happier with the outcome. But why would you ever think the model was thinking or reasoning? Reasoning requires intention and the intention. If the model isn't reasoning, the intentions come from the prompter, and the intention has come from the person who programmed it to do it. So I. But don't you think you can prompt it to have intention? Basically, start with the initial conditions and get it going where the, you know, currently large language models. Chad, GPT only talks to you when you talk to it. There's no reason why you can't just start it talking. But those initial conditions came from someone starting it. Yes. And that causal chain in there. So that intention comes from the outside. I think that there is something in that causal chain of intention that's super important. I don't disagree. We're going to get to AGI. It's a matter of when and what hardware. I think we're not going to do it in this hardware, and I think we're unnecessarily fetishizing really cool outputs and dopamine hits, because obviously that's what people want to sell us. Well, but there could be, I mean, AGI is a loaded term, but there could be incredibly super impressive intelligence systems on the way to AGI. So these large language models, I mean, I, if it appears conscious, if it appears super intelligent, who are we to say it's not? I agree, but I. The super intelligence, I want, I want to, I want to be able to have a discussion with it about coming up with fundamental new ideas that generate knowledge. And if this, if the super intelligent generator combined novelty from the future that I didn't see in its training set in the past, I would agree that something really interesting is coming on. I'll say that again. If the intelligence system, be it a human being, a chatbot, something else, is able to produce something truly novel that I could not predict, even having full audit trail from the past, then I'd be sold. Well. So we should be clear that it can currently produce things that are, in a shallow sense, novel, that are not in the training set. But you're saying truly novel. I think they are in the training set. I think everything it produces comes from a training set. They might be inter. There's a difference between interpret novelty and interpolation. We do not understand where these leaps come from. Yet that is what intelligence is. I would argue those leaps. And some people say, no, it's actually just what will happen if you just do cross domain training and all that stuff. And that may be true, and I may be completely wrong, but right now, the human mind is able to mine novelty in a way that artificial intelligence systems cannot. And this is why we still have a job and we're still doing stuff. And, you know, I used chat GPT for a few weeks. Oh, this is cool. And then it took me two. I had to. Well, what happened is it took me too much time to correct it, then it got really good, and now they've, they've done something to it. It's not actually that good. Yeah, right. I don't know what's going on. Censorship. Yeah, I mean, that's interesting, but it will push us humans to characterize novelty better. Like characterize the novel. Like, what is novel? What is truly novel? What's the difference between novelty and interpolation? I think that this, this is the thing that makes me most excited about these technologies, is they're going to help me demonstrate to you that time is fundamental and unit future is bigger than the, than the, than the present, which is why we, we are, human beings are quite good at generating novelty, because we have to expand our data set and to cope with unexpected things in our environment. Our environment froze them all at us again. We have to survive in that environment. And, I mean, I never say never. I would be very interested in how we can get cross domain training cheaply in chemical systems, because I'm a chemist, and Bray, the only sentient thing I know of is a human brain. But maybe that's just me being boring, predictable and not novel. Yeah, you mentioned GPT for electron density. So a GPT like system for generating molecules that can bind to hosts automatically. I mean, that's, that's interesting. That's really interesting. Applying this same kind of transform mechanism. Yeah, I mean, this is one, it goes, my team, I try and do things that are non obvious, but non obvious in certain areas. And one of the things I was always asking about in chemistry, people like to represent molecules as graphs, and it's quite difficult. It's really hard. If you're doing AI in chemistry, you really want to basically have good representations. You can generate new molecules. They're interesting. And I was thinking, well, molecules aren't really graphs, and they're not continuously differentiable. Could I do something that was continuously differentiable? I was like, well, molecules are actually made up of electron density. So I got thinking, say, well, okay, could there be a way where we could just basically take a, take a database of readily solved electron densities for millions of molecules? So we took the electron density for millions of molecules and just trained the model to put, to learn what electron density is. And so what we built was a system that you literally could give it a, let's say you could take a protein that has a particular active site, or, you know, a cup with a certain hole in it. You pour noise into it, and with the GPT, you turn the noise into electron density. And then in this case, it hallucinates like all of them do. But the hallucinations are good because it means I don't have to train on such a large number, such a huge data set, because these datasets are very expensive, because how do you produce it? So go back a step. So you've got all these molecules in this data set, but what you've literally done is a quantum mechanical calculation. We produce electron densities for each molecule. So you say, oh, this representation of this molecule has these electron densities shared with it. So you know what the representation is, and you train the neural network to know what electron density is. So then you give it an unknown pocket, you pour in noise, and you say, right, produce me electron density. It produces electron density that doesn't look ridiculous. And what we did in this case is we produce electron density that maximizes the electrostatic potential. So the stickiness, but minimizes what we call the steric hindrance. So the overlap. So it's repulsive. So make the perfect fit. And then we then use the kind of like a chat GPT type thing to turn that electron density into what's called a smile. A smile string is a way of representing a molecule in letters. And then we can then. So it just generates them. Just generates them. And then the other thing is then we bung that into the computer, and then it just makes it. Yeah, the computer being the thing that's. A robot that we've got that can basically just do chemistry. So kind of, we kind of got this end to end drug discovery machine where you can say, oh, you want to bind to this active site. Here you go. I mean, it's a bit leaky and things kind of break, but it's a proof of principle. But were the hallucinations, are those still accurate? Well, the hallucinations are really great in this case, because in the case of a large language model, the hallucinations just like, just make everything up. To when it doesn't just make everything up, but it gives you an output that you're plausibly comfortable with and thinks you're doing probabilistically. The problem on these electron density models is it's very expensive to solve a Schrodinger equation going up to many heavy atoms and large molecules. And so we wondered, if we trained the system on up to nine heavy atoms, whether it would go beyond nine. And it did. It started to generate molecules with twelve. No problem. They look pretty good. And I was like, well, this hallucination I will take for free, thank you very much, because it just basically, this is a case where interpolation extrapolation worked relatively well, and we were able to generate the really good molecules. And then what we were able to do here is, and this is a really good point, what I was trying to say earlier, that we were able to generate new molecules from the known data set that would bind to the host, so a new guest would bind. Were these truly novel? Not really, because they were constrained by the host. Were they new to us? Yes. So I do understand. I can concede that machine learning systems, artificial intelligence systems, can generate new entities, but how novel are they? It remains to be seen. Yeah. And how novel the things that humans generate is also difficult to quantify. They seem novel. That's what a lot of people say, like, you know, so the way to really get to genuine novelty and assembly theory shows you the way, is to have different causal chains overlap. And this really resonates with the time is fundamental argument. And if you're bringing together a couple of objects with different initial conditions coming together when they interact, the more different their histories, the more novelty they generate in time going forward. And so it could be that genuine novelty is basically about mix it up a little, and the human brain is able to mix it up a little. And all that stimulus comes from the environment. But all I think I'm saying is the universe is deterministic going back in time, non deterministic going forward in time, because the future is. The universe is too big in the future to contain in the present. Therefore, these collisions of known things generate unknown things that then become part of your data set and don't appear weird. That's how we give ourselves comfort. The past looks consistent with this initial condition hypothesis, but actually we're generating more and more novelty, and that's how it works. Simple. So it's hard to quantify a novelty looking backwards. I mean, the present and the future are the novelty generators. But I like this whole idea of mining novelty, I think it is going to reveal why the limitations of current AI is a bit like a printing press. Right? Everyone thought that when the printing press came, that writing books is going to be terrible, that you had evil spirits and all this, they were just books. The same would be with AI. But I think just the scale you can achieve in terms of impact with AI systems is pretty nerve wracking. That's what the big companies want you. To think, but not like in terms of destroy all humans. But you can have major consequences in the way social media has had major consequences, both positive and negative. And so you have to kind of think about and worry about it. But, yeah, people that fear monger, you. Know, my pet theory for this, you want to know. Yeah. Is I think that a lot of, and maybe I'm being, and I think I really do respect, you know, a lot of the people out there who are trying to have discourse about the positive future. So OpenAI guys, meta guys, and all this. And what I wonder if they're trying to cover up for the fact that social media has had a pretty disastrous effect on some level, and they just try to say, oh, yeah, we should do this, and covering up for the fact that we have got some problems with teenagers and Instagram and Snapchat and all this stuff, and maybe they're just overreacting now. It's like, oh, yeah, sorry, we made the bubonic plate and gave it to you all and you're all dying. And, oh, yeah, but look at this over here, it's even worse. Yeah, there's a little bit of that, but there's also not enough celebration of the positive impact that all these technologies have had. We tend to focus on the negative and tend to forget that, in part because it's hard to measure. Like, it's very hard to measure the positive impact social media had on the world. Yeah, I agree. But if what I worry about right now is, like, I'm really, I do care about the ethics of what we're doing, and one of the reasons why I'm so open about the things we're trying to do in lab make lies, look at intelligence, all this. So people say, what are the consequences of this? And you say, what are the consequences of not doing it? And I think that what worries me right now in the present is lack of authenticated users and authenticated data. Human users. Yeah, human. I still think that there will be AI agents that appear to be conscious, but they would have to be also authenticated and labeled as such. There's too much, there's too much value in that, you know, like friendships with AI systems, there's too much meaningful human experiences to have with the AI systems that I just. But that's like a tool, right? It's a bit like a meditation tool, right? Some people have a meditation tool. It makes them feel better. But I'm not sure you can ascribe sentience and legal rights to a chatbot that makes you feel less lonely. Sentience? Yes, I think legal rights, no, I think it's the same. You can have a really deep, meaningful relationship with a dog. With a dog. Sentient? Yes. The chat bots, right now, using the technology we use, it's not going to be sentient. This is going to be a fun continued conversation on Twitter that I look forward to. Since you've had also from another place, some debates that were inspired by the assembly theory paper. Let me ask you about God. Is there any room for notions of God in assembly theory? God? Yeah. I don't know what God is. I mean, so God exists in our mind, created by selection. So human beings have created the concept of God in the same way that human beings have created the concept of super intelligence. Sure. But does it, does it mean, does it not. It still could mean that that's a projection from the real world where we're just assigning words and concepts to a thing that is fundamental to the real world, that there is something out there that is a creative force underlying the universe. I think the universe, there is a creative force in the universe, but I don't think it's sentient. I mean, I think so. I do not understand the universe. So who am I to say that God doesn't exist? I am an atheist, but I'm not an angry atheist, right? I have lots of, I have lots of, there's some people I know that are angry atheists and say, you know, say that religious people are stupid. I don't think that's the case. I have faith in some things because I don't. I mean, when I was a kid, I kept like, you know, it's like, I need to know what the charge of electron is. And I was like, I can't measure the charge on electron. That was, you know, I just gave up and had faith. Okay. You know, resistors works. So when it comes to, I want to know why the universe is growing in the future and what humanity is going to become. And I've seen that the, the acquisition of knowledge via the generation of novelty to produce technology has uniformly made humans lives better. I would love to continue that tradition. And you said that there's that creative force. Do you think. Just to think on that point, do you think there's a creative force? Is there like a thing, like a driver that's creating stuff? Yeah, I think that. So I think that. And where, what is. Can you describe it, like, mathematically? Well, I think selection. I think selection. Selection is divorce. Selection is the force in the universe that creates novelty. Is selection somehow fundamental? Like what? What? Yeah, I think persistence of objects that could decay into nothing through operations that maintain that structure. I mean, think about it. If it's amazing that things existed at all, that we're just not a big commentorial mess. Yes. So the fact exists in a thing that exists, persists in time. Yeah, let's think. Maybe the universe is actually in the present. The things, everything that can exist in the present does exist. Well, that would mean it's deterministic, right? No, I think the universities might. So the universe started super small. The past was deterministic, there wasn't much going on, and it was able to. Mine, mine, mine, mine, mine. And so the process, I mean, is somehow generating universe is basically. I can't put. I'm trying to put this in. Did you just say there's no free will, though? No, I didn't say that. As if. Sorry, I said there is free will. I think. I think I'm saying that free will occurs at the boundary between the present, future, the past and the future. Yeah, I got you. But everything that can exist does exist. Everything that is so. Everything that's possible to exist at this. So, no, I'm really. There's a lot of loaded words there in the. So what, I mean, there's a time element loaded into this. I think that the universe is able to do what it can in the present, right? Yeah. And then I think in the future there are other things that could be possible. We can imagine lots of things, but they don't all happen. Sure. So what, that's where. That's what I sneak in. Free will right there. Yeah. So I guess what I'm saying is what, what exists is a. Is a convolution of the past with the present and the free will going into the future. But we can still imagine stuff, right? We can imagine stuff that never happened. And it's amazing force, because your imagina, this is the most important thing that we don't understand is our imaginations can actually change the future in a tangible way, which is what the initial conditions and physics cannot predict, like your imagination has a causal consequence in the future. Isn't that weird to you? Yeah, it breaks the laws of physics as we know them right now. Yeah. So you think the imagination has a causal effect on the future? Yeah, but it does exist in there, in the head, and there must be a lot of power. And whatever's going on, there could be a lot of power. Whatever's going on in there. If we then go back to the initial conditions, and that is simply not possible, that can happen. But if we go into, if we go into a universe where we accept that there is a finite ability to represent numbers and you have rounding. We're not rounding errors. You have some that some what happens, your ability to make decisions, imagine and do stuff is that that interface between the certain and the uncertain. It's not, as Yasha was saying to me, randomness goes and you just, you know, randomly do random stuff. It is that you are set free a little on your trajectory. Free will is about being able to explore on this narrow trajectory that allows you to build. You have a choice about what you build, or that choice is you interacting with a future in the present. What to you is most beautiful about this whole thing, the universe. The fact it seems to be very undecided, very open, and the fact that every time I think I'm getting towards an answer to a question, there are so many more questions that make the chase. Do you hate that it's going to be over at some point? No. For me, I think if you think about it, is it over for Newton? Now, Newton has had causal consequences in the future. We discuss him all the time, his. Ideas, but not the person. The person just had a lot of causal power when he was alive. But, oh, my God, one of the things I want to do is leave as many Easter eggs in the future when I'm gone to go, oh, that's cool. Would you be very upset if somebody made a good large language model that's fine tuned to Lee Connor? It would be quite boring because, I mean, novelty generation. If it's a faithful representation of what I've done in my life, that's great. That's an interesting artifact. But I think the most interesting thing about knowing each other is we don't know what we're going to do next. Sure. Sure. I mean, within some constraints I've got, you know, you might. I can predict some things about you, you can predict some things about me, but we can't predict everything. Everything. And it's because we can't predict everything is why we're excited to come back and discuss and see. It's so, yeah, I'm kind of. I'm happy that it'll be interesting that some things that I've done can be captured, but I'm pretty sure that my angle on mining novelty from the future will not be captured. Yeah. Yeah. That's what life is. It's just some novelty generation and you're done. Each one of us just generally a little bit, or have the capacity to at least. I think life is a selection produces life, and life affects the universe in them. Universes with life in them are materially, physically, fundamentally different than universes without life. And that's super interesting. And I have no beginnings of understanding. I think maybe this is like, in a thousand years there'll be a new discipline and the humans will be. Yeah, of course, this is is how it all works, right? And in retrospect, it will all be obvious. I think. I think assembly theory is obvious. That's why a lot of people got angry, right? They were like, oh my God, this is such nonsense. You know, like, oh, you know, actually it's not quite, but the writing's really bad. Well, I can't wait to see where it evolves, Lee. And I'm glad I get to exist in this universe with you. You're a fascinating human. This is always a pleasure. I hope to talk to you many more times, and I'm a huge fan of just watching you create stuff in this world. And thank you for talking today. It's a pleasure as always, Lex. Thanks for having me on. Thanks for listening to this conversation with Lee Cronin. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Carl Sagan. We can judge our progress by the courage of our questions and the depth of our answers, our willingness to embrace what is true rather than what feels good. Thank you for listening and hope to see you next time.

Utterances:
Speaker A: Every star in the sky probably has planets, and life is probably emerging on these planets. But I think the commentarial space associated with these planets is so different, our causal cones are never going to overlap or not easily. And this is the thing that makes me sad about alien life, why it's why we have to create alien life in the lab as quickly as possible, because I don't know if we are going to be able to be able to build architectures that will intersect with alien intelligence.
Speaker B: Architectures intersect. You don't mean in time or space?
Speaker A: Time and the ability to communicate.
Speaker B: The ability to communicate, yeah.
Speaker A: My biggest fear, in a way, is that life is everywhere, but we become infinitely more lonely because of our scaffolding in that commentarial space.
Speaker B: The following is a conversation with Lee Cronin, his third time on this podcast. He is a chemist from University of Glasgow who is one of the most fascinating, brilliant, and fun to talk to scientists I've ever had the pleasure of getting to know. This is a Lex Friedman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Lee Cronin. So your big assembly theory paper was published in Nature. Congratulations.
Speaker A: Thanks.
Speaker B: It created, I think it's fair to say, a lot of controversy, but also a lot of interesting discussion. So maybe I can try to summarize assembly theory and you tell me if I'm wrong.
Speaker A: Go for it.
Speaker B: So, assembly theory says that if we look at any object in the universe, any object, that we can quantify how complex it is by trying to find the number of steps it took to create it, and also we can determine if it was built by a process akin to evolution by looking at how many copies of the object there are.
Speaker A: Yep. That's spot on.
Speaker B: Yeah, spot on. I was not expecting that. Okay, so let's go through definitions. So there's a central equation I'd love to talk about, but definition wise, what is an object?
Speaker A: Yeah, an object. So, from. So if I'm going to try to be as meticulous as possible, objects need to be finite, and they need to be decomposable into subunits. All human made artifacts are objects. Is a planet an object? Probably, yes, if you scale out. So an object is finite and countable and decomposable, I suppose, mathematically, but, yeah, I still wake up some days and go think to myself, what is an object? Because it's a non trivial question, persists over time.
Speaker B: I'm quoting from the paper here. An object is finite, is distinguishable. That's a weird adjective. Distinguishable.
Speaker A: We've had so many people help offering to rewrite the paper after it came out. You wouldn't believe it's so funny.
Speaker B: Persists over time and is breakable. Such that the set of constraints to construct it from elementary building blocks is quantifiable. Such that the set of constraints to construct it from elementary building blocks is quantifiable.
Speaker A: The history is in the objects. It's kind of cool, right?
Speaker B: So, okay, so what defines the object is it's history or memory, whichever is the sexier word.
Speaker A: I'm happy with both, depending on the day.
Speaker B: Okay, so the set of steps it took to create the object. So there's a sense in which every object in the universe has a history.
Speaker A: Yeah.
Speaker B: And that is part of the thing that is used to describe its complexity, how complicated it is. Okay, what is an assembly index?
Speaker A: So the assembly index, if you're to take the object apart and be super lazy about it, or minimal, say what it might, you know, it's like you've got a really short term memory. So what you do is you lay all the parts on the path, and you find the minimum number of steps you take on the path to add the parts together to reproduce the object. And that minimum number is the assembly index. There's a minimum bounden. And it was always my intuition the minimum bound in assembly theory was really important. And I only worked out why a few weeks ago, which is kind of funny, because I was just like, no, this is sacrosanct. I don't know why it will come to me one day. And then when I was pushed by a bunch of mathematicians, we came up with the correct physical explanation, which I can get to, but it's the minimum, and it's really important. It's the minimum. And the reason I knew the minimum was right is because we could measure it. So almost before this paper came out, with published papers, explain how you can measure the assembly index of molecules.
Speaker B: Okay, so that's not so trivial to figure out. So when you look at an object, we can say molecule, we can say object more generally, to figure out the minimum number of steps it takes to create that object. That doesn't seem like a trivial thing to do.
Speaker A: So with molecules it is. It's not trivial, but it is possible, because what you can do, and because I'm a chemist, so I'm kind of like, I see the lens of the world through just chemistry. I break the molecule apart and break bonds. And if you take a molecule and you break it all apart, you have a bunch of atoms, and then you say, okay, I'm going to then take the atoms and form bonds and go up the chain of events to make the molecule. And that's what made me realize, take a toy example, literally, toy example. Take a Lego object, which is broken up of Lego blocks. So you could do exactly the same thing. In this case, the lego blocks are naturally the smallest. They're the atoms in the actual composite Lego architecture. But then if you maybe take a couple of blocks and put them together in a certain way, maybe they're offset in some way. That offset is on the memory. You can use that offset again with only a penalty of one, and you can then make a square triangle and keep going. And you remember those motifs on the chain. So you can then leap from the start with all the lego blocks or atoms just laid out in front of you and say, right, I'll take you, you connect and do the least amount of work. So it's really like the smallest steps you can take on the graph to make the object. And so for molecules, it came relatively intuitively, and then we started to apply it to language. We've even started to apply it to mathematical theorems. But I'm so well out of my depth. But it looks like you can take minimum set of axioms and then start to build up kind of mathematical architectures in the same way. And then the shortest path to get there is something interesting that I don't yet understand.
Speaker B: So what's the computational complexity of figuring out the shortest path with molecules, with language, with mathematical theorems? It seems like once you have the fully constructed Lego castle, or whatever your favorite Lego world is, figuring out how to get there from the building, basic building blocks isn't like a. Is that an empty, hard problem? It's a hard problem.
Speaker A: It's a hard problem. But actually, if you look at it. So the best way to look at it, let's take a molecule. So if the molecule has 13 bonds, first of all, take 13 copies of the molecule and just cut all the bonds. So take, cut twelve bonds, and then you just put them in order. Yeah. And then that's how it works. So you keep looking for symmetry or copies, so you can then shorten it as you go down. And that becomes commentarily quite hard for some natural product molecules. It becomes very hard. It's not impossible, but we're looking at the bounds on that at the moment. But as the object gets bigger, it becomes really hard. And. But that's the bad news. But the good news is there are shortcuts, and we might even be able to physically measure the complexity without computationally calculating it, which is kind of insane.
Speaker B: Wait, how would you do that?
Speaker A: Well, in the case of molecule. So, if you shine light on a molecule, let's take an infrared. The molecule has each of the bonds, absorbs the infrared differently in what we call the fingerprint region. And so it's a bit like. And because it's quantized as well, you have all these discrete kind of absorbances. And my intuition, after we realized we could cut molecules up in mass spec, that was the first go at this. We did it with using infrared, and the infrared gave us an even better correlation assembly index. And we used another technique as well, in addition to infrared, called NMR, nuclear magnetic resonance, which tells you about the number of different magnetic environments in a molecule. And that also worked out. So we have three techniques, which each of them independently gives us the same, or tending towards the same assembly index for a molecule that we can calculate mathematically.
Speaker B: Okay, so these are all methods of mass spectrometry. Mass spec. You scan a molecule, it gives you data in the form of a mass spectrum. And you're saying that the data correlates to the assembly index.
Speaker A: Yeah.
Speaker B: How generalizable is that shortcut, first of all, to chemistry, and second of all, beyond that, because that seems like a nice hack, and you're extremely knowledgeable about various aspects of chemistry, so you can say, okay, it kind of correlates. But, you know, the whole idea behind assembly theory paper, and perhaps why it's so controversial, is that it reaches bigger. It reaches for the bigger general theory of objects in the universe.
Speaker A: Yeah, I'd say so. I'd agree. So, I've started assembly theory of emoticons with my lab, believe it or not. So we take emojis, pixelate them, and work out the assembly index for the emoji, and then work out how many emojis you can make on the path of emojis. So there's the uber emoji, from which all other emojis emerge.
Speaker B: Yeah.
Speaker A: And then you can. So you can then take a photograph, and by looking at the shortest path, by reproducing the pixels to make the image you want, you can measure that. So then you start to be able to take spatial data. Now, there's some problems there. What is then the definition of the object? How many pixels? How do you break it down? And so we're just learning all this right now.
Speaker B: So how do you compute this? How would you begin to compute the assembly index of a graphical, like a set of pixels on a 2d plane that form a thing.
Speaker A: So you would first of all determine the resolution. So then what is your XY and what number on the X and Y plane? And then look at the surface area. And then you take all your emojis and make sure they're all looked at the same resolution.
Speaker B: Yes.
Speaker A: And then we will basically then do the, exactly the same thing we would do for cutting bonds. You'd cut bits out of the emoji and look at, you'd have a bag of pixels and you would then add those pixels together to make the overall emoji.
Speaker B: Wait a minute. But first of all, not every pixels. I mean this is at the core sort of machine learning and computer vision. Not every pixel is that important. And there's like macro features, there's micro features and all that kind of stuff. Exactly like, you know, the eyes appear in a lot of them, the smile appears in a lot of them.
Speaker A: So in the same way in chemistry, we assume the bond is fundamental. What we do in here is we assume the resolution at the scale at which we do it is fundamental. And we're just working that out. And that. You're right, that will change. Right. Because as you take your lens out a bit, it will change dramatically. But it's just a new way of looking at, not just compression. What we do right now in computer science and data, one big kind of misunderstanding is assembly theory is telling you about how compressed the object is. That's not right. It's a how much information is required on a chain of events. Because the nice thing is if, when you do compression in computer science, we're wandering a bit here, but it's kind of worth wandering, I think. You assume you have instantaneous access to all the information in the memory. In assembly theory, you say no, you don't get access to that memory until you've done the work. And then when you don't access that memory, you can have access, but not to the next one. And this is how in assembly theory we talk about the four universes, the assembly universe, the assembly possible and the assembly contingent. And then the assembly observed. And they're all scales in this combinatorial universe.
Speaker B: Yeah. Can you explain each one of them?
Speaker A: Yep. So the assembly universe is like anything goes just this, just combinatorial kind of explosion in everything.
Speaker B: So that's the biggest one?
Speaker A: That's the biggest one.
Speaker B: It's massive assembly universe. Assembly possible assembly contingent assembly observed. And on the y axis is assembly steps in time.
Speaker A: Yeah.
Speaker B: And you know, in the x axis, as the thing expands through time, more and more unique objects appear.
Speaker A: So, yeah. So assembly universe, everything goes, yep. Assembly possible laws of physics come in. In this case, in chemistry, bonds in assembly. So that means those are actually constraints, I guess. Yes, and they're the only constraints. They're the constraints at the base. The way to look at it is you've got all your atoms, they're quantized, and you can just bung them together. So then you can become a kind of. So in the way in computer science speak, I suppose the assembly universe is just like no laws of physics. Things can fly through mountains beyond the speed of light. In the assembly possible, you have to apply the laws of physics, but you can get access to all the motifs instantaneously with no effort. So that means you could make anything. Then the assembly contingent says, no, you can't have access to the highly assembled object in the future until you've done the work in the past on the causal chain. And that's really the really interesting shift where you go from assembly possible to assembly contingent. That is really the key thing in assembly theory that says you cannot just have instantaneous access to all those memories. You have to have done the work somehow. The universe has to have somehow built a system that allows you to select that path rather than other paths. And then the final thing the assembly observed is basically us saying, oh, these are the things we actually see. We can go backwards now and understand that they have been created by this causal process.
Speaker B: Wait a minute. So when you say the universe has to construct the system that does the work, is that like the environment that allows for, like, selection?
Speaker A: Yeah, yeah, yeah.
Speaker B: That's the thing that does the selection.
Speaker A: You could think about in terms of a von Neumann constructor versus the selection, a ribosome Tesla plant assembling Teslas. You know, the difference between the assembly universe in Teslaland and the Cesar factory is everyone says, no, Teslas are just easy. They just spring out. You know how to make them all a Tesla factory? You have to put things in sequence and out comes a Tesla.
Speaker B: So you're talking about the factory.
Speaker A: Yes. This is really nice. Super important point is that when I talk about the universe having a memory or there's some magic, it's not that. It's that tells you that there must be a process encoded somewhere in physical reality, be it a cell, a Tesla factory, or something else that is making that object. I'm not saying there's some kind of woo woo memory in the universe, morphic resonance or something. I'm saying that there is an actual causal process that is being directed, constrained in some way. So it's not kind of just making everything.
Speaker B: Yeah, but Lee, what's the factory that made the factory? So what is the. So, first of all, you assume the laws of physics has just sprung to existence at the beginning. Those are constraints. But what makes the factory the environment that does the selection?
Speaker A: This is the question of. Well, it's the first interesting question that I want to answer out of four. I think the factory emerges in the environment, the interplay between the environment and the objects that are being built. And I'll have a go at explaining to you the shortest path. So why is the shortest path important? Imagine you've got. I'm going to have to go chemistry for a moment, then abstract it. So imagine you've got a given environment that you have a budget of atoms you're just flinging together. And the objective of those atoms that being flung together in, say, molecule a, have to make. They decompose. So molecules decompose over time. So the molecules in this environment, in this magic environment, have to not die. But they do die, they have a half life. So the only way the molecules can get through that environment out the other side. Let's pretend the environment is a box and go in and out without dying, and there's just an infinite supply of atoms coming, or, well, a large supply. The molecule gets built, but the molecule that is able to template itself, being built and survives in the environment will. Will basically reign supreme. Now, let's say that molecule takes ten steps now, and it's using a finite set of atoms, right? Or now let's say another molecule, smart arse molecule, we'll call it, comes in and can survive in that environment and can copy itself, but it only needs five steps. The molecule that only needs five steps, because both molecules have been destroyed, but they're creating themselves faster. They can be destroyed. You can see that the shortest path reigns supreme. So the shortest path tells us something super interesting about the minimal amount of information required to propagate that motif in time and space. And it's just like a kind of. It seems to be like some kind of conservation law.
Speaker B: So one of the intuitions you have is the propagation of motifs in time will be done by the things that can construct themselves in the shortest path.
Speaker A: Yeah.
Speaker B: So, like, you can assume that most objects in the universe are built in the shortest, in the most efficient way. So, big leap I just took there.
Speaker A: Yeah. Yes and no, because there are other things. So in the limit. Yes, because you want to tell the difference between things that have required a factory to build them and just random processes. But you can find instances where the shortest path isn't taken for an individual object, an individual function, and people go, ah, that means the shortest path isn't right. And then I say, well, I don't know. I think it's right still, because. So of course, because there are other driving forces. It's not just one molecule. Now when you start to, now you start to consider two objects. You have a joint assembly space. And now it's a compromise between not just making a and b in the shortest path, you want to make a and b in the shortest path, which might mean that a is slightly longer, you have a compromise. So when you see slightly more nesting in the construction, when you take a given object that can look longer, but that's because the overall function is the object is still trying to be efficient. Yeah, and this is still very hand wavy and maybe have no leg to stand on, but we think we're getting somewhere with that.
Speaker B: And there's probably some parallelization.
Speaker A: Yeah, right.
Speaker B: So this is all, this is not sequential. The building is, I guess.
Speaker A: No, you're right.
Speaker B: When you're talking about complex objects, you don't have to work sequentially. You can work in parallel, you can get your friends together and they can.
Speaker A: Yeah. And the thing we're working on right now is how to understand these parallel processes. Now there's a new thing we've introduced called assembly depth. And assembly depth can be lower than the assembly index for a molecule when they're cooperating together, because exactly this parallel processing is going on. And my team have been working this out in the last few weeks because we're looking at what compromises does nature need to make when it's making molecules in a cell? And I wonder if maybe like, well, I'm always leaping out of my competence, but in economics, I'm just wondering if you could apply this in economic process. It seems like capitalism is very good at finding the shortest path every time, but there are ludicrous things that happen because actually the cost function has been minimized. And so I keep seeing parallels everywhere where they're complex nested systems, where if you give it enough time and you introduce a bit of heterogeneity, the system readjusts and finds a new shortest path. But the shortest path isn't fixed on just one model molecule. Now it's in the actual existence of the object over time. And that object could be a city it could be a cell, it could be a factory. But I think we're going way beyond molecules, and my competence probably should go back to molecules.
Speaker B: But, hey, all right, before we get too far, let's talk about the assembly equation. Okay, how should we do this? Now, let me just even read that part of the paper. We define assembly as the total amount of selection necessary to produce an ensemble of observed objects quantified using equation one. The equation basically has a on one side, which is the assembly of the ensemble, and then a sum from one to n, where n is the total number of unique objects. And then there is a few variables in there that include the assembly index, the copy number, which we'll talk about. That's an interesting. I don't remember you talking about that. That's an interesting addition. And I think a powerful one has to do with what, that you can create pretty complex objects randomly. And in order to know that they're not random, that there's a factory involved, you need to see a bunch of them. Yeah, that's the intuition there. It's an interesting intuition and then some normalization. What else is it in minus one?
Speaker A: Just to make sure that more than one object could be a one off and random, and then you have more than one identical object. That's interesting.
Speaker B: When there's two of a thing, two.
Speaker A: Of a thing is super important, especially if the index, assembly index is high.
Speaker B: So we could say several questions here. One, let's talk about selection. What is this term, selection, what is this term evolution that we're referring to? Which aspect of darwinian evolution that we're referring to? That's interesting here?
Speaker A: So, yeah, so this is probably what, you know, the paper. We should talk about the paper a second. The paper, what it did, is it kind of annoyed? We didn't know? I mean, it got intention and obviously angry people. The angry people were annoyed.
Speaker B: There's angry people in the world. That's good.
Speaker A: So what happened is the evolutionary biologists got angry. We were not expecting that because we thought evolutionary biologists would be cool. I knew that some, not many computational complexity people would get angry because I'd kind of been poking them and maybe I deserved it, but I was trying to poke them in a productive way. And then the physicists kind of got grumpy because the initial conditions tell everything. The prebiotic chemist got slightly grumpy because there's not enough chemistry in there. Then finally, when the creationist said it wasn't creationist enough, I was like, no, I've done my job you say in.
Speaker B: The physics, they say, because you're basically saying that physics is not enough to tell the story of how biology emerges.
Speaker A: I think so, cassie.
Speaker B: And then they said a few. Physics is the beginning and the end of the story.
Speaker A: Yeah. So what happened is the reason why people put the phone down on the call of the paper. If you view reading the paper like a phone call, they got to the abstract.
Speaker B: Yep.
Speaker A: And in the abstract, the first sentence is pretty. The first two sentences caused everybody.
Speaker B: Scientists have grappled with reconciling biological evolution with the immutable laws of the universe defined by physics.
Speaker A: True. Right. There's nothing wrong with that statement. Totally true.
Speaker B: Yeah. These laws underpin life's origin, evolution, and the development of human culture and technology, yet they do not predict the emergence of these phenomena. Wow. First of all, we should say the title of the paper. This paper was accepted and published in nature. The title is assembly theory explains and quantifies selection and evolution. Very humble title. And the entirety of the paper, I think, presents interesting ideas but reaches high.
Speaker A: I am not. I would do it all again. This paper was actually on the preprint server for over a year.
Speaker B: You regret nothing.
Speaker A: Yeah, I think, yeah, I don't regret anything.
Speaker B: You and Frank Sinatra did it your way.
Speaker A: What I love about being a scientist is kind of sometimes because I'm a bit dim, I'm like. And I don't understand what people telling me. I want to get to the point. This paper says, hey, laws of physics are really cool. The universe is great, but they don't really. It's not intuitive that you just run the standard model and get life out. I think most physicists might go, yeah, there's this, you know, it's not just, we can't just go back and say, that's what happened. Because physics can't explain the origin of life yet. It doesn't mean it won't or can't. Okay, just to be clear. Sorry, intelligent designers, we are going to get there. Second point, we say that evolution works, but we don't know how evolution got going. So biological evolution and biological selection. So for me, this seems like a simple continuum. So when I mentioned selection and evolution in the title, I think, and in the abstract, we should have maybe prefaced that and said non biological selection and non biological evolution, and then that might have made it even more crystal clear. But I didn't think that biology, evolutionary biology should be so bold to claim ownership of selection and evolution. And secondly, a lot of evolutionary biologists seem to dismiss the origin of life questions to say it's obvious. And that causes a real problem scientifically, because when two different, when the physicists are like, we own the universe, the universe is good, we explain all of it. Look at us. And biologists say we can explain biology, and the poor chemist in the middle going, but hang on. And this paper kind of says, hey, there is an interesting disconnect between physics and biology, and that's at the point at which memories get made in chemistry through bonds. And, hey, let's look at this close and see if we can quantify it. So, yeah, I mean, I never expected the paper to kind of get that much interest. And still, I mean, it's only been published just over a month ago now.
Speaker B: Just linger on the selection. What is the broader sense of what selection means?
Speaker A: Yeah, that's a really good for selection. Selection. So I think for selection, you need. So this is where, for me, the concept of an object is something that can persist in time and not die, but basically can be broken up. So if I was going to kind of bolster the definition of an object, so if something can form and persist for a long period of time under an existing environment that could destroy other, and I'm going to use anthropomorphic terms, I apologize that weaker objects or less robust, then the environment could have selected that. So good chemistry examples. If you took some carbon and you made a chain of carbon atoms, whereas if you took some, I don't know, some carbon, nitrogen and oxygen, and made chains from those, you'd start to get different reactions and rearrangements. So a chain of carbon atoms might be more resistant to falling apart under acidic or basic conditions versus another set of molecules. So it survives in that environment. So the acid pond, the molecule, the resistant molecule can get through, and then that molecule goes into another environment. So that environment, now, maybe being an acid bond is a basic pond, or maybe it's an oxidizing pond. And so if you've got carbon and it goes in an oxidizing pond, maybe the carbon starts to oxidize and break apart. So you go through all these kind of obstacle courses, if you like, given by reality. So selection is the ability happens when an object survives in an environment for some time. But, and this is the thing that's super subtle, the object has to be continually being destroyed and made by process. So it's not just about the process. The object, now, it's about the process and time that makes it. Because a rock could just stand on the mountainside for 4 billion years and nothing happened to it. And that's not necessarily really advanced selection. So for selection to get really interesting, you need to have a turnover in time. You need to be continually creating objects, producing them, what we call discovery time. So there's a discovery time for an object when that object is discovered. If it's, say, a molecule that can then act on itself, or the chain of events that caused itself to bolster its formation, then you go from discovery time to production time, and suddenly you have more of it in the universe. So it could be a self replicating molecule, and the interaction of the molecule in the environment, in the warm little pond or in the sea or wherever in the bubble, could then start to build a proto factory, the environment. So really, to answer your question, what the factory is, the factory is the environment, but it's not very autonomous, it's not very redundant. There's lots of things that could go wrong. So once you get high enough up the hierarchy of networks of interactions, something needs to happen that needs to be compressed into a smaller volume and made resistant, robust, because in biology, selection and evolution is robust, that you have error correction built in, you have really, you know, there's good ways of basically making sure propagation goes on. So really the difference between inorganic abiotic selection, evolution and evolution and stuff in biology is robustness. The ability to kind of propagate, overdose over in the ability to survive in lots of different environments, whereas our poor little inorganic salt molecule, whatever, just dies in lots of different environments. So there's something super special that happens from the inorganic molecule in the environment that kills it to where you've got evolution, and cells can survive everywhere.
Speaker B: How special is that? How do you know those kinds of evolution factors aren't everywhere in the universe?
Speaker A: I don't. And I'm excited because I think selection isn't special at all. I think what is special is the history of the environments on earth that gave rise to the first cell, that now has taken all those environments and is now more autonomous. And I would like to think that, you know, this paper could be very wrong, but I don't think it's very wrong. It means certainly wrong, but it's less wrong than some other ideas, I hope. Right? And if this allow inspires us to go and look for selection in the universe, because we now have an equation where we can say, we can look for selection going on and say, oh, that's interesting. We seem to have a process that's giving, giving us high copy number objects that also are highly complex, but that doesn't look like life as we know it. And we use that and say, oh, there's a hydrothermal vent. Oh, there's a process going on. There's molecular networks, because the assembly equation is not only meant to identify at the higher end, advanced selection. What you get, I would call in biology, super advanced selection. And even, I mean, you could use the assembly equation to look for technology. And I, God forbid we could talk about consciousness and abstraction, but let's keep it primitive molecules and biology. So I think the real power of the assembly equation is to say how much selection is going on in this space. And there's a really simple thought experiment I could do is you have a little petri dish, and on that petri dish you put some simple food. So the assembly index of all the sugars and everything is quite low. So then you put a single cell of E. Coli cell.
Speaker B: Yeah.
Speaker A: And then you say, I'm gonna, I'm gonna measure the assembly in this amount of assembly in the box. So it's quite low. But the rate of change of assembly, da dt, will go, voom, sigmoidal as it eats all the food. And the number of coli cells will replicate because they take all the food they can copy themselves. The assembly index of all the molecules goes up, up and up until the food is exhausted in the box. So now the, now the E. Coli has stopped. I mean, die is probably a strong word. They stop respiring because all the food is gone. But suddenly the amount of assembly in the box has gone up gigantically because of that. One E. Coli factory has just eaten through milled. Lots of other E. Coli factory has run out of food and stopped. And so looking at that. So in the initial box, although the amount of assembly was really small, it was able to replicate and use all the food and go up. And that's what we're trying to do in the lab, actually, is kind of make those kind of experiments and see if we can spot the emergence of molecular networks that are producing complexity as we feed in raw materials. And we feed a challenge, an environment, you know, we try and kill the molecules. And really that's the main kind of idea for the entire paper. Yeah.
Speaker B: And see if you can measure the changes in the assembly index throughout the whole system.
Speaker A: Yeah.
Speaker B: Okay. What about if I show up to a new planet, we go to Mars or some other planet from a different solar system? And how do we use assembly index there to discover alien life?
Speaker A: Very simply, actually, if we, let's say we'll go to Mars with a mass spectrometer with a sufficiently high resolution. So what you have to be able to do. So a good thing about mass spec is that you can select a molecule from the mass, and then if it's high enough resolution, you can be more and more sure that you're just seeing identical copies. You can count them and then you fragment them, and you count the number of fragments and look at the molecular weight, and the higher the molecular weight and the higher the number of the fragments, the higher the assembly index. So if you go to Mars and you take a mass spec or high enough resolution, and you can find molecules, and I'll give a guide on earth, if you could find molecules, say greater than 350 molecular weight, were more than 15 fragments, you have found artifacts that can only be produced, at least on earth, by life. Now, you would say, oh, maybe the geological process, I would argue very vehemently that that is not the case. But we can say, look, if you don't like the cut off on earth, go up higher, 3100, right? Because there's going to be a point where you find a molecule with so many different parts. The chances of you getting a molecule that has 100 different parts and finding a million identical copies, that's just impossible. That could never happen in an infinite set of universes.
Speaker B: Can you just linger on this copy number thing? A million different copies? What do you mean by copies? And why is the number of copies important?
Speaker A: Yeah, that was so interesting. And I always understood the copy number is really important, but I never explained it properly for ages. And I kept having this. It goes back to this. If I give you, I don't know, a really complicated molecule, and I say it's complicated, you could say, hey, that's really complicated, but is it just really random? And so I realized that ultimate randomness and ultimate complexity are indistinguishable until you can, you can see a structure in the randomness, so you can see copies.
Speaker B: So copies implies structure.
Speaker A: Yeah, the factory.
Speaker B: I mean, there's a deep, profound thing in there, because if you just have a random, random process, you're going to get a lot of complex, beautiful, sophisticated things. What makes them complex in the way we think life is complex? Or. Yeah, something like a factory that's operating under a selection process, there should be copies. Is there some looseness about copies? What does it mean for two objects to be equal?
Speaker A: It's all to do with the telescope or the microscope you're using. And so at the maximum resolution. So in the nice thing about, the nice thing about chemists, is they have this concept of the molecule, and they are all familiar with the molecule and molecules you can hold on your hand, and lots of them, identical copies. A molecule is actually a super important thing in chemistry to say, look, you can have a mole of a molecule and Avogadro's number of molecules, and they're identical. What does that mean? That means that the molecular composition, the bonding and so on, the configuration is indistinguishable. You can hold them together, you can overlay them. So the way I do it is if I say, here's a bag of ten identical molecules, let's prove they're identical. You pick one out of the bag, and you basically observe it using some technique, and then you put it, you take it away, and then you take another one out. If you observe it using technique, you see no differences. They're identical. It's really interesting to get right, because if you take, say, two molecules, molecules can be in different vibrational rotational states. They're moving all the time. So with this respect, identical molecules have identical bonding. In this case, we don't even talk about chirality because we don't have a chirality detector. So two identical molecules in one conception. Assembly theory basically considers both hands as being the same, but of course, they're not. They're different. As soon as you have a chiral distinguisher detect the left and the right hand, they become different. And so it's to do with the detection system that you have and the resolution.
Speaker B: So I wonder if there's an art and science to the which detection system is used when you show up to a new planet.
Speaker A: Yeah, yeah, yeah.
Speaker B: So, like, you're talking about chemistry a lot today we have kind of standardized detection systems. Right, of how to compare molecules. So, you know, when you start to talk about emojis and language and mathematical theorems and, I don't know, more sophisticated things, a different scale at a smaller scale than molecules. At a larger scale than molecules. Like what detection. If we look at the difference between you and me lexingly, are we the same? Are we different?
Speaker A: Sure. I mean, of course we're different close up, but if you zoom out a little bit, morphologically, look the same. Yeah. You know, high in characteristics, hair length, stuff like that.
Speaker B: Also like the species and.
Speaker A: Yeah, yeah, yeah.
Speaker B: And, and also there's a sense why we're both from earth.
Speaker A: Yeah, I agree. I mean, this is the power of assembly theory in that regard, that you. If, if you so, if everything, so the way to look at it, if you have a box of objects, if they're all, if they're all indistinguishable, then using your technique, what you then do is you then look at the assembly index. Now, if the assembly index of them is really low and they're all indistinguishable, then it's telling you that you have to go to another resolution. It's a sliding scale. It's kind of nice.
Speaker B: Those two are attention with each other. The number of copies and the assembly index. That's really, really interesting. So, okay, so you show up to a new planet, you'll be doing what.
Speaker A: I would do mass spec.
Speaker B: I would bring on a sample of what? Like, first of all, like, how big of a scoop do you take? Did you just take a scoop? Like what? Like, uh. So we're looking for primitive life.
Speaker A: I would, I would look, yeah. So if we're just going to Mars or Titan or Enceladus or somewhere. So a number of ways of doing it. So you could take a large scoop or you go for the atmosphere and detect stuff, you could make a life meter. So one of Sarah's colleagues at ASU, Paul Davies, keeps calling it a life meter, which is quite a nice idea because you think about it, if you've got a living system that's producing these highly complex molecules and they drift away and they're in a highly kind of demanding environment, they could be burnt, right? So they could just be falling apart. So you want to sniff a little bit of complexity and say, warmer, warmer, warmer. Oh, we've found life. We found the alien. We've found, we found the alien, Elon musk smoking a joint in the bottom of the cave on Mars, or Elon himself, whatever, right? You say, okay, found it. So what you can do is the mass spectrometer, you could just look for things in the gas phase, or you go on the surface, drill down, because you want to find molecules that are. You've either got to find the source living system, because the problem with just looking for complexity is it gets burned away. So in a harsh environment on the surface of Mars, there's a very low probability that you're going to find really complex molecules because of all the radiation and so on. If you drill down a little bit, you could drill down a bit into soil that's billions of years old. Then I would put in some solvent, water, alcohol or something, or take a scoop, make it volatile, put it into the mass spectrometer and just try and detect high complexity, high abundant molecules. And if you get them, hey, presto, you can have evidence of life. Wouldn't that then be great if you could say, okay, we've found evidence of life. Now we want to keep, keep the life meter keeps searching for more and more complexity until you actually find living cells. You can get those new living cells and then, and then you could bring them back to earth, or you could try and sequence them. You could see that they have different DNA and proteins, go along the gradient.
Speaker B: Of the life meter. How would you build a life meter? Let's say we're together, starting new company.
Speaker A: Launching a life meter mass spectrometer would be the first way of doing it.
Speaker B: No, no, but that's, that's a, that's one of the major components of it. But I'm talking about, like, what if it's a device, we got a branding logo we got to talk about. That's later. But what's the input? Like, how do you get to the metered output?
Speaker A: So I would take a. So my life meter, our life meter. There you go.
Speaker B: Thank you.
Speaker A: Yeah, you're welcome. Would have both infrared and aspect, so it would have two ports so we could shine a light. And so what it would do is you would have a vacuum chamber and you would have an electrostatic analyzer and you'd have a monochromator. To producing infrared, you'd add the sump, so you'd take a scoop of the sample, put it in the life meter. It would then add a solvent or heat up the sample so some volatiles come off. The volatiles would then be put into the, into the mass spectrometer, into electrostatic trap, and you'd weigh the molecules and fragment them. Alternatively, you'd shine infrared light on them. You'd count the number of bands, but you'd have to, in that case, do some separation because you want to separate. And so in mass spec, it's really nice and convenient because you can separate electrostatically, but you need to have that.
Speaker B: Can you do it in real time?
Speaker A: Yeah, pretty much. Pretty much, yeah. So let's go all the way back. So let's. Okay, we're really going to get this Lexus life, me, Lex and Lee's life.
Speaker B: It's a good, good, good ring to it.
Speaker A: All right, so you have a, you have a vacuum chamber. You have a little nose. The nose would have some. A packing material. So you would take your sample, add it onto the nose, add a solvent or a gas. It would then be sucked up the nose and that would be separated using chrome, what we call chromatography. And then as each band comes off the nose. We would then do mass spec and infrared. And in the case of the infrared, count the number of bands. In the case of the mass spec, count the number of fragments and weigh it. And then the further up in molecular weight range for the mass spec and the number of bands, you go up and up and up from the dead. Interesting, interesting. Over the threshold. Oh, my gosh. Earth life. And then right up to the batshit crazy. This is definitely alien intelligence that's made this life. Right? You could almost go all the way there, same in the infrared. And it's pretty simple. The thing that is really problematical is that for many years, decades, what people have done, and I can't blame them, is they've rather, they've been obsessing about small biomarkers on that we find on earth, amino acids, like single amino acids or evidence of small molecules and these things and looking for those rather than looking for complexity. Well, the beautiful thing about this is you can look for complexity without earth chemistry bias or earth biology bias. So assembly theory is just a way of saying, hey, complexity and abundance is evidence of selection. That's how our universal life meter will work.
Speaker B: Complexity in abundance is evidence of selection. Okay, so let's apply our life meter to earth. So what, you know, if we were just to apply assembly index measurements to earth, what kind of stuff are going to be get. Are going to get what's impressive about some of the complexity on earth.
Speaker A: So we did this a few years ago when I was trying to convince NASA and colleagues that this technique could work. And honestly, it's so funny because everyone's like, no, it ain't going to work. And I was just like. Because the chemist was saying, of course there are complicated molecules out there. You can detect that just form randomly, really. That's like, that was like, you know, as a bit like a. I don't know, someone saying, of course, Darwin textbook was just written randomly by some monkeys and a typewriter. I was just. For me, it was like, really? And I pushed a lot on the chemists now, and I think most of them are on board, but not totally. It really had some big arguments. But the copy number caught there because I think I confused the chemist by saying one off. And then when I made clear about the copy number, I think that made it a little bit easier.
Speaker B: Just to clarify, chemists might say that, of course, out there, outside of earth, there's complex molecules.
Speaker A: Yes.
Speaker B: Okay. And then you're saying, wait a minute, that's like saying, of course, there's aliens out there.
Speaker A: Yeah, exactly that.
Speaker B: Okay.
Speaker A: Exactly.
Speaker B: You say you clarify that. Thats actually a very interesting question. And we should be looking for complex molecules of which the copy number is two or greater.
Speaker A: Yeah, exactly. So on earth. So coming back to earth, what we did is we took a whole bunch of samples and we were running prebiotic chemistry experiments in the lab. We took various inorganic minerals and extracted them. Look at the volatile, because theres a special way of treating minerals and polymers and assembly theory in our life machine, we're looking at molecules. We don't care about polymers because they don't. They're not volatile. You can't hold them. How can you make. If you can't assert that they're identical, then it's very difficult for you to work out if there's undergone selection or they're just a random mess. Same with some minerals, but we can come back to that. So basically what you do, we got a whole load of samples, inorganic ones. We got a load of. We got scotch whiskey and also got took ard Berg, which is one of my favorite whiskies, which is very peaty. And another whisk.
Speaker B: What does peaty mean?
Speaker A: Is like. So the way that on, in Scotland, in Islay, which is little island, the scotch, the whisky is led to mature in barrels. And it said that the peat, the complex molecules in the peat might find their way through into the whiskey. And that's what gives it this intense brown color and really complex flavor. It's literally molecular complexity that does that. And so vodka is the complete opposite. It's just pure, right?
Speaker B: The better the whiskey, the higher the assembly index. The higher the assembly index, the better the whiskey.
Speaker A: I mean, I really love deep, peaty scottish whiskies. Near my house, there is one of the lowland distilleries called glengoyne. Still beautiful whisky, but not as complex. So for fun, I took some glencoin whiskey in our bag and put them into the mass spec and measure the assembly index. I also got e coli. So the way we do it, take the E. Coli, break the cell apart, take it all apart, and also got some beer. And people were ridiculing us, saying, oh, beer is evidence of complexity. One of the computational complexity people was just throwing. Yeah, kind of. He's very vigorous in his disagreement of assembly theory, was just saying, you know, you don't know what you're doing. Even beer is more complicated than human. What he didn't realize is that it's not beer per se. It is taking the yeast extract, taking the extract, breaking the cells extracting the molecules and just looking at the profile of the molecules, see if there's anything over the threshold. And we also put in a really complex molecule, taxol. So we took all of these, but also NASA gave us, I think, five samples and they wouldn't tell us what they are. They said, no, we don't believe you can get this to work. And they really gave us some super complex samples and they gave us two fossils, one that was a million years old and one was at 10,000 years old, something from Antarctica seabed. They gave us immersious and meteorite and a few others put them through the system. So we took all the samples, treat them all identically, put them into mass spec, fragmented them, counted, and in this case, implicit in the measurement was in mass spec. You only detect peaks when you've got more than say, let's say, 10,000 identical molecules. So the copy number is already baked in but wasn't quantified, which is super important there. This is in the first paper because I was like, it's abundant, of course. And when you then took it all out, we found that the biological samples gave you molecules that had an assembly index greater than 15 and all the abiotic samples were less than 15. And then we took the NASA samples and we looked at the ones that were more than 15, less than 15, and we gave them back to NASA and they're like, oh, gosh, I. Yep. Dead living. Dead living. You got it. And that's what we found on earth.
Speaker B: That's a success.
Speaker A: Yeah. Oh, yeah. Resounding success.
Speaker B: Can you just go back to the beer and the E. Coli? So what's the assembly index on those?
Speaker A: So what you were able to do is like the assembly index of. We found high assembly index molecules originating from the beer sample and the E. Coli sample. The east. And the beauty, I mean, I didn't know which one was higher. We didn't really do any detail there because now we are doing that because one of the things we've done, it's a secret, but I can tell you.
Speaker B: Nobody'S listening.
Speaker A: Well, is that we've just mapped the tree of life using assembly theory because everyone said, oh, that you can't do infant biology. And what we're able to do is. So you. I think there's three way. Well, two ways of doing tree of life traffic. Well, three ways, actually.
Speaker B: What's the tree of life?
Speaker A: So the tree of life is basically tracing back the history of life on earth for all the different species going back who evolved from what? And it all goes all the way back to the first kind of life forms, and they branch off and like, you have plant kingdom, the animal kingdom, the Fungi kingdom, and different branches all the way up and the way this was classically done. And I'm no evolutionary biologist. The evolutionary biologists are very tell me every day, at least ten times. I want to be one, though. I kind of like biology. It's kind of cool.
Speaker B: Yeah, it's very cool.
Speaker A: But basically, what Darwin and Mendeleev and all these people do is just, they draw pictures, right? And they tax her. They just con, they were able to draw pictures and say, oh, these look like common classes. Then.
Speaker B: There are artists, really. They're just, you know.
Speaker A: But they were able to find out a lot, right, in looking at Verber inverts Cameron explosion and all this stuff. And then came the genomic revolution, and suddenly everyone used gene sequencing. And Craig Venter is a good example. I think he's gone around the world in his yacht, just picking up samples, looking for new species where he's just found new species of life just from sequencing. It's amazing. So you have taxonomy, you have sequencing, and then you can also do a little bit of kind of molecular kind of archaeology, like measure the samples and kind of form some inference. What we did is we were able to fingerprint, we took a load of random samples from all of biology, and we used mass spectrometry. And what we did now is not just look for individual molecules, but we looked for coexisting molecules where they had to look at their joint assembly space, and where we were able to cut them apart and undergo recursion in the mass spec and infer some relationships. And we're able to recapitulate the tree of life using mass spectroscopy. No sequencing and no drawing.
Speaker B: All right, can you try to say that again with a little more detail? So, recreating, what does it take to recreate the tree of life? What does the reverse engineering process look like here?
Speaker A: So what you do is you take an unknown sample, you pung it into the mass spec you get, because this comes from what you ask, like, what do you see in E. Coli? And so in E. Coli, you don't just see, it's nothing. It's not that the most sophisticated cells on earth make the most sophisticated molecules. It is the coexistence of lots of complex molecules above a threshold. And so what we realize is you could fingerprint different life forms. So fungi make really complicated molecules. Why? Because they can't move. They have to make everything on site. Whereas some animals are like lazy, they can just go eat the fungi, they don't need to make very much. And so what you do is you look at the, so you take, I don't know, the fingerprint, maybe the top number of high molecular weight molecules you find in the sample. You fragment them to get their assembly indices. And then what you can do is you can infer common origins of molecules. You can do a kind of molecular, when the reverse engineering of the assembly space, you can infer common roots and look at what's called the joint assembly space. But let's translate that into the experiment. Take a sample, bung it the mass spec, take the top, say ten molecules, fragment them, and that gives you one fingerprint. Then you do it for another sample, you get another fingerprint. Now the question is, you say, hey, are these samples the same or different? And that's what we've been able to do. And by basically looking at the assembly space that these molecules create without any knowledge of assembly theory, you are unable to do it. With a knowledge of assembly theory, you can reconstruct the tree.
Speaker B: How does knowing if they're the same or different give you the tree?
Speaker A: Let's go to two leaves on different branches on the tree. Right. What you can do, by counting the number of differences, you can estimate how far away their origin was. And that's all we do. And it just works. But when we realized you could even use assembly theory to recapitulate the tree of life with no gene sequencing, we were like, huh?
Speaker B: So this is looking at samples that exist today in the world. What about, like, things that are no longer exist? I mean, the tree contains information about the past.
Speaker A: I would.
Speaker B: Some of it is gone.
Speaker A: Yeah, absolutely. I would love to get old fossil samples and apply assembly theory, mass spec and see if we can find new forms of life that have, that are no longer amenable to gene sequencing because the DNA is all gone. Because DNA in RNA is quite unstable, but some of the more complex molecules might be there that might give you a hint of something new. Or wouldn't it be great if you, if you find a sample that's worth really persevering and doing, you know, doing the proper extraction to, you know, PCR and so on, and then sequence it and then put it together so when.
Speaker B: A thing dies, you can still get some information about its complexity.
Speaker A: Yeah, and we can, and it appears that you can do some dating. Now. There are really good techniques. There's radiocarbon dating, there is longer dating go and looking at radioactive minerals and so on. And you can also, in bone, you can look at the, what happens after something dies is you get what's called racemization, where the chirality in the polymers basically changes and you get decomposition and the deviation from the pure enantiomer to the mixture. It gives you a time scale on it, half life, so you can date when it died. I want to use assembly theory, see if I can use it, date death and things, and trace the tree of life and also decomposition of molecules.
Speaker B: You think it's possible?
Speaker A: Oh, yeah, without a doubt. It may not be better than what? Because, like, I was just at a conference where some brilliant people were looking at isotope enrichment and looking at how life enriches isotopes, and they're really sophisticated stuff that they're doing, but I think there's some fun to be had there, because it gives you another dimension of dating. How old is this molecule in terms of, or more importantly, how long ago was this molecule produced by life? The more complex a molecule, the more prospect for decomposition, oxidation, reorganization, loss of chirality and all that jazz. But what life also does is it enriches. As you get older, the amount of carbon 13 in you goes up because of the way the bonding is in carbon 13. So it has a slightly different strength bond. Strengthen you is called a kinetic isotope effect. So you can literally date how old you are, or when you stop metabolizing, so you could date someone's debt how old they are. I think I'm making this up. This might be right, but I think it's roughly right. The amount of carbon 13 you have in you, you can kind of estimate how old you are.
Speaker B: How old living organ. Humans are living.
Speaker A: Yeah, yeah. Like you could say, oh, this person is ten years old and this person 30 years old, because they've been metabolizing more carbon and they've accumulated it. That's the basic idea. It's probably completely wrong.
Speaker B: Time scale signatures of chemistry are fascinating. So you've been saying a lot of chemistry examples for assembly theory. What if we zoom out and look at a bigger scale of an object, like really complex objects like humans or living organisms that are made up of millions or billions of other organisms. How do you try to apply assembly theory to that?
Speaker A: At the moment, we should be able to do this to morphology in cells. So we're looking at cell surfaces, and really I'm trying to extend further. It's just that we work so hard to get this paper out and people to start discussing the ideas, but it's kind of funny because I think the penny is falling on this.
Speaker B: What does it mean for a penny?
Speaker A: The pennies dropped, right? Because a lot of people were like, it's rubbish, it's rubbish. You've insulted me, it's wrong. And I'm. And then, you know, I mean, the paper got published on the 4 October, it had 2.3 million engagements on Twitter, right? And it's been downloaded over a few hundred thousand times. And someone actually said to me, wrote to me and said, this is an example of really bad writing and what not to do. And I was like, if all of my papers got read this much, because that's the objective of, I have a publishing paper on people to read it. I want to write that badly again.
Speaker B: Yeah. I don't know what's the deep insight here about the negativity in the space? I think it's probably the immune system of the scientific community making sure that there's no bullshit that gets published and it can over fire, it can do a lot of damage, it can shut down conversations in a way that's not productive.
Speaker A: We go back, I mean, I'll answer your question about the hierarchy and assembly, but let's go back to the perception, people saying the paper was badly written. I mean, of course we could improve it. We could always improve the clarity.
Speaker B: Let's go there. Before we go to the hierarchy, you know, it has been criticized quite a bit, the paper. What has been some criticism that you found most powerful, like that you can understand and can you explain it?
Speaker A: Yes. The most exciting criticism came from the evolutionary biologist telling me that they thought that origin of life was a solved problem. And I was like, whoa, we're really onto something, because it's clearly not. And when you poked them on that, they just said, no, you don't understand evolution. And I said, no, no, I don't think you understand that evolution had to occur before biology. And we need, there's a gap. That was really, for me, that misunderstanding, and that did cause an immune response, which was really interesting. The second thing was the fact that physicists, the physicists were actually really polite, right, really nice about it, but they just said, huh, we're not really sure about the initial conditions thing, but this is a really big debate that we should certainly get into, because the emergence of life was not encoded in the initial conditions of the universe, and it can't. And I think assembly theory shows why it can't be.
Speaker B: Sure.
Speaker A: If you could say that again, the emergence of life was not and cannot in principle be encoded in the initial conditions of the universe.
Speaker B: Just to clarify, what we mean by life is like, what, high assembly index objects.
Speaker A: Yeah. And this goes back to your favorite subject, what's that? Time.
Speaker B: Right. So why, so why, what does time have to do with it?
Speaker A: I mean, probably we can come back to it later, but I think it might be if we have time. But I think that. I think I now understand how to explain how lots of people got angry with the assembly paper. But also the ramifications of this is how time is fundamental in the universe and this notion of commentarial spaces. And there are so many layers on this, but you have to become an intuition, I think you have to become an intuitionist mathematician, and you have to abandon platonic mathematics. And also platonic mathematics has left physics astray. But there's a lot to unpack there so we can go to the platonic mathematics.
Speaker B: Okay. It's okay. The evolutionary biologists criticize because the origin of life is understood and not, it doesn't require an explanation that involves physics.
Speaker A: Yeah.
Speaker B: That's their statement.
Speaker A: Well, I mean, it was, I think they said lots of confusing statements. Basically, I realized the evolutionary biology community that were vocal and some of them really rude, really spiteful and needlessly so. Right. Because, like, you know, I didn't. People misunderstand publication as well. Some of the people have said, how dare this be published in nature? This is, you know, how. What a terrible journal. And it really, and I want to set the people look, this is a brand new idea that's not only potentially going to change the way we look at biology, it's going to change the way we look at the universe. And everyone's like saying, how dare you? How dare you be so grandiose? I'm like, no, no, no, this is not hype. We're not like saying we've invented some, I don't know, we've discovered an alien in a closet somewhere just for hype. We genuinely mean this to genuinely have the impact or ask the question. And the way people jumped on that was a really bad precedent for young people who want to actually do something new, because this makes a bold claim, and the chances are that it's not correct. But what I wanted to do is a couple of things, is I want to make a bold claim that was precise and testable and correctable, not a woolly, another woolly information in biology argument information, turing machine, blah, blah, blah, blah, blah. A concrete series of statements that can be falsified and explored and either the theory could be destroyed or built upon.
Speaker B: Well, what about the criticism of you're just putting a bunch of sexy names on something that's already obvious?
Speaker A: Yeah, that's really good. So the assembly index of a molecule is not obvious. No one had measured it before, and no one has thought to quantify selection, complexity and copy number before in such a primitive, quantifiable way. I think the nice thing about this paper, this paper is a tribute to all the people that understand that biology does something very interesting. Some people call it neg entropy. Some people call it, think about organizational principles, that. Lots of people were not shocked by the paper because they'd done it before. A lot of, the lot of the arguments we got, some people said, oh, it's rubbish. Oh, by the way, I had this idea 20 years before. I was like, which one is it the rubbish part or the really revolutionary part? So this kind of plucked two strings at once. It plucked the. There is something interesting that biology does. We can see around this, but we haven't quantified yet. And what, this is the first stab at quantifying that. So the fact that people said, this is obvious, but it's also, if it's obvious, why have you not done it?
Speaker B: Sure. But there's a few things to say there. One is, this is in part of a philosophical framework, because it's not like you can apply this generally to any object in the universe. It's very chemistry focused.
Speaker A: Yeah. Well, I think you will be able to. We just haven't got there robustly. We can say, how can we? Let's go up a level. So if we go up from level, we go up. Let's go up from molecules to cells, because you would jump to people and I jumped for motor cons, and both are good.
Speaker B: And they will be assembled sickle cells.
Speaker A: Yeah. So if we go from molecules to assemblies and let's take a cellular assembly. A nice thing about a cell is you can tell the difference between a eukaryote and a prokaryote, right. The organelles are specialized differently. We then look at the cell surface, and the cell surface has different glycosylation patterns, and these cells will stick together. Now let's go up a level. In multicellular creatures, you have cellular differentiation. Now, if you think about how embryos develop, you go all the way back, those cells undergo a differentiation in a causal way. That's biomechanically a feedback between the genetics and biomechanics. I think we can use assembly theory to apply to tissue types. We can even apply it to different cell disease types. So that's what we're doing next. But we're trying to walk. You know, the thing is, I'm trying to leap ahead. I want to leap ahead to go, whoa. We apply it to culture, but clearly you can apply it to memes and culture. And we've also applied assembly theory to cas and not, as you think, cellular automata, but yeah, yeah, to cellular automata, not just as you think. Different CA rules were invented by different people at different times. And one of my, one of my co workers, very talented chap, basically was like, oh, I can realize that different people had different ideas with different rules and they copied each other and made slightly different bit, but different cellular automata rules. And they. And looked at them online. And so he was able to affirm assembly index and copy number of rule, whatever, doing this thing. But I digress. But it does show you can apply it at higher scale. So what do we need to do to apply assembly theory? Two things we need to agree. There's a common set of building blocks. So in a cell, well, in a. In a multicellular creature, you need to look back in time. So there is the initial cell, which the creature is fertilized and then starts to grow, and then there is cell differentiation. And you have to then make that causal chain both on those that requires development of the organism in time. Or if you look at the cell surfaces and the cell types, they've got different features on the cell walls and inside the cell. So we're building up. But obviously, I want a leap to things like emoticons, language, mathematical theory.
Speaker B: That's a very large number of steps to get from a molecule to the human brain.
Speaker A: Yeah. And I think they are related, but in hierarchies of emergence. Right. So you shouldn't compare them. I mean, the assembly index of a human brain, what does that even mean? Well, maybe we can look at the morphology of the human brain. Say all human brains have these number of features in common. If they have those number. And then let's look at a brain in a whale or a dolphin or a chimpanzee or a bird and say, okay, let's look at the assembly indices, number of features in these. And now the copy number is just a number of how many birds are there, how many chimpanzees are there, how many humans are there.
Speaker B: Then you have to discover for that the features that you would be looking for.
Speaker A: Yeah. And that means you need to have a, you need to have some idea of the anatomy.
Speaker B: But is there an automated way to.
Speaker A: Discover features, I guess so. I mean, and I think this is a good way to apply machine learning and image recognition just to basically characterize.
Speaker B: Things, apply compression to it to see what emerges, and then use the thing, the features used as part of the compression, as the measurement of, as the thing that is searched for when you're measuring assembly index and copy number one.
Speaker A: And the compression has to be, remember the assembly universe, which is you have to go from assembly possible to assembly contingent, and that jump from, because assembly possible, all possible brains, all possible features all the time. But we know that on the tree of life and also on the lineage of life going back to Luca, the human brain just didn't spring into existence yesterday. It is a long lineage of brains going all the way back. And so if we could do assembly theory to understand the development, not just in evolutionary history, but in biological development, as you grow, we are going to learn something more.
Speaker B: What would be amazing is if you can use assembly theory, this framework, to show the increase in the assembly index, associate with, I don't know, cultures or pieces of text like language or images and so on, and illustrate without knowing the data ahead of time, just kind of like you did with NASA, that you're able to demonstrate that it applies in those other contexts, I mean, and that, you know, probably wouldn't at first. And you have to evolve the theory somehow. You have to change it, you have to expand it, you know?
Speaker A: I think so.
Speaker B: But like that, I guess this is, as a paper, a first step in saying, okay, can we create a general framework for measuring complexity of objects, for measuring life, the complexity of living organisms? Yeah, that's what this is reaching for.
Speaker A: That is the first step. And also to say, look, we have a way of quantifying selection and evolution in a fairly. In a fairly. Not mundane, but a fairly mechanical way, because before now, it wasn't very. The ground truth for it was very subjective, whereas here we're talking about clean observables and there's going to be layers on that. I mean, with collaborators right now, we already think we can do assembly theory on language. And not only that, wouldn't it be great if we can? So if we can figure out how under pressure, language is going to evolve and be more efficient, because you're going to want to transmit things. And again, it's not just about compression. It is about understanding how you can make the most of the. In the architecture you've already built. And I think this is something beautiful that evolution does. We're reusing those architectures, we can't just abandon our evolutionary history. And if you don't want to abandon your evolutionary history and you know that evolution has been happening, then assembly theory works. And I think that's a key comment I want to make, is that assembly theory is great for understanding where evolution has been used. The next jump is when we go to technology. Because of course if you take the M three processor, I want to buy, I haven't bought one yet, I can't justify it, but I want to at some point. The M three processor, arguably there's quite a lot of features, a quite large number. The M two came before it, then the m one all the way back. You can apply assembly theory to microprocessor architecture. It doesn't take a huge leap to see that.
Speaker B: I'm a Linux guy, by the way. So your examples go way over.
Speaker A: Yeah, well whatever.
Speaker B: Is that like, is that a fruit company of some sort? I don't even know. Yeah, there's a lot of interesting stuff to ask about language. Like you could look at. How would that work? You could look at GPT one, GPT-2 GPT 3354, and try to analyze the kind of language it produces. I mean that's almost trying to look at assembly index of intelligent systems.
Speaker A: Yeah, I mean, I think the thing about large language models, and this is a whole hobby horse I have at the moment, is that obviously they're all about the, the evidence of evolution in the large language model comes from all the people that produced all the language. And that's really interesting. And all the corrections in the mechanical Turk, right? Sure.
Speaker B: That's part of the history, part of the memory of the system.
Speaker A: Exactly. So it would be really interesting to basically use an assembly based approach to making language in a hierarchy. Right. I think my guess is that you could, we might be able to build a new type of large language model that uses assembly theory, that it has more understanding of the past and how things were created. Basically the thing with LLMs is they're like everything everywhere, all at once, splat and make the user happy. So there's not much intelligence in the model. The model is how the human interacts with the model. But wouldn't it be great if we could understand how to embed more intelligence in the system?
Speaker B: What do you mean by intelligence there? Like you seem to associate intelligence with history.
Speaker A: Yeah, memory. I think selection produces intelligence.
Speaker B: You're almost implying that selection is intelligence.
Speaker A: No, kind of. I would go out on a limb and say that, but I think it's a little bit more. Human beings have the ability to abstract and they can break beyond selection. And this is what darwinian selection, because a human being doesn't have to basically do trial and error. They can think about. They say, oh, that's a bad idea, won't do that. And then technologies and so on.
Speaker B: So we escaped darwinian evolution and now we're onto some other kind of evolution. I guess higher levels.
Speaker A: And assembly theory will measure that as well. Right, because it's all a lineage.
Speaker B: Okay. Another piece of criticism, or by way of question, is how is assembly theory, or maybe assembly index, different from Kolmogorov complexity? So for people who don't know, Kolmogorov complexity of an object is the length of a shortest computer program that produces the object as output.
Speaker A: Yeah. There seems to be a disconnect between the computational approach to common goller off measure requires a Turing machine, requires a computer, and that's one thing. And the other thing is assembly theory is supposed to trace the process by which life evolution emerged. There's a main thing there. There are lots of other layers. So common Golorov complexity, you can approximate common go off complexity, but it's not really telling you very much about the actual, it's really telling you about your data set, compression of your data set. And so that doesn't really help you identify the turtle in this case is the computer. And so what assembly theory does is, I'm going to say, trigger warning for anyone listening who loves complexity theory. I think that we're going to show that AIT is a very important subset of assembly theory, because here's what happens. I think that assembly theory allows us to build, understand when selection is occurring. Selection produces factories and things. Factories, in the end produce computers, and you can get algorithmic information theory comes out of that. The frustration I've had with looking at life through this kind of information theory is it doesn't take into account causation. So the main difference between assembly theory and all these complexity measures is there's no causal chain.
Speaker B: Yeah.
Speaker A: And I think that's the main, that's.
Speaker B: The causal chain is at the, at the core of assembly theory.
Speaker A: Exactly. And if you've got your data in a computer memory, all the data is the same. You can access it in the same way. You don't care, you just compress it. And you either look at the program runtime or the shortest program. And that, for me, is absolutely not capturing what it is, what its selection does.
Speaker B: But assembly theory looks at objects. It doesn't have information about the object history. It's going to try to infer that history by looking for the shortest history.
Speaker A: Right.
Speaker B: The object doesn't like, have a Wikipedia page that goes with it about its history.
Speaker A: I would say it does in a way, and it is fascinating. Look, so you've just got the object and you have no other information about the object. What assembly theory allows you to do just with the object is to. And the word infer is correct. I agree with infer. You say, well, that's not the history, but something really interesting comes from this. The shortest path is inferred from the object. That is the worst case scenario if you have no machine to make it. So that tells you about the depth of that object in time. And so what assembly theory allows you to do is without considering any other circumstances, to say from this object, how deep is this object in time, if we just treat the object as itself without any other, any other constraints. And that's super powerful because the shortest path then says, allows you to say, oh, this object wasn't just created randomly, there was a process. And so assembly theory is not meant to, you know, one up ait or to ignore the factory is just to say, it's just to say, hey, there was a factory and how big was that factory and how deep in time is it?
Speaker B: But it's still computationally very difficult to compute that history. Right?
Speaker A: For complex objects it is, it becomes harder. But one of the things that's super nice is that it constrains your initial conditions, right? It constrains where you're going to be. So if you take, say, imagine. So one of the things we're doing right now is applying assembly theory to drug discovery. Now what everyone's doing right now is taking all the proteins and looking at the proteins and looking at molecules, doctor, proteins. Why not instead take the look at the molecules that are involved in interacting with the receptors over time, rather thinking about and use the molecules that evolve over time as a proxy for how the proteins evolved over time, and then use that to constrain your drug discovery process. You flip the problem 180 and focus on the molecule evolution rather than the protein, and so you can guess in the future what might happen. So rather than having to consider all possible molecules, you know where to focus. And that's the same thing. If you're looking at an assembly spaces for an object where you don't know the entire history, but you know that in the history of this object, it's not going to have some other motif there that it doesn't apply. It doesn't appear in the past.
Speaker B: But just even for the drug discovery point you made, don't you have to simulate all of chemistry to figure out how to come up with constraints?
Speaker A: No.
Speaker B: The molecules? No, I don't know enough about protein.
Speaker A: Well, this is another thing that I think causes, because this paper goes across so many boundaries. So chemists have looked at this and said, this is not correct reaction. It's like. No, it's a graph.
Speaker B: Sure. There's assembly index and shortest path examples here on chemistry.
Speaker A: Yeah. And what you do is you look at the minimal constraints on that graph. Of course, it has some mapping to the synthesis, but actually, you don't have to know all of chemistry. You just have to understand you can build up the constraint space rather nicely. But this is just at the beginning, right? There are so many directions this could go in. And as I said, it could all be wrong, but hopefully it's less wrong.
Speaker B: What about the little criticism I saw of, by way of question, do you consider the different probabilities of each reaction in the chain so that there could be different? When you look at a chain of events that led up to the creation of an object, doesn't it matter that some parts in the chain are less likely than others?
Speaker A: No, it doesn't matter. No. No. Well, let's go back. So, no, not less likely, but react. So, no. So let's go back to what we're looking at here. So the assembly index is the minimal path that could have created that object probabilistically. So imagine you have all your atoms in a plasma. You got enough energy, you've got enough. There's collisions. What is the quickest way you could zip out that molecule with no reaction constraints?
Speaker B: How do you define quickest there, then?
Speaker A: It's just basically a walk on a random graph. So we make an assumption that basically the time scale for forming the bonds. I don't want to say that, because it's going to have people getting obsessing about this point. And your criticism is a really good one. What we're trying to say is this puts a lower bound on something. Of course, some reactions are less possible than others, but actually, I don't think chemical reactions exist.
Speaker B: Oh, boy. What does that mean? Why don't chemical reactions exist?
Speaker A: I'm writing a paper right now that I keep being told I have to finish, and it's called the origin of chemical reactions, and it merely says that reactivity exists as controlled by the laws of quantum mechanics and reactions. Chemists put names on reactions. So you could have like, I don't know, the wittic reaction, which is by wittic, you could have the Suzuki reaction, which is by Suzuki. Now, what are these reactions? So these reactions are constrained by the following. They're constrained by the fact they're on planet Earth, one G 298 kelvin, 1 bar. So these are constraints. They're also constrained by the chemical composition of Earth, oxygen availability, all this stuff. And that then allows us to focus in our chemistry. So when a chemist does a reaction, that's a really nice compressed shorthand for constraint application. Glass flask, pure reagent, temperature, pressure, bomb, bomb, bomb bomb, bomb control. Control. So of course we have bond energies. So the bond energies are kind of intrinsic in a vacuum, if you say that. So the bond energy, you have to have a bond. And so for assembly theory to work, you have to have a bond, which means that bond has to give the molecule certainly a half life. So you're probably going to find later on that some bonds are weaker and that you are going to miss in mass spectrum. When you look at the assembly of some molecules, you're going to miscount the assembly of the molecule because it falls apart too quickly because the bonds just form. But you can solve that with looking infrared. So when people think about the probability, they're kind of misunderstanding. Assembly theory says nothing about the chemistry because chemistry is chemistry and the constraints are put in by biology. There was no chemist on the origin of life, bacon, unless you believe in the chemist in the sky. And they were, you know, it's like Santa Claus, they had a lot of work to do. But chemical reactions do not exist in the constraints that allow chemical transformations to occur do exist.
Speaker B: Okay. Okay. So it's constraint application. So there's no chemical reactions. It's all constraint application.
Speaker A: Yeah.
Speaker B: Which enables the emergence of react. Of, what's a different word for chemical reaction?
Speaker A: Transformation. Transformation, yeah, like a function. It's a function, but no, but I love chemical reactions as a shorthand and. Yeah, and so the chemists don't all go mad. I mean, of course chemical reactions exist on earth.
Speaker B: It's a shorthand.
Speaker A: It's a shorthand for all these constraints.
Speaker B: Right. So assuming all these constraints that we've been using for so long that we just assume that that's what was the case in natural language conversation.
Speaker A: Exactly. The grammar of chemistry, of course, emerges in reactions and we can use them reliably, but I do not think the wittic reaction is accessible on Venus.
Speaker B: Right. And this is useful to remember, you know, to frame it as constraint application is useful for when you zoom out to the bigger picture of the universe and looking at the chemistry of the universe and then starting to apply assembly theory. Yeah, that's interesting. That's really interesting. But we've also pissed off the chemists now.
Speaker A: Oh, that's pretty happy, but. Well, most of them.
Speaker B: No, everybody. Everybody deep down is happy. I think they're just sometimes feisty. That's how they show. That's how they have fun.
Speaker A: Everyone is grumpy on some days when they. When you challenge. The problem with this paper is you. Why is like, it's almost like I went to a park. It's like you. I used to do this occasionally when I was younger. Go to a meeting and just find a way to offend everyone at the meeting simultaneously. Even the factions that don't like each other, they're all unified in their hatred of you, just offending them. This paper, it feels like the person that went to the party and offended everyone simultaneously, so stopped fighting with themselves and just focused on this paper.
Speaker B: Maybe just a little insider interesting information. What were the editors of nature, the reviews and so on? How difficult was that process? Because this is a pretty, like, big paper.
Speaker A: Yeah, I mean, the. So when we originally sent the paper, we sent the paper and the editor said that, you know, this was like, this was quite a long process. We sent the paper and the editor gave us some feedback and said, you know, I don't think it's that interesting. It's not, you know, or it's hard. It's a hard concept. And we asked and the editor gave us some feedback, and we, and Sarah and I took a year to rewrite the paper.
Speaker B: Was the nature of the feedback very specific on, like, this part? This part? Or was it like, like, what are you guys smoking? What kind of.
Speaker A: Yeah, it was kind of the latter. What you smoking?
Speaker B: Okay.
Speaker A: And, you know.
Speaker B: But polite and there's promise.
Speaker A: Yeah, well, the thing is, there was, the edit was really critical, but in a really professional way. And, I mean, for me, this was the way science should happen. So when it came back, you know, we had too many equations in the paper. If you look at the preprint, they're just equations everywhere. Like 23 equations. And when I said to Abhishek, who was the first author, we've got to remove all the equations. But my assembly equation, staying in Abhishek, was like, you know, no, we can't. I said, well, look, if we want to explain this to people, there's a real challenge. And so Sarah and I went through the I think it was actually 160 versions of the paper, but we basically, we got to version 40 or something. We said, right, zero. Let's start again. So we wrote the whole paper again. We knew the entire amazing. And we just went bit by bit by bit and said, what is it we want to say? And then we send the paper in, and we expected it to be rejected and not even go to review. And then we got notification back it had gone to review, and we were like, oh, my God, it's so going to get rejected. How's it going to get rejected? Because first assembly paper on the mass spec we sent to nature went through six rounds of review and rejected, right? And by a chemist just said, I don't believe you. You must be committing fraud. Long story, probably a boring story, but in this case, it went out to review. The comments came back, and the comments were incredibly. No, they were very. They were very deep comments from all the reviewers there were. And. But the nice thing was, the reviewers were kind of very critical but not dismissive. They were like, oh, really? Explain this. Explain this. Explain this. Explain this. Are you sure it's not common golla off? Are you sure it's not this? And we went through, I think, three rounds of review pretty quick, and the editor went, yeah, it's in.
Speaker B: But maybe you could just comment on the whole process. You've published some pretty huge papers on all kinds of topics within chemistry and beyond. Some of them have some little spice in them, a little spice of crazy, like Tom Wade says, I like my tom with a little drop of poison. It's not a mundane paper. So what's it like psychologically to go through all this process, to keep getting rejected, to. To get reviews from people that don't get the paper or all that kind of stuff? Just from a question of a scientist, what is that like?
Speaker A: I think it's. I mean, this paper, for me, kind of, because this wasn't the first time we tried to publish assembly theory at the highest level. The nature communications paper on the mass spec on the idea went through, went to nature and got rejected. Went through six rounds of review and got rejected. And I just was so confused when the chemist said, this can't be possible. I do not believe you can measure complexity using mass spec. And also, by the way, molecules, complex molecules, can randomly form. And will I put a look at the data, the data says. And they said, no, no, we don't believe you. And we went, and I just wouldn't give up. And the editor, in the end, was just like, different editors, actually. Right.
Speaker B: What's behind that? Never giving up. Like, when you're sitting there 10:00 in the evening, there's a melancholy feeling that comes over you. You're like, okay, this is rejection number five. Or it's not rejection, but maybe it feels like a rejection because, you know, the comments are that you totally don't get it. Like, what gives you strength to keep going there?
Speaker A: Yeah. I don't know. I don't normally get emotional about papers, but it's not about giving up because we want to get it published, because we want the glory or anything. It's just like, why don't you understand? And so what I did, so what? I would just try to be as. As rational as possible and say, yeah, you didn't like it? Tell me why. And then, sorry. Silly.
Speaker B: Any part.
Speaker A: Never get emotional about papers normally. But I think what we did, you just compressed, like five years of angst from this.
Speaker B: So it's been rough.
Speaker A: It's not just rough. It's like it happened, you know, I came up with the assembly equation, you know, remote from Sarah in Arizona and the people SFI. I felt like I was a mad person. Like, you know, the guy in depicted in a beautiful mind who was just like, not, not the actual genius part, but just gibberish.
Speaker B: Gibberish.
Speaker A: Because I kept writing expanded, and I have no mathematical ability at all. And I was expand. I was making these mathematical expansions where I kept seeing the same motif again. I was like, I think this is a copy number. The same string is carrying again and again. I couldn't do the math. And then I realized the copy number fell out of the equation and everything collapsed down, I was like, oh, that works, kind of. So we submitted the paper, and then when it was almost accepted, right, the mass spec one, and it was, astrobiologists said, great. You know, a mass spectroscopist said, great. And the chemist went, nonsense. Like, biggest pile of nonsense ever. Fraudental. And I was like, but why fraud? And they just said, just because. And I was like, well. And I could not convince the editor in this case. The editor was just so pissed off because they see it as like a kind of, you know, you're wasting my time. And I would not give up. I wrote, I went and dissected all the parts. And I think, although, I mean, I got upset about it, you know, it was kind of embarrassing, actually, but I. But I guess beautiful. But it was just trying to understand why they didn't like it. So they were, part of me was like, really devastated. And a part of me was super excited because I'm like, huh? They can't tell me why I'm wrong. And this kind of goes back to when I was at school. I was in a kind of learning difficulties class, and I kept going to the teacher and say, what do I do today to prove I'm smart? And they were like, nothing. You can't. I was like, give me a job. You know, give me something to do. Give me a job to do. Something to do as we. And I kind of felt like that a bit when I was arguing with the. And not arguing. There was no ad hominem. I wasn't telling the editor they were idiots or anything like this, or the reviewers. I kept it strictly, like, factual. And all I did is I just kept knocking it down bit by bit by bit by bit by bit. It was ultimately rejected, and it got published elsewhere, and then the actual experimental data. So this is kind of in this paper, the experimental justification was already published. So when we did this one, and we went through the versions, and then we sent it in, and in the end, it just got accepted. We were like, well, that's kind of cool, right? This is kind of like some days you had the student, sorry. The first author was like, I can't believe it got accepted. Like, nor am I, but it's great. It's like, it's good. And then when the paper was published, I was not expecting the backlash. I was expecting computational. No, actually, I was just expecting one person who'd been trolling me for a while about it just to carry on trolling, but I didn't expect the backlash. And then I wrote to the editor and apologized, and the editor was like, what are you apologizing for? It was a great paper. Of course it's going to get backlash. You said some controversial stuff, but it's awesome.
Speaker B: And so it's. I think it's a beautiful story of perseverance, and the backlash is just a negative word for discourse, which I think is beautiful.
Speaker A: I think you, as I said to, you know, when it got accepted and people were saying, we're kind of, like, hacking on it, I was like, papers are not gold medals. The reason I wanted to publish that paper in nature is because it says, hey, there's something before biological evolution. You have to have that. If you're not a creationist, by the way, this is an approach. First time someone has put a concrete mechanism, or, sorry, a concrete quantification, and what comes next you're pushing on is a mechanism, and that's what we need to get to, is an autocaladic set, self replicating molecules, some other features that come in. And the fact that this paper has been so discussed for me is a dream come true. Like, it doesn't get better than that if you can't accept a few people hating it. And the nice thing is, the thing that really makes me happy, is that no one has attacked the actual physical content. Like, you can measure the assembly index, you can measure selection now. So either that's right, or it's, well. Well, either that's helpful or unhelpful. If it's unhelpful, this paper will sink down and no one will use it again. If it's helpful, it'll help people build scaffold on it, and we'll start to converge to a new paradigm. So I think that that's the thing that I wanted to see. My colleagues, authors, collaborators, and people were like, you've just published this paper. You're a chemist. Why have you done this? Who are you to be doing evolutionary theory, Mike? Well, I don't know. I mean.
Speaker B: Sorry, did I need to cause anyone to do anything? Well, I'm glad you did. Let me just. Before coming back to origin of life and these kinds of questions, you mentioned learning difficulties. I didn't know about this. So what was it like?
Speaker A: I wasn't very good at school.
Speaker B: Right, this is when you were very young?
Speaker A: Yeah, yeah. But in primary school, my handwriting was really poor, and apparently I couldn't read, and my mathematics was very poor. So they just said, this is a problem. They identified it. My parents kind of, at the time, were confused because I was busy taking things apart, buying electronic junk from the shop, trying to build computers and things. And then once I got out of. When I was. I think about the major transition in my stupidity. Like, you know, everyone thought I wasn't that stupid when I was. Basically, everyone thought I was faking. I like stuff and I was faking wanting to be it. So I always want to be a scientist. So five, six, seven years old, I'd be a scientist, take things apart, and everyone's like, yeah, this guy wants to be a scientist, but he's an idiot. And so everyone was really confused. I think at first that I wasn't smarter than I was claiming to be, and then I just basically didn't do well in the test. I went down and down and down and down, and then. And I was kind of like, huh, this is really embarrassing. I really like maths, and everyone says I can't do it. I really like kind of, you know, physics and chemistry and all that, and science and people say, you're not. You can't. You can't read and write. And so I found myself in a learning difficulties class at the end of primary school and the beginning of secondary school in the UK. Secondary school is like 1112 years old. And I remember being put in the. In the remedial class. And the remedial class was basically full of, well, two types, three types of people. There were people that had quite violent, right? And there were people who couldn't speak English and there were people that really had learning difficulties. So the one thing I can objectively remember was, I mean, I could read. I like reading, I read a lot. But something in me, I'm a bit of a rebel. I refuse to read what I was told to read. And I found it difficult to read individual words in the way they were told. But anyway, I got caught one day teaching someone else to read and they said, okay, we don't understand this. I always knew what to be a scientist, but didn't really know what that meant. And I realized you had to go to university. And I thought, I can just go to university, take curious people, like, no, no, no, you need to have these. You have to be able to enter these exams to get this grade point average. And the fact is, the exams you've been entered into and you're just going to get C, D or E. You can't even get a b or c, right? These are the UK GCSE's. I was like, oh, shit. And I said, can you just put me into the higher exams? I said, no, no, you're going to fail. There's no chance. So my father kind of intervened and said, you know, just let him go on the exams. And they said, he's definitely going to fail. It's a waste of time, waste of money. And he said, well, what have we paid? So they said, well, okay, so you didn't actually have to pay. You didn't have to pay if I failed. So I took the exams and passed them. Fortunately, I didn't get the top grades, but I got into a levels. But then that also kind of limited what I could do at a levels. I wasn't allowed to do a level maths.
Speaker B: What do you mean you weren't allowed to?
Speaker A: Because I had such a bad math grade from my GCSE. I only had a c, but they wouldn't let me go into the ABC for maths because of some kind of coursework requirement back then. So the top grade I could have got was a c. So C dual ethereum. And then let me do kind of as level maths, which is this half intermediate, but get to go to university. But in the archaeological chemistry, I had a good chemistry teacher. So in the end, I got to university to do chemistry.
Speaker B: So through that kind of process, I think for kids in that situation, it's easy to start believing that you're not well, how do I put it? That you're stupid and basically give up, that you're just not good at math, you're not good at school. So this is by way of advice for people, for interesting people, for interesting young kids right now experiencing the same thing. Where was the place? What was the source of you not giving up there?
Speaker A: I have no idea, other than I. I was really. I really, like not understanding stuff. For me, when I not understand something I didn't understand, I feel like I don't understand anything, but now. But back then, I was so. I remember when I was like, I don't know, I tried to build a laser when I was like, eight, and I thought, how hard could it be? And I basically, I was going to build a co. Was going to build a CO2 laser, and I was like, right, I think I need some partially coated mirrors. I need some carbon dioxide, and I need a high voltage. So I kind of like, I didn't have a. And I was so stupid, right. I was kind of so embarrassed. I. To make enough CO2, I actually set a fire and tried to filter the flame.
Speaker B: Oh, nice.
Speaker A: To crap it off, CO2. And I was like, it completely failed. And I bent. Burnt half the garage down. So my parents were not very happy about that. So that was one thing I was like, I really like first principle thinking. And so I remember being super curious and being determined to find answers. And so when people do give advice about this, well, I ask for advice about this. I don't really have that much advice other than don't give up. And one of the things I try to do as a chemistry professor in my group is I hire people that I think that who am I? If they're persistent enough, who am I to deny them the chance? Because people gave me a chance and I was able to do stuff.
Speaker B: Do you believe in yourself? Essentially.
Speaker A: So I love being around smart people, and I love confusing smart people. And when I'm confusing smart people, not by stealing their wallets and hiding it somewhere, but if I can confuse smart people, that is the one piece of hope that I might be doing something interesting.
Speaker B: Wow, that's quite brilliant. Like, as a gradient to optimize.
Speaker A: Yeah.
Speaker B: Hang out with smart people and confuse them. And the more confusing it is, the more there's something there.
Speaker A: And as long as they're not telling you, just a complete idiot. And. And they give you different reasons.
Speaker B: Yeah.
Speaker A: And I mean, I'm, you know, if everyone. It's like with assembly theory, and people said, oh, it's wrong. And I was like, why? And they're like, and no one could give me a consistent reason. They said, oh, because it's been done before, or it's just komagola, or it's just there. That and the other. So I think the thing that I like to do is. And in academia, it's hard, right. Because people are critical. But I mean, you know, the criticism. I mean, although I got kind of upset about it earlier, which is kind of silly, but not silly, because obviously it's hard work being on your own or with a team spatially separated, like, during lockdown and trying to keep everyone on board and have some faith that. But I've always wanted to have a new idea, and so, you know, I like a new idea, and I want to. I don't want. I want to nurture it as long as possible. And if someone can give me actionable criticism, that's why I think I was trying to say earlier when I was kind of, like, stuck for words. Give me actionable criticism. You know, it's wrong. Okay, why is it wrong? You say, oh, it doesn't. Your equation's incorrect for this, or your method is wrong. And so what I try and do is get enough criticism from people to then triangulate and go back. And I've been very fortunate in my life that I've got great colleagues, great collaborators, funders, mentors, and people that will take the time to say, you're wrong, because. And then what I have to do is integrate the wrongness and go, oh, cool, maybe I can fix that. And I think criticism is really good. People have a go at me because I'm really critical. I'm like, but I'm not criticizing you as a person. I'm just criticizing the idea and trying to make it better and say, well, what about this? And sometimes my filters are truncating in some ways. I'm just like, that's wrong, that's wrong, that's wrong. What do this? And people are like, oh, my God, you just told me you destroyed my life's work. I'm like, relax. No, I'm just like, let's make it better. And I think that we don't do that enough because we're, you know, we're either personally critical, which isn't helpful, or we don't give any criticism at all because we're too scared.
Speaker B: Yeah, yeah. I've seen you be pretty aggressively critical, but it's. Every time I've seen it, it's the idea, not the person.
Speaker A: I'm sure I make mistakes in that. I mean, I argue lots with, with lots. I mean, I argue lots with Sarah, and she's, like, kind of shocked. I've argued with Yashta in the past, and he's like, you're just making Yasha buck. And you're like, you're just making that up. I'm like, no, not quite, but kind of. You know, I had a big argument with Sarah about time, and she's like, no, time. Time doesn't exist. I'm like, no, no time does exist. And now. And as she realized that her conception of assembly theory and my conception assembly theory, the same thing necessitated us to abandon the fact that time is eternal to actually really fundamentally question how the universe produces combinatorial novelty.
Speaker B: So time is fundamental for assembly theory. I'm just trying to figure out where you and Sarah converge.
Speaker A: So I think assembly theory is fine in this time right now, but I think it helps us understand that something interesting is going on. So there's. And I'm really inspired by a guy called Nick Gizzen. I'm going to butcher his argument, but I love his argument a lot, so I hope he forgives me if he hears about it. But basically, if you want free will, time has to be fundamental, and we can go. And if you want time to be fundamental, you have to give up on platonic mathematics, and you have to use intuitions. Mathematics, by the. By the way. And again, I'm going to butcher this. But basically Hilbert said that, you know, infinite numbers are allowed. And I think it was Brower said, no, you can't. All numbers are finite, so they're kind of like with. So let's go back a step, because it was like people can say, assembly theory seems to explain that large commentarial space allows you to produce things like life and technology, and that large commentarial space is so big, it's not even accessible to a Sean Carroll David Deutsch multiverse. The physicists saying that all of the universe already exists in time is probably provably. That's a strong word. Not correct that we are going to know that the universe, as it stands, the present, the way the present builds the future so big, the universe can't ever contain the future. And this is a really interesting thing. I think Max Tekmark has this mathematical universe where he says, you know, the universe is kind of like a block universe. I apologize to Max if I'm getting it wrong, but people think you can just move. You'd have the stat, you have the initial conditions, and you can run the universe right to the end and go backwards and forwards in that universe. That is not correct.
Speaker B: Let me load that in. The universe is not big enough to contain the future.
Speaker A: Yeah, that's why. That's it.
Speaker B: That's another. That's a beautiful way of saying that time is fundamental.
Speaker A: Yes. And you can have a. And that's what, this is why the law of the excluded middle, something is true or false, only works in the past. Is it going to snow in New York next week or in Austin? You might, in Austin say, probably not. In New York, you might say, yeah, if you go forward to next week and say, did it snow in New York last week? True or false? You can answer that question. The fact that the law of the excluded middle cannot apply to the future explains why time is fundamental.
Speaker B: Well, I mean, that's a good example, intuitive example, but it's possible that we might be able to predict, you know, whether it's gonna snow. If we had perfect information.
Speaker A: I think we're saying it. Not impossible. Impossible. So here's why. I'll make a really quick argument, and this argument isn't mine. It's. It's Nick's and a few other people.
Speaker B: Can you. Can you explain his view on fundamental, on time being fundamental?
Speaker A: Yeah. So I'll give my view, which kind of resonates with his. But basically, it's very simple, actually. He would say that free will, that your ability to design and do an experiment is exercising free will. So he used that thought process. I never really thought about it that way. And that you actively make decisions. I used to think that free will was a kind of. Kind of consequence of just selection. But I'm kind of understanding that human free will is something really interesting, and he very much inspired me. But I think that what Sarah Walker said, that inspired me as well. These will converge is that I think that the universe in the universe is very big. Huge. But actually, the place is largest in the universe right now. The largest place in the universe is Earth.
Speaker B: Yeah, I've seen you say that. And, boy, does that. That's a that's an interesting one to process. What do you mean by that? Earth is the biggest place in the.
Speaker A: Universe because we have this combinatorial scaffolding going all the way back from Luca. So you've, you've got cells that can self replicate, and then you go all the way to terraforming the earth. You've got all these architectures, the amount of selection that's going on, biological selection, just to be clear, biological evolution. And then you have multicellularity, then animals and abstraction. And with abstraction, there was another kick, because you can then build architectures and computers and cultures and language. And these things are the biggest things that exist in the universe because we can just build architectures that couldn't naturally arise anywhere. And the further that distance goes in time and this kind of is just gigantic.
Speaker B: And from a complexity perspective.
Speaker A: Yeah.
Speaker B: Okay, wait a minute. But, I mean, I know you're being poetic, but how do you know there's not other earth? Like, uh, like, how do you know? You're, you're basically saying earth is really special. It's awesome stuff. As far as we look out, there's nothing like it going on. But how do you know there's not nearly infinite number of places where cool stuff like this is going on?
Speaker A: I agree. And I would say, I'll say again, that Earth is the most gigantic thing we know in the universe. Commentarily, we know.
Speaker B: We know.
Speaker A: Now, I guess this is just purely a guess. I have no data, but other than hope. Well, maybe not hope, maybe no. I have some data that every star in the sky probably has planets, and life is probably emerging on these planets. The amount of contingency that is associated with life is that I think the commentarial space associated with these planets is so different, we are never going to, our causal cones are never going to overlap or not easily. And this is the thing that makes me sad about alien life. Why? It's why we have to create alien life in the lab as quickly as possible, because I don't know if we are going to be able to be able to build architectures that will intersect with alien intelligence.
Speaker B: Architectures intersect. You don't mean in time or space?
Speaker A: Time and the ability to communicate.
Speaker B: The ability to communicate, yeah.
Speaker A: My biggest fear, in a way, is that life is everywhere, but we become infinitely more lonely because of our scaffolding in that commentarial space because it's so big.
Speaker B: So you're saying the, the constraints created by the environment that led to the factory of darwinian evolution are just like, list a little tiny cone in a nearly infinite combinatorial space. So there's other cones like it. And why can't we communicate with other, like, just because we can't create it doesn't mean we can't appreciate the creation. Right. Sorry. Detect the creation.
Speaker A: I truly don't know, but I. It's an excuse for me to ask for people to give me money to make a planet simulator.
Speaker B: Yeah, right.
Speaker A: If I can make with a different kind of, like, another shameless say, it's like, give me money, I need.
Speaker B: This was all a long plug for a planet simulator.
Speaker A: It's like, you know, hey, I won't be the first in line to do my rick. My Rick garage has run out of room, you know.
Speaker B: Yeah, no, this is a planet simulator. You mean like a different kind of planet with different sets of environments and pressures?
Speaker A: Exactly. If we could basically recreate the selection before biology as we know it, that gives rise to a different biology. We should be able to put the constraints on where to look in the universe. So here's the thing. Here's my dream. My dream is that by creating life in the lab based upon constraints we understand, like this. Go for Venus type life or Earth type life or something. Again, do Earth 2.0. Screw it. Let's do IRF 2.0. An IRF 2.0 has a different genetic Alphabet. Fine, that's fine. Different protein Alphabet. Fine. We have cells and evolution, all that stuff. We will then be able to say, okay, life is a more general phenomena. Selection is more general than what we think is the chemical constraints on life. And we can point to James Webb and other telescopes at other planets that we are in that zone we are most likely to combinatorially overlap with. Right. So, because, you know, we basically. So there is chemistry.
Speaker B: You're looking for some overlap, and then.
Speaker A: We can then basically shine light on them, literally, and look at light coming back and apply advanced assembly theory to general theory of language that we will get and say, huh, in that signal, it looks random, but there's a copy number. Oh, this random set of things that shouldn't be. That looks like a true random number generator has structure as a not common golorov ait type structure, but evolutionary structure given by assembly theory. And we start to. But I would say that because I'm a shameless assembly theorist.
Speaker B: Yeah. It just feels like the. The cone. I might be misusing the word cone here, but the width of the cone is growing faster, is growing really fast to where eventually all the cones overlap, even in a very very, very large combinatorial space. It just. But then again, if you're saying the universe is also growing very quickly in.
Speaker A: Terms of possibilities, that's real. I hope that as we build abstractions, the main. I mean, one idea is that as we go to intelligence, intelligence allows us to look at the regularities around us in the universe, and that gives us some common grounding to discuss with aliens. And you might be right, we will overlap there even though we have completely different chemistry, literally completely different chemistry, that we will be our past information from one another. But it's not a given. And I have to kind of try and divorce hope and emotion away from what I can logically justify.
Speaker B: But it's just hard to intuit a world, a universe, where there's nearly infinite complexity, objects, and they somehow can't detect.
Speaker A: Each other, but the universe is expanding. But the nice thing is that I would say. I would look. You see, I think Carl Sagan did the wrong thing. Well, not the wrong thing. He flicked the Voyager probe around and pale blue dot said, look how big the universe is. I would have done it the other way around, said, look at the Voyager probe that came from the planet Earth, that came from Luca. Look at how big Earth is.
Speaker B: Then it produced that.
Speaker A: It produced that.
Speaker B: Yeah.
Speaker A: And I think is, like, completely amazing. And then that should allow people on Earth to think about, well, probably we should try and get causal chains off Earth onto Mars, onto the moon, wherever. Whether it's human life or martian life that we create, it doesn't matter. But I think this commentorial space tells us something very important about the universe and that I realized in assembly theory that the universe is too big to contain itself. And I think this is coming back. And I want to. I want to kind of change your mind about time, because I'm guessing that your time is just coordinate.
Speaker B: Yeah.
Speaker A: So I'm going to.
Speaker B: I'm going to change one of those.
Speaker A: I'm going to change one of those. I'm going to change your mind in real time or at least attempt.
Speaker B: Oh, in real time. There you go. I already got the tattoo, so this is going to be embarrassing if you change my mind.
Speaker A: But you can just add. You can just add a time onto it, right? Or erase it a bit. So. And the argument that I think that is really most interesting is, like people say, the initial conditions specify the future of the universe. Okay, fine. Let's say that's the case for a moment. Now let's go back to newtonian mechanics. Now, the uncertainty principle in newtonian mechanics is this. If I give you the coordinates of your. Of an object moving in space, and the coordinates of another object, and they collide in space, and you know those initial conditions, you should know exactly what's going to happen. However, you cannot specify these coordinates to infinite precision. Now, everyone said, you know, oh, this is kind of like, you know, the chaos theory argument. No, no, it's deeper than that. Here's a problem with numbers. This is where Hilbert and Brouwer fell out of. To have the coordinates of this object, a given object, colliding, you have to have them to infinite precision. That's what Hilbert says. It says, no problem, infinite precision is fine. Let's just take that for granted. But when the object is finite and it can't store its own coordinates, what do you do? So, in principle, if a finite object cannot be specified to infinite precision, in principle, the initial conditions don't apply.
Speaker B: Well, how do you know it can't store its.
Speaker A: Well, how do you store an infinitely long number in a finite size?
Speaker B: Well, we're using infinity very loosely here. No, no, we use infinite precision. I mean, not loosely, but very precise. So you think infinite precision is required?
Speaker A: Well, let's take the object. Let's say the object is a golf ball. Golf ball is a few centimeters in diameter. We can work out how many atoms are on the golf ball. And let's say we can store numbers down to atomic dislocations. So we can work out how many atoms there are in the golf ball, and we can store the coordinates in that golf ball down to that number. But beyond that, we can't. Let's make the golf ball smaller. And this is where I think that we think that we get randomness in quantum mechanics. And some people say you can't get randomness, quantum mechanics, deterministic. But, aha. This is where we realize that classical mechanics and quantum mechanics suffer from the same uncertainty principle, and that is the inability to specify the initial conditions to a precise enough degree to give you determinism. The universe is intrinsically too big, and that's why time exists. It's non deterministic. Looking back into the past, you can look at the. You can use logical arguments because you can say, was it true or false? You really know. But this is the fact we are unable to predict the future with the precision is not evidence of lack of knowledge. It's evidence the universe is generating new things.
Speaker B: Okay, so, to you, first of all, quantum mechanics, you can just say statistically, what's going to happen when two golf.
Speaker A: Balls hit each other statistically. Sure, I can say statistically what's going to happen. But then when they do happen, and you keep nesting it together, you can't. I mean, it goes almost back to look at, look at, look at. Let's think about entropy in the universe. So how do we understand entropy change? Well, we could do the look at or process. We can use the agordic hypothesis. We can also have, we can also have the counterfactuals where we have all the different states, and we can even put that in the multiverse. Right. But both those are kind of, they're non physical. The multiverse kind of collapses back to the same problem about the precision. So all the what you, if you accept, you don't have to have true and false going forward into the future, the real numbers are real, they're just, they're observables.
Speaker B: We're trying to see exactly where time being fundamental, sneaks in, and this difference between the golf ball can't contain its own position perfectly precisely how that leads to time needing to be fundamental.
Speaker A: Let me do you believe or do you accept you have free will?
Speaker B: Yeah, I think at this moment in time, I believe that I have free will.
Speaker A: So then you are. Then you have to believe that time is fundamental.
Speaker B: I understand that's the statement you've made.
Speaker A: Well, no, that we can logically follows, because if you don't have free will, so, like, if you're in it, if you're in a universe that has no time, the universe is deterministic. If it's deterministic, then you have no free will.
Speaker B: I think the space of how much we don't know is so vast that saying the universe is deterministic from that jumping there's no free will is just too difficult of a leap.
Speaker A: No, I logically follows. No, no, I don't disagree. I'm not saying any. I mean, it's deep and it's important. All I'm saying, and it's the difference, it's actually different to what I've said before, is that if you don't require platonistic mathematics and accepts that non determinism is how the universe looks, and that gives us our creativity in the way the universe is getting novelty. It's kind of really deeply important in assembly theory, because assembly theory starts to actually give you a mechanism why you go from boring time, which is basically initial conditions specify everything, to a mismatch in creative time. And I hope we'll do experiments. I think it's really important to. I would love to do an experiment that proved that time is fundamental and the universe is generating novelty. I don't know all the features of that experiment yet, but by having these conversations openly and getting people to think about the problems in a new way, better people, more intelligent people with good mathematical backgrounds can say, oh, hey, I've got an idea. I would love to do an experiment that. That shows that the universe. I mean, universe is too big for itself going forward in time. And I really, you know, this is why I really hate the idea of the Boltzmann brain. The Boltzmann brain makes me super kind of like, you know, everyone's having a free lunch. It's like saying. It's like, let's break all the laws of physics. So a Boltzmann brain is this idea that in a long enough universe, the brain will just emerge in the universe as conscious, and that neglects the causal chain of evolution required to produce that brain. And this is where the computational argument really falls down, because the computation is going to say, I can calculate the probability of a Boltzmann brain, and I can, and they'll give you a probability, but I can calculate probability of a Boltzmann brain zero.
Speaker B: Just because the space of possibilities is so large.
Speaker A: Yeah. It's like when we start fooling ourselves with numbers that we can't actually measure and we can't ever conceive of, I think it doesn't give us a good explanation. And I've become. I want to explain why life is in the universe. I think life is actually novelty minor. I mean, life basically mines novelty almost from the future and makes it actualizes it in the present.
Speaker B: Okay. Life is a novelty minor from the future that is actualized in the present.
Speaker A: Yep, I think so.
Speaker B: Novelty minor. First of all, novelty. What's the origin of novelty? When you go from boring time to creative time? Where is that? Is it as simple as randomness, like you're referring to?
Speaker A: I'm really struggling with randomness because I had a really good argument with Yasha Bach about randomness, and he said, randomness doesn't give you free will. That's insane, because you'd just be random. But I think. And I think he's right at that level. Yeah, but I don't think we. I don't think he is right on another level. And it's not about randomness. It's about. It's about constrained. I'm gonna sound like constrained opportunity. I'm making this up as I go along, so making this up. Constrained opportunity. So what I mean is, like, so you have to have. So that the novelty. What is novelty? You know, this is what I think is a funny thing you ever want to discuss, AI? Why I think everyone's kind of gone AI mad is that they're misunderstanding novelty. But let's think about novelty. Ask what is novelty? So I think novelty is a genuinely new configuration that is not predicted by the past. Right. And that you discover in the present. Right. And that is truly different. Right. Now, everyone says that. Some people say that novelty doesn't exist. It's always with precedent. I want to do experiments that show that that is not the case. And it goes back to a question you asked me a few moments ago, which is, where is the factory? Because I think the same mechanism that gives us a factory gives us novelty. And I think that is why I'm so deeply hung up on time. Of course I'm wrong, but how wrong? And I think that life opens up that commentarial space in a way that our current laws of physics as contrived in a deterministic initial condition universe, even with the get out of the multiverse, David Deutsch style, which I love, by the way, but I don't think is correct, but it's. It's really beautiful.
Speaker B: Multiverse.
Speaker A: David Deutsch's conception of the multiverse is kind of like given. But I think that the problem with wave particle duality and quantum mechanics is not about the multiverse. It's about understanding how determined the past is. Well, I don't just think that. Actually, this is a discussion I was having with Sarah about that, where she was like, oh, I think we've been debating this for a long time now about how do we reconcile novelty, determinism, indeterminism.
Speaker B: Just to clarify, both you and Sarah think the universe is not deterministic.
Speaker A: I won't speak for Sarah, but roughly, I think that the universe. I think the universe is deterministic looking back in the past, but undetermined going forward in the future. So I'm kind of having my cake and eating it here. This is because I fundamentally don't understand randomness, right? As Yasha told me, or other people told me. But if I adopt a new view now, which the new view is the universe is just non deterministic, but I'd like to refine that and say the universe appears deterministic going back in the past, but it's undetermined going forward in the future. So how can we have a determinist, a universe that has deterministically looking rules? That's non determined going into the future. It's this breakdown in precision in the initial conditions. And we have to just stop using initial conditions and start looking at trajectories and how the commentarial space behaves in expanding universe in time and space and assembly theory helps us quantify the transition to biology. And biology appears to be novelty mining because it's making crazy stuff. You know that we are unique to earth, right? There are objects on earth that are unique to earth that will not be found anywhere else because you can do the combinatorial math.
Speaker B: What was that statement you made about life? Is novelty mining from the future? Yeah. What's the little element of time that you introduced in.
Speaker A: So what I'm kind of meaning is because the future is bigger than the present in a deterministic universe. How do you go from the, how do the states go from one to another? I mean, there's a mismatch. Right?
Speaker B: Yeah.
Speaker A: So that must mean that you have a little bit of indeterminism, whether that's randomness or something else I don't understand. I want to do experiments to formulate a theory to refine that as we go forward. That might help us explain that. And I think that's why I'm so determined to try and crack a the non life to life transition, looking at networks and molecules and that might help us think about it, the mechanism. But certainly the future is bigger than the past in my conception of the universe. And some conception of the universe, by.
Speaker B: The way, that's not obvious, right? That's what the future being bigger than the past. Well, that's one statement. And the statement that the universe is not big enough to contain the future is another statement.
Speaker A: Yeah, yeah, yeah, yeah.
Speaker B: That one is a big one. That was a really big one.
Speaker A: I think so. I think. But I think it's entirely because, look, we have the second law and right now, I mean, I'm. We don't need the second law. If the future is bigger than the past, it follows naturally.
Speaker B: Right.
Speaker A: So why are we retrofitting all these, these sticking plasters onto our reality to hold on to a timeless universe?
Speaker B: Yeah, but that's because it, it's kind of difficult to imagine the universe that's. That can't contain the future.
Speaker A: But isn't that really exciting?
Speaker B: It's very exciting, but it's hard. I mean, we're humans on earth and we have a very kind of four dimensional conception of the world of 3d plus time. It's just hard to intuit a world where what does that even mean a universe that can't contain the future?
Speaker A: Yeah, it's kind of. It's kind of crazy, but obvious.
Speaker B: I mean, I suppose it sounds obvious. Yeah, if it's true.
Speaker A: But the nice thing is you can. So what I mean, so the reason why assembly theory turned me onto that was that let's just start in the present and look at all the complex molecules and go backwards in time and understand how evolutionary processes gave rise to them. It's not at all obvious that Taxol, which is one of the most complex natural products produced by biology, was going to be invented by biology. It's an accident. Taxol is unique to earth. There's no taxol elsewhere in the universe. And Taxol was not decided by the initial conditions. It was decided by this kind of, this interplay between the. So the past simply is embedded in the present. It gives some features. But why the past doesn't map to the future one to one is because the universe is too big to contain itself. That gives space for creativity, novelty, and some things which are unpredictable.
Speaker B: Okay, so given that you're disrespecting the power of the initial conditions, let me ask you about. So how do you explain that cellular automata are able to produce such incredible complexity given just basic rules and basic initial conditions?
Speaker A: I think that this falls into the Brouwer Hilbert trap. So how do you get a cellular automata produced complexity? You have a computer, you generate a display, and you map the change of that in time. There are some cas repeat like functions like, it's fascinating to me that for PI, there is a formula where you can go to the millionth decimal place of PI and read out the number without having to go there. But there are some numbers where you can't do that. You have to just crank through. Whether it's wolframian computational irreducibility or some other thing, it doesn't matter. But these cas that complexity. Is that just complexity or a number that is basically, you're mining that number in time. Is that just a display screen for that number, that function?
Speaker B: Well, can you say the same thing about the complexity on earth then?
Speaker A: No, because the complexity on earth has a copy number and an assembly index associated with it. That CA is just a number running.
Speaker B: You don't think it has a copy number? Wait, wait a minute.
Speaker A: Well, it does in the human, where we're looking at humans producing different rules, but then it's nested on selection. So those cas are produced by selection. Yeah, I mean, the CA is such a fascinating pseudo complexity generator. What I would love to do is understand, quantify the degree of surprise in a CA and write it long enough. But what I guess that means is we have to instantiate, we have to have a number of experiments where we're generating different rules and running them time spent steps. But. Oh, got it. Cas are mining novelty in the future by iteration. Right. And you're like, oh, that's great, that's great. You didn't predict it. Some rules you can predict what's going to happen, other rules you can't. So for me, if anything, Cas, are evidence that the universe is too big to contain itself, because otherwise you'd know what the rules are going to do forever more.
Speaker B: Right. I guess you were saying that the physicists saying that all you need is the initial conditions and the rules of physics is somehow missing the bigger picture.
Speaker A: Yeah.
Speaker B: And you know, if you look at cas, all you need is the initial condition and the rules and then run the thing.
Speaker A: You need three things. You need the initial conditions, you need the rules, and you need time iteration to mine it out. Without the coordinate, you can't get it out.
Speaker B: Sure. And that's that. That to use fundamental.
Speaker A: And you can't predict it from the initial conditions.
Speaker B: Yeah.
Speaker A: If you could, then be fine.
Speaker B: That time is a resource foundation of this is the history, the memory of each two things are created. It has to have that memory of all the things that led up to it.
Speaker A: I think it's. Yeah, you have to have the resource. Yeah, because time is a fundamental resource. And yeah, I'm becoming, I think I had a major epiphany about randomness, but I keep doing that every two days and then it goes away again. It's random.
Speaker B: You're a time fundamentalist.
Speaker A: You should be as well. If you believe in free will. The only conclusion is there is time is fundamental. Otherwise you cannot have free will. It logically follows.
Speaker B: Well, the foundation of my belief in free will is just observation driven. I think if you use logic, it's like logically it seems like the universe.
Speaker A: Is deterministic looking backwards in time. And that's correct, the universe is.
Speaker B: And then everything else is a kind of leap. It requires a leap.
Speaker A: I mean, I think that it's kind of, this is what I think machine learning is going to provide a big chunk of that. Right. Because it helped us explain this. So the way I'd say if you take, that's interesting.
Speaker B: Why?
Speaker A: Well, let's, let's just. My favorite one is because I'm the AI doomers are driving me mad. And, in fact, that we don't have any intelligence yet. I call AI autonomous informatics. Just to make people grumpy.
Speaker B: Yeah. And you're saying we're quite far away from AGI.
Speaker A: I think that we have no conception of intelligence, and I think that we don't understand how the human brain does what it does. I think that we are. Neuroscience is making great advances, but I think that we have no idea about AGI. So I am a technological, I guess, optimist. I believe we should do everything. The whole regulation of AI is nonsensical. I mean, why would you regulate excel, other than the fact that clippy should come back? And I love Excel 97, because we can play, you know, we can do the flight. Flight simulator.
Speaker B: I'm sorry, in Excel?
Speaker A: Yeah. Have you not played the flight simulator in 1990?
Speaker B: In Excel 97, yeah. What does that look like?
Speaker A: It's like wireframe, very, very basic, but basically, I think it's x zero, y zero shift, and it opens up and you can play the fight simulator.
Speaker B: Oh, wow. Wait, wait. Is he using Excel?
Speaker A: Excel. Excel 97.
Speaker B: Okay.
Speaker A: I resurrected it the other day and saw Clippy again for the first time in a long time.
Speaker B: Well, Clippy is definitely coming back. But you're saying we don't have a great understanding of what is intelligence? What is the intelligence?
Speaker A: I am very frustrated underpinning the human mind. I'm very frustrated, by the way, that we're AI dooming right now. People were bestowing some kind of magic. Now, let's go back a bit. So you said about AGI. Are we far away from AGI? Yes. I do not think we're going to get to AGI anytime soon. I've seen no evidence of it. And the AI doom scenario is nonsensical in the extreme, and the reason why I think it's nonsensical, but it's not. And I don't think there isn't things we should do and be very worried about. There are things we need to worry about right now. What AI doing, whether it's fake data, fake users. Right. I want authentic people or authentic data. I don't want everything to be faked. And I think it's a really big problem. And I absolutely want to go on the record to say I really worry about that. What I'm not worried about is that some fictitious entity is going to turn us all to paper clips or detonate nuclear bombs. I don't know. Maybe. I don't know. Anything you can't think of. Why is this is. And I'll take a very simple series of logical arguments. And this is the AI dumas have not had the correct. And this had not had the correct. They do not have the correct epistemology. They do not understand what knowledge is. And until we understand what knowledge is, they're not going to get anywhere because they're applying things falsely. So let me give you a very simple argument. People talk about the probability p doom AI. We can work out the probability of an asteroid hitting the planet. Why? Because it's happened before. We know the mechanism. We know that there's a gravity well or that space time is bent and stuff falls in. We don't know the probability of AGI because we have no mechanism. So let me give you another one, which is like, I'm really worried about Agda. What's ag is anti gravity. One day we could wake up in anti gravity. You know, it's discovered we're all going to die. The atmosphere is going to float away. We're going to float away. We're all doomed. What is the probability of ag? We don't know because there's no mechanism for ag. Do we worry about it? No. And I don't understand the current reason for these, for the, for certain people in certain areas to be generating this nonsense. I think they're not doing it maliciously. I think we're observing the emergence of new religions, how religions come, because religions are about kind of some control. So you got the optimists saying AI is going to cure us all and AI is going to kill us all. What's the reality? Well, we don't have AI. We have really powerful machine learning tools and they will allow us to do interesting things and we need to be careful about, about how we use those tools in terms of manipulating human beings and faking stuff.
Speaker B: Right, right. Well, let me, let me try just sort of steel, man, the AI doomers argument. Actually, I don't know. Are AI doomers in the Yadkowski camp saying it's definitely gonna kill us because there's a spectrum.
Speaker A: 95%, I think is the limit.
Speaker B: Yeah, 95% plus.
Speaker A: No, not plus. I think. I don't know. I was seeing on Twitter today various things, but I think yudakowski is at 95%.
Speaker B: But to belong to the AI Doomer club, is there a threshold? I don't know what the membership is maybe. And what are the fees?
Speaker A: I think, well, I saw, I think Scott Aronson, like I was quite surprised, had put two. I saw this online, so it could be wrong. So sorry if it's wrong says 2%. But the thing is, if you were to go, if you, if someone said there's a 2% chance you're gonna die going into the lift, would you go into the lift?
Speaker B: In the elevator.
Speaker A: For the elevator?
Speaker B: American English speaking audience well, no, not for the elevator.
Speaker A: So I would say anyone higher than 2%. I mean, like, I. I mean, I think there's a 0% chance of AGI doom. Zero.
Speaker B: Just to push back on the argument where the end of zero on the AGI, we can see on Earth that there's increasing levels of intelligence of organisms. We can see what humans with extra intelligence were able to do to the other species. So that is, uh, a lot of samples of data. What a delta in intelligence gives you when you have an increase in intelligence, how you're able to dominate a species on Earth. And so the idea there is that if you have a being that's ten x smarter than humans, we're not going to be able to predict what that's going to, with that being is going to be able to do, especially if it has the power to hurt humans, which you can imagine a lot of trajectories in which the more benefit AI systems give, the more control we give to those AI systems over our power grid, over our nuclear weapons or weapons of any sort. And then it's hard to know what ultra intelligence system would be able to do in that case. You don't find that convincing.
Speaker A: I think this is. I would fail that argument 100%. Here's a number of reasons to fail it on. First of all, we don't know where the intention comes from. The problem is that people think they keep watching all the hucksters online with a prompt engineering and all this stuff. When I talk to a typical AI computer scientist, they keep talking about the AI as having some kind of decision making ability. That is a category error. The decision making ability comes from human beings. We have no understanding of how humans make decision. We've just been discussing free will for the last half an hour. Right? We don't even know what that is. So the intention, I totally agree with you. People who intend to do bad things can do bad things, and we should not let that risk go. That's totally here and now. I do not want that to happen. And I'm happy to be regulated to make sure that systems I generate, whether they're like computer systems or, you know, I'm working on a new project called X called Ken Machina.
Speaker B: Nice. Well done.
Speaker A: Yeah, yeah. Which is basically a.
Speaker B: For people who don't understand the point that ex machina is a great film about, I guess, AGI embodied and chemistry, chemistry version of that.
Speaker A: And I only know one way to embody intelligence. That's in chemistry and human brainstor. So category error number one is agency. They have agency. Category error number two is saying that assuming that anything we make is going to be more intelligent. Now, you didn't say super intelligent. I'll put the words into our mouths here. Superintelligent. That I think that there is no reason to expect that we are going to make systems that are more intelligent, more capable. You know, when people play chess, computers, they don't expect to win now, right? They just. The chess computer is very good at chess. That doesn't mean it's super intelligent. So I think that super intelligence, I mean, I think even Nick Bostrom is pulling back on this now because he invented this. So I see this a lot. When does this first happen? Eric Drexler, nanotechnology, atomically precise machines. He came up with a world where we had these atom cogs everywhere. They were going to. We're going to make self replicating nanobots. Not possible. Why? Because there's no resources to build these self replicating nanobots. You can't get the precision. It doesn't work. It was a major category error in taking engineering principles down to the molecular level. The only functioning molecular technology we know. Not. Sorry, the only functioning nanomolecular technology we know produced by evolution. There. So now let's go forward to AGI. What is AGI? We don't know. It's super. It can do this or humans can't. Think that. I would argue the only AGIs that exist in the universe are produced by evolution. And sure, we may be able to make our working memory better. We might be able to do more things. The human brain is the most compact computing unit in the universe, uses 20 watts. It uses a ready limited volume. It's not like a chat GPT cluster, which has to have thousands of watts model that's generated and has to be corrected by human beings. You are autonomous and embodied intelligence. So I think that there are so many levels that we're missing out. We've just kind of went, oh, we've discovered fire. Oh, gosh, the planet's just going to burn one day randomly. I mean, I just don't understand that leap. There are bigger problems we need to worry about. So what is the motivation? Why are these people, let's assume they have their earnest, have this conviction? Well, I think it's just it's kind of, they're making leaps that they're trapped in a virtual reality that isn't reality.
Speaker B: Well, I mean, I can continue a set of arguments here, but also it is true that ideologies that fear monger are dangerous because you can then use it to control, to regulate in a way that halts progress, to control people and to, to cancel people, all that kind of stuff. So you have to be careful because the reason ultimately wins. Right. But there is a lot of concerns with super intelligent systems, very capable systems. When you, I think when I, when you hear the word super intelligent, you're hearing like, it's smarter than humans in every way that humans are smart. But the paperclip manufacturing system doesn't need to be smart in every way, just needs to be smart in a set of specific ways. And the more capable the AI systems become, the more you could see us giving them control over, like I said, our power grid, a lot of aspects of human life. And then that means they will be able to do more and more damage when there's unintended consequences that come to life.
Speaker A: I think that that's right. The unintended consequences we have to think about, and that I fully agree with. But let's go back a bit sentient. I mean, again, I'm far away from my comfort zone and all this stuff, but hey, let's talk about it, because I give myself a qualification.
Speaker B: Yeah, we're both qualified and sentience, I think.
Speaker A: Yeah.
Speaker B: So as much as anyone else, I.
Speaker A: Think the paperclip scenario is just such a poor one because, because let's think about how that would happen. And also let's think about we are being so unrealistic about how much of the earth's surface we have commandeered for paper clip manufacturing to really happen. I mean, do the math. It's like, it's not going to happen. There's not enough energy, there's not enough resource. Where is it all going to come from? I think that what happens in evolution is really why is, why has a killer virus not killed out all of, not killed all life on Earth? Well, what happens is, sure, super killer viruses that kill the ribosome have emerged, but you know what happens? They nuke a small space because they can't propagate. They all die. So there's this interplay between evolution and propagation, right, and death. And so in evolution, you don't think.
Speaker B: It'S possible to engineer, for example, sorry to interrupt, but like a perfect virus.
Speaker A: There'S deadly nothing, no nonsensical okay. I think that just wouldn't, again, it wouldn't work. So it was too deadly. It would just kill the radius and not replicate.
Speaker B: Yeah, I mean, you don't think it's possible to get a. I mean, if you were sup.
Speaker A: I mean, I if you were it.
Speaker B: Kill all of life on earth, but kill all humans. There's not many of us. There's only like 8 billion. There's so much more ants.
Speaker A: I mean, I don't, I.
Speaker B: So many more ants and they're pretty smart.
Speaker A: I think we. The nice thing about where we are, I would love for the AI crowd to take a leaf out of the book of the bio warfare, chemical warfare crowd. I mean, not love, because actually people have been killed with chemical weapons in the first and second world war and people and bioweapons have been made and we can argue about Covid-19 and all this stuff. Let's not go there just now. But I think there is a consensus that some certain things are bad and we shouldn't do them. Right. And sure, it would be possible for a bad actor to engineer something bad, but the damage would be, we would see it coming and we would be able to do something about it. Now, I guess what I'm trying to say is when people talk about doom and they just, when you ask them for the mechanism, they just say, you know, they just make something up. I mean, in this case, I'm with Jan Lecun. I think he put out a very good point about trying to regulate jet engines before we've even invented them. And I think that's what I'm saying. I'm not saying we should. I just don't understand why these guys are going around making, literally making stuff up about us all dying.
Speaker B: Yeah.
Speaker A: When basically we need to actually really focus on. Now, let's say there's some actors are earnest. Let's say Yudakowski is being earnest. Right. And he really cares, but he loves it. Goes, and then you're all going to die. It's like, you know, why don't we try and do the same thing and say you could do this and then you're going to be happy forever after. Yeah. You know.
Speaker B: Well, I think there's several things to say there. One, I think there is a role in society for people that say we're all going to die because I think it filters through as a message, as a viral message that gives us the proper amount of concern.
Speaker A: Okay. All right.
Speaker B: Meaning not the, it's not 95%, but when you say 95%, and it filters through society, you'll give an average of, like a 0.03% an average. So it's nice to have people that are like, we're all going to die, then we'll have a proper concern. Like, for example, I do believe we're not properly concerned about the threat of nuclear weapons currently, like that. It just seems like people have forgotten that that's a thing. And, you know, there's a war in Ukraine with the nuclear power involved. There's nuclear powers throughout the world. And it just feels like we're on the brink of a potential world war to a percentage that I don't think people are properly calibrating. Like, in their head, we're all thinking it's a twitter battle as opposed to, like, actual threat. So, like, it's nice to have that kind of level of concern. But to me, like, what I, when I hear AI doomers, what I'm imagining is with unintended consequences, a potential situation where, let's say, 5% of the world suffers deeply because of a mistake made of unintended consequences. I don't imagine the entirety of human civilization dying, but there could be a lot of suffering if this is done.
Speaker A: I understand that. And I'm, I kind of, I guess, I mean, I'm involved in the whole hype cycle. Like, why I would like us to. I don't want us to. So what's happening right now is there seems to be, so let me, let's say having some people saying AI doom is a worry, fine, let's give them that. But what seems to be happening is there seems to be people who don't think AI is doom, and they're trying to use that to control regulation and to push people to regulate, which stops humans generating knowledge. And I am an advocate for generating as much knowledge as possible when it comes to nuclear weapons. I grew up in the seventies and eighties where the nuclear doom, a lot of adults really had existential threat almost as bad as now with AI doom. They were really worried, right? There was some great, were not great. There were some horrific documentaries. I think there's one called freds that was generated in the UK, which was like, it was terrible. It was like, so scary. And I think that the correct thing to do is obviously get rid of nuclear weapons. But let's think about unintended consequences. We've got rid of. This is such a nonsecretary. We got rid of all the sulfur particles in the atmosphere, right? Or the soot. And what's happened in the last couple of years is global warming has accelerated because we've cleaned up the atmosphere too much.
Speaker B: Sure. I mean, the same thing. If you get rid of nuclear weapons, you get.
Speaker A: Exactly. That's my point. So what we could do is if we actually started to put the AI in charge, which is. I really like an AI to be in charge of all world politics. And this sounds ridiculous for a second. Hang on. But if we could all agree on the AI.
Speaker B: Drummers just woke up.
Speaker A: Yeah, yeah, yeah.
Speaker B: In that statement.
Speaker A: But I really don't like politicians who are basically just looking at local sampling. But if you could say globally. But here's some game theory here. What is the minimum number of nuclear weapons we need to distribute around the world to everybody to basically reduce war to zero?
Speaker B: I mean, just this thought experiment of the United States and China and Russia and major nuclear powers get together and say, all right, we're going to distribute nuclear weapons to every single nation on earth.
Speaker A: Yep.
Speaker B: Oh, boy. I mean, that has a probably greater than 50% chance of eliminating major military conflict. Yeah, yeah. But it's not 100%.
Speaker A: But. But I don't think anyone will use them because I think. I think. And look, what you've got to try and do is like, for. To qualify for these nuclear weapons. This is a great idea. The game theorists could do this. Right. I think the question is this. I really buy your question. We have too many nukes of. From just from a feeling point of view that we've got too many of them. So let's reduce the number, but not get rid of them, because we'll have too much conventional warfare. So then what is the minimum number of nuclear weapons we can distribute around to remove humans hurting each other is something we should stop doing. It's not out with our conceptual capability. But right now, what about the nations, certain nations that are being exploited for their natural resources in the future because for a short term gain, because we don't want to generate knowledge. And so if everybody had an equal doomsday switch, I predict the quality of life, average human will go up faster. I am an optimist and I believe that humanity is going to get better and better and better, that we're going to eliminate more problems. But I think. Yeah, let's.
Speaker B: But the probability of a bad actor, of one of the nations setting off a nuclear weapon, I mean, you have to. You have to integrate that into the.
Speaker A: But we get. We just give you the nukes like population. Right. We give. What we do is we can't. But anyway, let's just go there. So if a small nation with a couple of nukes uses one because they're a bit bored or annoyed, they're gonna. They. The likelihood that they are gonna be pummeled out of existence immediately is 100%. And yet they've only. They've only nuked one other city. I know this is crazy, and I apologize for.
Speaker B: Well, no, no, I think it's just to be clear, we're just having a thought experiment. That's interesting. But, you know, there's terrorist organizations that would take. That would take. Would take that trade.
Speaker A: Yeah.
Speaker B: I mean, we have to ask ourselves a question of how many, which percentage of humans would be suicide bombers, essentially, where they would sacrifice their own life because they hate another group of people. I believe it's a very small fraction. But is it large enough if you give out nuclear weapons?
Speaker A: I can predict a future where we take all nuclear material and we burn it for energy because we're getting there. And the other thing you could do is say, look, there's a gap. So if we get all the countries to sign up to the virtual nuclear agreement where we all exist, we have a simulation where we can nuke each other in the simulation, and the. And the economic consequences are catastrophic.
Speaker B: Sure. In the simulation. I love it. It's not going to kill all humans. It's just going to have economic consequences.
Speaker A: Yeah. I don't know. I just made it up. It seems, like interesting.
Speaker B: I mean, but it's interesting whether that would have as much power on human psychology as actual physical nuclear.
Speaker A: I think so.
Speaker B: It's possible. But people don't take economic consequences as seriously, I think, as actual nuclear weapons.
Speaker A: I think they do in Argentina and they do in Somalia, and they do in a lot of these places where. No, I think this is a great idea. I'm a strong advocate now for. So what have we come up with? Burning all the nuclear material to have energy. And before we do that, because mad is good, mutually assured destruction is very powerful. Let's take it into the metaverse and then get people to kind of subscribe to that. And if they actually nuke each other, even for fun, in the metaverse, there are dire consequences.
Speaker B: Yeah. Yeah. So it's like a video game. We all had to join this metaverse. Video game.
Speaker A: Yeah.
Speaker B: I can't believe it's dire economic consequences. I don't know how. And it's all run by AI, as you mentioned. So the AI doomers are really terrifying at this point.
Speaker A: No, they're happy to have a job for another 20 years, right?
Speaker B: Oh, fear monger.
Speaker A: Yeah, yeah, yeah. We got. I'm a believer in equal employment.
Speaker B: You've mentioned that. Would you call chem machina? Yeah, yeah. So you've mentioned that a chemical brain is something you're interested in creating, and that's a way to get conscious. AI soon. Can you explain what a chemical brain is?
Speaker A: I want to understand the mechanism of intelligence that's gone through evolution, right. Because the way that. The way that intelligence was produced by evolution appears to be the origin of life. Multicellularity, locomotion senses. Once you can start to see things coming towards you and you can remember the past and interrogate the present and imagine the future, you can do something amazing. Right? So. And I think only in recent years did humans become Turing complete, right?
Speaker B: Yeah.
Speaker A: And so that Turing completeness kind of gave us another kick up. But our ability to process that information is produced in a wet brain. And I think that we are not getting going. We do not have the correct hardware architectures to have the domain flexibility and the. The ability to integrate information. I think intelligence also comes at a massive compromise of data. Right now we're obsessing about getting more and more data, more and more processing, more and more tricks to get dopamine hits. So when we look back on this going, oh, yeah, that was really cool, because when I asked chat GPT, it made me really feel really happy. I got a hit from it, but actually it just exposed how little intelligence I use in every moment because I'm easily fooled. So what I would like to do is to say, well, hey, hang on, what is it about the brain? So the brain has this incredible connectivity and it has the ability to. As I said earlier about my nephew, I went from Bill to Billy and he went, all right, Leroy. How did he make that leap that he was able to? Basically, without any training, I extended his name. He went, gay. That he doesn't like. He wants to be called Bill. He went back and said, you like to be called Lee. I'm going to call you Leroy. So human beings have a brilliant ability, or intelligent beings appear to have a brilliant ability to integrate across all domains all at once and to synthesize something which allows us to generate knowledge and becoming Turing complete on our own, I don't. Although AI's are built in Turing complete things, their thinking is not Turing complete in that they are not able to build universal explanations. And that lack of universal explanation means that they're just inductivists. Inductivism doesn't get you anywhere. It's just basically a party trick. It's like, you know, the, I like the, I think it's in the fabric of reality from David Deutsch, where basically, you know, the farmer is feeding the chicken every day, and the chicken's getting fat and happy, and the chicken's like, I'm really happy every time the farmer comes in and feeds me. And then one day the farmer comes in and doesn't, instead of feeding the chicken, just rings its neck, you know? And that's kind of. And had the chicken had an alternative understanding of why the farmer was feeding it.
Speaker B: Mm hmm. It's interesting, though, because we don't know what's special about the human mind that's able to come up with these kind of generalities, uh, this universal theories of things.
Speaker A: So that's.
Speaker B: And will come up with novelty, I can imagine, because you gave an example, you know, you know, about William and Leroy. I I feel like example like that will be able to see in future versions of large language models, will be really, really, really impressed by the humor, the insights, all of it, because it's fundamentally trained on all the incredible humor and insights that's available out there on the Internet. Right. So we'll be impressed. I think we'll be impressed.
Speaker A: Oh, I'm impressed.
Speaker B: Right?
Speaker A: I'm impressed.
Speaker B: Increasingly so.
Speaker A: But we're mining the past.
Speaker B: Yes.
Speaker A: And what the human brain appears to be able to do is mine the future.
Speaker B: Yes. So, novelty. It is interesting whether these large language models will ever be able to come up with something truly novel.
Speaker A: I can show on the back of a piece of paper why that's impossible. And it's like, the problem is that, and again, these are domain experts kind of bullshitting each other. The term generative.
Speaker B: Yes.
Speaker A: Right. Average person. Oh, it's generous. No, no, no. Look, if I take the numbers between zero and 1000, and I train a model to pick out the prime numbers by giving them all the prime numbers between zero and 1000, it doesn't know what prime number is. Occasionally, if I can cheat a bit, it will start to guess. It never will produce anything out with the data set because you mine the past. The thing that I'm getting to is I think that actually current machine learning technologies might actually help reveal why time is fundamental. It's like, kind of insane because they tell you about what's happened in the past, but they can never help you understand what's happening in the future without training examples. Sure. If that thing happens again, it's like, so I think. So let's think about what large language models are doing. We have all the Internet as we know it, language, but also they're doing something else. We're having human beings correcting it all the time. Those models are being corrected.
Speaker B: Steered.
Speaker A: Corrected. Modified. Tweaked.
Speaker B: Yeah, but I mean, cheating. Well, you could say that training on human data in the first place is cheating.
Speaker A: Well, let me. Human is in the loop. Sorry to interrupt.
Speaker B: Yes, a human is definitely in the loop, but it's not just human is in the loop. A very large collection of humans is in the car. And that could be, I mean, to me, it's not intuitive that you said prime numbers, that the system can generate an algorithm, right? That. The algorithm that can generate prime numbers or the algorithm that can tell you if a number is prime and so on, and generate algorithms that generate algorithms that generate algorithms that, that start to look a lot like human reasoning.
Speaker A: You know, I don't think, I think, again, we can show that on the piece of paper that. Sure. I think there has to. You have to have. So this is the failure in epistemology. Like, I'm glad I even can say that word. Let me know what it means.
Speaker B: I said it multiple times.
Speaker A: I know, it's like three times now.
Speaker B: Quit while you're ahead. Just don't say it again. You did really well.
Speaker A: Thanks. So, but I think the. So what is reasoning? So, coming back to the chemical brain, if I could basically, if I could show that in a. Because, I mean, I'm never going to make an intelligence in Cam machina because we don't have brain cells, they don't have glial cells, they don't have neurons. But if I can make, if I can take a gel and engineer the gel to have it be a hybrid hardware for reprogramming, which I think I know how to do, I will be, I process a lot more information and train models billions of times cheaper and use cross domain knowledge. And there are certain techniques I think we can do, but it's still missing, though. The abilities of human beings have had to become true and complete. And so I guess the question to give back is, like, how do you tell the difference between trial and error and the generation of new knowledge? I think the way you can do it is this, is that you come up with a theory, an explanation. Inspiration comes from out. Yeah. And then you then test that, and then you see that's going towards the truth. And human beings are very good at doing that in the transition between philosophy, mathematics, physics and natural sciences. And I think that we can see that where I get confused is why people misappropriate the term artificial intelligence to say, hey, there's something else going on here. Because I think you and I both agree machine learning is really good. It's only going to get better. We can get happier with the outcome. But why would you ever think the model was thinking or reasoning? Reasoning requires intention and the intention. If the model isn't reasoning, the intentions come from the prompter, and the intention has come from the person who programmed it to do it. So I.
Speaker B: But don't you think you can prompt it to have intention? Basically, start with the initial conditions and get it going where the, you know, currently large language models. Chad, GPT only talks to you when you talk to it. There's no reason why you can't just start it talking.
Speaker A: But those initial conditions came from someone starting it.
Speaker B: Yes.
Speaker A: And that causal chain in there. So that intention comes from the outside. I think that there is something in that causal chain of intention that's super important. I don't disagree. We're going to get to AGI. It's a matter of when and what hardware. I think we're not going to do it in this hardware, and I think we're unnecessarily fetishizing really cool outputs and dopamine hits, because obviously that's what people want to sell us.
Speaker B: Well, but there could be, I mean, AGI is a loaded term, but there could be incredibly super impressive intelligence systems on the way to AGI. So these large language models, I mean, I, if it appears conscious, if it appears super intelligent, who are we to say it's not?
Speaker A: I agree, but I. The super intelligence, I want, I want to, I want to be able to have a discussion with it about coming up with fundamental new ideas that generate knowledge. And if this, if the super intelligent generator combined novelty from the future that I didn't see in its training set in the past, I would agree that something really interesting is coming on. I'll say that again. If the intelligence system, be it a human being, a chatbot, something else, is able to produce something truly novel that I could not predict, even having full audit trail from the past, then I'd be sold.
Speaker B: Well. So we should be clear that it can currently produce things that are, in a shallow sense, novel, that are not in the training set. But you're saying truly novel.
Speaker A: I think they are in the training set. I think everything it produces comes from a training set. They might be inter. There's a difference between interpret novelty and interpolation. We do not understand where these leaps come from. Yet that is what intelligence is. I would argue those leaps. And some people say, no, it's actually just what will happen if you just do cross domain training and all that stuff. And that may be true, and I may be completely wrong, but right now, the human mind is able to mine novelty in a way that artificial intelligence systems cannot. And this is why we still have a job and we're still doing stuff. And, you know, I used chat GPT for a few weeks. Oh, this is cool. And then it took me two. I had to. Well, what happened is it took me too much time to correct it, then it got really good, and now they've, they've done something to it. It's not actually that good.
Speaker B: Yeah, right.
Speaker A: I don't know what's going on.
Speaker B: Censorship. Yeah, I mean, that's interesting, but it will push us humans to characterize novelty better. Like characterize the novel. Like, what is novel? What is truly novel? What's the difference between novelty and interpolation?
Speaker A: I think that this, this is the thing that makes me most excited about these technologies, is they're going to help me demonstrate to you that time is fundamental and unit future is bigger than the, than the, than the present, which is why we, we are, human beings are quite good at generating novelty, because we have to expand our data set and to cope with unexpected things in our environment. Our environment froze them all at us again. We have to survive in that environment. And, I mean, I never say never. I would be very interested in how we can get cross domain training cheaply in chemical systems, because I'm a chemist, and Bray, the only sentient thing I know of is a human brain. But maybe that's just me being boring, predictable and not novel.
Speaker B: Yeah, you mentioned GPT for electron density. So a GPT like system for generating molecules that can bind to hosts automatically. I mean, that's, that's interesting. That's really interesting. Applying this same kind of transform mechanism.
Speaker A: Yeah, I mean, this is one, it goes, my team, I try and do things that are non obvious, but non obvious in certain areas. And one of the things I was always asking about in chemistry, people like to represent molecules as graphs, and it's quite difficult. It's really hard. If you're doing AI in chemistry, you really want to basically have good representations. You can generate new molecules. They're interesting. And I was thinking, well, molecules aren't really graphs, and they're not continuously differentiable. Could I do something that was continuously differentiable? I was like, well, molecules are actually made up of electron density. So I got thinking, say, well, okay, could there be a way where we could just basically take a, take a database of readily solved electron densities for millions of molecules? So we took the electron density for millions of molecules and just trained the model to put, to learn what electron density is. And so what we built was a system that you literally could give it a, let's say you could take a protein that has a particular active site, or, you know, a cup with a certain hole in it. You pour noise into it, and with the GPT, you turn the noise into electron density. And then in this case, it hallucinates like all of them do. But the hallucinations are good because it means I don't have to train on such a large number, such a huge data set, because these datasets are very expensive, because how do you produce it? So go back a step. So you've got all these molecules in this data set, but what you've literally done is a quantum mechanical calculation. We produce electron densities for each molecule. So you say, oh, this representation of this molecule has these electron densities shared with it. So you know what the representation is, and you train the neural network to know what electron density is. So then you give it an unknown pocket, you pour in noise, and you say, right, produce me electron density. It produces electron density that doesn't look ridiculous. And what we did in this case is we produce electron density that maximizes the electrostatic potential. So the stickiness, but minimizes what we call the steric hindrance. So the overlap. So it's repulsive. So make the perfect fit. And then we then use the kind of like a chat GPT type thing to turn that electron density into what's called a smile. A smile string is a way of representing a molecule in letters. And then we can then.
Speaker B: So it just generates them.
Speaker A: Just generates them. And then the other thing is then we bung that into the computer, and then it just makes it.
Speaker B: Yeah, the computer being the thing that's.
Speaker A: A robot that we've got that can basically just do chemistry. So kind of, we kind of got this end to end drug discovery machine where you can say, oh, you want to bind to this active site. Here you go. I mean, it's a bit leaky and things kind of break, but it's a proof of principle.
Speaker B: But were the hallucinations, are those still accurate?
Speaker A: Well, the hallucinations are really great in this case, because in the case of a large language model, the hallucinations just like, just make everything up. To when it doesn't just make everything up, but it gives you an output that you're plausibly comfortable with and thinks you're doing probabilistically. The problem on these electron density models is it's very expensive to solve a Schrodinger equation going up to many heavy atoms and large molecules. And so we wondered, if we trained the system on up to nine heavy atoms, whether it would go beyond nine. And it did. It started to generate molecules with twelve. No problem. They look pretty good. And I was like, well, this hallucination I will take for free, thank you very much, because it just basically, this is a case where interpolation extrapolation worked relatively well, and we were able to generate the really good molecules. And then what we were able to do here is, and this is a really good point, what I was trying to say earlier, that we were able to generate new molecules from the known data set that would bind to the host, so a new guest would bind. Were these truly novel? Not really, because they were constrained by the host. Were they new to us? Yes. So I do understand. I can concede that machine learning systems, artificial intelligence systems, can generate new entities, but how novel are they? It remains to be seen.
Speaker B: Yeah. And how novel the things that humans generate is also difficult to quantify. They seem novel.
Speaker A: That's what a lot of people say, like, you know, so the way to really get to genuine novelty and assembly theory shows you the way, is to have different causal chains overlap. And this really resonates with the time is fundamental argument. And if you're bringing together a couple of objects with different initial conditions coming together when they interact, the more different their histories, the more novelty they generate in time going forward. And so it could be that genuine novelty is basically about mix it up a little, and the human brain is able to mix it up a little. And all that stimulus comes from the environment. But all I think I'm saying is the universe is deterministic going back in time, non deterministic going forward in time, because the future is. The universe is too big in the future to contain in the present. Therefore, these collisions of known things generate unknown things that then become part of your data set and don't appear weird. That's how we give ourselves comfort. The past looks consistent with this initial condition hypothesis, but actually we're generating more and more novelty, and that's how it works. Simple.
Speaker B: So it's hard to quantify a novelty looking backwards. I mean, the present and the future are the novelty generators.
Speaker A: But I like this whole idea of mining novelty, I think it is going to reveal why the limitations of current AI is a bit like a printing press. Right? Everyone thought that when the printing press came, that writing books is going to be terrible, that you had evil spirits and all this, they were just books.
Speaker B: The same would be with AI. But I think just the scale you can achieve in terms of impact with AI systems is pretty nerve wracking.
Speaker A: That's what the big companies want you.
Speaker B: To think, but not like in terms of destroy all humans. But you can have major consequences in the way social media has had major consequences, both positive and negative. And so you have to kind of think about and worry about it. But, yeah, people that fear monger, you.
Speaker A: Know, my pet theory for this, you want to know.
Speaker B: Yeah.
Speaker A: Is I think that a lot of, and maybe I'm being, and I think I really do respect, you know, a lot of the people out there who are trying to have discourse about the positive future. So OpenAI guys, meta guys, and all this. And what I wonder if they're trying to cover up for the fact that social media has had a pretty disastrous effect on some level, and they just try to say, oh, yeah, we should do this, and covering up for the fact that we have got some problems with teenagers and Instagram and Snapchat and all this stuff, and maybe they're just overreacting now. It's like, oh, yeah, sorry, we made the bubonic plate and gave it to you all and you're all dying. And, oh, yeah, but look at this over here, it's even worse.
Speaker B: Yeah, there's a little bit of that, but there's also not enough celebration of the positive impact that all these technologies have had. We tend to focus on the negative and tend to forget that, in part because it's hard to measure. Like, it's very hard to measure the positive impact social media had on the world.
Speaker A: Yeah, I agree. But if what I worry about right now is, like, I'm really, I do care about the ethics of what we're doing, and one of the reasons why I'm so open about the things we're trying to do in lab make lies, look at intelligence, all this. So people say, what are the consequences of this? And you say, what are the consequences of not doing it? And I think that what worries me right now in the present is lack of authenticated users and authenticated data.
Speaker B: Human users.
Speaker A: Yeah, human.
Speaker B: I still think that there will be AI agents that appear to be conscious, but they would have to be also authenticated and labeled as such. There's too much, there's too much value in that, you know, like friendships with AI systems, there's too much meaningful human experiences to have with the AI systems that I just.
Speaker A: But that's like a tool, right? It's a bit like a meditation tool, right? Some people have a meditation tool. It makes them feel better. But I'm not sure you can ascribe sentience and legal rights to a chatbot that makes you feel less lonely.
Speaker B: Sentience? Yes, I think legal rights, no, I think it's the same. You can have a really deep, meaningful relationship with a dog.
Speaker A: With a dog. Sentient?
Speaker B: Yes.
Speaker A: The chat bots, right now, using the technology we use, it's not going to be sentient.
Speaker B: This is going to be a fun continued conversation on Twitter that I look forward to. Since you've had also from another place, some debates that were inspired by the assembly theory paper. Let me ask you about God. Is there any room for notions of God in assembly theory? God?
Speaker A: Yeah. I don't know what God is. I mean, so God exists in our mind, created by selection. So human beings have created the concept of God in the same way that human beings have created the concept of super intelligence.
Speaker B: Sure. But does it, does it mean, does it not. It still could mean that that's a projection from the real world where we're just assigning words and concepts to a thing that is fundamental to the real world, that there is something out there that is a creative force underlying the universe.
Speaker A: I think the universe, there is a creative force in the universe, but I don't think it's sentient. I mean, I think so. I do not understand the universe. So who am I to say that God doesn't exist? I am an atheist, but I'm not an angry atheist, right? I have lots of, I have lots of, there's some people I know that are angry atheists and say, you know, say that religious people are stupid. I don't think that's the case. I have faith in some things because I don't. I mean, when I was a kid, I kept like, you know, it's like, I need to know what the charge of electron is. And I was like, I can't measure the charge on electron. That was, you know, I just gave up and had faith. Okay. You know, resistors works. So when it comes to, I want to know why the universe is growing in the future and what humanity is going to become. And I've seen that the, the acquisition of knowledge via the generation of novelty to produce technology has uniformly made humans lives better. I would love to continue that tradition.
Speaker B: And you said that there's that creative force. Do you think. Just to think on that point, do you think there's a creative force? Is there like a thing, like a driver that's creating stuff?
Speaker A: Yeah, I think that. So I think that.
Speaker B: And where, what is. Can you describe it, like, mathematically?
Speaker A: Well, I think selection. I think selection.
Speaker B: Selection is divorce.
Speaker A: Selection is the force in the universe that creates novelty.
Speaker B: Is selection somehow fundamental? Like what? What?
Speaker A: Yeah, I think persistence of objects that could decay into nothing through operations that maintain that structure. I mean, think about it. If it's amazing that things existed at all, that we're just not a big commentorial mess.
Speaker B: Yes. So the fact exists in a thing that exists, persists in time.
Speaker A: Yeah, let's think. Maybe the universe is actually in the present. The things, everything that can exist in the present does exist.
Speaker B: Well, that would mean it's deterministic, right?
Speaker A: No, I think the universities might. So the universe started super small. The past was deterministic, there wasn't much going on, and it was able to. Mine, mine, mine, mine, mine. And so the process, I mean, is somehow generating universe is basically. I can't put. I'm trying to put this in.
Speaker B: Did you just say there's no free will, though?
Speaker A: No, I didn't say that.
Speaker B: As if.
Speaker A: Sorry, I said there is free will. I think. I think I'm saying that free will occurs at the boundary between the present, future, the past and the future.
Speaker B: Yeah, I got you. But everything that can exist does exist.
Speaker A: Everything that is so. Everything that's possible to exist at this. So, no, I'm really.
Speaker B: There's a lot of loaded words there in the. So what, I mean, there's a time element loaded into this.
Speaker A: I think that the universe is able to do what it can in the present, right?
Speaker B: Yeah.
Speaker A: And then I think in the future there are other things that could be possible. We can imagine lots of things, but they don't all happen.
Speaker B: Sure.
Speaker A: So what, that's where. That's what I sneak in.
Speaker B: Free will right there.
Speaker A: Yeah. So I guess what I'm saying is what, what exists is a. Is a convolution of the past with the present and the free will going into the future.
Speaker B: But we can still imagine stuff, right? We can imagine stuff that never happened.
Speaker A: And it's amazing force, because your imagina, this is the most important thing that we don't understand is our imaginations can actually change the future in a tangible way, which is what the initial conditions and physics cannot predict, like your imagination has a causal consequence in the future.
Speaker B: Isn't that weird to you?
Speaker A: Yeah, it breaks the laws of physics as we know them right now.
Speaker B: Yeah. So you think the imagination has a causal effect on the future? Yeah, but it does exist in there, in the head, and there must be a lot of power. And whatever's going on, there could be a lot of power. Whatever's going on in there.
Speaker A: If we then go back to the initial conditions, and that is simply not possible, that can happen. But if we go into, if we go into a universe where we accept that there is a finite ability to represent numbers and you have rounding. We're not rounding errors. You have some that some what happens, your ability to make decisions, imagine and do stuff is that that interface between the certain and the uncertain. It's not, as Yasha was saying to me, randomness goes and you just, you know, randomly do random stuff. It is that you are set free a little on your trajectory. Free will is about being able to explore on this narrow trajectory that allows you to build. You have a choice about what you build, or that choice is you interacting with a future in the present.
Speaker B: What to you is most beautiful about this whole thing, the universe.
Speaker A: The fact it seems to be very undecided, very open, and the fact that every time I think I'm getting towards an answer to a question, there are so many more questions that make the chase.
Speaker B: Do you hate that it's going to be over at some point?
Speaker A: No. For me, I think if you think about it, is it over for Newton? Now, Newton has had causal consequences in the future. We discuss him all the time, his.
Speaker B: Ideas, but not the person.
Speaker A: The person just had a lot of causal power when he was alive. But, oh, my God, one of the things I want to do is leave as many Easter eggs in the future when I'm gone to go, oh, that's cool.
Speaker B: Would you be very upset if somebody made a good large language model that's fine tuned to Lee Connor?
Speaker A: It would be quite boring because, I mean, novelty generation. If it's a faithful representation of what I've done in my life, that's great. That's an interesting artifact. But I think the most interesting thing about knowing each other is we don't know what we're going to do next.
Speaker B: Sure.
Speaker A: Sure. I mean, within some constraints I've got, you know, you might. I can predict some things about you, you can predict some things about me, but we can't predict everything.
Speaker B: Everything.
Speaker A: And it's because we can't predict everything is why we're excited to come back and discuss and see. It's so, yeah, I'm kind of. I'm happy that it'll be interesting that some things that I've done can be captured, but I'm pretty sure that my angle on mining novelty from the future will not be captured.
Speaker B: Yeah. Yeah. That's what life is. It's just some novelty generation and you're done. Each one of us just generally a little bit, or have the capacity to at least.
Speaker A: I think life is a selection produces life, and life affects the universe in them. Universes with life in them are materially, physically, fundamentally different than universes without life. And that's super interesting. And I have no beginnings of understanding. I think maybe this is like, in a thousand years there'll be a new discipline and the humans will be. Yeah, of course, this is is how it all works, right?
Speaker B: And in retrospect, it will all be obvious. I think.
Speaker A: I think assembly theory is obvious. That's why a lot of people got angry, right? They were like, oh my God, this is such nonsense. You know, like, oh, you know, actually it's not quite, but the writing's really bad.
Speaker B: Well, I can't wait to see where it evolves, Lee. And I'm glad I get to exist in this universe with you. You're a fascinating human. This is always a pleasure. I hope to talk to you many more times, and I'm a huge fan of just watching you create stuff in this world. And thank you for talking today.
Speaker A: It's a pleasure as always, Lex. Thanks for having me on.
Speaker B: Thanks for listening to this conversation with Lee Cronin. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Carl Sagan. We can judge our progress by the courage of our questions and the depth of our answers, our willingness to embrace what is true rather than what feels good. Thank you for listening and hope to see you next time.
