Transcription for Mark Zuckerberg： First Interview in the Metaverse ｜ Lex Fridman Podcast #398.mp3:
Full transcript: The following is a conversation with Mark Zuckerberg inside the metaverse. Mark and I are hundreds of miles apart from each other in physical space, but it feels like we're in the same room because we appear to each other as photorealistic codec avatars in 3d with spatial audio. This technology is incredible, and I think it's the future of how human beings connect to each other in a deeply meaningful way. On the Internet, these avatars can capture many of the nuances of facial expressions that we use. We humans use to communicate emotion to each other. Now I just need to work on upgrading my emotion expressing capabilities of the underlying human. This is the Lex Friedman podcast. And now, dear friends, here's Mark Zuckerberg. Wow. This is so great. Lighting change. Wow. Yeah, we can put the light anywhere. And it doesn't feel awkward to be really close to you. No, it does. I actually moved you. I moved you back a few feet before you got into a headset. You were like, right here. I don't know if people can see this, but this is incredible. The realism here is just incredible. Where am I? Where are you, Mark? Where are we? You're in Austin, right? No, I mean this place. We're shrouded by darkness with ultra realistic face, and it just feels like we're in the same room. This is really the most incredible thing I've ever seen. And sorry to be in your personal space. I mean, we have done jujitsu before. Yeah, no, I was commenting to the team before that even that I feel like we've choked each other from further distances than it feels like we are right now. I mean, this is just really incredible. I don't know how to describe it with words. It really feels like. It feels like we're in the same room. Yeah. Feels like the future. This is truly, truly incredible. I just wanted to take it in. I'm still getting used to it. It's like it's you. It's really you. But you're not here with me, right. You're there wearing a headset, and I'm wearing a headset. It's. It's really, really incredible. So what, um. Can you describe what it takes currently for us to appear so photorealistic to each other? Yeah, so, I mean, for background, we both did these scans for this research project that we have at meta called codec avatars. And the idea is that instead of our avatars being cartoony and instead of actually transmitting a video, what it does is we've sort of scanned ourselves in a lot of different expressions. And we've built a computer model of sort of each of our faces and bodies and the different expressions that we make and collapse that into a codec that then when you have the headset on your head, it sees your face, it sees your expression, and it can basically send a. An encoded version of what you're supposed to look like over the wire. So in addition to being photorealistic, it's also actually much more bandwidth efficient than transmitting a full video, or especially a 3d, immersive video of a whole scene like this. And it captures everything. The flaws, to me, the subtleties of the human face, even the flaws, that's all amazing. It makes you. It makes it so much more immersive. It makes you realize that, like, perfection isn't the thing that leads to immersion. It's like the little subtle flaws, like freckles and, like, variations in color and just. Yeah. Wrinkles. All stuff about roses. Yeah. Asymmetry and just the different, like, the corners of the eyes, like what your eyes do when you smile. All that kind of stuff. Yeah. Eyes are a huge part of it. Yeah. I mean, there's all the studies that most of communication, even when people are speaking, is not actually the words that they're saying. Right. It's kind of the expression and all that. So we try to capture that with the kind of classical expressive avatar system that we have. That's the kind of more cartoon designed one. You can kind of put those kind of expressions on those faces as well. But there's obviously a certain realism that comes with delivering kind of this photorealistic experience that. I don't know, I just think it's really magical. I mean, this gets to kind of the core of what the vision around virtual and augmented reality is of, like delivering a sense of presence as if you're there together no matter where you actually are in the world. And, I mean, this experience, I think, is a good embodiment of that, where it's like, I mean, we're in two completely different states halfway across the country, and it just, like, looks like you're just sitting right in front of me. It's pretty wild. Yeah, I mean, I can't. It's. I'm almost getting emotional. It's like. It feels like a totally fundamentally new experience. Like, for me to have this kind of conversation with loved ones, it would just change everything. Maybe just to elaborate. So the. I went to Pittsburgh and went through the whole scanning procedure, which has so much incredible technology, so software and hardware going on, but it is a lengthy process so what's your vision for the future of this in terms of making this more accessible to people? It starts off with a small number of people doing these very detailed scans, which that's the version that you did and that I did and before, there are a lot of people who we've done this kind of a scan for. We probably need to kind of over collect expressions when we're doing the scanning, because we haven't figured out how much we can reduce that down to a really streamlined process and extrapolate from the scans that have already been done. But the goal, and we have a project that's working on this already, is just to do a very quick scan with your cell phone, where you just take your phone, wave it in front of your face for a couple of minutes, say a few sentences, make a bunch of expressions, but overall, have the whole process just be two to three minutes, and then produce something that's of the quality of what we have right now. So I think that that's one of the big challenges that remains. And right now we have the ability to do the scans if you have hours to sit for one. And with today's technology, I mean, you're using a meta headset that exists. It's a product that's for sale. Now, you can drive these with that, but the production of these scans in a very efficient way is one of the last pieces that we still need to really nail. And then obviously, there's all the experiences around it. Right now, we're sitting in a dark room, which is familiar for your podcast. But I think part of the vision for this over time is not just having this be like a video call. That's fine, it's cool, or it feels like it's immersive, but you can do a video call on your phone. The thing that you can do in the metaverse that is different from what you can do on a phone is doing stuff where you're physically there together and participating in things together. And we could play games like this, we could have meetings like this in the future. Once you get mixed reality and augmented reality, we could have codec avatars like this and go into a meeting and have some people physically there and have some people show up in this photorealistic form superimposed on the, on the physical environment. I think that stuff like that is going to be super powerful. So we got to still build out all those kind of applications and the use cases around it. But I don't know. I think it's going to be a pretty wild. Next few years around this, I mean, I just. I'm actually almost at a loss of words. This is just so incredible. This is truly incredible. I hope that people, like, watching this can get a glimpse of, like, how incredible it is. It really feels like we're in the same room. Like, there is that. I guess there's an uncanny valley that seems to have been crossed here. Like, it looks like you. Yeah, there's still a bunch of tuning that I think we'll want to do where different people emote to different extents. Right? So I think one of the big questions is, you know, like, when you smile, how wide is your smile and how wide do you want your smile to be? And I think getting that to be tuned on a per person basis is going to be one of the things that we're going to need to figure out. It's like, to what extent do you want to give people control over that? Some people might try to prefer a version of themselves that's more emotive in their avatar than their actual faces, for example. You know, I always get a lot of critique and shit for having, like, a relatively stiff expression, but, you know, I mean, I might feel pretty happy, but just make a pretty small smile. So, I mean, maybe, you know, for me, I would. It's actually. It's like I'd wanna have my avatar really be able to better express, like, how I'm feeling than how I can do physically. So I think that there's a question about how you wanna tune that. But. But overall, yeah, I mean, we want to start from the baseline of capturing how people actually emote and express themselves. And I think the initial version of this has been pretty impressive. And like you said, I do think we're kind of beyond the uncanny valley here where it does feel like you. It doesn't feel weird or anything like that. I mean, that's going to be the meme that the two most monotone people are in a metaverse together. But I think that actually makes it more difficult. The amazing thing here is that the subtleties of the expression of the eyes. People say I'm monotone and emotionless, but I'm not. It's just this. Maybe my expression of emotion is more subtle, usually, like, with the eyes. And that's one of the things I've noticed, is just how expressive the subtle movement of the corners of the eyes are in terms of displaying happiness or boredom or all that kind of stuff. I am curious to see, just because I've never done one of these before, I've never done a podcast as one of these codec avatars, and I'm curious to see what people think of it, because one of the issues that we've had in some of the VR and mixed reality work is it tends to feel a lot more profound when you're in it than the 2d videos capturing the experience. So I think that this one, because it's photorealistic, may look kind of as amazing in 2d for people watching it, as it. As it feels, I think, to be in it. But we've certainly had this issue where a lot of the other things just. It's like you feel the sense of immersion when you're in it. That doesn't quite translate to a 2d screen. But I don't know, I'm curious to see. To see what people think. Yeah, I'm curious to see if people could see that, like, my heart is actually beating fast now. This is super interesting. Like, the. Such intimacy of conversation could be achieved remotely. There's been, you know, I don't do remote podcasts for this reason. And this is like, breaks all of that. This feels like just an incredible transition to something else, to different kind of communication. Breaks all barriers, like geographic, physical barriers. What you mentioned, do you have a sense of timeline in terms of how many difficult things have to be solved to make this more accessible to scanning with a smartphone? Yeah, I think we'll probably roll this out progressively over time, so it's not going to be like we roll it out and one day everyone has a codec avatar. We want to get more people scanned and into the system, and then we want to start integrating it into each one of our apps, making it so that. I think that for a lot of the work style things, productivity, I think that this is going to make a ton of sense in a lot of game environments. I mean, this could be fine, but games tend to have their own style, right, where you almost want to fit more with the aesthetic style of the. Of the game. Um, but I think for doing meetings and one of the things that we get a lot of feedback on workrooms where, you know, people are pretty blown away by the experience and this feeling that you can, like, be remote, but feel like you're physically there around a table with people, but then, you know, we get some feedback that people have a hard time with, the fact that the avatars are so expressive and. And don't feel as realistic in that environment. So I think something like this could make a very big difference for those remote meetings and especially with quest three coming out, which is going to be the first mainstream mixed reality product where you're really taking digital expressions of either a person or objects and overlaying them on the physical world. I think the ability to do remote meetings and things like that, where you're just remote hang sessions with friends, I think that's going to be very exciting. So, yeah, rolling it out over the next few years, it's not ready to be a mainstream product yet, but we just want to. We'll keep tuning in, keep getting more scans in there, and kind of rolling it out into more of the features. But, yeah, I mean, definitely in the next few years, you'll be seeing a bunch more experiences like this. Yeah, I would love to see some celebrities scanned and some non celebrities. I just. Just more people to experience this. I would love to see that this is something that, I mean, my mind is blowing. I'm literally at a loss of words because it's very difficult to just convey how incredible this is, how, like, how I feel the emotion, how I feel the presence, how I feel, like, the subtleties of the emotion in terms of, like, work meetings or any kind of. In terms of podcasts, this is awesome. I don't even need your arms or legs. Is that. Well, we got to get that. I mean, that's its own challenge. And part of the question is also, so you have the scan, then it takes a certain amount of compute to go drive that, both for the sensors on the headset and then rendering it. So one of the things that we're working through is, what is the level of fidelity that is optimal? You could do the full body in a codec, and that can be quite intensive. But one of the things that we're thinking about is, all right, maybe you can stitch a somewhat lower fidelity version of your body, which still have the main movements, but your face is really the thing that we have the most resolution on in terms of being able to read and express emotions. I mean, like you said, if you move your eyebrows like a millimeter, I mean, that really changes the expression and what you're emoting, whereas moving your arm like an inch probably doesn't matter quite as much. So, yeah, so I think that we do want to get all of that into here, and that'll be some of the work over the next period as well. So you mentioned Quest three. That's coming out. I've gotten a chance to try that, too. That's awesome. So how did you pull off the mixed. So it's not just virtual reality, it's mixed reality? Yeah, I think it's going to be the first mainstream mixed reality device. I mean, obviously, we shipped Quest pro last year, but it was $1,500. And part of what I'm super proud of is we try to innovate, not just on pushing the state of the art and delivering new capabilities, but making it so it can be available to everyone. We have this, and it's coming out. It's $500. And in some ways, I think the mixed reality is actually better in quest three than it was, than what we're using right now in Quest pro. I'm really proud of the team for being able to deliver that kind of an innovation and get it out, but some of this is just software. You tune over time and get to be better. Part of it is you put together a product and you figure out what are the bottlenecks in terms of making it a good experience. So we got the resolution for the mixed reality cameras and sensors to be multiple times better in quest three. And we just figured that that made a very big difference when we saw the experience that we were able to put together for Quest Pro. And part of it is also that Qualcomm just came out with their next generation chipset for VR, and mister that we worked with them on a custom version of it, but that was available this year for Quest three, and it wasn't available in Quest Pro. So in a way, I'm quest three, even though it's nothing. The pro product actually has a stronger chipset in it than the pro line at a third of the cost. I'm really excited to get this in people's hands. It does all the VR stuff that quest two and the others have done, too. It does it better because the display is better and the chip is better, so you'll get better graphics. It's 40% thinner, so just more comfortable as well. But the mister is really the big capability shift. And part of what's exciting about the whole space right now is this isn't like smartphones, where companies put out a new smartphone every year, and you can almost barely tell the difference between that and the one the year before it. Now, for this, each time we put out a new headset, it has a major new capability. And the big one now is mixed reality. The ability to basically take digital representations of people, um, or objects and. And superimpose them on the world. And basically, you know, I mean, there's a, one version of this is you're going to kind of have these augments or, or holograms and experiences that you can kind of bring into your living room or a meeting space or office. Um, another thing that I just think is going to be a much kind of simpler innovation is that there are a lot of VR experiences today that don't need to be fully immersive. And if you're playing a shooter game or you're doing a fitness experience, sometimes people get worried about swinging their arms around, like, am I going to hit a lamp or something? And am I going to run into something? So having that in mixed reality actually is just a lot more comfortable for people. You kind of still get the immersion and the 3d experience, and you can have an experience that just wouldn't be possible in the physical world alone. But by being anchored to and being able to see the physical world around you, it's like, it just feels so much safer and more secure. And I think a lot of people are really going to enjoy that, too. So, yeah, I'm really excited to see how people use it, but, yeah, quest three coming out later this fall. Yeah. And I got to experience it with other people sitting around and there's a lot of furniture. And so you get to see that furniture. You get to see those people, and you get to see those people, like, enjoy the ridiculousness of you, like swinging your arms. I mean, presumably they're friends of yours, even if they make fun of you. There's a lot of love behind that. And that you got to experience that. That's a really fundamentally different experience than just pure VR with, like, with zombies coming out of walls and. Yeah, it's like someone shooting at you and you hide behind your real couch in order to duck the fire. Yeah, it's incredible how it's all integrated, but also, like, subtle stuff, like in a room with no windows, you can add windows to it and you can look outside as the zombies run towards you. But, like, it's still nice view outside of, you know. Yeah, it's really. And so that's pulled off by having cameras on the outside of the headset that do the pass through. That technology is incredible to do that on a small headset. Yeah, it's not just the cameras. You basically need to. You need multiple cameras to capture the different angles and sort of the three dimensional space. And then it's a pretty complex compute problem, an AI problem, to map that to your perspective because the cameras aren't exactly where your eyes are, because no two people's eyes are going to be in exactly the same place. You need to get that to line up and then do that basically in real time and then generate something that feels natural and then superimpose whatever digital objects you want to put there. So, yeah, it's a very interesting technical challenge. I think we'll continue tuning this for the years to come as well. But I'm pretty excited to get this out because I think Quest three is going to be the first device like this that millions of people are going to get. That's mixed reality, and it's only when you have millions of people using something that you start getting the whole developer community really starting to experiment and build stuff, because now there are going to be people who actually use it. So I think we got some of that flywheel going with Quest Pro, but I think it'll really get accelerated once quest three gets out there. So, yeah, I'm pretty excited about this one. Plus there's hand tracking without, so you don't need to have a control. So the cameras aren't just doing the pass through of the entire physical reality around you, it's also tracking the details of your hands in order to use that for, like, gesture recognition, this kind of stuff. Yeah, we've been able to get way further on hand recognition in a shorter period of time than I expected, so that's been pretty cool. I don't know. Did you see the demo experience that we built around piano? Like. Yeah, the piano. Learning to play piano. Yeah, it's incredible. You're basically playing piano on a table, and that's without any controller and how well it matches physical reality with no latency, and it's tracking your hands with no latency, and it's tracking all the people around you with no latency. Integrating physical reality and digital reality, obviously that connects exactly to this Kodak avatar, which is in parallel, allows us to have ultra realistic copies of ourselves in this mixed reality. So it's all converging towards an incredible digital experience in the metaverse, to me, obviously, I love the intimacy of conversation, so even this is awesome. But do you have other ideas of what this unlocks? Something like Kodak Avatar unlocks in terms of applications, in terms of things, were we able to do? Well, there's what you can do with avatars overall in terms of superimposing digital objects on the physical world, and then there's kind of psychologically, what does having photorealistic do? So I think we're moving towards a world where we're going to have something that looks like normal glasses, where you see the physical world, but you also see holograms, and in that world, I think that they're going to be not too far off. Maybe by the end of this decade, we'll be living in a world where there are as many holograms when you walk into a room as there are physical objects. And it really raises this interesting question about what are about. A lot of people have this phrase where they call the physical world the real world. And I kind of think increasingly, the physical world is super important, but I actually think the real world is the combination of the physical world and the digital worlds coming together. But until this technology, they were sort of separate. It's like you access the digital world through a screen, and maybe it's a small screen that you carry around, or it's a bigger screen when you sit down at your desk and strap in for a long session. But they're fundamentally divorced and disconnected. And I think part of what this technology is going to do is bring those together into a single coherent experience of what the modern real world is, which is it's got to be physical, because we're physical beings. So the physical world is always going to be super important. But increasingly, I think a lot of the things that we think of can be digital holograms. I mean, any screen that you have can be a hologram in any media, in any book, art. It can basically be just as effective as a hologram, as a physical object. Any game that you're playing, a board game or any kind of physical game, cards, ping pong, things like that, they're often a lot better as holograms because you could just of snap your fingers and instantiate them and have them show up. It's like you have a ping pong table show up in your living room, but then you can snap your fingers and have it be gone. So that's super powerful. So I think that it's actually an amazing thought experiment of how many physical things we have today that could actually be better as interactive holograms. But then beyond that, I think the most important thing, obviously, is people. So the ability to have these mixed hangouts, whether they're social or meetings where you show up to a conference room, you're wearing glasses or a headset in the very near term, but hopefully by over the next five years, glasses or so, and you're there physically. Some people are there physically, but other people are just there as holograms. And it feels like it's theme, um, who are right there. And, and also, by the way, another thing that I think is going to be fascinating about being able to blend together the digital and physical worlds in this way is we're also going to be able to embody, um, AI's as well. So I think you'll also have meetings in the future where you're basically, you know, maybe you're sitting there physically, and then you have, you know, a couple of other people who are there as holograms, and then you have, like, Bob, the AI, who's an engineer on your team who's helping with things, and he can now be embodied as a realistic avatar as well, and just join the meeting in that way. So I think that that's going to be pretty compelling as well. Okay, so what can you do with photorealistic avatars compared to kind of the more expressive ones that we have today? Well, I think a lot of this actually comes down to acceptance of the technology and because all of the stuff that we're doing, I mean, the motion of your eyebrows, the motion of your eyes, the cheeks and all of that, there's actually no reason why you couldn't do that on an expressive avatar, too. I mean, it wouldn't look exactly like you, but you could make a cartoon version of yourself and still have it be almost as expressive. But I do think that there's this bridge between the current state of most our interactions in the physical world and where we're getting in the future with this kind of hybrid physical and digital world, where I think it's going to be a lot easier for people to kind of take some of these experiences seriously with the photorealistic avatars to start. And then I'm actually really curious to see where it goes longer term. I could see a world where people stick to the photorealistic and maybe they modify them to make them a little bit more interesting. But maybe fundamentally, we like photo realistic things. But I can also see a world that once people get used to the photorealistic avatars and they get used to these experiences, I actually think that there could be a world where people actually prefer being able to express themselves in ways that aren't so tied to their physical reality. And so that's one of the things that I'm really curious about. And I don't know, in a bunch of our internal experiments on this, one of the things that I thought was psychologically pretty interesting is people have no issues blending photo realistic stuff. And not so we could have a. For this specific scene that we're in now, we happen to sort of being in a dark room. I think part of that aesthetic decision, I think, was based on the way you like to do your podcast. But we've done experiences like this where you have a cartoony background, but photo realistic people who you're talking to and we seem to like, people just seem to just think that that is completely normal. It doesn't bother you, it doesn't feel like it's weird. Another thing that we've experienced with is basically you have a photorealistic avatar that you're talking to, and then right next to them, you have an expressive kind of cartoon avatar. And that actually is pretty normal too. Right? It's not that weird to basically being, interacting with different people in different modes like that. So I'm not sure. I think it'll be an interesting question to what extent these photorealistic avatars are a key part of just transitioning from being comfortable in the physical world to this kind of new, modern real world that kind of includes both the digital and physical. Or if this is like the long term way that it stays. Um, that's, that's a. I mean, I think that they're going to be useless for both the expressive and the photorealistic over time. I just don't know what the balance is going to be. Yeah, it's a really good, interesting philosophical question, but to me, in the short term, the photorealistic is amazing to where I would prefer, like you said, the work room. But like, on a beach with a beer, just to see a buddy of mine remotely on a chair next to me drinking a beer. I mean, that as realistic as possible is an incredible experience. So I don't want any fake hats on him. I don't want any just chilling with it with a friend, drinking beer, looking at the ocean while not being in the same place together. I mean, that. Yeah, that experience is just, it's a fundamentally, it's just a high quality experience of friendship. Whatever we seek in friendship, it seems to be present there in the same kind of realism I'm seeing right now. This is totally a game changer. So to me, I can see myself sticking with this for a long time. Yeah. And I mean, it's also, it's novel, and it's also a technological feat. Right. It's like, being able to pull this off is like, it's like a pretty impressive, and I think to some degree it's just this kind of like, awesome experience. But I'm already, sorry to interrupt, I'm already forgetting that you're not real. Like this really novel. This is just an avatar version of me. But it's a philosophical question. Yes, but I mean, but here's some of the. So I put this on this morning, and I was like, all right. It's like, okay, so my hair is a little shorter in this than my physical hair is right now. I probably need to go get a haircut and like. And I actually, I did happen to shave this morning, but if I hadn't, I could still have this photo realistic avatar that is more cleanly shaven, even if I'm a few days in physically. So I do think that there are going to start to be these subtle questions that seep in where the avatar is realistic in the sense of, this is what you looked like at the time of capture, but it's not necessarily temporally accurate to exactly what you look like in this moment. I think there are going to end up being a bunch of questions that come from that over time that I think are going to be fascinating, too. You mean just the nature of identity, of who we are? You know, how people do, like, summer beach body will people be for the scan? They'll try to lose some weight and look their best and sexiest with the nice hair and everything like that? It does. It does raise the question of, if a lot of people are interacting with the digital version of ourselves, who are we really? Are we the entity driving the avatar, or are we the avatar? Well, I mean, I think our physical bodies also fluctuate and change over time, too. So I think there's a similar question of which version of that are we? Right. There's like the. I mean, and it's interesting identity question, because. All right, it's like. I don't know, it's like weight fluctuates or things like that. I think most people don't tend to think of themselves as the. I don't know. It's an interesting psychological question. Maybe some people. Maybe a lot of people do think about themselves as the kind of worst version, but I think a lot of people probably think about themselves as the best version, and then it's like what you are on a day to day basis doesn't necessarily map to. To either of those. So I know that's. Yeah, there will definitely be a bunch of social scientists and folks will have to, and psychologists. Really. There's gonna be a lot to understand about how our perception of ourselves and others has shifted from this. Well, this might be a bit of a complicated and a dark question, but one of the first feelings I had experiencing this is, I would love to talk to loved ones. And the next question I have is, I would love to talk to people who are no longer here that are loved ones. So, like, if you look into the future, is that something you think about? Who people who pass away, but they can still exist in the metaverse. You can still have, you know, talk to your father, talk to your grandfather and grandmother and mother once they pass away. The power of that experience is one of the first things my mind jumped to because it's like, this is so real. Yeah, I think that there are a lot of norms and things that people have to figure out around that. There's probably some balance where if someone has lost a loved one and is grieving, there may be ways in which being able to interact or relive certain memories could be helpful, but then theres also probably an extent to which it could become unhealthy. And I mean, im not an expert in that, so I think wed have to study that and understand it in more detail. We have a fair amount of experience with how to handle death and identity and peoples digital content through social media already. Unfortunately. Unfortunately, people who use our services die every day and their families often want to have access to their profiles. And we have whole protocols that we go through where there are certain parts of it that we try to memorialize so that way the family can get access to it, so that way the account doesn't just go away immediately. But then there are other things that are important, private things that that person has. Like we're not going to give the family access to someone's messages, for example. So yeah, I think that there's some best practices, I think, from the current digital world that we'll carry over. But yeah, I think that this will enable some different things. Another version of this is how this intersects with AI's, because one of the things that we're really focused on is we want there to, we want the world to evolve in a way where there isn't like a single AI super intelligence, but where a lot of people are empowered by having AI tools to do their jobs and make their lives better. And if you're a creator and if you run a podcast like you do, then you have a big community of people who are super interested to talk to you. I know you'd love to cultivate that community and you interact with them online outside of the the podcast as well. But I mean, there's way more demand both to interact with you, and I'm sure you'd love to interact with the community more, but you just are limited by the number of hours in the day. So at some point, I think making it so that you could build an AI version of yourself that could interact with people, not after you die, but while you're here to help people kind of fulfill this desire to, to interact with you and your desire to build a community. And there's a lot of interesting questions around that, and that's obviously, it's not just in the metaverse. I think we'd want to make that work across all the messaging platforms, WhatsApp and Messenger and Instagram direct. But there's certainly a version of that where if you could have an avatar version of yourself in the metaverse that people can interact with, and you could define that sort of an AI version where people know that they're interacting with an AI, that it's not the kind of physical version of you, but maybe that AI, even if they know it's an AI, is the next best thing because they're probably not going to necessarily all get to interact with you directly. I think that that could be a really compelling experience. There's a lot of things that we need to get right about it, that we're not ready to release the version, that a creator can build a version of themselves yet, but we're starting to experiment with it in terms of releasing a number of AI's that people can interact with in different ways. And I think that that is also just going to be a very powerful set of capabilities that people have over time. So you've made major strides in developing these early AI personalities with the idea where you can talk to them across the meta apps and have interesting, unique kind of conversations. Can you describe your vision there in these early strides, and what are some technical challenges there? Yeah, so a lot of the vision comes from this idea that I don't think we necessarily want there to be one big super intelligence. We want to empower everyone to both have more fun, accomplish their business goals, just everything that they're trying to do. And we don't tend to have one person that we work with on everything. And I don't think in the future we're going to have one AI that we work with. I think you're going to want a variety of these. There are a bunch of different uses. Some will be more assistant oriented. There's sort of the kind of plain and simple one that we're building is called just meta AI. It's simple. You can chat with it in any of your threads. It doesn't have a face, it's just more vanilla and neutral and factual. But it can help you with a bunch of stuff, then there are a bunch of cases that are more business oriented. Let's say you want to contact a small business. Similarly, that business probably doesn't want to have to staff someone to man the phones, and you probably want to wait on the phone to talk to someone. But having someone who you can just talk to in a natural way, who can help you if you're having an issue with a product, or if you want to make a reservation, or if you want to buy something online, having the ability to do that and have a natural conversation rather than navigate some website or have to call someone and wait on hold, I think it's going to be really good both for the businesses and for normal people who want to interact with businesses. So I think stuff like that makes sense. Then there are going to be a bunch of use cases that I think are just fun. So I think people are going to. I think that there will be AI's that can tell jokes, you can put them into chat thread with friends. I think a lot of this because we're a social company, we're fundamentally around helping people connect in different ways. And part of what I'm excited about is how do you enable these kinds of AI's to facilitate connection between two people or more put them in a group chat, make the group chat more interesting around. Whatever your interests are. Sports, fashion, trivia, video games. I love the idea of playing. I think you mentioned Baldur's Gate, an incredible game. Just having an AI that you play together with, I mean, that seems like a small thing, but it could deeply enrich the gaming experience. I do think that AI's will make the NPC's a lot better in games too. So that's a separate thing that I'm pretty excited about. But yeah, I mean, one of the AI's that we've built that just in our internal testing people have loved the most, is like a adventure text based. Like a dungeon master. Nice. And I think part of what has been fun, we talked about this a bit, but we've gotten some real kind of cultural figures to play a bunch of these folks and be the embodiment and the avatar of them. So Snoop Dogg is the dungeon master, which I think is just hilarious in. Terms of the next steps of, you know, if you mentioned, you mentioned Snoop to create a snoop AI. So basically AI personality replica a copy or not a copy, maybe inspired by Snoop. What are some of the technical challenges of that? What does that experience look like for Snoop to be able to. So starting off creating new Personas is easier because it doesn't need to stick exactly to what that physical person would want, how they'd want to be represented. It's like it's just a new character that we created. So even though Snoop in that case is he's basically an actor, he's playing the dungeon master, but it's not Snoop Dogg, it's whoever the dungeon master is. If you want to actually make it so that you have an AI embodying a real creator, there's a whole set of things that you need to do to make sure that that AI is not going to say things that the creator doesn't want, and that the AI is going to know things and be able to represent things in the way that the creator would want, the way that the creator would know. I think that it's less of a question around having the Avatar express them that I think it's like we have our v one of that that will release soon after connect, but that'll get better over time. But a lot of this is really just about continuing to make the models for these AI's, that they're just more and more, I don't know, you could say, reliable or predictable in terms of what they'll communicate. So that way, when you want to create the Lex assistant AI that your community can talk to, you don't program them like normal computers. You're training them. They're AI models, not normal computer programs. But you want to get it to be predictable enough so that way you can set some parameters for it. And even if it isn't perfect all the time, you want it to generally be able to stay within those bounds. So that's a lot of what I think we need to nail for the creators. And that's why that one's actually a much harder problem, I think, than starting with new characters that you're creating from scratch. So that one, I think, will probably start releasing sometime next year, not this year, but experimenting with existing characters and the assistant and games and a bunch of different personalities and experimenting with some small businesses. I think that that stuff will be ready to do this year, and we're rolling it out basically right after Kinect. Yeah. I'm deeply entertained by the possibility of me sitting down with myself and saying, hey, man, you need to stop the dad jokes or whatever. The idea of a podcast between you and AI assistant Lex podcast, I mean. There is just even the experience of a codec avatar being able to freeze yourself, like basically first mimic yourself. So everything you do, you get to see yourself do it. That's a surreal experience that feels like if I was like an ape looking in a mirror for the first time, realizing, like, oh, that's you, but then freezing that and being able to look around like I'm looking at you, it's a. I don't know how to put it into words, but it just feels like a fundamentally new experience. Like, I'm seeing maybe color for the first time, seeing. I'm experiencing a new way of seeing the world for the first time because it's physical reality, but it's digital, like, and realizing that that's possible is just blowing my mind. It's just really exciting because I lived most of my life before the Internet and experiencing the Internet, experiencing voice communication and video communication, you think like, well, there's a ceiling to this, but this is making me feel like, oh, there might not be. There might be that blend of physical reality and digital reality. That's actually what the future is. Yeah, I think so. It's a weird experience. It feels like the early days of, like, a totally new way of living, and, like, there's a lot of people that kind of complain. Well, you know, the Internet is not. That's not reality. You need to turn all that off and go, you know, in nature. But this feels like this will make those people happy, I feel like. Because this feels real, the flaws and everything. Yeah, well, I mean, a big part of how we're trying to design these new computing products is that they should be physical. I think that's a big part of the issue with computers and tvs and even phones is like, yeah, I mean, maybe you can interact with them in different places, but they're fundamentally, like, you're sitting, you're still. And, I mean, people are just not meant to be that way. I mean, I think you and I have this shared passion for sports and martial arts and doing stuff like that. We're just moving around. It's like, so much of what makes us people is like, you move around, we're not just like a brain in a tank. Right? It's where the human experience is a physical one. So it's not just about having the immersive expression of the digital world. It's about being able to really natively bring that together. And I do really think that the real world is this mix of the physical and the digital is. There's too much digital at this point for it to just be siloed to a small screen. But the physical is too important. So you don't want to just sit down all day long at a desk. So I think that this is, yeah, I do think that this is the future. This is, I think the kind of philosophical way that I would want the world to work in the future is a much more coherently blended physical and digital world. There might be some difficult philosophical and even ethical questions we have to figure out as a society. Maybe you can comment on this. So the metaverse seems to enable, sort of unlock a lot of experiences that we don't have in the physical world. And the question is like, what is and isn't allowed in the metaverse? You know, in video games, we allowed all kinds of crazy stuff, and in physical reality, a lot of that is illegal. So where's that line, where's that gray area between video game and physical reality? Do you have a sense of that? Well, I think, I mean, there are content policies and things like that, right, in terms of what people are allowed to create. But I mean, a lot of the rules around physical, I think you try to have a society that is as free as possible, meaning that people can do as much of what they want, unless you're going to do damage to other people and infringe on their rights. And the idea of damage is somewhat different in a digital environment. I mean, when I get into some world with my friends, the first thing we start doing is shooting each other, which obviously we would not do in the physical world because you hurt each other. But in a game, that's just almost, it's just fun. And even the lobby of a game, it's not even bearing on the game. It's kind of a funny sort of humorous thing to do. So it's like, is that problematic? I don't think so, because fundamentally you're not causing harm in that world. So I think that the part of the question that I think we need to figure out is what are the ways where things could have been harmful in the physical world, that we will now be freed from that, and therefore there should be fewer restrictions in the digital world. And then there might be new ways in which there could be harm in the digital world that there werent the case before. So theres more anonymity, right? When you show up to a restaurant or something, its all the norms where you pay the bill at the end. Its because you have one identity, and if you stiff them, then life is a repeat game, and, and that's not going to work out well for you. But in a digital world, where you can be anonymous and show up in different ways, I think the incentive to act like a good citizen can be a lot less, and that causes a lot of issues and toxic behavior. So that needs to get sorted out. So I think in terms of what is allowed, I think you want to just look at what are the damages, but then there's also other things that are not related to kind of harm. Less about what should be allowed and more about what will be possible that are more about the laws of physics. It's like if you wanted to travel to see me in person, you'd have to get on a plane, and that would take a few hours to get here, whereas we could just jump in a conference room and put on these headsets, and we're basically teleported into a space where we're, you know, it feels like we're together. So that's a very novel experience that, um, that it. It breaks down some things that previously would have defied the laws of physics for what it would take to get together, and I think that that will create a lot of new opportunities. Right. So, um. And one of the things that I'm curious about is there are all these debates right now about, you know, remote work or people being together. And, you know, I think this gets us a lot closer to being able to work physically in different places, but actually have it feel like we're together. Um, so, you know, I think that the dream is that, is that people will one day be able to just work wherever they want. Uh, but we'll have all the same opportunities because you'll be able to feel like you're physically together. I think we're not there today with. With, um. With just video conferencing and the basic technologies that we have. But I think part of the idea is that with something like this, over time, you could get closer to that, and that would open up a lot of opportunities. Right. Because then people could live physically where they want while still being able to get the benefits of being physically or kind of feeling like you're together with people at work. All the ways that that helps to build more culture and build better relationships and build trust, which I think are real issues that if you're not seeing people in person ever. So, yeah, I don't know. I think it's going to be. It's very hard from first principles to think about all the implications of a technology like this and all the good and the things that you need to mitigate. So you try to do your best to envision what things are going to be like and accentuate the things that they're going to be awesome and hopefully mitigate some of the downside things. But the reality is that we're going to be building this out one year at a time. It's going to take a while, so we're going to just get to see how it evolves and what developers and different folks do with it. If you could comment, this might be a bit of a very specific technical question, but llama two is incredible. You've released it recently, there's already been a lot of exciting developments around it. What's your sense about its release and is there a llama three in the future? Yeah, I mean, I think on the last podcast that we did together, we were talking about the debate that we were having around open sourcing Lama two, and I'm glad that we did. I think at this point the value of open sourcing a foundation model like Lama two is significantly greater than the risks in my view. We spent a lot of time, took a very rigorous assessment of that and red teaming it, but I'm very glad that we released Lama two. I think the reception has been, it's just been really exciting to see how excited people have been about it. And it's gotten way more downloads and usage than I would have even expected and I was pretty optimistic about it. That's been great. Llama three, there's always another model that we're training for right now. We train Lama two and we released as an open source model. And right now the priority is building that into a bunch of the consumer products, all the different AI's and a bunch of different products that we're basically building as consumer products. Because llama two, by itself, it's not a consumer product. It's more of a piece of infrastructure that people could build things with. That's been the big priority is continuing to fine tune and just get llama two and the branches that we built off of it ready for consumer products that hopefully hundreds of millions of people will enjoy using those products in billions one day. But yeah, we're also working on the future foundation models and I don't have anything new or news on that. I don't know exactly when it's going to be ready. I think just like we had a debate around llama two and open sourcing it, I think we'll need to have a similar debate and process to red team this and make sure that this is safe. And my hope is that we'll be able to open source this next version when it's ready too. But we're nothing close to doing that this month. It's a thing that we're still somewhat early and working on. Well, in general. Thank you so much for open sourcing llama two and for being transparent about all the exciting developments around AI. I feel like that's contributing to a really awesome conversation about where we go with AI. And obviously, it's really interesting to see all the same kind of technology integrated into these personalized AI systems with the AI Personas, which I think when you put it in people's hands and they get to have conversations with these AI Personas, you get to see interesting failure cases like where the things are dumb or they go into weird directions. And we get to learn as a society together what's too far, what's interesting, what's fun, how much personalization is good, how much generic is good, and we get to learn all of this, and you probably don't know this yourself, we have to all figure it out by using it, right? Yeah. I mean, part of what we're trying to do with the initial AI's launch is having a diversity of different use cases just so that people can try different things, because I don't know what's going to work. I mean, are people going to like playing in the text based adventure games? Or are they going to like having a comedian who can add jokes, um, to, to threads, or they can want to interact with historical figures? Um, you know, we made, we made one of Jane Austen and one of Marcus Aurelius, and I'm curious to see how that goes. I'm excited for both as a big fan, I'm excited for both to have a conversation with them. I mean, yeah, that's, yeah, you know, and I am also excited to see, you know, the Internet, I don't know if you heard, can get kind of weird, and I applaud them for it, so. I heard that, yeah, yeah. It'd be nice to see how weird they take it. What kind of memes are generated from this? And I think all of it is, especially in these early stages of development, as we progress towards AGI, it's good to learn by playing with those systems and interacting with them at like, a large scale, like you said. Yeah, totally. I mean, that's why, well, we're starting out with a set, and then we're also working on this platform that we call AI studio that's going to make it so that over time, anyone will be able to create one of these AI's, almost like they create any other ugc content across the platform. So I'm excited about that. I think that to some degree, we're not going to see the full potential of this until you just have the full creativity of the whole community being able to build stuff. But there's a lot of stuff that we need to get right. Um, so I'm excited to take this in stages. I don't. I don't think anyone out there is really doing what we're doing here. I think that there are. There are people who are. Who are doing kind of like, fictional or consumer oriented character type stuff. But the extent to which we're building it out with the avatars and expressiveness and. And making it so that they can interact across all of the different apps, and they'll have profiles, we'll be able to engage people on Instagram and Facebook. I think it's just. It's going to be really fun. Well, I'm still. So we're talking about AI, but I'm still blown away this entire time that I'm talking to Mark Zuckerberg and you're not here, but you feel like you're here. I've done quite a few intimate conversations with people alone in a room, and this feels like that. So I keep forgetting for long stretches of time that, like, we're not in the same room. And for me to imagine a future where I can, with a snap of a finger, do that with anyone in my life, the way we can just call right now and have this kind of shallow 2d experience, to have this experience, like we're sitting next to each other is like, I don't think we can even imagine what. How that changes things. Where you can immediately have intimate one on one conversations with anyone that might, like, in a way we might not even predict, change civilization. Well, I mean, this is a lot of the thesis behind the whole metaverse is giving people the ability to feel like you're present with someone. I mean, this is like, the main thing I talk about all the time, but I do think that there's a lot to process about it. I mean, from my perspective, I mean, I. I'm definitely here. We're just not. We're not physically in the same place. It's not like you're not talking to an AI. Right? So I think the thing that's novel is the ability to convey through technology, a sense of almost physical presence. So the thing that is not physically real is us being in the same physical place, but kind of everything else is. And I think that that gets to this somewhat philosophical question about what is the nature of kind of the modern real world. And I just think that that's, it really is this combination of a physical world and the presence that we feel, but also being able to combine that with this increasingly rich and powerful and capable digital world that we have and all of the. The innovation that's getting created there. So I think it's super exciting because the digital world is just increasing in its capability and our ability to do awesome things. But the physical world is so profound, and that's a lot of what makes us human is that we're physical beings. So I don't think we want to run away from that and just spend all day on a screen. And that's like, it's one of the reasons why I care so much about helping to shape and accelerate the, these future computing platforms. I just think this is so powerful. And even though the current version of this is like you're wearing a headset, I just think this is going to be by far the most human and social computing platform that has ever existed. And that's what makes me excited. Yeah, I think just to linger on this kind of changing nature of reality of what is real, maybe shifting it towards the sort of consciousness. So what is real is the subjective experience of a thing that makes it feel real versus necessarily being in the same physical space, because it feels like we're in the same physical space, and that the conscious experience of it, that's probably what is real. Not like that, the space time, like the physics of it. Like, you're basically breaking physics and focusing on the consciousness. That's what's real, just whatever is going on inside my head. But there are a lot of social and psychological things that go along with that experience that was previously only physical presence. Right. I think that there's like an intimacy, a trust. You know, there's a level of communication, because so much of communication is nonverbal, and it's based on expressions that you. You're kind of, you're sharing with someone when you're in this kind of environment. And before, those things would have only been possible had I gotten on a plane and flown to Austin and sat physically with you in the same place. So I think we're basically shortcutting those laws of physics and delivering the social and psychological benefits of being able to be present and feel like you're there with another person, which I think are real benefits to anyone in the world. And I think that, like you said, I think that is going to be a very profound thing. And a lot of that is that's the promise of the metaverse and why I think that that's the next frontier for what we're working on. I started working on social networks when they were primarily text or the first version of Facebook. Your profile, you had one photo, and the rest of it was like, lists of things that you were interested in. And then we kind of went through the period where we're doing photos, and now we're kind of in the period where most of the content is video. But there's a clear trend where over time, the way that we want to express ourselves and kind of get insight and content about the world around us gets increasingly just richer and more vivid. And I think the ability to be immersed and feel present with the people around you or the people who you care about is, from my perspective, clearly the next frontier. It just so happens that it's incredibly technologically difficult. Right. And requires building up these new computing platforms and completely new software stacks to deliver that. But, I mean, I kind of feel like that's what we're here to do as a company. Well, I really love the connection you have through conversation. And so for me, this photorealism is really, really exciting. I'm really excited for this future, and thank you for building it. Thanks to you, and thanks to the amazing meta teams that I've met, the engineers, and just everybody I've met here, thank you for helping to build this future. And thank you, Mark, for talking to me inside the metaverse. This is blowing my mind. I can't quite express. I would love to measure my heart rate this whole time. Would be hilarious if you're actually, like, sitting on a beach right now. I'm not. I'm in a conference room. Okay, well, I'm at a beach and not wearing any pants. I'm really sorry about that for anyone else who's watching me in physical space. Anyway, thank you so much for talking today. This really blew my mind. It's one of the most incredible experiences of my life. So thank you for giving that to me. Awesome, awesome. Glad you got to check it out, and I'm. It's always fun to talk. All right, I'll catch you soon. See ya. See you later. This is so, so amazing, man. This is so amazing.

Utterances:
Speaker A: The following is a conversation with Mark Zuckerberg inside the metaverse. Mark and I are hundreds of miles apart from each other in physical space, but it feels like we're in the same room because we appear to each other as photorealistic codec avatars in 3d with spatial audio. This technology is incredible, and I think it's the future of how human beings connect to each other in a deeply meaningful way. On the Internet, these avatars can capture many of the nuances of facial expressions that we use. We humans use to communicate emotion to each other. Now I just need to work on upgrading my emotion expressing capabilities of the underlying human. This is the Lex Friedman podcast. And now, dear friends, here's Mark Zuckerberg.
Speaker B: Wow.
Speaker A: This is so great. Lighting change. Wow.
Speaker B: Yeah, we can put the light anywhere.
Speaker A: And it doesn't feel awkward to be really close to you.
Speaker B: No, it does. I actually moved you. I moved you back a few feet before you got into a headset. You were like, right here.
Speaker A: I don't know if people can see this, but this is incredible. The realism here is just incredible. Where am I? Where are you, Mark? Where are we?
Speaker B: You're in Austin, right?
Speaker A: No, I mean this place. We're shrouded by darkness with ultra realistic face, and it just feels like we're in the same room. This is really the most incredible thing I've ever seen. And sorry to be in your personal space. I mean, we have done jujitsu before.
Speaker B: Yeah, no, I was commenting to the team before that even that I feel like we've choked each other from further distances than it feels like we are right now.
Speaker A: I mean, this is just really incredible. I don't know how to describe it with words. It really feels like. It feels like we're in the same room.
Speaker B: Yeah.
Speaker A: Feels like the future. This is truly, truly incredible. I just wanted to take it in. I'm still getting used to it. It's like it's you. It's really you. But you're not here with me, right. You're there wearing a headset, and I'm wearing a headset. It's. It's really, really incredible. So what, um. Can you describe what it takes currently for us to appear so photorealistic to each other?
Speaker B: Yeah, so, I mean, for background, we both did these scans for this research project that we have at meta called codec avatars. And the idea is that instead of our avatars being cartoony and instead of actually transmitting a video, what it does is we've sort of scanned ourselves in a lot of different expressions. And we've built a computer model of sort of each of our faces and bodies and the different expressions that we make and collapse that into a codec that then when you have the headset on your head, it sees your face, it sees your expression, and it can basically send a. An encoded version of what you're supposed to look like over the wire. So in addition to being photorealistic, it's also actually much more bandwidth efficient than transmitting a full video, or especially a 3d, immersive video of a whole scene like this.
Speaker A: And it captures everything. The flaws, to me, the subtleties of the human face, even the flaws, that's all amazing. It makes you. It makes it so much more immersive. It makes you realize that, like, perfection isn't the thing that leads to immersion. It's like the little subtle flaws, like freckles and, like, variations in color and just.
Speaker B: Yeah. Wrinkles.
Speaker A: All stuff about roses. Yeah. Asymmetry and just the different, like, the corners of the eyes, like what your eyes do when you smile. All that kind of stuff.
Speaker B: Yeah. Eyes are a huge part of it. Yeah. I mean, there's all the studies that most of communication, even when people are speaking, is not actually the words that they're saying. Right. It's kind of the expression and all that. So we try to capture that with the kind of classical expressive avatar system that we have. That's the kind of more cartoon designed one. You can kind of put those kind of expressions on those faces as well. But there's obviously a certain realism that comes with delivering kind of this photorealistic experience that. I don't know, I just think it's really magical. I mean, this gets to kind of the core of what the vision around virtual and augmented reality is of, like delivering a sense of presence as if you're there together no matter where you actually are in the world. And, I mean, this experience, I think, is a good embodiment of that, where it's like, I mean, we're in two completely different states halfway across the country, and it just, like, looks like you're just sitting right in front of me. It's pretty wild.
Speaker A: Yeah, I mean, I can't. It's. I'm almost getting emotional. It's like. It feels like a totally fundamentally new experience. Like, for me to have this kind of conversation with loved ones, it would just change everything. Maybe just to elaborate. So the. I went to Pittsburgh and went through the whole scanning procedure, which has so much incredible technology, so software and hardware going on, but it is a lengthy process so what's your vision for the future of this in terms of making this more accessible to people?
Speaker B: It starts off with a small number of people doing these very detailed scans, which that's the version that you did and that I did and before, there are a lot of people who we've done this kind of a scan for. We probably need to kind of over collect expressions when we're doing the scanning, because we haven't figured out how much we can reduce that down to a really streamlined process and extrapolate from the scans that have already been done. But the goal, and we have a project that's working on this already, is just to do a very quick scan with your cell phone, where you just take your phone, wave it in front of your face for a couple of minutes, say a few sentences, make a bunch of expressions, but overall, have the whole process just be two to three minutes, and then produce something that's of the quality of what we have right now. So I think that that's one of the big challenges that remains. And right now we have the ability to do the scans if you have hours to sit for one. And with today's technology, I mean, you're using a meta headset that exists. It's a product that's for sale. Now, you can drive these with that, but the production of these scans in a very efficient way is one of the last pieces that we still need to really nail. And then obviously, there's all the experiences around it. Right now, we're sitting in a dark room, which is familiar for your podcast. But I think part of the vision for this over time is not just having this be like a video call. That's fine, it's cool, or it feels like it's immersive, but you can do a video call on your phone. The thing that you can do in the metaverse that is different from what you can do on a phone is doing stuff where you're physically there together and participating in things together. And we could play games like this, we could have meetings like this in the future. Once you get mixed reality and augmented reality, we could have codec avatars like this and go into a meeting and have some people physically there and have some people show up in this photorealistic form superimposed on the, on the physical environment. I think that stuff like that is going to be super powerful. So we got to still build out all those kind of applications and the use cases around it. But I don't know. I think it's going to be a pretty wild. Next few years around this, I mean, I just.
Speaker A: I'm actually almost at a loss of words. This is just so incredible. This is truly incredible. I hope that people, like, watching this can get a glimpse of, like, how incredible it is. It really feels like we're in the same room. Like, there is that. I guess there's an uncanny valley that seems to have been crossed here. Like, it looks like you.
Speaker B: Yeah, there's still a bunch of tuning that I think we'll want to do where different people emote to different extents. Right? So I think one of the big questions is, you know, like, when you smile, how wide is your smile and how wide do you want your smile to be? And I think getting that to be tuned on a per person basis is going to be one of the things that we're going to need to figure out. It's like, to what extent do you want to give people control over that? Some people might try to prefer a version of themselves that's more emotive in their avatar than their actual faces, for example. You know, I always get a lot of critique and shit for having, like, a relatively stiff expression, but, you know, I mean, I might feel pretty happy, but just make a pretty small smile. So, I mean, maybe, you know, for me, I would. It's actually. It's like I'd wanna have my avatar really be able to better express, like, how I'm feeling than how I can do physically. So I think that there's a question about how you wanna tune that. But. But overall, yeah, I mean, we want to start from the baseline of capturing how people actually emote and express themselves. And I think the initial version of this has been pretty impressive. And like you said, I do think we're kind of beyond the uncanny valley here where it does feel like you. It doesn't feel weird or anything like that.
Speaker A: I mean, that's going to be the meme that the two most monotone people are in a metaverse together. But I think that actually makes it more difficult. The amazing thing here is that the subtleties of the expression of the eyes. People say I'm monotone and emotionless, but I'm not. It's just this. Maybe my expression of emotion is more subtle, usually, like, with the eyes. And that's one of the things I've noticed, is just how expressive the subtle movement of the corners of the eyes are in terms of displaying happiness or boredom or all that kind of stuff.
Speaker B: I am curious to see, just because I've never done one of these before, I've never done a podcast as one of these codec avatars, and I'm curious to see what people think of it, because one of the issues that we've had in some of the VR and mixed reality work is it tends to feel a lot more profound when you're in it than the 2d videos capturing the experience. So I think that this one, because it's photorealistic, may look kind of as amazing in 2d for people watching it, as it. As it feels, I think, to be in it. But we've certainly had this issue where a lot of the other things just. It's like you feel the sense of immersion when you're in it. That doesn't quite translate to a 2d screen. But I don't know, I'm curious to see. To see what people think.
Speaker A: Yeah, I'm curious to see if people could see that, like, my heart is actually beating fast now. This is super interesting. Like, the. Such intimacy of conversation could be achieved remotely. There's been, you know, I don't do remote podcasts for this reason. And this is like, breaks all of that. This feels like just an incredible transition to something else, to different kind of communication. Breaks all barriers, like geographic, physical barriers. What you mentioned, do you have a sense of timeline in terms of how many difficult things have to be solved to make this more accessible to scanning with a smartphone?
Speaker B: Yeah, I think we'll probably roll this out progressively over time, so it's not going to be like we roll it out and one day everyone has a codec avatar. We want to get more people scanned and into the system, and then we want to start integrating it into each one of our apps, making it so that. I think that for a lot of the work style things, productivity, I think that this is going to make a ton of sense in a lot of game environments. I mean, this could be fine, but games tend to have their own style, right, where you almost want to fit more with the aesthetic style of the. Of the game. Um, but I think for doing meetings and one of the things that we get a lot of feedback on workrooms where, you know, people are pretty blown away by the experience and this feeling that you can, like, be remote, but feel like you're physically there around a table with people, but then, you know, we get some feedback that people have a hard time with, the fact that the avatars are so expressive and. And don't feel as realistic in that environment. So I think something like this could make a very big difference for those remote meetings and especially with quest three coming out, which is going to be the first mainstream mixed reality product where you're really taking digital expressions of either a person or objects and overlaying them on the physical world. I think the ability to do remote meetings and things like that, where you're just remote hang sessions with friends, I think that's going to be very exciting. So, yeah, rolling it out over the next few years, it's not ready to be a mainstream product yet, but we just want to. We'll keep tuning in, keep getting more scans in there, and kind of rolling it out into more of the features. But, yeah, I mean, definitely in the next few years, you'll be seeing a bunch more experiences like this.
Speaker A: Yeah, I would love to see some celebrities scanned and some non celebrities. I just. Just more people to experience this. I would love to see that this is something that, I mean, my mind is blowing. I'm literally at a loss of words because it's very difficult to just convey how incredible this is, how, like, how I feel the emotion, how I feel the presence, how I feel, like, the subtleties of the emotion in terms of, like, work meetings or any kind of. In terms of podcasts, this is awesome. I don't even need your arms or legs. Is that.
Speaker B: Well, we got to get that. I mean, that's its own challenge. And part of the question is also, so you have the scan, then it takes a certain amount of compute to go drive that, both for the sensors on the headset and then rendering it. So one of the things that we're working through is, what is the level of fidelity that is optimal? You could do the full body in a codec, and that can be quite intensive. But one of the things that we're thinking about is, all right, maybe you can stitch a somewhat lower fidelity version of your body, which still have the main movements, but your face is really the thing that we have the most resolution on in terms of being able to read and express emotions. I mean, like you said, if you move your eyebrows like a millimeter, I mean, that really changes the expression and what you're emoting, whereas moving your arm like an inch probably doesn't matter quite as much. So, yeah, so I think that we do want to get all of that into here, and that'll be some of the work over the next period as well.
Speaker A: So you mentioned Quest three. That's coming out. I've gotten a chance to try that, too. That's awesome. So how did you pull off the mixed. So it's not just virtual reality, it's mixed reality?
Speaker B: Yeah, I think it's going to be the first mainstream mixed reality device. I mean, obviously, we shipped Quest pro last year, but it was $1,500. And part of what I'm super proud of is we try to innovate, not just on pushing the state of the art and delivering new capabilities, but making it so it can be available to everyone. We have this, and it's coming out. It's $500. And in some ways, I think the mixed reality is actually better in quest three than it was, than what we're using right now in Quest pro. I'm really proud of the team for being able to deliver that kind of an innovation and get it out, but some of this is just software. You tune over time and get to be better. Part of it is you put together a product and you figure out what are the bottlenecks in terms of making it a good experience. So we got the resolution for the mixed reality cameras and sensors to be multiple times better in quest three. And we just figured that that made a very big difference when we saw the experience that we were able to put together for Quest Pro. And part of it is also that Qualcomm just came out with their next generation chipset for VR, and mister that we worked with them on a custom version of it, but that was available this year for Quest three, and it wasn't available in Quest Pro. So in a way, I'm quest three, even though it's nothing. The pro product actually has a stronger chipset in it than the pro line at a third of the cost. I'm really excited to get this in people's hands. It does all the VR stuff that quest two and the others have done, too. It does it better because the display is better and the chip is better, so you'll get better graphics. It's 40% thinner, so just more comfortable as well. But the mister is really the big capability shift. And part of what's exciting about the whole space right now is this isn't like smartphones, where companies put out a new smartphone every year, and you can almost barely tell the difference between that and the one the year before it. Now, for this, each time we put out a new headset, it has a major new capability. And the big one now is mixed reality. The ability to basically take digital representations of people, um, or objects and. And superimpose them on the world. And basically, you know, I mean, there's a, one version of this is you're going to kind of have these augments or, or holograms and experiences that you can kind of bring into your living room or a meeting space or office. Um, another thing that I just think is going to be a much kind of simpler innovation is that there are a lot of VR experiences today that don't need to be fully immersive. And if you're playing a shooter game or you're doing a fitness experience, sometimes people get worried about swinging their arms around, like, am I going to hit a lamp or something? And am I going to run into something? So having that in mixed reality actually is just a lot more comfortable for people. You kind of still get the immersion and the 3d experience, and you can have an experience that just wouldn't be possible in the physical world alone. But by being anchored to and being able to see the physical world around you, it's like, it just feels so much safer and more secure. And I think a lot of people are really going to enjoy that, too. So, yeah, I'm really excited to see how people use it, but, yeah, quest three coming out later this fall.
Speaker A: Yeah. And I got to experience it with other people sitting around and there's a lot of furniture. And so you get to see that furniture. You get to see those people, and you get to see those people, like, enjoy the ridiculousness of you, like swinging your arms. I mean, presumably they're friends of yours, even if they make fun of you. There's a lot of love behind that. And that you got to experience that. That's a really fundamentally different experience than just pure VR with, like, with zombies coming out of walls and.
Speaker B: Yeah, it's like someone shooting at you and you hide behind your real couch in order to duck the fire.
Speaker A: Yeah, it's incredible how it's all integrated, but also, like, subtle stuff, like in a room with no windows, you can add windows to it and you can look outside as the zombies run towards you. But, like, it's still nice view outside of, you know. Yeah, it's really. And so that's pulled off by having cameras on the outside of the headset that do the pass through. That technology is incredible to do that on a small headset.
Speaker B: Yeah, it's not just the cameras. You basically need to. You need multiple cameras to capture the different angles and sort of the three dimensional space. And then it's a pretty complex compute problem, an AI problem, to map that to your perspective because the cameras aren't exactly where your eyes are, because no two people's eyes are going to be in exactly the same place. You need to get that to line up and then do that basically in real time and then generate something that feels natural and then superimpose whatever digital objects you want to put there. So, yeah, it's a very interesting technical challenge. I think we'll continue tuning this for the years to come as well. But I'm pretty excited to get this out because I think Quest three is going to be the first device like this that millions of people are going to get. That's mixed reality, and it's only when you have millions of people using something that you start getting the whole developer community really starting to experiment and build stuff, because now there are going to be people who actually use it. So I think we got some of that flywheel going with Quest Pro, but I think it'll really get accelerated once quest three gets out there. So, yeah, I'm pretty excited about this one.
Speaker A: Plus there's hand tracking without, so you don't need to have a control. So the cameras aren't just doing the pass through of the entire physical reality around you, it's also tracking the details of your hands in order to use that for, like, gesture recognition, this kind of stuff.
Speaker B: Yeah, we've been able to get way further on hand recognition in a shorter period of time than I expected, so that's been pretty cool. I don't know. Did you see the demo experience that we built around piano? Like. Yeah, the piano. Learning to play piano.
Speaker A: Yeah, it's incredible. You're basically playing piano on a table, and that's without any controller and how well it matches physical reality with no latency, and it's tracking your hands with no latency, and it's tracking all the people around you with no latency. Integrating physical reality and digital reality, obviously that connects exactly to this Kodak avatar, which is in parallel, allows us to have ultra realistic copies of ourselves in this mixed reality. So it's all converging towards an incredible digital experience in the metaverse, to me, obviously, I love the intimacy of conversation, so even this is awesome. But do you have other ideas of what this unlocks? Something like Kodak Avatar unlocks in terms of applications, in terms of things, were we able to do?
Speaker B: Well, there's what you can do with avatars overall in terms of superimposing digital objects on the physical world, and then there's kind of psychologically, what does having photorealistic do? So I think we're moving towards a world where we're going to have something that looks like normal glasses, where you see the physical world, but you also see holograms, and in that world, I think that they're going to be not too far off. Maybe by the end of this decade, we'll be living in a world where there are as many holograms when you walk into a room as there are physical objects. And it really raises this interesting question about what are about. A lot of people have this phrase where they call the physical world the real world. And I kind of think increasingly, the physical world is super important, but I actually think the real world is the combination of the physical world and the digital worlds coming together. But until this technology, they were sort of separate. It's like you access the digital world through a screen, and maybe it's a small screen that you carry around, or it's a bigger screen when you sit down at your desk and strap in for a long session. But they're fundamentally divorced and disconnected. And I think part of what this technology is going to do is bring those together into a single coherent experience of what the modern real world is, which is it's got to be physical, because we're physical beings. So the physical world is always going to be super important. But increasingly, I think a lot of the things that we think of can be digital holograms. I mean, any screen that you have can be a hologram in any media, in any book, art. It can basically be just as effective as a hologram, as a physical object. Any game that you're playing, a board game or any kind of physical game, cards, ping pong, things like that, they're often a lot better as holograms because you could just of snap your fingers and instantiate them and have them show up. It's like you have a ping pong table show up in your living room, but then you can snap your fingers and have it be gone. So that's super powerful. So I think that it's actually an amazing thought experiment of how many physical things we have today that could actually be better as interactive holograms. But then beyond that, I think the most important thing, obviously, is people. So the ability to have these mixed hangouts, whether they're social or meetings where you show up to a conference room, you're wearing glasses or a headset in the very near term, but hopefully by over the next five years, glasses or so, and you're there physically. Some people are there physically, but other people are just there as holograms. And it feels like it's theme, um, who are right there. And, and also, by the way, another thing that I think is going to be fascinating about being able to blend together the digital and physical worlds in this way is we're also going to be able to embody, um, AI's as well. So I think you'll also have meetings in the future where you're basically, you know, maybe you're sitting there physically, and then you have, you know, a couple of other people who are there as holograms, and then you have, like, Bob, the AI, who's an engineer on your team who's helping with things, and he can now be embodied as a realistic avatar as well, and just join the meeting in that way. So I think that that's going to be pretty compelling as well. Okay, so what can you do with photorealistic avatars compared to kind of the more expressive ones that we have today? Well, I think a lot of this actually comes down to acceptance of the technology and because all of the stuff that we're doing, I mean, the motion of your eyebrows, the motion of your eyes, the cheeks and all of that, there's actually no reason why you couldn't do that on an expressive avatar, too. I mean, it wouldn't look exactly like you, but you could make a cartoon version of yourself and still have it be almost as expressive. But I do think that there's this bridge between the current state of most our interactions in the physical world and where we're getting in the future with this kind of hybrid physical and digital world, where I think it's going to be a lot easier for people to kind of take some of these experiences seriously with the photorealistic avatars to start. And then I'm actually really curious to see where it goes longer term. I could see a world where people stick to the photorealistic and maybe they modify them to make them a little bit more interesting. But maybe fundamentally, we like photo realistic things. But I can also see a world that once people get used to the photorealistic avatars and they get used to these experiences, I actually think that there could be a world where people actually prefer being able to express themselves in ways that aren't so tied to their physical reality. And so that's one of the things that I'm really curious about. And I don't know, in a bunch of our internal experiments on this, one of the things that I thought was psychologically pretty interesting is people have no issues blending photo realistic stuff. And not so we could have a. For this specific scene that we're in now, we happen to sort of being in a dark room. I think part of that aesthetic decision, I think, was based on the way you like to do your podcast. But we've done experiences like this where you have a cartoony background, but photo realistic people who you're talking to and we seem to like, people just seem to just think that that is completely normal. It doesn't bother you, it doesn't feel like it's weird. Another thing that we've experienced with is basically you have a photorealistic avatar that you're talking to, and then right next to them, you have an expressive kind of cartoon avatar. And that actually is pretty normal too. Right? It's not that weird to basically being, interacting with different people in different modes like that. So I'm not sure. I think it'll be an interesting question to what extent these photorealistic avatars are a key part of just transitioning from being comfortable in the physical world to this kind of new, modern real world that kind of includes both the digital and physical. Or if this is like the long term way that it stays. Um, that's, that's a. I mean, I think that they're going to be useless for both the expressive and the photorealistic over time. I just don't know what the balance is going to be.
Speaker A: Yeah, it's a really good, interesting philosophical question, but to me, in the short term, the photorealistic is amazing to where I would prefer, like you said, the work room. But like, on a beach with a beer, just to see a buddy of mine remotely on a chair next to me drinking a beer. I mean, that as realistic as possible is an incredible experience. So I don't want any fake hats on him. I don't want any just chilling with it with a friend, drinking beer, looking at the ocean while not being in the same place together. I mean, that. Yeah, that experience is just, it's a fundamentally, it's just a high quality experience of friendship. Whatever we seek in friendship, it seems to be present there in the same kind of realism I'm seeing right now. This is totally a game changer. So to me, I can see myself sticking with this for a long time.
Speaker B: Yeah. And I mean, it's also, it's novel, and it's also a technological feat. Right. It's like, being able to pull this off is like, it's like a pretty impressive, and I think to some degree it's just this kind of like, awesome experience.
Speaker A: But I'm already, sorry to interrupt, I'm already forgetting that you're not real. Like this really novel.
Speaker B: This is just an avatar version of me.
Speaker A: But it's a philosophical question.
Speaker B: Yes, but I mean, but here's some of the. So I put this on this morning, and I was like, all right. It's like, okay, so my hair is a little shorter in this than my physical hair is right now. I probably need to go get a haircut and like. And I actually, I did happen to shave this morning, but if I hadn't, I could still have this photo realistic avatar that is more cleanly shaven, even if I'm a few days in physically. So I do think that there are going to start to be these subtle questions that seep in where the avatar is realistic in the sense of, this is what you looked like at the time of capture, but it's not necessarily temporally accurate to exactly what you look like in this moment. I think there are going to end up being a bunch of questions that come from that over time that I think are going to be fascinating, too.
Speaker A: You mean just the nature of identity, of who we are? You know, how people do, like, summer beach body will people be for the scan? They'll try to lose some weight and look their best and sexiest with the nice hair and everything like that? It does. It does raise the question of, if a lot of people are interacting with the digital version of ourselves, who are we really? Are we the entity driving the avatar, or are we the avatar?
Speaker B: Well, I mean, I think our physical bodies also fluctuate and change over time, too. So I think there's a similar question of which version of that are we? Right. There's like the. I mean, and it's interesting identity question, because. All right, it's like. I don't know, it's like weight fluctuates or things like that. I think most people don't tend to think of themselves as the. I don't know. It's an interesting psychological question. Maybe some people. Maybe a lot of people do think about themselves as the kind of worst version, but I think a lot of people probably think about themselves as the best version, and then it's like what you are on a day to day basis doesn't necessarily map to. To either of those. So I know that's. Yeah, there will definitely be a bunch of social scientists and folks will have to, and psychologists.
Speaker A: Really.
Speaker B: There's gonna be a lot to understand about how our perception of ourselves and others has shifted from this.
Speaker A: Well, this might be a bit of a complicated and a dark question, but one of the first feelings I had experiencing this is, I would love to talk to loved ones. And the next question I have is, I would love to talk to people who are no longer here that are loved ones. So, like, if you look into the future, is that something you think about? Who people who pass away, but they can still exist in the metaverse. You can still have, you know, talk to your father, talk to your grandfather and grandmother and mother once they pass away. The power of that experience is one of the first things my mind jumped to because it's like, this is so real.
Speaker B: Yeah, I think that there are a lot of norms and things that people have to figure out around that. There's probably some balance where if someone has lost a loved one and is grieving, there may be ways in which being able to interact or relive certain memories could be helpful, but then theres also probably an extent to which it could become unhealthy. And I mean, im not an expert in that, so I think wed have to study that and understand it in more detail. We have a fair amount of experience with how to handle death and identity and peoples digital content through social media already. Unfortunately. Unfortunately, people who use our services die every day and their families often want to have access to their profiles. And we have whole protocols that we go through where there are certain parts of it that we try to memorialize so that way the family can get access to it, so that way the account doesn't just go away immediately. But then there are other things that are important, private things that that person has. Like we're not going to give the family access to someone's messages, for example. So yeah, I think that there's some best practices, I think, from the current digital world that we'll carry over. But yeah, I think that this will enable some different things. Another version of this is how this intersects with AI's, because one of the things that we're really focused on is we want there to, we want the world to evolve in a way where there isn't like a single AI super intelligence, but where a lot of people are empowered by having AI tools to do their jobs and make their lives better. And if you're a creator and if you run a podcast like you do, then you have a big community of people who are super interested to talk to you. I know you'd love to cultivate that community and you interact with them online outside of the the podcast as well. But I mean, there's way more demand both to interact with you, and I'm sure you'd love to interact with the community more, but you just are limited by the number of hours in the day. So at some point, I think making it so that you could build an AI version of yourself that could interact with people, not after you die, but while you're here to help people kind of fulfill this desire to, to interact with you and your desire to build a community. And there's a lot of interesting questions around that, and that's obviously, it's not just in the metaverse. I think we'd want to make that work across all the messaging platforms, WhatsApp and Messenger and Instagram direct. But there's certainly a version of that where if you could have an avatar version of yourself in the metaverse that people can interact with, and you could define that sort of an AI version where people know that they're interacting with an AI, that it's not the kind of physical version of you, but maybe that AI, even if they know it's an AI, is the next best thing because they're probably not going to necessarily all get to interact with you directly. I think that that could be a really compelling experience. There's a lot of things that we need to get right about it, that we're not ready to release the version, that a creator can build a version of themselves yet, but we're starting to experiment with it in terms of releasing a number of AI's that people can interact with in different ways. And I think that that is also just going to be a very powerful set of capabilities that people have over time.
Speaker A: So you've made major strides in developing these early AI personalities with the idea where you can talk to them across the meta apps and have interesting, unique kind of conversations. Can you describe your vision there in these early strides, and what are some technical challenges there?
Speaker B: Yeah, so a lot of the vision comes from this idea that I don't think we necessarily want there to be one big super intelligence. We want to empower everyone to both have more fun, accomplish their business goals, just everything that they're trying to do. And we don't tend to have one person that we work with on everything. And I don't think in the future we're going to have one AI that we work with. I think you're going to want a variety of these. There are a bunch of different uses. Some will be more assistant oriented. There's sort of the kind of plain and simple one that we're building is called just meta AI. It's simple. You can chat with it in any of your threads. It doesn't have a face, it's just more vanilla and neutral and factual. But it can help you with a bunch of stuff, then there are a bunch of cases that are more business oriented. Let's say you want to contact a small business. Similarly, that business probably doesn't want to have to staff someone to man the phones, and you probably want to wait on the phone to talk to someone. But having someone who you can just talk to in a natural way, who can help you if you're having an issue with a product, or if you want to make a reservation, or if you want to buy something online, having the ability to do that and have a natural conversation rather than navigate some website or have to call someone and wait on hold, I think it's going to be really good both for the businesses and for normal people who want to interact with businesses. So I think stuff like that makes sense. Then there are going to be a bunch of use cases that I think are just fun. So I think people are going to. I think that there will be AI's that can tell jokes, you can put them into chat thread with friends. I think a lot of this because we're a social company, we're fundamentally around helping people connect in different ways. And part of what I'm excited about is how do you enable these kinds of AI's to facilitate connection between two people or more put them in a group chat, make the group chat more interesting around. Whatever your interests are. Sports, fashion, trivia, video games.
Speaker A: I love the idea of playing. I think you mentioned Baldur's Gate, an incredible game. Just having an AI that you play together with, I mean, that seems like a small thing, but it could deeply enrich the gaming experience.
Speaker B: I do think that AI's will make the NPC's a lot better in games too. So that's a separate thing that I'm pretty excited about. But yeah, I mean, one of the AI's that we've built that just in our internal testing people have loved the most, is like a adventure text based. Like a dungeon master.
Speaker A: Nice.
Speaker B: And I think part of what has been fun, we talked about this a bit, but we've gotten some real kind of cultural figures to play a bunch of these folks and be the embodiment and the avatar of them. So Snoop Dogg is the dungeon master, which I think is just hilarious in.
Speaker A: Terms of the next steps of, you know, if you mentioned, you mentioned Snoop to create a snoop AI. So basically AI personality replica a copy or not a copy, maybe inspired by Snoop. What are some of the technical challenges of that? What does that experience look like for Snoop to be able to.
Speaker B: So starting off creating new Personas is easier because it doesn't need to stick exactly to what that physical person would want, how they'd want to be represented. It's like it's just a new character that we created. So even though Snoop in that case is he's basically an actor, he's playing the dungeon master, but it's not Snoop Dogg, it's whoever the dungeon master is. If you want to actually make it so that you have an AI embodying a real creator, there's a whole set of things that you need to do to make sure that that AI is not going to say things that the creator doesn't want, and that the AI is going to know things and be able to represent things in the way that the creator would want, the way that the creator would know. I think that it's less of a question around having the Avatar express them that I think it's like we have our v one of that that will release soon after connect, but that'll get better over time. But a lot of this is really just about continuing to make the models for these AI's, that they're just more and more, I don't know, you could say, reliable or predictable in terms of what they'll communicate. So that way, when you want to create the Lex assistant AI that your community can talk to, you don't program them like normal computers. You're training them. They're AI models, not normal computer programs. But you want to get it to be predictable enough so that way you can set some parameters for it. And even if it isn't perfect all the time, you want it to generally be able to stay within those bounds. So that's a lot of what I think we need to nail for the creators. And that's why that one's actually a much harder problem, I think, than starting with new characters that you're creating from scratch. So that one, I think, will probably start releasing sometime next year, not this year, but experimenting with existing characters and the assistant and games and a bunch of different personalities and experimenting with some small businesses. I think that that stuff will be ready to do this year, and we're rolling it out basically right after Kinect.
Speaker A: Yeah. I'm deeply entertained by the possibility of me sitting down with myself and saying, hey, man, you need to stop the dad jokes or whatever.
Speaker B: The idea of a podcast between you and AI assistant Lex podcast, I mean.
Speaker A: There is just even the experience of a codec avatar being able to freeze yourself, like basically first mimic yourself. So everything you do, you get to see yourself do it. That's a surreal experience that feels like if I was like an ape looking in a mirror for the first time, realizing, like, oh, that's you, but then freezing that and being able to look around like I'm looking at you, it's a. I don't know how to put it into words, but it just feels like a fundamentally new experience. Like, I'm seeing maybe color for the first time, seeing. I'm experiencing a new way of seeing the world for the first time because it's physical reality, but it's digital, like, and realizing that that's possible is just blowing my mind. It's just really exciting because I lived most of my life before the Internet and experiencing the Internet, experiencing voice communication and video communication, you think like, well, there's a ceiling to this, but this is making me feel like, oh, there might not be. There might be that blend of physical reality and digital reality. That's actually what the future is.
Speaker B: Yeah, I think so.
Speaker A: It's a weird experience. It feels like the early days of, like, a totally new way of living, and, like, there's a lot of people that kind of complain. Well, you know, the Internet is not. That's not reality. You need to turn all that off and go, you know, in nature. But this feels like this will make those people happy, I feel like. Because this feels real, the flaws and everything.
Speaker B: Yeah, well, I mean, a big part of how we're trying to design these new computing products is that they should be physical. I think that's a big part of the issue with computers and tvs and even phones is like, yeah, I mean, maybe you can interact with them in different places, but they're fundamentally, like, you're sitting, you're still. And, I mean, people are just not meant to be that way. I mean, I think you and I have this shared passion for sports and martial arts and doing stuff like that. We're just moving around. It's like, so much of what makes us people is like, you move around, we're not just like a brain in a tank. Right? It's where the human experience is a physical one. So it's not just about having the immersive expression of the digital world. It's about being able to really natively bring that together. And I do really think that the real world is this mix of the physical and the digital is. There's too much digital at this point for it to just be siloed to a small screen. But the physical is too important. So you don't want to just sit down all day long at a desk. So I think that this is, yeah, I do think that this is the future. This is, I think the kind of philosophical way that I would want the world to work in the future is a much more coherently blended physical and digital world.
Speaker A: There might be some difficult philosophical and even ethical questions we have to figure out as a society. Maybe you can comment on this. So the metaverse seems to enable, sort of unlock a lot of experiences that we don't have in the physical world. And the question is like, what is and isn't allowed in the metaverse? You know, in video games, we allowed all kinds of crazy stuff, and in physical reality, a lot of that is illegal. So where's that line, where's that gray area between video game and physical reality? Do you have a sense of that?
Speaker B: Well, I think, I mean, there are content policies and things like that, right, in terms of what people are allowed to create. But I mean, a lot of the rules around physical, I think you try to have a society that is as free as possible, meaning that people can do as much of what they want, unless you're going to do damage to other people and infringe on their rights. And the idea of damage is somewhat different in a digital environment. I mean, when I get into some world with my friends, the first thing we start doing is shooting each other, which obviously we would not do in the physical world because you hurt each other. But in a game, that's just almost, it's just fun. And even the lobby of a game, it's not even bearing on the game. It's kind of a funny sort of humorous thing to do. So it's like, is that problematic? I don't think so, because fundamentally you're not causing harm in that world. So I think that the part of the question that I think we need to figure out is what are the ways where things could have been harmful in the physical world, that we will now be freed from that, and therefore there should be fewer restrictions in the digital world. And then there might be new ways in which there could be harm in the digital world that there werent the case before. So theres more anonymity, right? When you show up to a restaurant or something, its all the norms where you pay the bill at the end. Its because you have one identity, and if you stiff them, then life is a repeat game, and, and that's not going to work out well for you. But in a digital world, where you can be anonymous and show up in different ways, I think the incentive to act like a good citizen can be a lot less, and that causes a lot of issues and toxic behavior. So that needs to get sorted out. So I think in terms of what is allowed, I think you want to just look at what are the damages, but then there's also other things that are not related to kind of harm. Less about what should be allowed and more about what will be possible that are more about the laws of physics. It's like if you wanted to travel to see me in person, you'd have to get on a plane, and that would take a few hours to get here, whereas we could just jump in a conference room and put on these headsets, and we're basically teleported into a space where we're, you know, it feels like we're together. So that's a very novel experience that, um, that it. It breaks down some things that previously would have defied the laws of physics for what it would take to get together, and I think that that will create a lot of new opportunities. Right. So, um. And one of the things that I'm curious about is there are all these debates right now about, you know, remote work or people being together. And, you know, I think this gets us a lot closer to being able to work physically in different places, but actually have it feel like we're together. Um, so, you know, I think that the dream is that, is that people will one day be able to just work wherever they want. Uh, but we'll have all the same opportunities because you'll be able to feel like you're physically together. I think we're not there today with. With, um. With just video conferencing and the basic technologies that we have. But I think part of the idea is that with something like this, over time, you could get closer to that, and that would open up a lot of opportunities. Right. Because then people could live physically where they want while still being able to get the benefits of being physically or kind of feeling like you're together with people at work. All the ways that that helps to build more culture and build better relationships and build trust, which I think are real issues that if you're not seeing people in person ever. So, yeah, I don't know. I think it's going to be. It's very hard from first principles to think about all the implications of a technology like this and all the good and the things that you need to mitigate. So you try to do your best to envision what things are going to be like and accentuate the things that they're going to be awesome and hopefully mitigate some of the downside things. But the reality is that we're going to be building this out one year at a time. It's going to take a while, so we're going to just get to see how it evolves and what developers and different folks do with it.
Speaker A: If you could comment, this might be a bit of a very specific technical question, but llama two is incredible. You've released it recently, there's already been a lot of exciting developments around it. What's your sense about its release and is there a llama three in the future?
Speaker B: Yeah, I mean, I think on the last podcast that we did together, we were talking about the debate that we were having around open sourcing Lama two, and I'm glad that we did. I think at this point the value of open sourcing a foundation model like Lama two is significantly greater than the risks in my view. We spent a lot of time, took a very rigorous assessment of that and red teaming it, but I'm very glad that we released Lama two. I think the reception has been, it's just been really exciting to see how excited people have been about it. And it's gotten way more downloads and usage than I would have even expected and I was pretty optimistic about it. That's been great. Llama three, there's always another model that we're training for right now. We train Lama two and we released as an open source model. And right now the priority is building that into a bunch of the consumer products, all the different AI's and a bunch of different products that we're basically building as consumer products. Because llama two, by itself, it's not a consumer product. It's more of a piece of infrastructure that people could build things with. That's been the big priority is continuing to fine tune and just get llama two and the branches that we built off of it ready for consumer products that hopefully hundreds of millions of people will enjoy using those products in billions one day. But yeah, we're also working on the future foundation models and I don't have anything new or news on that. I don't know exactly when it's going to be ready. I think just like we had a debate around llama two and open sourcing it, I think we'll need to have a similar debate and process to red team this and make sure that this is safe. And my hope is that we'll be able to open source this next version when it's ready too. But we're nothing close to doing that this month. It's a thing that we're still somewhat early and working on.
Speaker A: Well, in general. Thank you so much for open sourcing llama two and for being transparent about all the exciting developments around AI. I feel like that's contributing to a really awesome conversation about where we go with AI. And obviously, it's really interesting to see all the same kind of technology integrated into these personalized AI systems with the AI Personas, which I think when you put it in people's hands and they get to have conversations with these AI Personas, you get to see interesting failure cases like where the things are dumb or they go into weird directions. And we get to learn as a society together what's too far, what's interesting, what's fun, how much personalization is good, how much generic is good, and we get to learn all of this, and you probably don't know this yourself, we have to all figure it out by using it, right?
Speaker B: Yeah. I mean, part of what we're trying to do with the initial AI's launch is having a diversity of different use cases just so that people can try different things, because I don't know what's going to work. I mean, are people going to like playing in the text based adventure games? Or are they going to like having a comedian who can add jokes, um, to, to threads, or they can want to interact with historical figures? Um, you know, we made, we made one of Jane Austen and one of Marcus Aurelius, and I'm curious to see how that goes.
Speaker A: I'm excited for both as a big fan, I'm excited for both to have a conversation with them. I mean, yeah, that's, yeah, you know, and I am also excited to see, you know, the Internet, I don't know if you heard, can get kind of weird, and I applaud them for it, so. I heard that, yeah, yeah. It'd be nice to see how weird they take it. What kind of memes are generated from this? And I think all of it is, especially in these early stages of development, as we progress towards AGI, it's good to learn by playing with those systems and interacting with them at like, a large scale, like you said.
Speaker B: Yeah, totally. I mean, that's why, well, we're starting out with a set, and then we're also working on this platform that we call AI studio that's going to make it so that over time, anyone will be able to create one of these AI's, almost like they create any other ugc content across the platform. So I'm excited about that. I think that to some degree, we're not going to see the full potential of this until you just have the full creativity of the whole community being able to build stuff. But there's a lot of stuff that we need to get right. Um, so I'm excited to take this in stages. I don't. I don't think anyone out there is really doing what we're doing here. I think that there are. There are people who are. Who are doing kind of like, fictional or consumer oriented character type stuff. But the extent to which we're building it out with the avatars and expressiveness and. And making it so that they can interact across all of the different apps, and they'll have profiles, we'll be able to engage people on Instagram and Facebook. I think it's just. It's going to be really fun.
Speaker A: Well, I'm still. So we're talking about AI, but I'm still blown away this entire time that I'm talking to Mark Zuckerberg and you're not here, but you feel like you're here. I've done quite a few intimate conversations with people alone in a room, and this feels like that. So I keep forgetting for long stretches of time that, like, we're not in the same room. And for me to imagine a future where I can, with a snap of a finger, do that with anyone in my life, the way we can just call right now and have this kind of shallow 2d experience, to have this experience, like we're sitting next to each other is like, I don't think we can even imagine what. How that changes things. Where you can immediately have intimate one on one conversations with anyone that might, like, in a way we might not even predict, change civilization.
Speaker B: Well, I mean, this is a lot of the thesis behind the whole metaverse is giving people the ability to feel like you're present with someone. I mean, this is like, the main thing I talk about all the time, but I do think that there's a lot to process about it. I mean, from my perspective, I mean, I. I'm definitely here. We're just not. We're not physically in the same place. It's not like you're not talking to an AI. Right? So I think the thing that's novel is the ability to convey through technology, a sense of almost physical presence. So the thing that is not physically real is us being in the same physical place, but kind of everything else is. And I think that that gets to this somewhat philosophical question about what is the nature of kind of the modern real world. And I just think that that's, it really is this combination of a physical world and the presence that we feel, but also being able to combine that with this increasingly rich and powerful and capable digital world that we have and all of the. The innovation that's getting created there. So I think it's super exciting because the digital world is just increasing in its capability and our ability to do awesome things. But the physical world is so profound, and that's a lot of what makes us human is that we're physical beings. So I don't think we want to run away from that and just spend all day on a screen. And that's like, it's one of the reasons why I care so much about helping to shape and accelerate the, these future computing platforms. I just think this is so powerful. And even though the current version of this is like you're wearing a headset, I just think this is going to be by far the most human and social computing platform that has ever existed. And that's what makes me excited.
Speaker A: Yeah, I think just to linger on this kind of changing nature of reality of what is real, maybe shifting it towards the sort of consciousness. So what is real is the subjective experience of a thing that makes it feel real versus necessarily being in the same physical space, because it feels like we're in the same physical space, and that the conscious experience of it, that's probably what is real. Not like that, the space time, like the physics of it. Like, you're basically breaking physics and focusing on the consciousness. That's what's real, just whatever is going on inside my head.
Speaker B: But there are a lot of social and psychological things that go along with that experience that was previously only physical presence. Right. I think that there's like an intimacy, a trust. You know, there's a level of communication, because so much of communication is nonverbal, and it's based on expressions that you. You're kind of, you're sharing with someone when you're in this kind of environment. And before, those things would have only been possible had I gotten on a plane and flown to Austin and sat physically with you in the same place. So I think we're basically shortcutting those laws of physics and delivering the social and psychological benefits of being able to be present and feel like you're there with another person, which I think are real benefits to anyone in the world. And I think that, like you said, I think that is going to be a very profound thing. And a lot of that is that's the promise of the metaverse and why I think that that's the next frontier for what we're working on. I started working on social networks when they were primarily text or the first version of Facebook. Your profile, you had one photo, and the rest of it was like, lists of things that you were interested in. And then we kind of went through the period where we're doing photos, and now we're kind of in the period where most of the content is video. But there's a clear trend where over time, the way that we want to express ourselves and kind of get insight and content about the world around us gets increasingly just richer and more vivid. And I think the ability to be immersed and feel present with the people around you or the people who you care about is, from my perspective, clearly the next frontier. It just so happens that it's incredibly technologically difficult. Right. And requires building up these new computing platforms and completely new software stacks to deliver that. But, I mean, I kind of feel like that's what we're here to do as a company.
Speaker A: Well, I really love the connection you have through conversation. And so for me, this photorealism is really, really exciting. I'm really excited for this future, and thank you for building it. Thanks to you, and thanks to the amazing meta teams that I've met, the engineers, and just everybody I've met here, thank you for helping to build this future. And thank you, Mark, for talking to me inside the metaverse. This is blowing my mind. I can't quite express. I would love to measure my heart rate this whole time. Would be hilarious if you're actually, like, sitting on a beach right now.
Speaker B: I'm not. I'm in a conference room.
Speaker A: Okay, well, I'm at a beach and not wearing any pants. I'm really sorry about that for anyone else who's watching me in physical space. Anyway, thank you so much for talking today. This really blew my mind. It's one of the most incredible experiences of my life. So thank you for giving that to me.
Speaker B: Awesome, awesome. Glad you got to check it out, and I'm. It's always fun to talk. All right, I'll catch you soon. See ya.
Speaker A: See you later. This is so, so amazing, man. This is so amazing.
