Transcription for Vijay Kumar： Flying Robots ｜ Lex Fridman Podcast #37.mp3:
Full transcript: The following is a conversation with Vijay Kumar. He's one of the top roboticists in the world, a professor at the University of Pennsylvania, a dean of Penn engineering, former director of Grasp Lab, or the general robotics, automation, sensing and perception laboratory at Penn that was established back in 1979. That's 40 years ago. Vijay is perhaps best known for his work in multi robot systems, robot swarms, and microaerial vehicles, robots that elegantly cooperate in flight under all the uncertainty and challenges that the real world conditions present. This is the artificial intelligence podcast. If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter exfriedman, spelled f r I d m a nde. And now here's my conversation with Vijay Kumar. What is the first robot you've ever built or were a part of building? Way back when I was in graduate school, I was part of a fairly big project that involved building a very large hexapod. Weighed close to 7000 pounds, and it was powered by hydraulic actuation, or was actuated by hydraulics with 18 motors. Hydraulic motors, each controlled by an Intel 8085 processor and an Intel 8086 coprocessor. And so imagine this huge monster that had 18 joints, each controlled by an independent computer. And there was a 19th computer that actually did the coordination between these 18 joints. So I was part of this project, and my thesis work was, how do you coordinate the 18 legs, and in particular, the pressures in the hydraulic cylinders to get efficient locomotion? It sounds like a giant mess. How difficult is it to make all the motors communicate? Presumably you have to send signals hundreds of times a second, or at least. So this was not my work, but the folks who worked on this wrote what I believe to be the first multiprocessor operating system. This was in the eighties, and you had to make sure that, obviously, messages got across from one joint to another. You have to remember the clock speeds on those computers were about half a megahertz the eighties. So, not to romanticize the notion, but how did it make you feel to make. To see that robot move? It was amazing. In hindsight, it looks like, well, we built this thing, which really should have been much smaller. And of course, today's robots are much smaller. You look at Boston Dynamics or ghost robotics, a spin off from Penn. But back then, you were stuck with the substrate. You had the compute you had. So things were unnecessarily big. But at the same time, and this is just human psychology, somehow bigger means grander. People never have the same appreciation for nanotechnology or nano devices as they do for the space shuttle or the Boeing 747. Yeah, you've actually done quite a good job at illustrating that small is beautiful in terms of robotics. So what is on that topic is the most beautiful or elegant robot in motion that you've ever seen? Not to pick favorites or whatever, but something that just inspires you, that you remember. Well, I think the thing that I'm most proud of that my students have done is really think about small UAV's that can maneuver in constrained spaces, in particular, their ability to coordinate with each other and form three dimensional patterns. So once you can do that, you can essentially create 3d objects in the sky, and you can deform these objects on the fly. So in some sense, your toolbox of what you can create is suddenly got enhanced. And before that, we did the two dimensional version of this. So we had ground robots forming patterns and so on. So that was not as impressive, that was not as beautiful. But if you do it in 3d, suspended in midair, and you've got to go back to 2011 when we did this. Now, it's actually pretty standard to do these things eight years later. But back then, it was a big accomplishment. So the distributed cooperation is where beauty emerges in your eyes. I think beauty, to an engineer, is very different from beauty to someone who's looking at robots from the outside, if you will. But what I meant there. So before we said that grand is associated with size. And another way of thinking about this is just the physical shape and the idea that you can get physical shapes in midair and have them. Deformity, that's beautiful. But the individual components, the agility is beautiful too, right? That is true, too. So then how quickly can you actually manipulate these three dimensional shapes and the individual components? Yes, you're right. But by the way, you said UAV, unmanned aerial vehicle, what's a good term for drones? UAV's quadcopters. Is there a term that's being standardized? I don't know if that is. Everybody wants to use the word drones, and I often said this. Drones, to me, is a pejorative word. It signifies something that's dumb, that's pre programmed, that does one little thing, and robots are anything but drones. So I actually don't like that word. But that's what everybody uses. You could call it unpiloted. Unpiloted. But even unpiloted could be radio controlled, could be remotely controlled in many different ways. And I think the right word is thinking about it as an aerial robot. You also say agile autonomous aerial robot. Right. Fertility is an attribute, but they don't have to be. So what biological system? Because you've also drawn a lot of inspiration from those I've seen bees and ants that you've talked about. What living creatures have you found to be most inspiring as an engineer instructive in your work in robotics, to me? So ants are really quite incredible creatures, right? I mean, the individuals, arguably, are very simple in how they're built, and yet they're incredibly resilient as a population. And as individuals, they're incredibly robust. So if you take an ant with six legs, you remove one leg, it still works just fine, and it moves along, and I don't know that he even realizes it's lost a leg. So that's the robustness at the individual ant level. But then you look about this instinct for self preservation of the colonies, and they adapt in so many amazing ways, transcending gaps by just chaining themselves together. When you have a flood, being able to recruit other teammates to carry big morsels of food and then going out in different directions looking for food, and then being able to demonstrate consensus, even though they don't communicate directly with each other, the way we communicate with each other, in some sense, they also know how to do democracy probably better than what we do. Yeah. Somehow, even democracy is emergent. It seems like all of the phenomena that we see is all emergent. It seems like there's no centralized communicator. There is. So I think a lot is made about that word emergent, and it means lots of things to different people. But you're absolutely right. I think as an engineer, you think about what element, elemental behaviors, what primitives you could synthesize, so that the whole looks incredibly powerful, incredibly synergistic, the whole definitely being greater than the sum of the parts. And ants are living proof of that. So when you see these beautiful swarms where there's biological systems of robots, do you sometimes think of them as a single individual living intelligent organism? So it's the same as thinking of our human civilization as one organism? Or do you still, as an engineer, think about the individual components and all the engineering that went into the individual components? Well, that's very interesting. So, again, philosophically, as engineers, what we want to do is to go beyond the individual components, the individual units, and think about it as a unit, as a cohesive unit, without worrying about the individual components. If you start obsessing about the individual building blocks and what they do, you inevitably will find it hard to scale up just mathematically. Just think about individual things you want to model, and if you want to have ten of those, then you essentially are taking cartesian products of ten things. That makes it really complicated, then to do any kind of synthesis or design in that high dimensional space is really hard. So the right way to do this is to think about the individuals in a clever way, so that at the higher level, when you look at lots and lots of them abstractly, you can think of them in some low dimensional space. So what does that involve for the individual? You have to try to make the way they see the world as local as possible. And the other thing, do you just have to make them robust to collisions? Like you said with the ants, if something fails, the whole swarm doesn't fail. Right. I think as engineers, we do this. I mean, think about we build planes or we build iPhones, and we know that. Bye. Taking individual components, well engineered components with well specified interfaces that behave in a predictable way, you can build complex systems. So that's ingrained, I would claim, in most engineers thinking, and it's true for computer scientists as well. I think what's different here is that you want the individuals to be robust in some sense, as we do in these other settings, but you also want some degree of resiliency for the population, and so you really want them to be able to reestablish communication with their neighbors. You want them to rethink their strategy for group behavior. You want them to reorganize. And that's where I think a lot of the challenges lie. So just at a high level, what does it take for a bunch of, what should we call them, flying robots to create a formation just for people who are not familiar with robotics in general, how much information is needed? How do you even make it happen without a centralized controller? So, I mean, there are a couple of different ways of looking at this. If you are a purist, you think of it as a way of recreating what nature does. So nature forms groups for several reasons, but mostly it's because of this instinct that organisms have of preserving their colonies, their population, which means what? You need shelter, you need food, you need to procreate, and that's basically it. So the kinds of interactions you see are all organic, they're all local, and the only information that they share, and mostly it's indirectly, is to, again, preserve the herd or the flock or the swarm, and either by looking for new sources of food or looking for new shelters. Right, right. As engineers, when we build swarms, we have a mission. And when you think of a mission and it involves mobility, most often it's described in some kind of a global coordinate system. As a human, as an operator, as a commander, or as a collaborator. I have my coordinate system, and I want the robots to be consistent with that. So I might think of it slightly differently. I might want the robots to recognize that coordinate system, which means not only do they have to think locally in terms of who their immediate neighbors are, but they have to be cognizant of, of what the global environment looks like. So if I go, if I say, surround this building and protect this from intruders, well, they're immediately in a building centered coordinate system, and I have to tell them where the building is. And they're globally collaborating on the map of that building. They're maintaining some kind of global, not just in the frame of the building, but there's information that's ultimately being built up explicitly, as opposed to kind of implicitly like nature might. Correct, correct. So in some sense, nature is very, very sophisticated, but the tasks that nature solves or needs to solve are very different from the kind of engineered tasks, artificial tasks that we are forced to address. And again, there's nothing preventing us from solving these other problems. But ultimately it's about impact. You want these swarms to do something useful, and so you're kind of driven into this very unnatural, if you will. Unnatural meaning, not like how nature does setting. And it's probably a little bit more expensive to do it the way nature does because nature is less sensitive to the loss of the individual. And cost wise in robotics, I think you're more sensitive to losing individuals. I think that's true. Although if you look at the price to performance ratio of robotic components, it's coming down dramatically. It continues to come down. So I think we're asymptotically approaching the point where we would get. Yeah, the cost of individuals would really become insignificant. So let's step back at a high level view. The impossible question of what kind of, as an overview, what kind of autonomous flying vehicles are there in general, I. Think the ones that receive a lot of notoriety are obviously the military vehicles. Military vehicles are controlled by a base station, but have a lot of human supervision, but have limited autonomy, which is the ability to go from point a to point b. And even the more sophisticated vehicles can do autonomous takeoff and landing. And those usually have wings, and they're heavy. Usually they're wings. But there's nothing preventing us from doing this for helicopters as well. I mean, there are many military organizations that have autonomous helicopters in the same vein. And by the way, you look at autopilots and airplanes, and it's actually very similar. In fact, one interesting question we can ask is if you look at all the air safety violations, all the crashes that occurred, would they have happened if the plane were truly autonomous? And I think you'll find that in many of the cases because of pilot error, we make silly decisions. And so in some sense, even in air traffic, commercial air traffic, there's a lot of applications, although we only see autonomy being enabled at very high altitudes when, when the plane is on autopilot. There'S still a role for the human. And that kind of autonomy is you're kind of implying, I don't know what the right word is, but it's a little dumb, dumber than it could be, right? So in the lab, of course, we can afford to be a lot more aggressive. And the question we try to ask is, can we make robots that will be able to make decisions without any kind of external infrastructure? So what does that mean? So the most common piece of infrastructure that airplanes use today is GPS. GPS is also the most brittle form of information. If you have driven in a city, tried to use GPS navigation in tall buildings, you immediately lose GPS. And so that's not a very sophisticated way of building autonomy. I think the second piece of infrastructure they rely on is communications. Again, it's very easy to jam communications. In fact, if you use Wifi, you know that Wi Fi signals drop out, cell signals drop out. So to rely on something like that is nothing is not good. The third form of infrastructure we use, and I hate to call it infrastructure, but it is that in the sense of robots, it's people. So you could rely on somebody to pilot you, right. And so the question you want to ask is if there are no pilots, there's no communications with any base station, if there's no knowledge of position, and if there's no a priori map, a priori knowledge of what the environment looks like, a priori model of what might happen in the future, can robots navigate? So that is true autonomy. So that's true autonomy. And we're talking about, you mentioned, like, military application of drones. Okay, so what else is there? You talk about agile autonomous flying robots, aerial robots. So that's a different kind of, it's not winged, it's not big, at least it's small. So I use the word agility mostly. Or at least we're motivated to do agile robots, mostly because robots can operate and should be operating in constrained environments. And if you want to operate the way a global hawk operates, I mean, the kinds of conditions in which you operate are very, very restrictive. If you go on to go inside a building, for example, for search and rescue, or to locate an active shooter, or you want to navigate under the canopy in an orchard, to look at health of plants, or to look for, to count fruits, to measure the tree trunks. These are things we do, by the way. Yeah, some cool agriculture stuff you've shown in the past. It's really awesome. So in those kinds of settings, you do need that agility. Agility does not necessarily mean you break records for the 100 meters dash. What it really means is you see the unexpected and you're able to maneuver in a safe way and in a way that gets you the most information about the thing you're trying to do. By the way, you may be the only person who in a TED talk has used a math equation, which is amazing. People should go see one of your TED talk. Actually, it's very interesting because the TeD curator, Chris Anderson, told me, you can't show math. And I thought about it, but that's who I am, that's our work. And so I felt compelled to give the audience a taste for at least some math. So on that point, simply, what does it take to make a thing with four motors fly? A quadcopter, one of these little flying robots. How hard is it to make it fly? How do you coordinate for motors? How do you convert those motors into actual movement? So, this is an interesting question. We've been trying to do this since 2000. It is a commentary on the sensors that were available back then, the computers that were available back then, and a number of things happened between 2000 and 2007. One is the advances in computing, which is so we all know about Moore's law, but I think 2007 was a tipping point. The year of the iPhone, the year of the cloud. Lots of things happened in 2007, but going back even further, inertial measurement units as a sensor really matured. Again, lots of reasons for that. Certainly there's a lot of federal funding, particularly DARPA and the US, but they didn't anticipate this boom in Imus. But if you look subsequently, what happened is that every car manufacturer had to put an airbag in, which meant you had to have an accelerometer on board that drove down the price to performance ratio. I should know this. That's very interesting. That's very interesting connection there. And that's why research is very, it's very hard to predict the outcomes. And again, the federal government spent a ton of money on things that they thought were useful for resonators, but it ended up enabling these small UAV's, which is great, because I could have never raised that much money and told, you know, sold this project, hey, we want to build these small UAV's. Can you, can you actually fund the development of low cost IMuse? So why do you need an IMU on it? I'll come back to that. So, in 2007, 2008, we were able to build these. And then the question you're asking was a good one, how do you coordinate the motors to develop this? But over the last ten years, everything is commoditized. A high school kid today can pick up a raspberry PI kit and build this. All the low level functionality is all automated, but basically, at some level, you have to drive the motors at the right rpms, the right velocity in order to generate the right amount of thrust, in order to position it and orient it in a way that you need to in order to fly. The feedback that you get is from onboard sensors, and the IMU is an important part of it. The IMU tells you what the acceleration is as well as what the angular velocity is, and those are important pieces of information. In addition to that, you need some kind of local position or velocity information. For example, when we walk, we implicitly have this information because we kind of know what our stride length is. We also are looking at images, fly past our retina, if you will, and so we can estimate velocity. We also have accelerometers in our head, and we're able to integrate all these pieces of information to determine where we are as we walk. And so robots have to do something very similar. You need an IMU, you need some kind of a camera or other sensor that's measuring velocity, and then you need some kind of a global reference frame if you really want to think about doing something in a world coordinate system. And so how do you estimate your position with respect to that global reference frame? That's important as well. So coordinating the rpms of the four motors is what allows you to, first of all, fly and hover, and then you can change the orientation and the velocity and so on. Exactly, exactly. Just a bunch of degrees of freedom that you're playing with. There's six degrees of freedom, but you only have four inputs, four motors, and it turns out to be a remarkably versatile configuration. You think at first, well, I only have four motors. How do I go sideways? But it's not too hard to say. Well, if I tilt myself, I can go sideways and then you have four motors pointing up. How do I rotate in place about a vertical axis? Well, you rotate them at different speeds and that generates reaction moments and that allows you to turn. So it's actually a pretty, it's an optimal configuration from an engineer standpoint. It's very simple, very cleverly done and very versatile. So if you could step back to a time. So I've always known flying robots. As to me, it was natural that a quadcopter should fly. But when you first started working with it, how surprised are you that you can make do so much with the four motors? How surprising is that you can make this thing fly? First of all, you can make it hover, then you can add control to it. Firstly, this is not, the four motor configuration is not ours. It has at least a hundred year history. Oh, it does. Various people. Various people try to get quadrotors to fly without much success. As I said, we've been working on this since 2000. Our first designs were, well, this is way too complicated. Why not we try to get an omnidirectional flying robot. So our early designs, we had eight rotors. And so these eight rotors were arranged uniformly on a sphere, if you will. So you can imagine a symmetric configuration and so you should be able to fly anywhere. But the real challenge we had is the strength to weight ratio is not enough. And of course, we didn't have the sensors and so on. So everybody knew, or at least the people who worked with rotorcrafts knew, four rotors will get it done. So that was not our idea, but it took a while before we could actually do the onboard sensing and the computation that was needed for the kinds of agile maneuvering that we wanted to do in our little aerial robots. And that only happened between 2007 and 2009 in our lab. Yeah. And you have to send the signal maybe 100 times a second. So the compute there, everything has to come down in price. And what are the steps of getting from point a to point b? So we just talked about like local control. But if all the kind of cool dancing in the air that I've seen you show, how do you make it happen? Make a trajectory, first of all. Okay, figure out a trajectory. So plan a trajectory. And then how do you make that trajectory happen? Yeah, I think planning is a very fundamental problem in robotics. I think ten years ago it was an esoteric thing, but today, with self driving cars, everybody can understand this basic idea that a car sees a whole bunch of things. And it has to keep a lane or maybe make a right turn or switch lanes. It has to plan a trajectory, it has to be safe, it has to be efficient. So everybody's familiar with that. That's kind of the first step that you have to think about when you say autonomy. And so for us, it's about finding smooth motions, motions that are safe. So we think about these two things. One is optimality, one is safety. Clearly, you cannot compromise safety, so you're looking for safe, optimal motions. The other thing you have to think about is, can you actually compute a reasonable trajectory in a small amount of time? Cause you have a time budget. So the optimal becomes suboptimal. But in our lab, we focus on synthesizing smooth trajectory that satisfy all the constraints. In other words, don't violate any safety constraints and is as efficient as possible. And when I say efficient, it could mean I want to get from point a to point b as quickly as possible, or I want to get to it as gracefully as possible, or I want to consume as little energy as. Possible, but always staying within the safety. Constraints, but yes, always finding a safe trajectory. So there's a lot of excitement and progress in the field of machine learning and reinforcement learning and the neural network variant of that with deep reinforcement learning. Do you see a role of machine learning in. So, a lot of the success with flying robots did not rely on machine learning, except for maybe a little bit of the perception, the computer vision side, on the control side, and the planning. Do you see there's a role in the future for machine learning? So let me disagree a little bit with you. I think we never perhaps called out in my work, called out learning. But even this very simple idea of being able to fly through a constrained space, the first time you try it, you'll invariably, you might get it wrong. If the task is challenging and the reason is to get it perfectly right, you have to model everything in the environment. And flying is notoriously hard to model. There are aerodynamic effects that we constantly discovered. Even just before I was talking to you, I was talking to a student about how blades flap when they fly, and that ends up changing how a rotorcraft is accelerated in the angular direction. This is like micro flaps or something. It's not micro flaps. We assume that each blade is rigid, but actually it flaps a little bit. It bends. Interesting. Yeah. And so the models rely on the fact, on an assumption that they're actually rigid, but that's not true. If you're flying really quickly, these effects become significant. If you're flying close to the ground, you get pushed off by the ground, right? Something which every pilot knows when he tries to land or she tries to land. This is called a ground effect. Something very few pilots think about is what happens when you go close to a ceiling? Well, you get sucked into a ceiling. There are very few aircraft that fly close to any kind of ceiling. Likewise, when you go close to a wall, there are these wall effects. And if you've gone on a train and you pass another train that's traveling in the opposite direction, you feel the buffeting. And so these kinds of microclimates affect our UAV's significantly, and they're impossible to model, essentially. I wouldn't say they're impossible to model, but the level of sophistication you would need in the model and the software would be tremendous. Plus, to get everything right would be awfully tedious. So the way we do this is over time, we figure out how to adapt to these conditions. So early on, we used a form of learning that we call iterative learning. So this idea, if you want to perform a task, there are a few things that you need to change and iterate over few parameters that over time you can figure out. So I could call it policy gradient reinforcement learning, but actually it was just iterative learning. And so this was there way back. I think what's interesting is if you look at autonomous vehicles today, learning occurs, could occur in two pieces. One is perception, understanding the world. Second is action taking actions. Everything that I've seen that is successful is on the perception side of things. So in computer vision, we've made amazing strides in the last ten years. So recognizing objects, actually detecting objects, classifying them and tagging them, in some sense annotating them, this is all done through machine learning on the action side. On the other hand, I don't know if any examples where there are fielded systems where we actually learn the right. Behavior outside of single demonstration of successfully. In the laboratory, this is the holy grail. Can you do end to end learning? Can you go from pixels to motor currents? This is really, really hard. And I think if you go forward, the right way to think about these things is data driven approaches, learning based approaches in concert with model based approaches, which is the traditional way of doing things. So I think there's a piece, there's a role for each of these methodologies. So what do you think? Just jumping out on topics. Since you mentioned autonomous vehicles, what do you think are the limits on the perception side? So I've talked to Elon Musk. And there on the perception side, they're using primarily computer vision to perceive the environment in your work with, because you work with the real world a lot in the physical world. What are the limits of computer vision? Do you think we can solve autonomous vehicles? Focus on the perception side, focusing on vision alone and machine learning. So we also have a spinoff company, Exxon Technologies, that works underground in mines. So you go into mines, they're dark, they're dirty, you fly in a dirty area, there's stuff you kick up by the propellers, the downwash kicks up dust. I challenge you to get a computer vision algorithm to work there. So we use lidars in that setting indoors and even outdoors when we fly through fields. I think there's a lot of potential for just solving the problem using computer vision alone. But I think the bigger question is, can you actually solve, or can you actually identify all the corner cases using a single sensing modality and using learning alone? What's your intuition there? So, look, if you have a corner case and your algorithm doesn't work, your instinct is to go get data about the corner case and patch it up, learn how to deal with that corner case. But at some point, this is going to saturate. This approach is not viable. So today, computer vision algorithms can detect 90% of the objects, or can detect objects 90% of the time, classify them 90% of the time. Cats on the Internet, I probably can do 95%. But to get from 90% to 99%, you need a lot more data. And then I tell you, well, that's not enough, because I have a safety critical application. I want to go from 99% to 99.9%. That's even more data. So I think if you look at wanting accuracy on the x axis and look at the amount of data on the y axis, I believe that curve is an exponential curve. Wow. Okay. It's even hard if it's linear. It's hard if it's linear, totally. But I think it's exponential. The other thing you have to think about is that this process is a very, very power hungry process to run data farms or servers. Power. Do you mean literally power? Literally power. Literally power. So in 2014, five years ago, and I don't have more recent data, 2% of us electricity consumption was from data farms. So we think about this as an information science and information processing problem. Actually, it is an energy processing problem. And so unless we figure out better ways of doing this, I don't think this is viable. So talking about driving, which is a safety critical application and some aspect of flight. Is safety critical? Maybe. Philosophical question, maybe an engineering one. What problem do you think is harder to solve? Autonomous driving or autonomous flight? That's a really interesting question. I think autonomous flight has several advantages that autonomous driving doesn't have. So, look, if I want to go from point a to point b, I have a very, very safe trajectory. Go vertically up to a maximum altitude, fly horizontally to just about the destination, and then come down vertically. This is pre programmed. The equivalent of that is very hard to find in a self driving car world, because you're on the ground, you're in a two dimensional surface, and the trajectories on the two dimensional surface are more likely to encounter obstacles. I mean, this in an intuitive sense, but mathematically true, that's mathematically as well, that's true. There's other option on the 2G space of platooning or because there's so many obstacles, you can connect with those obstacles and all these things, but those exist. In the three dimensional space as well, so they do. So the question also implies how difficult are obstacles in the three dimensional space in flight? So that's the downside, I think, in three dimensional space, you're modeling three dimensional world, not just because you want to avoid it, but you want to reason about it and you want to work in that three dimensional environment, and that's significantly harder. So that's one disadvantage. I think the second disadvantage is, of course, anytime you fly, you have to put up with the peculiarities of aerodynamics, and there are complicated environments. How do you negotiate that? So that's always a problem. Do you see a time in the future where there is, you mentioned there's agriculture applications. There's a lot of applications of flying robots. But do you see a time in the future where there is a tens of thousands or maybe hundreds of thousands of delivery drones that fill the sky? A delivery flying robots. I think there's a lot of potential for the last mile delivery. And so, in crowded cities, I don't know. If you go to a place like Hong Kong, just crossing the river can take half an hour, and while a drone can just do it in five minutes at most, I think you look at delivery of supplies to remote villages. I work with a nonprofit called weave Robotics. So they work in the peruvian Amazon, where the only highways are rivers. And to get from point a to point b may take 5 hours, while with a drone, you can get there in 30 minutes. So just delivering drugs, retrieving samples for testing vaccines, I think there's huge potential here so I think the challenges are not technological. The challenges are economical. The one thing I'll tell you that nobody thinks about is the fact that we've not made huge strides in battery technology. Yes, it's true. Batteries are becoming less expensive because we have these mega factories that are coming up, but they're all based on lithium based technologies. And if you look at the energy density and the power density, those are two fundamentally limiting numbers. So, power density is important because for a uav to take off vertically into the air, which most drones do, they don't have a Runway. You consume roughly 200 watts per kilo. At the small size, that's a lot. Right? In contrast, the human brain consumes less than 80 watts, the whole of the human brain. So just imagine just lifting yourself into the air is like two or three light bulbs, which makes no sense to me. Yeah. So you're going to have to, at scale, solve the energy problem, then charging the batteries, storing the energy, and so on. And then the storage is the second problem. But storage limits the range. But, you know, you have to remember that you have to burn a lot of it per given time. So the burning is another problem, which is the power question. Yes. And do you think, just your intuition, there are breakthroughs in batteries on the horizon? How hard is that problem? Look, there are a lot of companies that are promising flying cars that are autonomous and that are clean. I think they're over promising. The autonomy piece is doable. The clean piece, I don't think so. There's another company that I work with called Jataptra. They make small jet engines, and they can get up to 50 miles an hour very easily and lift 50 kilos. But they're jet engines. They're efficient. They're a little louder than electric vehicles, but they can build flying cars. So your sense is that there's a lot of pieces that have come together. So, on this crazy question, if you look at companies like Kitty Hawk working on electric. So the clean. Talking to Sebastian thruin, right, it's a. It's a crazy dream, you know, but you work with flight a lot. You've mentioned before that, man, flights or carrying a human body is very difficult to do. So how crazy is flying cars? Do you think? There'll be a day when we have vertical takeoff and landing vehicles that are sufficiently affordable that we're going to see a huge amount of them, and they would look like something like we dream of when we think about flying cars. Yeah. Like the Jetsons. The Jetsons, yeah. So, look, there are a lot of smart people working on this, and you never say something is not possible when you have people like Sebastian Tron working on it. So I totally think it's viable. I question again, the electric piece. The electric piece, and again, for short distances, you can do it. And there's no reason to suggest that these are all just have to be rotorcrafts. You take off vertically, but then you morph into a forward flight. I think there are a lot of interesting designs. The question to me is, are these economically viable? And if you agree to do this with fossil fuels, the instinct immediately becomes viable. That's a real challenge. Do you think it's possible for robots and humans to collaborate successfully on tasks? So a lot of robotics folks that I talk to and work with, I mean, humans just add a giant mess to the picture, so it's best to remove them from consideration when solving specific tasks. It's very difficult to model. There's just a source of uncertainty in your work with these agile flying robots. Do you think there's a role for collaboration with humans, or is it best to model tasks in a way that doesn't have a human in the picture? Well, I don't think we should ever think about robots without human in the picture. Ultimately, robots are there because we want them to solve problems for humans, but there's no general solution to this problem. I think if you look at human interaction and how humans interact with robots, we think of these in three different ways. One is the human commanding the robot. The second is the human collaborating with the robot. So, for example, we work on how a robot can actually pick up things with a human and carry things. That's like true collaboration. And third, we think about humans as bystanders, self driving cars. What's the human's role? And how do self driving cars acknowledge the presence of humans? So I think all of these things are different scenarios. It depends on what kind of humans, what kind of task. And I think it's very difficult to say that there's a general theory that we all have for this, but at the same time, it's also silly to say that we should think about robots independent of humans. So to me, human robot interaction is almost a mandatory aspect of everything we do. Yes, but situation degree. So your thoughts? If you jump to autonomous vehicles, for example, there's a big debate between what's called level two and level four. So semi autonomous and autonomous vehicles. And so the Tesla approach currently at least has a lot of collaboration between human and machine. So the human is supposed to actively supervise the operation of the robot. Part of the safety definition of how safe a robot is in that case is how effective is the human in monitoring it, do you think? That's ultimately not a good approach and sort of having a human in the picture, not as a bystander or part of the infrastructure, but really as part of what's required to make the system safe. This is harder than it sounds, I think. You know, if you. I mean, I'm sure you've driven before in highways and so on. It's. It's really very hard to have to relinquish control to a machine and then take over when needed. So I think Tesla's approach is interesting because it allows you to periodically establish some kind of contact with the car. Toyota, on the other hand, is thinking about shared autonomy, or collaborative autonomy as a paradigm, if I may argue. These are very, very simple ways of human robot collaboration because the task is pretty boring. You sit in a vehicle, you go from point a to point b. I think the more interesting thing to me is, for example, search and rescue. I've got a human first responder, robot first responders. I got to do something. It's important. I have to do it in two minutes. The building is burning, there's been an explosion, it's collapsed. How do I do it? I think to me, those are the interesting things where it's very, very unstructured and what's the role of the human? What's the role of the robot? Clearly, there's lots of interesting challenges, and as a field, I think we're going to make a lot of progress in this area. Yeah, it's an exciting form of collaboration. You're right. In autonomous driving, the main enemy is just boredom of the human, as opposed to in rescue operations. It's literally life and death, and the collaboration enables the effective completion of the mission. So it's exciting in some sense. We're also doing this. You think about the human driving a car, and almost invariably the human's trying to estimate the state of the car. They estimate the state of the environment and so on. But what if the car were to estimate the state of the human? So, for example, I'm sure you have a smartphone, and the smartphone tries to figure out what you're doing and send you reminders and oftentimes telling you to drive to a certain place, although you have no intention of going there, because it thinks that that's where you should be because of some Gmail calendar entry or something like that. And it's trying to constantly figure out who you are, what you're doing. If a car were to do that, maybe that would make the driver safer, because the car is trying to figure out, is the driver paying attention, looking at his or her eyes, looking at circadian movements? So I think the potential is there. But from the reverse side, it's nothing. Robot modeling, but it's human modeling. It's more in the human right. And I think the robots can do a very good job of modeling humans. If you really think about the framework that you have, a human sitting in a cockpit surrounded by sensors, all staring at him, in addition to be staring outside, but also staring at him, I think there's a real synergy there. Yeah, I love that problem because it's a new 21st century form of psychology, actually AI enabled psychology. A lot of people have Sci-Fi inspired fears of walking robots, like those from Boston dynamics. If you just look at shows on Netflix and so on, or flying robots like those you work with, how would you. How do you think about those fears? How would you alleviate those fears? Do you have inklings, echoes of those same concerns? You know, anytime we develop a technology meaning to have positive impact in the world, there's always the worry that somebody could subvert those technologies and use it in an adversarial setting. And robotics is no exception. I think it's very easy to weaponize robots. I think we talk about swarms. One thing I worry a lot about is for us to get swarms to work and do something reliably is really hard. But suppose I have this. This challenge of trying to destroy something, and I have a swarm of robots where only one out of the swarm needs to get to its destination, so that suddenly becomes a lot more doable. And so I worry about this general idea of using autonomy with lots and lots of agents. I mean, having said that, look, a lot of this technology is not very mature. My favorite saying is that if somebody had to develop this technology, wouldn't you rather the good guys do it? So the good guys have a good understanding of the technology, so they can figure out how this technology is being used in a bad way or could be used in a bad way and try to defend against it. So we think a lot about that. So we have a. We're doing research on how to defend against swarms, for example. That's interesting. There's, in fact, a report by the National Academies on counter UA's technologies. This is a real threat, but we're also thinking about how to defend against this and knowing how swarms work. Knowing how autonomy works is, I think, very important. So it's not just politicians. Do you think engineers have a role in this discussion? Absolutely. I think the days where politicians can be agnostic to technology are gone. I think every politician needs to be literate in technology, and I often say technology is the new liberal art. Understanding how technology will change your life, I think, is important, and every human being needs to understand that. And maybe we can elect some engineers to office as well. On the other side, what are the biggest open problems in robotics, in your view? You said we're in the early days in some sense. What are the problems we would like to solve in robotics? I think there are lots of problems. Right. But I would phrase it in the following way. If you look at the robots we're building, they're still very much tailored towards doing specific tasks in specific settings. I think the question of how do you get them to operate in much broader settings where things can change in unstructured environments is up in the air. So, you know, think of a self driving cars. Today. We can build a self driving car in a parking lot. We can do level five autonomy in a parking lot. But can you do level five autonomy in the streets of Napoli in Italy or Mumbai in India? No. In some sense, when we think about robotics, we have to think about where they're functioning, what kind of environment, what kind of a task. We have no understanding of how to put both those things together. So we're in the very early days of applying it to the physical world, and I was just in Naples, actually. And there's levels of difficulty and complexity depending on which area you're applying into. I think so. And we don't have a systematic way of understanding that. Everybody says just because a computer can now beat a human at any board game, we certainly know something about intelligence. That's not true. A computer board game is very, very structured. It is the equivalent of working in a Henry Ford factory where things, parts come, you assemble, move on. It's a very, very, very structured setting. That's the easiest thing, and we know how to do that. So you've done a lot of incredible work at the UPenn University of Pennsylvania grass lab. You're now dean of engineering at UPenn. What advice do you have for a new bright eyed undergrad interested in robotics or AI or engineering? Well, I think there's really three things. One is. One is you have to get used to the idea that the world will not be the same in five years or four years whenever you graduate, which is really hard to do. So this thing about predicting the future, every one of us needs to be trying to predict the future always. Not because you'll be any good at it, but by thinking about it, I think you sharpen your senses and you become smarter. So that's number one. Number two, and it's a corollary of the first piece, which is you really don't know what's going to be important. So this idea that I'm going to specialize in something which will allow me to go in a particular direction, it may be interesting, but it's important also to have this breadth. So you have this jumping off point. I think the third thing, and this is where I think Penn excels. I mean, we teach engineering, but it's always in the context of the liberal arts. It's always in the context of society. As engineers, we cannot afford to lose sight of that. So I think that's important. But I think one thing that people underestimate when they do robotics is the importance of mathematical foundations, the importance of representations. Not everything can just be solved by looking for RoS packages on the Internet or to find a deep neural network that works. I think the representation question is key, even to machine learning, where if you ever hope to achieve or get to explainable AI, somehow there need to be representations that you can understand. So if you want to do robotics, you should also do mathematics. And you said liberal arts, a little literature. If you want to build a robot, you should be reading Dostoevsky. I agree with that. Very good. Vijay, thank you so much for talking today. It was an honor. Thank you. A very exciting conversation. Thank you.

Utterances:
Speaker A: The following is a conversation with Vijay Kumar. He's one of the top roboticists in the world, a professor at the University of Pennsylvania, a dean of Penn engineering, former director of Grasp Lab, or the general robotics, automation, sensing and perception laboratory at Penn that was established back in 1979. That's 40 years ago. Vijay is perhaps best known for his work in multi robot systems, robot swarms, and microaerial vehicles, robots that elegantly cooperate in flight under all the uncertainty and challenges that the real world conditions present. This is the artificial intelligence podcast. If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter exfriedman, spelled f r I d m a nde. And now here's my conversation with Vijay Kumar. What is the first robot you've ever built or were a part of building?
Speaker B: Way back when I was in graduate school, I was part of a fairly big project that involved building a very large hexapod. Weighed close to 7000 pounds, and it was powered by hydraulic actuation, or was actuated by hydraulics with 18 motors. Hydraulic motors, each controlled by an Intel 8085 processor and an Intel 8086 coprocessor. And so imagine this huge monster that had 18 joints, each controlled by an independent computer. And there was a 19th computer that actually did the coordination between these 18 joints. So I was part of this project, and my thesis work was, how do you coordinate the 18 legs, and in particular, the pressures in the hydraulic cylinders to get efficient locomotion?
Speaker A: It sounds like a giant mess. How difficult is it to make all the motors communicate? Presumably you have to send signals hundreds of times a second, or at least.
Speaker B: So this was not my work, but the folks who worked on this wrote what I believe to be the first multiprocessor operating system. This was in the eighties, and you had to make sure that, obviously, messages got across from one joint to another. You have to remember the clock speeds on those computers were about half a megahertz the eighties.
Speaker A: So, not to romanticize the notion, but how did it make you feel to make. To see that robot move?
Speaker B: It was amazing. In hindsight, it looks like, well, we built this thing, which really should have been much smaller. And of course, today's robots are much smaller. You look at Boston Dynamics or ghost robotics, a spin off from Penn. But back then, you were stuck with the substrate. You had the compute you had. So things were unnecessarily big. But at the same time, and this is just human psychology, somehow bigger means grander. People never have the same appreciation for nanotechnology or nano devices as they do for the space shuttle or the Boeing 747.
Speaker A: Yeah, you've actually done quite a good job at illustrating that small is beautiful in terms of robotics. So what is on that topic is the most beautiful or elegant robot in motion that you've ever seen? Not to pick favorites or whatever, but something that just inspires you, that you remember.
Speaker B: Well, I think the thing that I'm most proud of that my students have done is really think about small UAV's that can maneuver in constrained spaces, in particular, their ability to coordinate with each other and form three dimensional patterns. So once you can do that, you can essentially create 3d objects in the sky, and you can deform these objects on the fly. So in some sense, your toolbox of what you can create is suddenly got enhanced. And before that, we did the two dimensional version of this. So we had ground robots forming patterns and so on. So that was not as impressive, that was not as beautiful. But if you do it in 3d, suspended in midair, and you've got to go back to 2011 when we did this. Now, it's actually pretty standard to do these things eight years later. But back then, it was a big accomplishment.
Speaker A: So the distributed cooperation is where beauty emerges in your eyes.
Speaker B: I think beauty, to an engineer, is very different from beauty to someone who's looking at robots from the outside, if you will. But what I meant there. So before we said that grand is associated with size. And another way of thinking about this is just the physical shape and the idea that you can get physical shapes in midair and have them. Deformity, that's beautiful.
Speaker A: But the individual components, the agility is beautiful too, right?
Speaker B: That is true, too. So then how quickly can you actually manipulate these three dimensional shapes and the individual components? Yes, you're right.
Speaker A: But by the way, you said UAV, unmanned aerial vehicle, what's a good term for drones? UAV's quadcopters. Is there a term that's being standardized?
Speaker B: I don't know if that is. Everybody wants to use the word drones, and I often said this. Drones, to me, is a pejorative word. It signifies something that's dumb, that's pre programmed, that does one little thing, and robots are anything but drones. So I actually don't like that word. But that's what everybody uses. You could call it unpiloted.
Speaker A: Unpiloted.
Speaker B: But even unpiloted could be radio controlled, could be remotely controlled in many different ways. And I think the right word is thinking about it as an aerial robot.
Speaker A: You also say agile autonomous aerial robot.
Speaker B: Right. Fertility is an attribute, but they don't have to be.
Speaker A: So what biological system? Because you've also drawn a lot of inspiration from those I've seen bees and ants that you've talked about. What living creatures have you found to be most inspiring as an engineer instructive in your work in robotics, to me?
Speaker B: So ants are really quite incredible creatures, right? I mean, the individuals, arguably, are very simple in how they're built, and yet they're incredibly resilient as a population. And as individuals, they're incredibly robust. So if you take an ant with six legs, you remove one leg, it still works just fine, and it moves along, and I don't know that he even realizes it's lost a leg. So that's the robustness at the individual ant level. But then you look about this instinct for self preservation of the colonies, and they adapt in so many amazing ways, transcending gaps by just chaining themselves together. When you have a flood, being able to recruit other teammates to carry big morsels of food and then going out in different directions looking for food, and then being able to demonstrate consensus, even though they don't communicate directly with each other, the way we communicate with each other, in some sense, they also know how to do democracy probably better than what we do.
Speaker A: Yeah. Somehow, even democracy is emergent. It seems like all of the phenomena that we see is all emergent. It seems like there's no centralized communicator.
Speaker B: There is. So I think a lot is made about that word emergent, and it means lots of things to different people. But you're absolutely right. I think as an engineer, you think about what element, elemental behaviors, what primitives you could synthesize, so that the whole looks incredibly powerful, incredibly synergistic, the whole definitely being greater than the sum of the parts. And ants are living proof of that.
Speaker A: So when you see these beautiful swarms where there's biological systems of robots, do you sometimes think of them as a single individual living intelligent organism? So it's the same as thinking of our human civilization as one organism? Or do you still, as an engineer, think about the individual components and all the engineering that went into the individual components?
Speaker B: Well, that's very interesting. So, again, philosophically, as engineers, what we want to do is to go beyond the individual components, the individual units, and think about it as a unit, as a cohesive unit, without worrying about the individual components. If you start obsessing about the individual building blocks and what they do, you inevitably will find it hard to scale up just mathematically. Just think about individual things you want to model, and if you want to have ten of those, then you essentially are taking cartesian products of ten things. That makes it really complicated, then to do any kind of synthesis or design in that high dimensional space is really hard. So the right way to do this is to think about the individuals in a clever way, so that at the higher level, when you look at lots and lots of them abstractly, you can think of them in some low dimensional space.
Speaker A: So what does that involve for the individual? You have to try to make the way they see the world as local as possible. And the other thing, do you just have to make them robust to collisions? Like you said with the ants, if something fails, the whole swarm doesn't fail.
Speaker B: Right. I think as engineers, we do this. I mean, think about we build planes or we build iPhones, and we know that. Bye. Taking individual components, well engineered components with well specified interfaces that behave in a predictable way, you can build complex systems. So that's ingrained, I would claim, in most engineers thinking, and it's true for computer scientists as well. I think what's different here is that you want the individuals to be robust in some sense, as we do in these other settings, but you also want some degree of resiliency for the population, and so you really want them to be able to reestablish communication with their neighbors. You want them to rethink their strategy for group behavior. You want them to reorganize. And that's where I think a lot of the challenges lie.
Speaker A: So just at a high level, what does it take for a bunch of, what should we call them, flying robots to create a formation just for people who are not familiar with robotics in general, how much information is needed? How do you even make it happen without a centralized controller?
Speaker B: So, I mean, there are a couple of different ways of looking at this. If you are a purist, you think of it as a way of recreating what nature does. So nature forms groups for several reasons, but mostly it's because of this instinct that organisms have of preserving their colonies, their population, which means what? You need shelter, you need food, you need to procreate, and that's basically it. So the kinds of interactions you see are all organic, they're all local, and the only information that they share, and mostly it's indirectly, is to, again, preserve the herd or the flock or the swarm, and either by looking for new sources of food or looking for new shelters. Right, right. As engineers, when we build swarms, we have a mission. And when you think of a mission and it involves mobility, most often it's described in some kind of a global coordinate system. As a human, as an operator, as a commander, or as a collaborator. I have my coordinate system, and I want the robots to be consistent with that. So I might think of it slightly differently. I might want the robots to recognize that coordinate system, which means not only do they have to think locally in terms of who their immediate neighbors are, but they have to be cognizant of, of what the global environment looks like. So if I go, if I say, surround this building and protect this from intruders, well, they're immediately in a building centered coordinate system, and I have to tell them where the building is.
Speaker A: And they're globally collaborating on the map of that building. They're maintaining some kind of global, not just in the frame of the building, but there's information that's ultimately being built up explicitly, as opposed to kind of implicitly like nature might.
Speaker B: Correct, correct. So in some sense, nature is very, very sophisticated, but the tasks that nature solves or needs to solve are very different from the kind of engineered tasks, artificial tasks that we are forced to address. And again, there's nothing preventing us from solving these other problems. But ultimately it's about impact. You want these swarms to do something useful, and so you're kind of driven into this very unnatural, if you will. Unnatural meaning, not like how nature does setting.
Speaker A: And it's probably a little bit more expensive to do it the way nature does because nature is less sensitive to the loss of the individual. And cost wise in robotics, I think you're more sensitive to losing individuals.
Speaker B: I think that's true. Although if you look at the price to performance ratio of robotic components, it's coming down dramatically. It continues to come down. So I think we're asymptotically approaching the point where we would get. Yeah, the cost of individuals would really become insignificant.
Speaker A: So let's step back at a high level view. The impossible question of what kind of, as an overview, what kind of autonomous flying vehicles are there in general, I.
Speaker B: Think the ones that receive a lot of notoriety are obviously the military vehicles. Military vehicles are controlled by a base station, but have a lot of human supervision, but have limited autonomy, which is the ability to go from point a to point b. And even the more sophisticated vehicles can do autonomous takeoff and landing.
Speaker A: And those usually have wings, and they're heavy.
Speaker B: Usually they're wings. But there's nothing preventing us from doing this for helicopters as well. I mean, there are many military organizations that have autonomous helicopters in the same vein. And by the way, you look at autopilots and airplanes, and it's actually very similar. In fact, one interesting question we can ask is if you look at all the air safety violations, all the crashes that occurred, would they have happened if the plane were truly autonomous? And I think you'll find that in many of the cases because of pilot error, we make silly decisions. And so in some sense, even in air traffic, commercial air traffic, there's a lot of applications, although we only see autonomy being enabled at very high altitudes when, when the plane is on autopilot.
Speaker A: There'S still a role for the human. And that kind of autonomy is you're kind of implying, I don't know what the right word is, but it's a little dumb, dumber than it could be, right?
Speaker B: So in the lab, of course, we can afford to be a lot more aggressive. And the question we try to ask is, can we make robots that will be able to make decisions without any kind of external infrastructure? So what does that mean? So the most common piece of infrastructure that airplanes use today is GPS. GPS is also the most brittle form of information. If you have driven in a city, tried to use GPS navigation in tall buildings, you immediately lose GPS. And so that's not a very sophisticated way of building autonomy. I think the second piece of infrastructure they rely on is communications. Again, it's very easy to jam communications. In fact, if you use Wifi, you know that Wi Fi signals drop out, cell signals drop out. So to rely on something like that is nothing is not good. The third form of infrastructure we use, and I hate to call it infrastructure, but it is that in the sense of robots, it's people. So you could rely on somebody to pilot you, right. And so the question you want to ask is if there are no pilots, there's no communications with any base station, if there's no knowledge of position, and if there's no a priori map, a priori knowledge of what the environment looks like, a priori model of what might happen in the future, can robots navigate? So that is true autonomy.
Speaker A: So that's true autonomy. And we're talking about, you mentioned, like, military application of drones. Okay, so what else is there? You talk about agile autonomous flying robots, aerial robots. So that's a different kind of, it's not winged, it's not big, at least it's small.
Speaker B: So I use the word agility mostly. Or at least we're motivated to do agile robots, mostly because robots can operate and should be operating in constrained environments. And if you want to operate the way a global hawk operates, I mean, the kinds of conditions in which you operate are very, very restrictive. If you go on to go inside a building, for example, for search and rescue, or to locate an active shooter, or you want to navigate under the canopy in an orchard, to look at health of plants, or to look for, to count fruits, to measure the tree trunks. These are things we do, by the way.
Speaker A: Yeah, some cool agriculture stuff you've shown in the past. It's really awesome.
Speaker B: So in those kinds of settings, you do need that agility. Agility does not necessarily mean you break records for the 100 meters dash. What it really means is you see the unexpected and you're able to maneuver in a safe way and in a way that gets you the most information about the thing you're trying to do.
Speaker A: By the way, you may be the only person who in a TED talk has used a math equation, which is amazing. People should go see one of your TED talk.
Speaker B: Actually, it's very interesting because the TeD curator, Chris Anderson, told me, you can't show math. And I thought about it, but that's who I am, that's our work. And so I felt compelled to give the audience a taste for at least some math.
Speaker A: So on that point, simply, what does it take to make a thing with four motors fly? A quadcopter, one of these little flying robots. How hard is it to make it fly? How do you coordinate for motors? How do you convert those motors into actual movement?
Speaker B: So, this is an interesting question. We've been trying to do this since 2000. It is a commentary on the sensors that were available back then, the computers that were available back then, and a number of things happened between 2000 and 2007. One is the advances in computing, which is so we all know about Moore's law, but I think 2007 was a tipping point. The year of the iPhone, the year of the cloud. Lots of things happened in 2007, but going back even further, inertial measurement units as a sensor really matured. Again, lots of reasons for that. Certainly there's a lot of federal funding, particularly DARPA and the US, but they didn't anticipate this boom in Imus. But if you look subsequently, what happened is that every car manufacturer had to put an airbag in, which meant you had to have an accelerometer on board that drove down the price to performance ratio.
Speaker A: I should know this. That's very interesting. That's very interesting connection there.
Speaker B: And that's why research is very, it's very hard to predict the outcomes. And again, the federal government spent a ton of money on things that they thought were useful for resonators, but it ended up enabling these small UAV's, which is great, because I could have never raised that much money and told, you know, sold this project, hey, we want to build these small UAV's. Can you, can you actually fund the development of low cost IMuse?
Speaker A: So why do you need an IMU on it?
Speaker B: I'll come back to that. So, in 2007, 2008, we were able to build these. And then the question you're asking was a good one, how do you coordinate the motors to develop this? But over the last ten years, everything is commoditized. A high school kid today can pick up a raspberry PI kit and build this. All the low level functionality is all automated, but basically, at some level, you have to drive the motors at the right rpms, the right velocity in order to generate the right amount of thrust, in order to position it and orient it in a way that you need to in order to fly. The feedback that you get is from onboard sensors, and the IMU is an important part of it. The IMU tells you what the acceleration is as well as what the angular velocity is, and those are important pieces of information. In addition to that, you need some kind of local position or velocity information. For example, when we walk, we implicitly have this information because we kind of know what our stride length is. We also are looking at images, fly past our retina, if you will, and so we can estimate velocity. We also have accelerometers in our head, and we're able to integrate all these pieces of information to determine where we are as we walk. And so robots have to do something very similar. You need an IMU, you need some kind of a camera or other sensor that's measuring velocity, and then you need some kind of a global reference frame if you really want to think about doing something in a world coordinate system. And so how do you estimate your position with respect to that global reference frame? That's important as well.
Speaker A: So coordinating the rpms of the four motors is what allows you to, first of all, fly and hover, and then you can change the orientation and the velocity and so on.
Speaker B: Exactly, exactly.
Speaker A: Just a bunch of degrees of freedom that you're playing with.
Speaker B: There's six degrees of freedom, but you only have four inputs, four motors, and it turns out to be a remarkably versatile configuration. You think at first, well, I only have four motors. How do I go sideways? But it's not too hard to say. Well, if I tilt myself, I can go sideways and then you have four motors pointing up. How do I rotate in place about a vertical axis? Well, you rotate them at different speeds and that generates reaction moments and that allows you to turn. So it's actually a pretty, it's an optimal configuration from an engineer standpoint. It's very simple, very cleverly done and very versatile.
Speaker A: So if you could step back to a time. So I've always known flying robots. As to me, it was natural that a quadcopter should fly. But when you first started working with it, how surprised are you that you can make do so much with the four motors? How surprising is that you can make this thing fly? First of all, you can make it hover, then you can add control to it.
Speaker B: Firstly, this is not, the four motor configuration is not ours. It has at least a hundred year history.
Speaker A: Oh, it does.
Speaker B: Various people. Various people try to get quadrotors to fly without much success. As I said, we've been working on this since 2000. Our first designs were, well, this is way too complicated. Why not we try to get an omnidirectional flying robot. So our early designs, we had eight rotors. And so these eight rotors were arranged uniformly on a sphere, if you will. So you can imagine a symmetric configuration and so you should be able to fly anywhere. But the real challenge we had is the strength to weight ratio is not enough. And of course, we didn't have the sensors and so on. So everybody knew, or at least the people who worked with rotorcrafts knew, four rotors will get it done. So that was not our idea, but it took a while before we could actually do the onboard sensing and the computation that was needed for the kinds of agile maneuvering that we wanted to do in our little aerial robots. And that only happened between 2007 and 2009 in our lab.
Speaker A: Yeah. And you have to send the signal maybe 100 times a second. So the compute there, everything has to come down in price. And what are the steps of getting from point a to point b? So we just talked about like local control. But if all the kind of cool dancing in the air that I've seen you show, how do you make it happen? Make a trajectory, first of all. Okay, figure out a trajectory. So plan a trajectory. And then how do you make that trajectory happen?
Speaker B: Yeah, I think planning is a very fundamental problem in robotics. I think ten years ago it was an esoteric thing, but today, with self driving cars, everybody can understand this basic idea that a car sees a whole bunch of things. And it has to keep a lane or maybe make a right turn or switch lanes. It has to plan a trajectory, it has to be safe, it has to be efficient. So everybody's familiar with that. That's kind of the first step that you have to think about when you say autonomy. And so for us, it's about finding smooth motions, motions that are safe. So we think about these two things. One is optimality, one is safety. Clearly, you cannot compromise safety, so you're looking for safe, optimal motions. The other thing you have to think about is, can you actually compute a reasonable trajectory in a small amount of time? Cause you have a time budget. So the optimal becomes suboptimal. But in our lab, we focus on synthesizing smooth trajectory that satisfy all the constraints. In other words, don't violate any safety constraints and is as efficient as possible. And when I say efficient, it could mean I want to get from point a to point b as quickly as possible, or I want to get to it as gracefully as possible, or I want to consume as little energy as.
Speaker A: Possible, but always staying within the safety.
Speaker B: Constraints, but yes, always finding a safe trajectory.
Speaker A: So there's a lot of excitement and progress in the field of machine learning and reinforcement learning and the neural network variant of that with deep reinforcement learning. Do you see a role of machine learning in. So, a lot of the success with flying robots did not rely on machine learning, except for maybe a little bit of the perception, the computer vision side, on the control side, and the planning. Do you see there's a role in the future for machine learning?
Speaker B: So let me disagree a little bit with you. I think we never perhaps called out in my work, called out learning. But even this very simple idea of being able to fly through a constrained space, the first time you try it, you'll invariably, you might get it wrong. If the task is challenging and the reason is to get it perfectly right, you have to model everything in the environment. And flying is notoriously hard to model. There are aerodynamic effects that we constantly discovered. Even just before I was talking to you, I was talking to a student about how blades flap when they fly, and that ends up changing how a rotorcraft is accelerated in the angular direction.
Speaker A: This is like micro flaps or something.
Speaker B: It's not micro flaps. We assume that each blade is rigid, but actually it flaps a little bit. It bends.
Speaker A: Interesting. Yeah.
Speaker B: And so the models rely on the fact, on an assumption that they're actually rigid, but that's not true. If you're flying really quickly, these effects become significant. If you're flying close to the ground, you get pushed off by the ground, right? Something which every pilot knows when he tries to land or she tries to land. This is called a ground effect. Something very few pilots think about is what happens when you go close to a ceiling? Well, you get sucked into a ceiling. There are very few aircraft that fly close to any kind of ceiling. Likewise, when you go close to a wall, there are these wall effects. And if you've gone on a train and you pass another train that's traveling in the opposite direction, you feel the buffeting. And so these kinds of microclimates affect our UAV's significantly, and they're impossible to model, essentially. I wouldn't say they're impossible to model, but the level of sophistication you would need in the model and the software would be tremendous. Plus, to get everything right would be awfully tedious. So the way we do this is over time, we figure out how to adapt to these conditions. So early on, we used a form of learning that we call iterative learning. So this idea, if you want to perform a task, there are a few things that you need to change and iterate over few parameters that over time you can figure out. So I could call it policy gradient reinforcement learning, but actually it was just iterative learning. And so this was there way back. I think what's interesting is if you look at autonomous vehicles today, learning occurs, could occur in two pieces. One is perception, understanding the world. Second is action taking actions. Everything that I've seen that is successful is on the perception side of things. So in computer vision, we've made amazing strides in the last ten years. So recognizing objects, actually detecting objects, classifying them and tagging them, in some sense annotating them, this is all done through machine learning on the action side. On the other hand, I don't know if any examples where there are fielded systems where we actually learn the right.
Speaker A: Behavior outside of single demonstration of successfully.
Speaker B: In the laboratory, this is the holy grail. Can you do end to end learning? Can you go from pixels to motor currents? This is really, really hard. And I think if you go forward, the right way to think about these things is data driven approaches, learning based approaches in concert with model based approaches, which is the traditional way of doing things. So I think there's a piece, there's a role for each of these methodologies.
Speaker A: So what do you think? Just jumping out on topics. Since you mentioned autonomous vehicles, what do you think are the limits on the perception side? So I've talked to Elon Musk. And there on the perception side, they're using primarily computer vision to perceive the environment in your work with, because you work with the real world a lot in the physical world. What are the limits of computer vision? Do you think we can solve autonomous vehicles? Focus on the perception side, focusing on vision alone and machine learning.
Speaker B: So we also have a spinoff company, Exxon Technologies, that works underground in mines. So you go into mines, they're dark, they're dirty, you fly in a dirty area, there's stuff you kick up by the propellers, the downwash kicks up dust. I challenge you to get a computer vision algorithm to work there. So we use lidars in that setting indoors and even outdoors when we fly through fields. I think there's a lot of potential for just solving the problem using computer vision alone. But I think the bigger question is, can you actually solve, or can you actually identify all the corner cases using a single sensing modality and using learning alone?
Speaker A: What's your intuition there?
Speaker B: So, look, if you have a corner case and your algorithm doesn't work, your instinct is to go get data about the corner case and patch it up, learn how to deal with that corner case. But at some point, this is going to saturate. This approach is not viable. So today, computer vision algorithms can detect 90% of the objects, or can detect objects 90% of the time, classify them 90% of the time. Cats on the Internet, I probably can do 95%. But to get from 90% to 99%, you need a lot more data. And then I tell you, well, that's not enough, because I have a safety critical application. I want to go from 99% to 99.9%. That's even more data. So I think if you look at wanting accuracy on the x axis and look at the amount of data on the y axis, I believe that curve is an exponential curve.
Speaker A: Wow. Okay. It's even hard if it's linear.
Speaker B: It's hard if it's linear, totally. But I think it's exponential. The other thing you have to think about is that this process is a very, very power hungry process to run data farms or servers.
Speaker A: Power. Do you mean literally power?
Speaker B: Literally power. Literally power. So in 2014, five years ago, and I don't have more recent data, 2% of us electricity consumption was from data farms. So we think about this as an information science and information processing problem. Actually, it is an energy processing problem. And so unless we figure out better ways of doing this, I don't think this is viable.
Speaker A: So talking about driving, which is a safety critical application and some aspect of flight. Is safety critical? Maybe. Philosophical question, maybe an engineering one. What problem do you think is harder to solve? Autonomous driving or autonomous flight?
Speaker B: That's a really interesting question. I think autonomous flight has several advantages that autonomous driving doesn't have. So, look, if I want to go from point a to point b, I have a very, very safe trajectory. Go vertically up to a maximum altitude, fly horizontally to just about the destination, and then come down vertically. This is pre programmed. The equivalent of that is very hard to find in a self driving car world, because you're on the ground, you're in a two dimensional surface, and the trajectories on the two dimensional surface are more likely to encounter obstacles. I mean, this in an intuitive sense, but mathematically true, that's mathematically as well, that's true.
Speaker A: There's other option on the 2G space of platooning or because there's so many obstacles, you can connect with those obstacles and all these things, but those exist.
Speaker B: In the three dimensional space as well, so they do.
Speaker A: So the question also implies how difficult are obstacles in the three dimensional space in flight?
Speaker B: So that's the downside, I think, in three dimensional space, you're modeling three dimensional world, not just because you want to avoid it, but you want to reason about it and you want to work in that three dimensional environment, and that's significantly harder. So that's one disadvantage. I think the second disadvantage is, of course, anytime you fly, you have to put up with the peculiarities of aerodynamics, and there are complicated environments. How do you negotiate that? So that's always a problem.
Speaker A: Do you see a time in the future where there is, you mentioned there's agriculture applications. There's a lot of applications of flying robots. But do you see a time in the future where there is a tens of thousands or maybe hundreds of thousands of delivery drones that fill the sky? A delivery flying robots.
Speaker B: I think there's a lot of potential for the last mile delivery. And so, in crowded cities, I don't know. If you go to a place like Hong Kong, just crossing the river can take half an hour, and while a drone can just do it in five minutes at most, I think you look at delivery of supplies to remote villages. I work with a nonprofit called weave Robotics. So they work in the peruvian Amazon, where the only highways are rivers. And to get from point a to point b may take 5 hours, while with a drone, you can get there in 30 minutes. So just delivering drugs, retrieving samples for testing vaccines, I think there's huge potential here so I think the challenges are not technological. The challenges are economical. The one thing I'll tell you that nobody thinks about is the fact that we've not made huge strides in battery technology. Yes, it's true. Batteries are becoming less expensive because we have these mega factories that are coming up, but they're all based on lithium based technologies. And if you look at the energy density and the power density, those are two fundamentally limiting numbers. So, power density is important because for a uav to take off vertically into the air, which most drones do, they don't have a Runway. You consume roughly 200 watts per kilo. At the small size, that's a lot. Right? In contrast, the human brain consumes less than 80 watts, the whole of the human brain. So just imagine just lifting yourself into the air is like two or three light bulbs, which makes no sense to me.
Speaker A: Yeah. So you're going to have to, at scale, solve the energy problem, then charging the batteries, storing the energy, and so on.
Speaker B: And then the storage is the second problem. But storage limits the range. But, you know, you have to remember that you have to burn a lot of it per given time. So the burning is another problem, which is the power question.
Speaker A: Yes. And do you think, just your intuition, there are breakthroughs in batteries on the horizon? How hard is that problem?
Speaker B: Look, there are a lot of companies that are promising flying cars that are autonomous and that are clean. I think they're over promising. The autonomy piece is doable. The clean piece, I don't think so. There's another company that I work with called Jataptra. They make small jet engines, and they can get up to 50 miles an hour very easily and lift 50 kilos. But they're jet engines. They're efficient. They're a little louder than electric vehicles, but they can build flying cars.
Speaker A: So your sense is that there's a lot of pieces that have come together. So, on this crazy question, if you look at companies like Kitty Hawk working on electric. So the clean. Talking to Sebastian thruin, right, it's a. It's a crazy dream, you know, but you work with flight a lot. You've mentioned before that, man, flights or carrying a human body is very difficult to do. So how crazy is flying cars? Do you think? There'll be a day when we have vertical takeoff and landing vehicles that are sufficiently affordable that we're going to see a huge amount of them, and they would look like something like we dream of when we think about flying cars.
Speaker B: Yeah. Like the Jetsons.
Speaker A: The Jetsons, yeah.
Speaker B: So, look, there are a lot of smart people working on this, and you never say something is not possible when you have people like Sebastian Tron working on it. So I totally think it's viable. I question again, the electric piece. The electric piece, and again, for short distances, you can do it. And there's no reason to suggest that these are all just have to be rotorcrafts. You take off vertically, but then you morph into a forward flight. I think there are a lot of interesting designs. The question to me is, are these economically viable? And if you agree to do this with fossil fuels, the instinct immediately becomes viable.
Speaker A: That's a real challenge. Do you think it's possible for robots and humans to collaborate successfully on tasks? So a lot of robotics folks that I talk to and work with, I mean, humans just add a giant mess to the picture, so it's best to remove them from consideration when solving specific tasks. It's very difficult to model. There's just a source of uncertainty in your work with these agile flying robots. Do you think there's a role for collaboration with humans, or is it best to model tasks in a way that doesn't have a human in the picture?
Speaker B: Well, I don't think we should ever think about robots without human in the picture. Ultimately, robots are there because we want them to solve problems for humans, but there's no general solution to this problem. I think if you look at human interaction and how humans interact with robots, we think of these in three different ways. One is the human commanding the robot. The second is the human collaborating with the robot. So, for example, we work on how a robot can actually pick up things with a human and carry things. That's like true collaboration. And third, we think about humans as bystanders, self driving cars. What's the human's role? And how do self driving cars acknowledge the presence of humans? So I think all of these things are different scenarios. It depends on what kind of humans, what kind of task. And I think it's very difficult to say that there's a general theory that we all have for this, but at the same time, it's also silly to say that we should think about robots independent of humans. So to me, human robot interaction is almost a mandatory aspect of everything we do.
Speaker A: Yes, but situation degree. So your thoughts? If you jump to autonomous vehicles, for example, there's a big debate between what's called level two and level four. So semi autonomous and autonomous vehicles. And so the Tesla approach currently at least has a lot of collaboration between human and machine. So the human is supposed to actively supervise the operation of the robot. Part of the safety definition of how safe a robot is in that case is how effective is the human in monitoring it, do you think? That's ultimately not a good approach and sort of having a human in the picture, not as a bystander or part of the infrastructure, but really as part of what's required to make the system safe.
Speaker B: This is harder than it sounds, I think. You know, if you. I mean, I'm sure you've driven before in highways and so on. It's. It's really very hard to have to relinquish control to a machine and then take over when needed. So I think Tesla's approach is interesting because it allows you to periodically establish some kind of contact with the car. Toyota, on the other hand, is thinking about shared autonomy, or collaborative autonomy as a paradigm, if I may argue. These are very, very simple ways of human robot collaboration because the task is pretty boring. You sit in a vehicle, you go from point a to point b. I think the more interesting thing to me is, for example, search and rescue. I've got a human first responder, robot first responders. I got to do something. It's important. I have to do it in two minutes. The building is burning, there's been an explosion, it's collapsed. How do I do it? I think to me, those are the interesting things where it's very, very unstructured and what's the role of the human? What's the role of the robot? Clearly, there's lots of interesting challenges, and as a field, I think we're going to make a lot of progress in this area.
Speaker A: Yeah, it's an exciting form of collaboration. You're right. In autonomous driving, the main enemy is just boredom of the human, as opposed to in rescue operations. It's literally life and death, and the collaboration enables the effective completion of the mission.
Speaker B: So it's exciting in some sense. We're also doing this. You think about the human driving a car, and almost invariably the human's trying to estimate the state of the car. They estimate the state of the environment and so on. But what if the car were to estimate the state of the human? So, for example, I'm sure you have a smartphone, and the smartphone tries to figure out what you're doing and send you reminders and oftentimes telling you to drive to a certain place, although you have no intention of going there, because it thinks that that's where you should be because of some Gmail calendar entry or something like that. And it's trying to constantly figure out who you are, what you're doing. If a car were to do that, maybe that would make the driver safer, because the car is trying to figure out, is the driver paying attention, looking at his or her eyes, looking at circadian movements? So I think the potential is there. But from the reverse side, it's nothing. Robot modeling, but it's human modeling.
Speaker A: It's more in the human right.
Speaker B: And I think the robots can do a very good job of modeling humans. If you really think about the framework that you have, a human sitting in a cockpit surrounded by sensors, all staring at him, in addition to be staring outside, but also staring at him, I think there's a real synergy there.
Speaker A: Yeah, I love that problem because it's a new 21st century form of psychology, actually AI enabled psychology. A lot of people have Sci-Fi inspired fears of walking robots, like those from Boston dynamics. If you just look at shows on Netflix and so on, or flying robots like those you work with, how would you. How do you think about those fears? How would you alleviate those fears? Do you have inklings, echoes of those same concerns?
Speaker B: You know, anytime we develop a technology meaning to have positive impact in the world, there's always the worry that somebody could subvert those technologies and use it in an adversarial setting. And robotics is no exception. I think it's very easy to weaponize robots. I think we talk about swarms. One thing I worry a lot about is for us to get swarms to work and do something reliably is really hard. But suppose I have this. This challenge of trying to destroy something, and I have a swarm of robots where only one out of the swarm needs to get to its destination, so that suddenly becomes a lot more doable. And so I worry about this general idea of using autonomy with lots and lots of agents. I mean, having said that, look, a lot of this technology is not very mature. My favorite saying is that if somebody had to develop this technology, wouldn't you rather the good guys do it? So the good guys have a good understanding of the technology, so they can figure out how this technology is being used in a bad way or could be used in a bad way and try to defend against it. So we think a lot about that. So we have a. We're doing research on how to defend against swarms, for example. That's interesting. There's, in fact, a report by the National Academies on counter UA's technologies. This is a real threat, but we're also thinking about how to defend against this and knowing how swarms work. Knowing how autonomy works is, I think, very important.
Speaker A: So it's not just politicians. Do you think engineers have a role in this discussion?
Speaker B: Absolutely. I think the days where politicians can be agnostic to technology are gone. I think every politician needs to be literate in technology, and I often say technology is the new liberal art. Understanding how technology will change your life, I think, is important, and every human being needs to understand that.
Speaker A: And maybe we can elect some engineers to office as well. On the other side, what are the biggest open problems in robotics, in your view? You said we're in the early days in some sense. What are the problems we would like to solve in robotics?
Speaker B: I think there are lots of problems. Right. But I would phrase it in the following way. If you look at the robots we're building, they're still very much tailored towards doing specific tasks in specific settings. I think the question of how do you get them to operate in much broader settings where things can change in unstructured environments is up in the air. So, you know, think of a self driving cars. Today. We can build a self driving car in a parking lot. We can do level five autonomy in a parking lot. But can you do level five autonomy in the streets of Napoli in Italy or Mumbai in India? No. In some sense, when we think about robotics, we have to think about where they're functioning, what kind of environment, what kind of a task. We have no understanding of how to put both those things together.
Speaker A: So we're in the very early days of applying it to the physical world, and I was just in Naples, actually. And there's levels of difficulty and complexity depending on which area you're applying into.
Speaker B: I think so. And we don't have a systematic way of understanding that. Everybody says just because a computer can now beat a human at any board game, we certainly know something about intelligence. That's not true. A computer board game is very, very structured. It is the equivalent of working in a Henry Ford factory where things, parts come, you assemble, move on. It's a very, very, very structured setting. That's the easiest thing, and we know how to do that.
Speaker A: So you've done a lot of incredible work at the UPenn University of Pennsylvania grass lab. You're now dean of engineering at UPenn. What advice do you have for a new bright eyed undergrad interested in robotics or AI or engineering?
Speaker B: Well, I think there's really three things. One is. One is you have to get used to the idea that the world will not be the same in five years or four years whenever you graduate, which is really hard to do. So this thing about predicting the future, every one of us needs to be trying to predict the future always. Not because you'll be any good at it, but by thinking about it, I think you sharpen your senses and you become smarter. So that's number one. Number two, and it's a corollary of the first piece, which is you really don't know what's going to be important. So this idea that I'm going to specialize in something which will allow me to go in a particular direction, it may be interesting, but it's important also to have this breadth. So you have this jumping off point. I think the third thing, and this is where I think Penn excels. I mean, we teach engineering, but it's always in the context of the liberal arts. It's always in the context of society. As engineers, we cannot afford to lose sight of that. So I think that's important. But I think one thing that people underestimate when they do robotics is the importance of mathematical foundations, the importance of representations. Not everything can just be solved by looking for RoS packages on the Internet or to find a deep neural network that works. I think the representation question is key, even to machine learning, where if you ever hope to achieve or get to explainable AI, somehow there need to be representations that you can understand.
Speaker A: So if you want to do robotics, you should also do mathematics. And you said liberal arts, a little literature. If you want to build a robot, you should be reading Dostoevsky. I agree with that.
Speaker B: Very good.
Speaker A: Vijay, thank you so much for talking today. It was an honor.
Speaker B: Thank you. A very exciting conversation. Thank you.
